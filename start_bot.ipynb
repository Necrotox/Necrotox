{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Necrotox/Necrotox/blob/main/start_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8-zPSBcWmQl",
        "outputId": "ccc6dffe-8716-4e7a-c0ae-895eddd87713"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu \\\n",
        "  torch==2.7.1+cpu > /dev/null 2>&1\n",
        "\n",
        "!pip install -q --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu \\\n",
        "  torchvision==0.22.0+cpu > /dev/null 2>&1\n",
        "!pip install -q --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu \\\n",
        "  torchaudio==2.7.1+cpu > /dev/null 2>&1\n",
        "\n",
        "!pip install -q --no-warn-script-location \\\n",
        "  pytorch-lightning==2.5.2 pytorch-forecasting==1.4.0 > /dev/null 2>&1\n",
        "\n",
        "!pip install -q tinkoff-investments dill telebot --upgrade mplfinance > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "g3YVzfjxJVAK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1mri67_vog8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e69ab8-9e41-4ee1-aa84-16593038f96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные 1 успешно загружены.\n",
            "Данные 2 успешно загружены.\n",
            "Данные 3 успешно загружены.\n",
            "Загрузка Моделей Память: 3267.93 МБ\n",
            "Модель MiniBatchKMeans успешно загруженна Память: 3267.93 МБ\n",
            "Скалер успешно загружен Память: 3267.93 МБ\n",
            "Параметры для тикетов загруженны Память: 3267.97 МБ\n",
            "Параметры для тикетов с фазами загруженны Память: 3268.05 МБ\n",
            "[INIT] Активных тикеров: 1\n",
            "\n",
            "Обработка тикера MRKV (1/1)\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import contextlib\n",
        "import functools\n",
        "import statsmodels.api as sm\n",
        "import inspect\n",
        "import zipfile\n",
        "import pickle\n",
        "import json\n",
        "import gc\n",
        "import re\n",
        "import io\n",
        "import time\n",
        "import typing\n",
        "import logging\n",
        "import pytz\n",
        "import gzip\n",
        "import dill\n",
        "import lzma\n",
        "import pandas as pd\n",
        "import nest_asyncio\n",
        "import hashlib\n",
        "import random\n",
        "import joblib\n",
        "import math\n",
        "import psutil\n",
        "\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spla\n",
        "\n",
        "\n",
        "from numba import jit, njit\n",
        "from grpc import StatusCode\n",
        "from grpc.aio import AioRpcError\n",
        "from dataclasses import dataclass\n",
        "from contextlib import redirect_stderr, redirect_stdout\n",
        "from collections.abc import Sequence\n",
        "from tinkoff.invest import AsyncClient, CandleInterval\n",
        "from tinkoff.invest.exceptions import RequestError\n",
        "from tinkoff.invest import (\n",
        "    AsyncClient,\n",
        "    #CandleInstrument,\n",
        "    MarketDataRequest,\n",
        "    #SubscribeCandlesRequest,\n",
        "    #SubscriptionAction,\n",
        "    SubscriptionInterval,\n",
        ")\n",
        "from tinkoff.invest.schemas import (\n",
        "    SubscribeCandlesRequest,\n",
        "    SubscriptionAction,\n",
        "    CandleInstrument,\n",
        ")\n",
        "from tinkoff.invest.market_data_stream.market_data_stream_manager import MarketDataRequest\n",
        "from tinkoff.invest.schemas import Candle\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "from scipy.stats import norm\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from collections import defaultdict, deque\n",
        "from multiprocessing import Process\n",
        "from multiprocessing import Process\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "import mplfinance as mpf\n",
        "import telebot\n",
        "import datetime\n",
        "import matplotlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats import norm, pearsonr\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import BaseCrossValidator\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, PowerTransformer, QuantileTransformer, RobustScaler, StandardScaler\n",
        "\n",
        "from sklearn.neighbors import BallTree\n",
        "\n",
        "from bisect import bisect_left\n",
        "\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data.encoders import EncoderNormalizer\n",
        "from pytorch_forecasting.metrics import Metric, QuantileLoss\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import RichProgressBar, TQDMProgressBar\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from torchmetrics import MeanSquaredError\n",
        "from torchmetrics.functional import mean_squared_error as torchmetrics_mse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from typing import Any, Dict, Iterable, Iterator, List, Literal, Mapping, Optional, Tuple\n",
        "import os, gc, warnings, typing as tp\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "matplotlib.use(\"agg\")\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import psutil\n",
        "import os.path\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Настройка логирования\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "TOKEN = 't.bWjxPlU6vz77qoqS754OKy0QorLDaZP-CE091dhGl56v7GHrqgF-mQAdWaeRg2kDRJmmxzvaaOwKUTxW6dnOKg'\n",
        "\n",
        "TICKERS1 =  ['RAGR', 'MGNT', 'MSTT', 'VRSB', 'PRFN', 'MTLR', 'LIFE', 'UPRO', 'GECO',\n",
        "       'BANE', 'MTLRP', 'GEMC', 'NVTK', 'TRNFP', 'TRMK', 'LSNGP', 'OBNEP',\n",
        "       'SNGSP', 'UWGN', 'MRKP', 'KZOSP', 'YDEX', 'NLMK', 'IRKT', 'CNTLP',\n",
        "       'LENT', 'KLSB', 'SELG', 'NMTP', 'UNAC', 'VKCO', 'MRKU', 'UGLD', 'NTZL',\n",
        "       'BANEP', 'FLOT', 'TGKJ', 'MAGN', 'ROSN', 'TGKB', 'AFKS', 'TTLK', 'HEAD',\n",
        "       'KZIZ', 'NOMP', 'OKEY', 'ABRD', 'NSVZ', 'MRKV', 'LSNG', 'MRKC', 'SVAV',\n",
        "       'ETLN', 'MRKZ', 'LNZL', 'CNRU', 'BSPB', 'RBCM', 'PMSB', 'LSRG', 'RNFT',\n",
        "       'MOEX', 'GTRK', 'NKHP', 'LKOH', 'SBERP', 'SBER', 'PLZL', 'RENI', 'MDMG',\n",
        "       'AFLT', 'FESH', 'OBNE', 'X5', 'MGTSP', 'DVEC', 'KROT', 'TATNP', 'OZPH',\n",
        "       'TGKN', 'TATN', 'PMSBP', 'TGKBP', 'SPBE', 'LNZLP', 'CHMK', 'KZIZP',\n",
        "       'RKKE', 'FRHC']\n",
        "\n",
        "TICKERS = ['MRKV']#, 'NOMP', 'OBNEP']\n",
        "\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/t_ml/data/'\n",
        "path_to_save = '/content/drive/MyDrive/t_ml/data/'\n",
        "CANDLE_INTERVAL = CandleInterval.CANDLE_INTERVAL_15_MIN\n",
        "TIMEFRAME_MINUTES = 15\n",
        "HISTORY_DATA_POINTS = 5000\n",
        "\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}open_price.txt', 'r') as f:\n",
        "        open_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}close_price.txt', 'r') as f:\n",
        "        close_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}high_price.txt', 'r') as f:\n",
        "        high_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}low_price.txt', 'r') as f:\n",
        "        low_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}volume.txt', 'r') as f:\n",
        "        volume = json.loads(f.read())\n",
        "\n",
        "    print(\"Данные 1 успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке данных: {e}\")\n",
        "    open_price, close_price, high_price, low_price, volume = {}, {}, {}, {}, {}\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}time_last_kline_start.txt', 'r') as f:\n",
        "        time_last_kline_start = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}time_last_kline_end.txt', 'r') as f:\n",
        "        time_last_kline_end = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}ma.txt', 'r') as f:\n",
        "        ma = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}open_trades.txt', 'r') as f:\n",
        "        open_trades = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}trading_data.txt', 'r') as f:\n",
        "        trading_data = json.loads(f.read())\n",
        "\n",
        "    print(\"Данные 2 успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке данных: {e}\")\n",
        "    time_last_kline_start, time_last_kline_end, ma, open_trades, trading_data = {}, {}, {}, {}, {}\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "\n",
        "    with open(f'{path_to_save}pmax.txt', 'r') as f:\n",
        "        pmax = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}signals.txt', 'r') as f:\n",
        "        signals = json.loads(f.read())\n",
        "\n",
        "    print(\"Данные 3 успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке данных: {e}\")\n",
        "    pmax, signals = {}, {}\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "print('Загрузка Моделей', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "\n",
        "try:\n",
        "    kmeans_global = joblib.load(f'{path_to_save}models/kmeans_global.pkl')\n",
        "    print('Модель MiniBatchKMeans успешно загруженна', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели MiniBatchKMeans: {e}\")\n",
        "    kmeans_global = joblib.load(f'{path_to_save}models/kmeans_global.pkl')\n",
        "    print('Модель MiniBatchKMeans загруженна со второй попытки', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    scaler_global = joblib.load(f'{path_to_save}models/scaler_global.pkl')\n",
        "    print('Скалер успешно загружен', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели MiniBatchKMeans: {e}\")\n",
        "    scaler_global = joblib.load(f'{path_to_save}models/scaler_global.pkl')\n",
        "    print('Скалер загружен со второй попытки', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "'''\n",
        "try:\n",
        "    with open(f'{path_to_save}/models/regression_model_general.dill', 'rb') as file:\n",
        "        regression_model = dill.load(file)\n",
        "        print('Модель выхода из сделки загруженна', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели регрессии: {e}\")\n",
        "    with open(f'{path_to_save}/models/regression_model_general.dill', 'rb') as file:\n",
        "        regression_model = dill.load(file)\n",
        "        print('Модель выхода из сделки загруженна с второйпопытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "try:\n",
        "    with open(f'{path_to_save}/models/global_model.dill', 'rb') as file:\n",
        "        classifier_model = dill.load(file)\n",
        "        print('Глобальная модель поиска входа для всех кластеров заргуженна',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели поиска входа для 0 кластера: {e}\")\n",
        "    with open(f'{path_to_save}/ful_tickers_params.txt', 'rb') as file:\n",
        "        classifier_model = dill.load(file)\n",
        "        print('Глобальная модель поиска входа для всех кластеров загруженна с второй попытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "'''\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}/ful_tickers_params_new.txt', 'r') as file:\n",
        "      ticker_params = json.load(file)\n",
        "      print('Параметры для тикетов загруженны',\n",
        "            f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке параметров тикетов: {e}\")\n",
        "    with open(f'{path_to_save}/ful_tickers_params_new.txt', 'r') as file:\n",
        "        ticker_params = json.load(file)\n",
        "        print('Параметры для тикетов загруженны со второй попытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    #transformers_path = f'{path_to_save}/models/neuros/'\n",
        "    #models_path = f'{path_to_save}/models/final_models/'\n",
        "\n",
        "    with open(f'{path_to_save}/models/final_cols.pkl', 'rb') as f:\n",
        "        final_cols = pickle.load(f)\n",
        "\n",
        "    with open(f'{path_to_save}/models/final_params.pkl', 'rb') as f:\n",
        "        final_params = pickle.load(f)\n",
        "\n",
        "    with open(f'{path_to_save}/models/best_methods.json', 'rb') as f:\n",
        "        methods = json.load(f)\n",
        "\n",
        "    with open(f'{path_to_save}close_preds.txt', 'r') as f:\n",
        "        close_preds = json.loads(f.read())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при определении пути на модели и трансформеры: {e}\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}/phase_ful_tickers_params.txt', 'r') as file:\n",
        "      phase_ticker_params = json.load(file)\n",
        "      print('Параметры для тикетов с фазами загруженны',\n",
        "            f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке параметров тикетов с фазами: {e}\")\n",
        "    with open(f'{path_to_save}/phase_ful_tickers_params.txt', 'r') as file:\n",
        "        phase_ticker_params = json.load(file)\n",
        "        print('Параметры для тикетов с фазами загруженны со второй попытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "\n",
        "def _whittaker_smooth(y: np.ndarray, lam: float = 50.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Whittaker–Eilers smoothing (penalized least squares, D2).\n",
        "    Линейный безфазовый фильтр, хорошо убирает шум, не смещая тренд.\n",
        "    \"\"\"\n",
        "    import scipy.sparse as sp\n",
        "    import scipy.sparse.linalg as spla\n",
        "\n",
        "    n = len(y)\n",
        "    if n <= 2:\n",
        "        return y.copy()\n",
        "\n",
        "    E = sp.eye(n, format=\"csc\")\n",
        "    # Вторая разность (D2): размер (n-2) x n\n",
        "    diagonals = [np.ones(n), -2*np.ones(n), np.ones(n)]\n",
        "    D2 = sp.diags(diagonals, [0, 1, 2], shape=(n-2, n), format=\"csc\")\n",
        "    coef = E + lam * (D2.T @ D2)\n",
        "    z = spla.spsolve(coef, y.astype(float))\n",
        "    return z\n",
        "\n",
        "def _rearrange_preserving_marginal(z_raw: np.ndarray, z_smooth: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Distribution-preserving smoothing via monotone rearrangement:\n",
        "    - сортируем исходный z_raw -> z_sorted,\n",
        "    - берём порядок (argsort) сглаженного z_smooth,\n",
        "    - раскладываем z_sorted по этому порядку.\n",
        "    В итоге: гладко по времени (за счёт порядка z_smooth), но эмпирическое\n",
        "    распределение строго совпадает с исходным (z_raw).\n",
        "    \"\"\"\n",
        "    if len(z_raw) == 0:\n",
        "        return z_raw\n",
        "    order = np.argsort(z_smooth)\n",
        "    z_sorted = np.sort(z_raw)\n",
        "    out = np.empty_like(z_raw)\n",
        "    out[order] = z_sorted\n",
        "    return out\n",
        "\n",
        "def calculate_smoothed_target_qnorm(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    batch_start: int = 0,\n",
        "    epsilon: float = 1e-6,\n",
        "    round_decimals: int = 1,\n",
        "\n",
        "    # базовая нормализация по окну (buy->sell)\n",
        "    tight_spread_thr: float = 1e-4,\n",
        "\n",
        "    # сглаживание в z-домене\n",
        "    smooth_method: Literal[\"gauss\", \"savgol\", \"whittaker\"] = \"gauss\",\n",
        "    gauss_sigma: float = 2.0,\n",
        "    savgol_window: int = 11,   # нечётное\n",
        "    savgol_poly: int = 3,\n",
        "    whittaker_lambda: float = 50.0,\n",
        "\n",
        "    # квантильная нормализация и глобальный маппинг\n",
        "    clip_z: float = 2.5,       # клип в z-подобной шкале перед [-1,1]\n",
        "    tanh_scale: float | None = None,\n",
        "\n",
        "    # джиттер перед ECDF\n",
        "    dequant_jitter: float = 1e-4,\n",
        "\n",
        "    # опция \"обязательно растянуть каждый батч\" (робастная эквализация по квантилям)\n",
        "    per_batch_equalize: bool = False,\n",
        "    per_batch_q: float = 0.01,  # напр. 1% и 99% -> [-1, 1]\n",
        "\n",
        "    random_state: int | None = 42,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Возвращает df с колонками:\n",
        "      - normalized_target ∈ [-1, 1] (единая глобальная шкала)\n",
        "      - batch (int64): идентификатор события (buy→sell)\n",
        "\n",
        "    Алгоритм:\n",
        "      1) Внутри каждого события: base(0..1) -> ECDF -> z_raw ~ N(0,1).\n",
        "      2) Сглаживаем (Gaussian/Savitzky–Golay/Whittaker) -> z_smooth.\n",
        "      3) Rearrangement: z_preserved = rearrange(z_raw, order-of z_smooth).\n",
        "         Это убирает шум, но полностью сохраняет исходное распределение.\n",
        "      4) Глобальная квантильная нормализация: приводим все батчи к общей\n",
        "         маргинальной функции Q_global(p).\n",
        "      5) Единая глобальная шкала (median/MAD), клип до [-clip_z, clip_z],\n",
        "         линейный маппинг в [-1, 1], опционально tanh.\n",
        "      6) (Опционально) per-batch эквализация по квантилям до [-1, 1].\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    df = df.copy()\n",
        "    df[\"normalized_target\"] = np.nan\n",
        "    df[\"batch\"] = np.nan\n",
        "    df[\"event_sell_time\"] = pd.to_datetime(df[\"event_sell_time\"], utc=True)\n",
        "\n",
        "    if savgol_window % 2 == 0:\n",
        "        savgol_window += 1\n",
        "    use_savgol = (savgol_window >= savgol_poly + 2)\n",
        "\n",
        "    all_indices: list[np.ndarray] = []\n",
        "    all_z_preserved: list[np.ndarray] = []\n",
        "    batch = batch_start\n",
        "\n",
        "    buy_rows = df.index[df[\"buy_signal\"] == True]\n",
        "    for start_i in buy_rows:\n",
        "        sell_time = df.at[start_i, \"event_sell_time\"]\n",
        "        if pd.isna(sell_time):\n",
        "            continue\n",
        "        sell_rows = df.index[df[\"time\"] == sell_time]\n",
        "        if len(sell_rows) == 0:\n",
        "            continue\n",
        "        end_i = sell_rows[0]\n",
        "\n",
        "        mask = (df.index >= start_i) & (df.index <= end_i)\n",
        "        idx = df.index[mask]\n",
        "        if idx.empty:\n",
        "            continue\n",
        "\n",
        "        high_s = df.loc[idx, \"high\"]\n",
        "        low_s  = df.loc[idx, \"low\"]\n",
        "\n",
        "        # Робастные полки только для базовой формы (0..1)\n",
        "        max_p = np.round(high_s.quantile(0.92), round_decimals)\n",
        "        min_p = np.round(low_s .quantile(0.08), round_decimals)\n",
        "        if max_p - min_p < tight_spread_thr:\n",
        "            max_p, min_p = float(high_s.max()), float(low_s.min())\n",
        "\n",
        "        use_profit_norm = (max_p - min_p) < tight_spread_thr\n",
        "\n",
        "        # 1) base 0..1\n",
        "        if not use_profit_norm:\n",
        "            base = (df.loc[idx, \"close\"] - min_p) / (max_p - min_p + 1e-12)\n",
        "        else:\n",
        "            buy_price = df.at[start_i, \"close\"]\n",
        "            max_prof = (high_s.max() - buy_price) / max(buy_price, 1e-12)\n",
        "            max_prof = max(max_prof, epsilon)\n",
        "            base = (df.loc[idx, \"close\"] - buy_price) / (buy_price * max_prof)\n",
        "            base = 0.5 + 0.5 * base\n",
        "\n",
        "        base = np.clip(base.to_numpy(float), epsilon, 1 - epsilon)\n",
        "\n",
        "        # Разбиваем дубликаты\n",
        "        if dequant_jitter and len(base) > 0:\n",
        "            base = base + rng.normal(scale=dequant_jitter, size=base.shape)\n",
        "            base = np.clip(base, epsilon, 1 - epsilon)\n",
        "\n",
        "        # 2) ECDF -> z_raw ~ N(0,1)\n",
        "        n = len(base)\n",
        "        ranks = pd.Series(base, index=idx).rank(method=\"first\").to_numpy()\n",
        "        ecdf = (ranks - 0.5) / max(n, 1)\n",
        "        ecdf = np.clip(ecdf, epsilon, 1 - epsilon)\n",
        "        z_raw = norm.ppf(ecdf)\n",
        "\n",
        "        # 3) Сглаживание (без фазовых сдвигов)\n",
        "        if n > 2:\n",
        "            if smooth_method == \"gauss\":\n",
        "                z_sm = gaussian_filter1d(z_raw, sigma=gauss_sigma, mode=\"nearest\")\n",
        "            elif smooth_method == \"savgol\" and use_savgol and n >= savgol_window:\n",
        "                z_sm = savgol_filter(z_raw, window_length=savgol_window, polyorder=savgol_poly, mode=\"interp\")\n",
        "            elif smooth_method == \"whittaker\":\n",
        "                z_sm = _whittaker_smooth(z_raw, lam=whittaker_lambda)\n",
        "            else:\n",
        "                # запасной вариант, если окно слишком короткое\n",
        "                z_sm = z_raw.copy()\n",
        "        else:\n",
        "            z_sm = z_raw.copy()\n",
        "\n",
        "        # 4) Rearrangement: сохраняем распределение z_raw, но используем порядок z_sm\n",
        "        z_preserved = _rearrange_preserving_marginal(z_raw, z_sm)\n",
        "        #z_preserved = np.where(z_preserved > 0, z_preserved * 1.2, z_preserved)  # Усиливаем положительные пики\n",
        "        #z_preserved = np.clip(z_preserved, -clip_z * 1.5, clip_z * 1.5)\n",
        "\n",
        "        all_indices.append(idx.to_numpy())\n",
        "        all_z_preserved.append(z_preserved)\n",
        "        df.loc[idx, \"batch\"] = batch\n",
        "        batch += 1\n",
        "\n",
        "    # Если событий не нашлось\n",
        "    if len(all_indices) == 0:\n",
        "        df[\"batch\"] = df[\"batch\"].fillna(batch_start).astype(\"int64\", errors=\"ignore\")\n",
        "        df[\"normalized_target\"] = df[\"normalized_target\"].fillna(0.0)\n",
        "        return df\n",
        "\n",
        "    # 5) Глобальная квантильная нормализация: одна общая маргинальная функция\n",
        "    z_pool = np.concatenate(all_z_preserved, axis=0)\n",
        "    z_pool_sorted = np.sort(z_pool)\n",
        "    N = len(z_pool_sorted)\n",
        "    # сетка перцентилей соответствующая отсортированным значениям\n",
        "    p_pool = (np.arange(N) + 0.5) / N\n",
        "\n",
        "    def q_global(p: np.ndarray) -> np.ndarray:\n",
        "        p = np.clip(p, p_pool[0], p_pool[-1])\n",
        "        return np.interp(p, p_pool, z_pool_sorted)\n",
        "\n",
        "    all_z_qn: list[np.ndarray] = []\n",
        "    for z_preserved in all_z_preserved:\n",
        "        n = len(z_preserved)\n",
        "        # перцентиль внутри батча\n",
        "        p_batch = (pd.Series(z_preserved).rank(method=\"first\").to_numpy() - 0.5) / max(n, 1)\n",
        "        z_qn = q_global(p_batch)  # теперь у батча та же маргиналка, что и у пула\n",
        "        all_z_qn.append(z_qn)\n",
        "\n",
        "    # 6) Единая глобальная шкала -> [-1, 1]\n",
        "    g_med = np.median(z_pool)\n",
        "    g_mad = np.median(np.abs(z_pool - g_med)) + 1e-12\n",
        "    scale = 1.4826 * g_mad\n",
        "\n",
        "    pos = 0\n",
        "    for idx, z_qn in zip(all_indices, all_z_qn):\n",
        "        z_g = (z_qn - g_med) / scale\n",
        "        y = np.clip(z_g, -clip_z, clip_z) / clip_z\n",
        "        if tanh_scale:\n",
        "            y = np.tanh(y * tanh_scale) / np.tanh(tanh_scale)\n",
        "\n",
        "        # 7) (опционально) робастная per-batch эквализация до [-1,1]\n",
        "        if per_batch_equalize and len(y) >= 3:\n",
        "            q = per_batch_q\n",
        "            lo, hi = np.quantile(y, [q, 1 - q])\n",
        "            if hi - lo > 1e-12:\n",
        "                y = (y - lo) / (hi - lo)  # [0..1]\n",
        "                y = 2.0 * np.clip(y, 0.0, 1.0) - 1.0  # [-1..1]\n",
        "            y = np.clip(y, -1.0, 1.0)\n",
        "\n",
        "        df.loc[idx, \"normalized_target\"] = y\n",
        "        pos += len(idx)\n",
        "\n",
        "    df[\"batch\"] = df[\"batch\"].astype(\"int64\", errors=\"ignore\")\n",
        "    return df\n",
        "\n",
        "time_last_kline_dt_cache = {}\n",
        "\n",
        "def _to_utc_floor_minute(ts):\n",
        "    return pd.to_datetime(ts, utc=True).floor('T')\n",
        "\n",
        "def _iso_utc(ts):\n",
        "    return pd.Timestamp(ts, tz='UTC').floor('T').isoformat()\n",
        "\n",
        "def _get_dt_scale_for_ticker(ticker):\n",
        "    times_iso = time_last_kline_start.get(ticker, [])\n",
        "    if not times_iso:\n",
        "        return pd.DatetimeIndex([])\n",
        "    if ticker not in time_last_kline_dt_cache or len(time_last_kline_dt_cache[ticker]) != len(times_iso) or (\n",
        "        len(times_iso) and time_last_kline_dt_cache[ticker][-1] != _to_utc_floor_minute(times_iso[-1])\n",
        "    ):\n",
        "        time_last_kline_dt_cache[ticker] = pd.DatetimeIndex(pd.to_datetime(times_iso, utc=True))\n",
        "    return time_last_kline_dt_cache[ticker]\n",
        "\n",
        "\n",
        "def _slice_indices_by_time(ticker, start_time_utc=None, end_time_utc=None):\n",
        "    \"\"\"\n",
        "    Возвращает (start_idx, end_idx) по шкале time_last_kline_start[ticker], границы включительные.\n",
        "    Если start_time_utc/end_time_utc None — граница опущена.\n",
        "    Возвращает None, если шкала пуста или нет пересечения.\n",
        "    \"\"\"\n",
        "    dt_scale = _get_dt_scale_for_ticker(ticker)\n",
        "    if len(dt_scale) == 0:\n",
        "        return None\n",
        "\n",
        "    if start_time_utc is None:\n",
        "        start_idx = 0\n",
        "    else:\n",
        "        start_ts = _to_utc_floor_minute(start_time_utc)\n",
        "        start_idx = int(dt_scale.searchsorted(start_ts, side='left'))\n",
        "        if start_idx >= len(dt_scale):\n",
        "            return None\n",
        "\n",
        "    if end_time_utc is None:\n",
        "        end_idx = len(dt_scale) - 1\n",
        "    else:\n",
        "        end_ts = _to_utc_floor_minute(end_time_utc)\n",
        "        # хотим включительно — берем правую границу и вычитаем 1, но если точное совпадение c началом свечи — ок\n",
        "        end_idx = int(dt_scale.searchsorted(end_ts, side='right') - 1)\n",
        "        if end_idx < 0:\n",
        "            return None\n",
        "\n",
        "    if start_idx > end_idx:\n",
        "        return None\n",
        "    return start_idx, end_idx\n",
        "\n",
        "def _now_monotonic():\n",
        "    return time.monotonic()\n",
        "\n",
        "def _exponential_backoff(attempt: int, base=1.0, cap=15.0, jitter=True):\n",
        "    # attempt: 0,1,2,...\n",
        "    delay = min(cap, base * (2 ** attempt))\n",
        "    if jitter:\n",
        "        # Полуджиттер: равномерный [delay/2, delay]\n",
        "        return random.uniform(delay / 2, delay)\n",
        "    return delay\n",
        "\n",
        "def _is_retryable_grpc_error(e: AioRpcError) -> bool:\n",
        "    code = e.code()\n",
        "    # UNAVAILABLE и CANCELLED — точно перезапускаем\n",
        "    if code in (StatusCode.UNAVAILABLE, StatusCode.CANCELLED, StatusCode.DEADLINE_EXCEEDED):\n",
        "        return True\n",
        "    # INTERNAL иногда тоже имеет смысл ретраить, но осторожно\n",
        "    if code == StatusCode.INTERNAL:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def _is_retryable_generic_error(err: Exception) -> bool:\n",
        "    s = str(err)\n",
        "    needles = [\n",
        "        \"Remote end closed connection without response\",\n",
        "        \"RST_STREAM\",\n",
        "        \"Connection reset by peer\",\n",
        "        \"Server disconnected\",\n",
        "        \"Transport closed\",\n",
        "        \"EOF occurred in violation of protocol\",\n",
        "        \"Stream removed\",\n",
        "        \"recvmsg\",\n",
        "        \"Broken pipe\",\n",
        "        \"Timed out\",\n",
        "    ]\n",
        "    return any(n in s for n in needles)\n",
        "\n",
        "@dataclass\n",
        "class TransformerEntry:\n",
        "    pipe: Pipeline  # preprocessing -> to_dense -> model\n",
        "\n",
        "@dataclass\n",
        "class LGBEntry:\n",
        "    best_method: str\n",
        "    pipe_reg: Optional[Pipeline]\n",
        "    pipe_rank: Optional[Pipeline]\n",
        "    meta: Dict[str, Any]\n",
        "    threshold: float\n",
        "    calib_reg: Dict[str, float]\n",
        "    w_reg: Optional[float]\n",
        "\n",
        "class ModelsRuntimeCache:\n",
        "    def __init__(self):\n",
        "        self.transformers_path: str = \"\"\n",
        "        self.models_path: str = \"\"\n",
        "        self.final_cols: Dict[str, list] = {}\n",
        "        self.final_params: Dict[str, Any] = {}\n",
        "        self.methods: Dict[str, str] = {}\n",
        "        self.scaler_global = None\n",
        "        self.kmeans_global = None\n",
        "        self.transformers: Dict[str, TransformerEntry] = {}\n",
        "        self.lgb_models: Dict[str, LGBEntry] = {}\n",
        "\n",
        "    def init_metadata(self, path_to_save: str):\n",
        "        # Нормализуем пути\n",
        "        self.transformers_path = os.path.join(path_to_save, \"models\", \"neuros\")\n",
        "        self.models_path = os.path.join(path_to_save, \"models\", \"final_models\")\n",
        "\n",
        "        # Метаданные\n",
        "        with open(os.path.join(path_to_save, \"models\", \"final_cols.pkl\"), \"rb\") as f:\n",
        "            self.final_cols = pickle.load(f)\n",
        "        with open(os.path.join(path_to_save, \"models\", \"final_params.pkl\"), \"rb\") as f:\n",
        "            self.final_params = pickle.load(f)\n",
        "        with open(os.path.join(path_to_save, \"models\", \"best_methods.json\"), \"rb\") as f:\n",
        "            self.methods = json.load(f)\n",
        "\n",
        "        # Глобальные объекты\n",
        "        self.scaler_global = joblib.load(os.path.join(path_to_save, \"models\", \"scaler_global.pkl\"))\n",
        "        self.kmeans_global = joblib.load(os.path.join(path_to_save, \"models\", \"kmeans_global.pkl\"))\n",
        "\n",
        "    def _has_transformer_on_disk(self, ticker: str) -> bool:\n",
        "        base = os.path.join(self.transformers_path, ticker)\n",
        "        return os.path.isdir(base)\n",
        "\n",
        "    def _has_lgb_on_disk(self, ticker: str) -> bool:\n",
        "        # Если у вас load_model_for_ticker сам умеет искать файлы — можно опустить эту проверку.\n",
        "        # Оставим мягкую проверку по каталогу тикера.\n",
        "        base = os.path.join(self.models_path, ticker)\n",
        "        return os.path.isdir(base)\n",
        "\n",
        "    def load_transformer_for(self, ticker: str, device: Optional[str] = \"cpu\") -> Optional[Pipeline]:\n",
        "        if ticker in self.transformers:\n",
        "            return self.transformers[ticker].pipe\n",
        "        if not self._has_transformer_on_disk(ticker):\n",
        "            return None\n",
        "        base = os.path.join(self.transformers_path, ticker)\n",
        "        pipe = load_transformer_exact(base, device=device or \"cpu\")\n",
        "        self.transformers[ticker] = TransformerEntry(pipe=pipe)\n",
        "        return pipe\n",
        "\n",
        "    def load_lgb_for(self, ticker: str) -> Optional[LGBEntry]:\n",
        "        if ticker in self.lgb_models:\n",
        "            return self.lgb_models[ticker]\n",
        "        if not self._has_lgb_on_disk(ticker):\n",
        "            return None\n",
        "        data = load_model_for_ticker(ticker, models_dir=self.models_path)\n",
        "        entry = LGBEntry(\n",
        "            best_method=data[\"best_method\"],\n",
        "            pipe_reg=data.get(\"pipe_reg\"),\n",
        "            pipe_rank=data.get(\"pipe_rank\"),\n",
        "            meta=data.get(\"meta\", {}),\n",
        "            threshold=data.get(\"threshold\", 0.0),\n",
        "            calib_reg=data.get(\"calib_reg\", {\"a\": 1.0, \"b\": 0.0}),\n",
        "            w_reg=data.get(\"w_reg\"),\n",
        "        )\n",
        "        self.lgb_models[ticker] = entry\n",
        "        return entry\n",
        "\n",
        "    def preload_all(self, tickers: list, device: str = \"cpu\"):\n",
        "        \"\"\"Аккуратно предзагружает модели только для тех тикеров, которые есть во всех справочниках\n",
        "        и у которых реально есть файлы на диске. Остальные — тихо пропускает.\"\"\"\n",
        "        loaded, skipped = [], []\n",
        "\n",
        "        for t in tickers:\n",
        "            # Проверим наличие описаний в метаданных\n",
        "            has_params = t in self.final_params\n",
        "            has_cols = t in self.final_cols\n",
        "            # Выбираем метод, но отсутствие метода не критично — дефолт 'regressor'\n",
        "            method = self.methods.get(t, \"regressor\")\n",
        "\n",
        "            if not (has_params and has_cols):\n",
        "                skipped.append((t, \"no_meta\"))\n",
        "                continue\n",
        "\n",
        "            # Трансформер\n",
        "            tr_ok = self.load_transformer_for(t, device=device) is not None\n",
        "            # LGB\n",
        "            lgb_ok = self.load_lgb_for(t) is not None\n",
        "\n",
        "            if tr_ok and lgb_ok:\n",
        "                loaded.append(t)\n",
        "            else:\n",
        "                reason = (\"no_transformer\" if not tr_ok else \"no_lgb\")\n",
        "                skipped.append((t, reason))\n",
        "\n",
        "        return {\"loaded\": loaded, \"skipped\": skipped}\n",
        "\n",
        "def to_dense(X):\n",
        "    \"\"\"Преобразует разреженную матрицу в плотную.\"\"\"\n",
        "    if issparse(X):\n",
        "        return X.toarray()\n",
        "    return X\n",
        "\n",
        "class ToDenseTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Преобразует разреженную матрицу в плотную numpy-массив.\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        if issparse(X):\n",
        "            return X.toarray()\n",
        "        return X\n",
        "    def get_feature_names_out(self, input_features: tp.Sequence[str] | None = None):\n",
        "        return np.asarray(input_features) if input_features is not None else np.array([])\n",
        "\n",
        "def deep_elbow(imp: np.ndarray, win: int = 5, eps: float = 0.02) -> int:\n",
        "    \"\"\"\n",
        "    Берём окно длиной win, считаем средний относительный спад.\n",
        "    Первое место, где спад < eps, считаем плато.\n",
        "    \"\"\"\n",
        "    if len(imp) <= win:\n",
        "        return len(imp)\n",
        "    dif = np.abs(np.diff(imp) / (imp[:-1] + 1e-9))\n",
        "    # скользящее среднее\n",
        "    m = np.convolve(dif, np.ones(win) / win, mode=\"valid\")\n",
        "    flat = np.nonzero(m < eps)[0]\n",
        "    return int(flat[0] + win) if flat.size else len(imp)\n",
        "\n",
        "# ───────────────────────────────────────────────────────\n",
        "# 2.  корреляционная чистка (быстрая, исправленная)\n",
        "# ───────────────────────────────────────────────────────\n",
        "def corr_prune(df: pd.DataFrame, feats: list[str], thr=.95) -> list[str]:\n",
        "    if len(feats) < 2 or thr >= 1:\n",
        "        return feats\n",
        "    X  = df[feats].apply(pd.to_numeric, errors='ignore')\n",
        "    C  = X.corr().abs().to_numpy()\n",
        "    keep = []\n",
        "    for i in range(len(feats)):\n",
        "        if not keep or C[i, keep].max() < thr:\n",
        "            keep.append(i)\n",
        "    return [feats[i] for i in keep]\n",
        "\n",
        "# ───────────────────────────────────────────────────────\n",
        "# 3.  универсальный быстрый селектор\n",
        "# ───────────────────────────────────────────────────────\n",
        "def fast_feature_select(\n",
        "        res           : pd.DataFrame,      # feature / importance\n",
        "        df_full       : pd.DataFrame,      # датасет для corr-prune\n",
        "        target_col    : str = \"target\",\n",
        "        *,\n",
        "        method        : str = \"elbow\",     # elbow | deep_elbow | percentile | quantile | top_k\n",
        "        top_k         : int = 150,         # для method=\"top_k\"\n",
        "        perc_limit    : float = .90,       # для method=\"percentile\"\n",
        "        quantile_q    : float = .10,       # для method=\"quantile\"\n",
        "        elbow_eps     : float = .05,       # (> flat %) для (shallow) elbow\n",
        "        deep_win      : int = 5,           # окно для deep_elbow\n",
        "        deep_eps      : float = .02,       # порог для deep_elbow\n",
        "        corr_thr      : float = .95        # корреляционный порог\n",
        ") -> list[str]:\n",
        "\n",
        "    ranked = res.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
        "    feats  = ranked.feature.to_numpy()\n",
        "    imps   = ranked.importance.to_numpy()\n",
        "\n",
        "    # ---------- 1) сколько оставить  ----------\n",
        "    if method == \"elbow\":                 # одношаговое колено\n",
        "        k = np.argmax(np.abs(np.diff(imps) / (imps[:-1] + 1e-9)) < elbow_eps) + 1\n",
        "        if k == 1:        # колено не найдено\n",
        "            k = len(imps)\n",
        "    elif method == \"deep_elbow\":\n",
        "        k = deep_elbow(imps, win=deep_win, eps=deep_eps)\n",
        "    elif method == \"percentile\":          # кумулятивная доля\n",
        "        cum = np.cumsum(imps)\n",
        "        k   = np.searchsorted(cum / cum[-1], perc_limit) + 1\n",
        "    elif method == \"quantile\":\n",
        "        thr = np.quantile(imps, 1 - quantile_q)\n",
        "        k   = int((imps >= thr).sum())\n",
        "    elif method == \"top_k\":\n",
        "        k = min(top_k, len(feats))\n",
        "    else:\n",
        "        raise ValueError(\"unknown method\")\n",
        "\n",
        "    selected = feats[:k].tolist()\n",
        "\n",
        "    # ---------- 2) корреляционная чистка ----------\n",
        "    selected = corr_prune(\n",
        "        df_full.drop(columns=[target_col], errors='ignore'),\n",
        "        selected,\n",
        "        thr=corr_thr\n",
        "    )\n",
        "\n",
        "    return selected\n",
        "\n",
        "def patch_feature_timings(cls):\n",
        "    \"\"\"\n",
        "    Оборачивает все методы cls, начинающиеся на _feat_,\n",
        "    и складывает затраченное время в self._timings[method_name].\n",
        "    Вызывать сразу после объявления класса.\n",
        "    \"\"\"\n",
        "    def timed(func):\n",
        "        def wrapper(self, *args, **kwargs):\n",
        "            t0 = time.perf_counter()\n",
        "            result = func(self, *args, **kwargs)\n",
        "            dt = time.perf_counter() - t0\n",
        "            # заводим словарь при первом же вызове\n",
        "            if not hasattr(self, \"_timings\"):\n",
        "                self._timings = {}\n",
        "            self._timings[func.__name__] = dt\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "    for name, method in inspect.getmembers(cls, inspect.isfunction):\n",
        "        if name.startswith(\"_feat_\"):             # ← только расчётные функции\n",
        "            setattr(cls, name, timed(method))\n",
        "\n",
        "    return cls\n",
        "\n",
        "def _slope(y):\n",
        "        x = np.arange(len(y))\n",
        "        # линейная регрессия «по формуле»\n",
        "        xm, ym = x.mean(), y.mean()\n",
        "        beta = ((x - xm) * (y - ym)).sum() / ((x - xm)**2).sum()\n",
        "        return beta\n",
        "\n",
        "@njit\n",
        "def _rolling_entropy_exact_numba(x, window):\n",
        "    \"\"\" Точная реализация rolling entropy с bins='auto' для каждого окна. \"\"\"\n",
        "    n = len(x)\n",
        "    res = np.empty(n, dtype=np.float32)\n",
        "    res[:] = np.nan\n",
        "    if window < 2:\n",
        "        return res\n",
        "    for end in range(window - 1, n):\n",
        "        win = x[end - window + 1 : end + 1]\n",
        "        a_min = np.min(win)\n",
        "        a_max = np.max(win)\n",
        "        if a_min == a_max:\n",
        "            res[end] = 0.0\n",
        "            continue\n",
        "        sorted_win = np.sort(win)\n",
        "        idx25 = int(0.25 * window)\n",
        "        idx75 = int(0.75 * window)\n",
        "        q25 = sorted_win[idx25]\n",
        "        q75 = sorted_win[idx75]\n",
        "        iqr = q75 - q25\n",
        "        sturges = int(np.ceil(np.log2(window) + 1))\n",
        "        if iqr > 0:\n",
        "            bin_width = 2.0 * iqr / (window ** (1.0 / 3.0))\n",
        "            fd = int(np.ceil((a_max - a_min) / bin_width))\n",
        "        else:\n",
        "            fd = 1\n",
        "        nbins = max(sturges, fd, 1)\n",
        "        edges = np.empty(nbins + 1, dtype=np.float32)\n",
        "        step = (a_max - a_min) / nbins\n",
        "        edges[0] = a_min\n",
        "        for i in range(1, nbins):\n",
        "            edges[i] = a_min + i * step\n",
        "        edges[nbins] = a_max\n",
        "        counts = np.zeros(nbins, dtype=np.int32)  # int32 достаточно для window<=1e9\n",
        "        for val in win:\n",
        "            idx = np.searchsorted(edges, val, side='right') - 1\n",
        "            if 0 <= idx < nbins:\n",
        "                counts[idx] += 1\n",
        "        ent = 0.0\n",
        "        total = float(window)\n",
        "        for c in counts:\n",
        "            if c > 0:\n",
        "                p = c / total\n",
        "                ent -= p * np.log(p + 1e-10)\n",
        "        res[end] = ent\n",
        "    return res\n",
        "\n",
        "@jit(nopython=True)\n",
        "def rolling_autocorr(arr, window):\n",
        "    n = len(arr)\n",
        "    result = np.full(n, 0.0)\n",
        "    for i in range(n):\n",
        "        start = max(0, i - window + 1)\n",
        "        w = i - start + 1\n",
        "        if w <= 1:\n",
        "            continue\n",
        "        s = arr[start: i + 1]\n",
        "        a = s[1:]\n",
        "        b = s[:-1]\n",
        "        n_pts = w - 1\n",
        "        mean_a = np.sum(a) / n_pts\n",
        "        mean_b = np.sum(b) / n_pts\n",
        "        cov = np.dot(a, b) / n_pts - mean_a * mean_b\n",
        "        var_a = np.dot(a, a) / n_pts - mean_a * mean_a\n",
        "        var_b = np.dot(b, b) / n_pts - mean_b * mean_b\n",
        "        if var_a <= 0 or var_b <= 0:\n",
        "            result[i] = np.nan\n",
        "        else:\n",
        "            std_a = np.sqrt(var_a)\n",
        "            std_b = np.sqrt(var_b)\n",
        "            result[i] = cov / (std_a * std_b)\n",
        "    return result\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "@patch_feature_timings\n",
        "class FeatureCalculatorForRegression:\n",
        "    \"\"\"\n",
        "    df  -- исходный OHLCV-DataFrame.\n",
        "    required_features -- список имён колонок, которые нужны модели.\n",
        "    params -- { primitive_name: {... гиперпараметры ...}, 'stat_window': int }.\n",
        "    \"\"\"\n",
        "\n",
        "    _PRIMITIVES = {\n",
        "        \"MEDPRICE\":               \"_feat_base\",\n",
        "        \"MACD\":                   \"_feat_macd\",\n",
        "        \"MACD_Hist\":              \"_feat_macd\",\n",
        "        \"Overbought_Oversold\":    \"_feat_overbought\",\n",
        "        \"Overbought_Oversold_Index_mean\": \"_feat_overbought\",\n",
        "        \"Price_MADist%\":          \"_feat_madist\",\n",
        "        \"Mean_Reversion\":         \"_feat_mean_reversion\",\n",
        "        \"Fear_Greed\":             \"_feat_fear_greed\",\n",
        "        \"perc_var_open_close\":    \"_feat_price_variation\",\n",
        "        \"pmax_norm\":              \"_feat_pmax_ma\",\n",
        "        \"ma_norm\":                \"_feat_pmax_ma\",\n",
        "        \"ma_pmax_norm_rage\":      \"_feat_pmax_ma\",\n",
        "        \"ma_pmax_norm_rage_pct\":  \"_feat_pmax_ma\",\n",
        "        \"slope_trend\":            \"_feat_slope\",\n",
        "        \"ema_trend\":              \"_feat_ema_trend\",\n",
        "        \"hp_trend\":               \"_feat_hp_trend\",\n",
        "        \"trade_bars_counter\":     \"_feat_trade_duration\",\n",
        "        \"ROC\":                    \"_feat_roc\",\n",
        "        \"ATR_norm\":               \"_feat_atr\",\n",
        "        \"BB_Width\":               \"_feat_bb_width\",\n",
        "        \"Asset_Growth\":           \"_feat_asset_growth\",\n",
        "        \"ema_acceleration\":       \"_feat_ema_acceleration\",\n",
        "        \"price_change\":           \"_feat_price_change\",\n",
        "        \"Asset_To_Equity_Ratio\":  \"_feat_asset_to_equity_ratio\",\n",
        "        \"volume_ratio\":           \"_feat_fear_greed_index\",\n",
        "        \"WILLR\":                  \"_feat_willr\",\n",
        "        \"kf_trend\":               \"_feat_kf_trend\",\n",
        "        \"Fractal_Dim\":            \"_feat_fractal_dim\",\n",
        "        \"Peak_Exhaustion_Score\":  \"_feat_peak_exhaustion\",\n",
        "        \"%B_BB\":                  \"_feat_bb_percent\",\n",
        "        \"Kurtosis_roll\":          \"_feat_kurtosis_roll\",\n",
        "        \"OBV_div\":                \"_feat_obv_div\",\n",
        "        \"RSI_slope\":              \"_feat_rsi_slope\",\n",
        "        \"Vol_Decay\":              \"_feat_vol_decay\",\n",
        "        \"Accel_Decay\":            \"_feat_accel_decay\",\n",
        "        \"Entropy_roll\":           \"_feat_entropy_roll\",\n",
        "        \"Wavelet_Var_Ratio\":      \"_feat_wavelet_var\",\n",
        "        \"Autocorr_Lag1\":          \"_feat_autocorr\",\n",
        "        \"Beta_Market\":            \"_feat_beta\",\n",
        "        \"PSC\":                    \"_feat_peak_squeeze_curvature\",\n",
        "        \"PSC_raw\":                \"_feat_peak_squeeze_curvature\",\n",
        "        \"PSC_z\":                  \"_feat_peak_squeeze_curvature\",\n",
        "        \"PSC_sigmoid\":            \"_feat_peak_squeeze_curvature\",\n",
        "    }\n",
        "\n",
        "    # СТАРАЯ: r\"^ago_(\\d+)_\"\n",
        "    # НОВАЯ: умеет и \"ago50_\", и \"ago_50_\"\n",
        "    _LAG_RE  = re.compile(r\"^ago_?(\\d+)_\")\n",
        "    _STAT_RE = re.compile(r\"_(mean|min|max|std|skew|kurt|quantile(\\d{2}))$\")\n",
        "    _LOGSF   = \"_logsf\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, ticker):\n",
        "        self.df = df.copy()\n",
        "        self.ticker = ticker\n",
        "        f64 = self.df.select_dtypes(\"float64\").columns\n",
        "        self.df[f64] = self.df[f64].astype(np.float32)\n",
        "        if \"time\" in self.df:\n",
        "            ts = pd.to_datetime(self.df[\"time\"], utc=True, errors=\"coerce\")\n",
        "            self.df[\"hour\"]        = ts.dt.hour.astype(\"int8\")\n",
        "            self.df[\"day_of_week\"] = ts.dt.day_of_week.astype(\"int8\")\n",
        "\n",
        "    def calculate_features(\n",
        "        self,\n",
        "        required_features: Iterable[str],\n",
        "        params: Mapping[str, Mapping[str, Any]] | None = None\n",
        "    ) -> pd.DataFrame:\n",
        "        saved_cols = ['regime', 'normalized_target', 'batch', 'time', 'open', 'close', 'high', 'low', 'volume', 'buy_signal',\n",
        "                      'sell_signal', 'event_sell_time', 'event_sell_price', 'event_time', 'event_price', 'event_sell_time',\n",
        "                      'event_sell_price', 'target', 'pnl', 'ma', 'pmax']\n",
        "        self._params      = defaultdict(dict, params or {})\n",
        "        self._stat_window = self._params.get(\"stat_window\", 50)\n",
        "        for col in required_features:\n",
        "            self._ensure_column(col)\n",
        "        out = self.df[list(required_features)].copy()\n",
        "        f64 = out.select_dtypes(\"float64\").columns\n",
        "        out[f64] = out[f64].astype(np.float32)\n",
        "\n",
        "        for mandatory_col in saved_cols:\n",
        "            if mandatory_col in self.df.columns:\n",
        "                out[mandatory_col] = self.df[mandatory_col]\n",
        "\n",
        "        return out\n",
        "\n",
        "    def calculate_all_possible_features(self, params: Mapping[str, Mapping[str, Any]] | None = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Вычисляет все возможные фичи, исключая lag-версии для указанных колонок.\n",
        "        Все бесконечные значения (np.inf/-np.inf) заменяются на 0.\n",
        "        Порядок вычислений:\n",
        "        1. Все базовые примитивы\n",
        "        2. Lag-версии фич (кроме исключенных)\n",
        "        3. Статистики для всех фич\n",
        "        \"\"\"\n",
        "        # Инициализация параметров\n",
        "        if not hasattr(self, '_params'):\n",
        "            self._params = defaultdict(dict, params or {})\n",
        "        self._stat_window = self._params.get(\"stat_window\", 50)\n",
        "\n",
        "        # Колонки, для которых не нужно создавать lag-версии\n",
        "        EXCLUDE_FROM_LAGS = {\n",
        "            'time', 'open', 'close', 'high', 'low', 'volume',\n",
        "            'ma', 'pmax', 'buy_signal', 'sell_signal', 'regime',\n",
        "            'event_time', 'event_price', 'event_sell_time',\n",
        "            'event_sell_price', 'pnl', 'target', 'normalized_target',\n",
        "            'batch', 'hour', 'day_of_week', 'trade_bars_counter'\n",
        "        }\n",
        "\n",
        "        # 1. Вычисляем все базовые примитивы\n",
        "        all_primitives = list(self._PRIMITIVES.keys())\n",
        "        for primitive in all_primitives:\n",
        "            method_name = self._PRIMITIVES[primitive]\n",
        "            primitive_params = self._params.get(primitive, {})\n",
        "            try:\n",
        "                getattr(self, method_name)(**primitive_params)\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка при вычислении примитива {primitive}: {str(e)}\")\n",
        "\n",
        "        # 2. Добавляем lag-версии только для разрешенных фич\n",
        "        numeric_cols = [\n",
        "            col for col in self.df.select_dtypes(include=['float32', 'float64', 'int32', 'int64']).columns\n",
        "            if col not in EXCLUDE_FROM_LAGS and  # Исключаем указанные колонки\n",
        "            not self._LAG_RE.match(col) and      # Исключаем уже lag-фичи\n",
        "            not col.endswith(self._LOGSF) and    # Исключаем logsf-фичи\n",
        "            not self._STAT_RE.search(col)        # Исключаем статистики\n",
        "        ]\n",
        "\n",
        "        lag_periods = [1, 2, 3, 5, 10, 20, 50]  # Стандартные лаги\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            for lag in lag_periods:\n",
        "                lag_col = f\"ago_{lag}_{col}\"\n",
        "                if lag_col not in self.df.columns:\n",
        "                    self.df[lag_col] = self.df[col].shift(lag)\n",
        "\n",
        "        # 3. Добавляем статистики для всех фич (кроме исключенных)\n",
        "        all_cols_for_stats = [\n",
        "            col for col in self.df.columns\n",
        "            if col not in EXCLUDE_FROM_LAGS and\n",
        "            not col.endswith(self._LOGSF) and\n",
        "            not self._STAT_RE.search(col)\n",
        "        ]\n",
        "\n",
        "        stats = ['mean', 'std', 'min', 'max', 'skew', 'kurt']\n",
        "\n",
        "        for col in all_cols_for_stats:\n",
        "            for stat in stats:\n",
        "                stat_col = f\"{col}_{stat}\"\n",
        "                if stat_col not in self.df.columns:\n",
        "                    try:\n",
        "                        self._add_stat(col, stat)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Ошибка при вычислении статистики {stat} для {col}: {str(e)}\")\n",
        "\n",
        "        # 4. Добавляем logsf-версии только для разрешенных фич\n",
        "        main_cols_for_logsf = [\n",
        "            col for col in numeric_cols\n",
        "            if not col.startswith('ago_') and\n",
        "            not col.endswith(self._LOGSF) and\n",
        "            col not in EXCLUDE_FROM_LAGS\n",
        "        ]\n",
        "\n",
        "        for col in main_cols_for_logsf:\n",
        "            logsf_col = f\"{col}{self._LOGSF}\"\n",
        "            if logsf_col not in self.df.columns:\n",
        "                try:\n",
        "                    self.df[logsf_col] = norm.logsf(self.df[col])\n",
        "                except Exception as e:\n",
        "                    print(f\"Ошибка при вычислении logsf для {col}: {str(e)}\")\n",
        "\n",
        "        # 5. Заменяем бесконечные значения на 0\n",
        "        numeric_cols_all = self.df.select_dtypes(include=['float32', 'float64', 'int32', 'int64']).columns\n",
        "        self.df[numeric_cols_all] = self.df[numeric_cols_all].replace([np.inf, -np.inf], 0)\n",
        "\n",
        "        # Сохраняем все оригинальные колонки\n",
        "        for col in EXCLUDE_FROM_LAGS:\n",
        "            if col in self.df.columns and col not in self.df:\n",
        "                self.df[col] = self.df[col]\n",
        "\n",
        "        return self.df.copy()\n",
        "\n",
        "    def _ensure_column(self, name: str):\n",
        "        if name in self.df:\n",
        "            return\n",
        "\n",
        "        # 1) lag-префикс \"ago50_\" или \"ago_50_\"\n",
        "        m = self._LAG_RE.match(name)\n",
        "        if m:\n",
        "            lag  = int(m.group(1))\n",
        "            base = name[m.end():]\n",
        "            self._ensure_column(base)\n",
        "            self.df[name] = self.df[base].shift(lag)\n",
        "            return\n",
        "\n",
        "        # 2) _logsf\n",
        "        if name.endswith(self._LOGSF):\n",
        "            base = name[:-len(self._LOGSF)]\n",
        "            self._ensure_column(base)\n",
        "            self.df[name] = norm.logsf(self.df[base])\n",
        "            return\n",
        "\n",
        "        # 3) статистический суффикс\n",
        "        m = self._STAT_RE.search(name)\n",
        "        if m:\n",
        "            stat = m.group(1)\n",
        "            base = name[:m.start()]\n",
        "            self._ensure_column(base)\n",
        "            self._add_stat(base, stat)\n",
        "            return\n",
        "\n",
        "        # 4) примитив\n",
        "        prim = name\n",
        "        if prim.startswith(\"Overbought_Oversold\"):\n",
        "            prim = \"Overbought_Oversold\"\n",
        "        if prim.startswith(\"Fear_Greed\"):\n",
        "            prim = \"Fear_Greed\"\n",
        "        if prim not in self._PRIMITIVES:\n",
        "            raise KeyError(f\"Не знаю, как получить примитив «{prim}» для «{name}»\")\n",
        "        getattr(self, self._PRIMITIVES[prim])(**self._params.get(prim, {}))\n",
        "        if name not in self.df:\n",
        "            raise RuntimeError(f\"После _feat_{prim}() нет колонки «{name}»\")\n",
        "\n",
        "    def _add_stat(self, base: str, stat: str):\n",
        "        col = f\"{base}_{stat}\"\n",
        "        if col in self.df:\n",
        "            return\n",
        "        s = self.df[base]; w = self._stat_window\n",
        "        if stat == \"mean\":\n",
        "            self.df[col] = s.rolling(w).mean()\n",
        "        elif stat == \"std\":\n",
        "            self.df[col] = s.rolling(w).std()\n",
        "        elif stat == \"min\":\n",
        "            self.df[col] = s.rolling(w).min()\n",
        "        elif stat == \"max\":\n",
        "            self.df[col] = s.rolling(w).max()\n",
        "        elif stat == \"skew\":\n",
        "            self.df[col] = s.rolling(w).skew()\n",
        "        elif stat == \"kurt\":\n",
        "            self.df[col] = s.rolling(w).kurt()\n",
        "        elif stat.startswith(\"quantile\"):\n",
        "            q = int(stat[-2:]) / 100\n",
        "            self.df[col] = s.rolling(w).quantile(q)\n",
        "        else:\n",
        "            raise ValueError(f\"Неизвестная stat «{stat}»\")\n",
        "\n",
        "    # ---------------------- ПРИМИТИВЫ ----------------------\n",
        "\n",
        "    def _feat_base(self, medprice: int = 50):\n",
        "        if \"MEDPRICE\" in self.df:\n",
        "            return\n",
        "        self.df[\"MEDPRICE\"]      = (self.df[\"high\"] + self.df[\"low\"]) / 2\n",
        "        self.df[\"MEDPRICE_std\"] = self.df[\"MEDPRICE\"].rolling(medprice).std()\n",
        "\n",
        "    def _feat_macd(self, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"\n",
        "        Быстрый расчет нормализованного MACD с использованием векторизованных операций\n",
        "        \"\"\"\n",
        "        if {\"MACD\",\"MACD_Hist\"}.issubset(self.df.columns):\n",
        "            return\n",
        "\n",
        "        close = self.df['close']\n",
        "        # Создаем множества для уникальных периодов\n",
        "        ema_cache_fp = close.ewm(span=fast, adjust=False).mean()\n",
        "\n",
        "        ema_cache_sp = close.ewm(span=slow, adjust=False).mean()\n",
        "        rolling_cache = close.rolling(window=slow).mean()\n",
        "\n",
        "        # Основной цикл вычислений\n",
        "        ema_fast = ema_cache_fp\n",
        "        ema_slow = ema_cache_sp\n",
        "        rolling_mean = rolling_cache\n",
        "        macd = ema_fast - ema_slow\n",
        "        macd_norm = macd / rolling_mean\n",
        "        self.df[f'MACD'] = macd_norm\n",
        "        signal = macd.ewm(span=signal, adjust=False).mean()\n",
        "        signal_norm = signal / rolling_mean\n",
        "\n",
        "        # Сохраняем результаты\n",
        "        self.df[f'MACD_Hist'] = macd_norm - signal_norm\n",
        "\n",
        "    def _feat_overbought(self, rsi_p: int = 14, stoch_p: int = 14):\n",
        "        name = \"Overbought_Oversold_Index\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        c   = self.df[\"close\"]; d = c.diff()\n",
        "        g   = d.clip(lower=0); l = (-d).clip(lower=0)\n",
        "        rs  = g.rolling(rsi_p).mean() / (l.rolling(rsi_p).mean().add(1e-10))\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        lo  = self.df[\"low\"].rolling(stoch_p).min()\n",
        "        hi  = self.df[\"high\"].rolling(stoch_p).max()\n",
        "        st  = 100*(c - lo)/(hi - lo + 1e-10)\n",
        "        self.df[name] = (rsi + st)/2\n",
        "\n",
        "    def _feat_madist(self, span_lenght: int = 200):\n",
        "        name = \"Price_MADist%\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ema = self.df[\"close\"].ewm(span=span_lenght, adjust=False).mean()\n",
        "        self.df[name] = (self.df[\"close\"]/ema - 1)*100\n",
        "\n",
        "    def _feat_mean_reversion(self, window: int = 20):\n",
        "        name = \"Mean_Reversion\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ma = self.df[\"close\"].rolling(window).mean()\n",
        "        self.df[name] = self.df[\"close\"] - ma\n",
        "\n",
        "    def _feat_fear_greed(self, window: int = 14):\n",
        "        name = \"Fear_Greed_Index\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        v  = self.df[\"close\"].pct_change().rolling(window).std()\n",
        "        vc = self.df[\"volume\"].pct_change().rolling(window).mean()\n",
        "        tr = self.df[\"close\"]/self.df[\"close\"].rolling(window).mean()\n",
        "        self.df[name] = (v + vc + tr)/3*100\n",
        "\n",
        "    def _feat_price_variation(self):\n",
        "        name = \"perc_var_open_close\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        eps = 1e-10\n",
        "        self.df[name] = (self.df[\"close\"]-self.df[\"open\"])/(self.df[\"open\"]+eps)*100\n",
        "\n",
        "    def _feat_pmax_ma(self,\n",
        "        pmax_ma_length: int = 10,\n",
        "        pmax_ma_length_roll: int = 50,\n",
        "        pct_window: int = 5\n",
        "    ):\n",
        "        need = {\n",
        "            \"pmax_norm\", \"ma_norm\",\n",
        "            \"ma_pmax_norm_rage\", \"ma_pmax_norm_rage_pct\"\n",
        "        }\n",
        "        if need.issubset(self.df.columns):\n",
        "            return\n",
        "        if {\"pmax\",\"ma\"}.difference(self.df.columns):\n",
        "            raise ValueError(\"Нужны 'pmax' и 'ma'\")\n",
        "        c = self.df[\"close\"]\n",
        "        self.df[\"pmax_norm\"]             = (c-self.df[\"pmax\"])/self.df[\"pmax\"]\n",
        "        self.df[\"ma_norm\"]               = (c-self.df[\"ma\"])/self.df[\"ma\"]\n",
        "        self.df[\"ma_pmax_norm_rage\"]     = self.df[\"ma_norm\"] - self.df[\"pmax_norm\"]\n",
        "        # новый примитив — pct-динамика\n",
        "        self.df[\"ma_pmax_norm_rage_pct\"] = \\\n",
        "          self.df[\"ma_pmax_norm_rage\"].pct_change(pct_window).fillna(0)\n",
        "\n",
        "    def _feat_slope(self, slope_lag: int = 300, pct_window: int = 6):\n",
        "        name = \"slope_trend\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        r = self.df[\"close\"].pct_change(pct_window).fillna(0)\n",
        "        self.df[name] = r.rolling(slope_lag, min_periods=slope_lag)\\\n",
        "                         .apply(_slope, raw=True)\n",
        "\n",
        "    def _feat_ema_trend(self, span: int = 300, pct_window: int = 6):\n",
        "        name = \"ema_trend\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        r = self.df[\"close\"].pct_change(pct_window).fillna(0)\n",
        "        e = r.ewm(span=span, adjust=False).mean()\n",
        "        self.df[name] = e.diff().fillna(0)\n",
        "\n",
        "    def _feat_asset_to_equity_ratio(self):\n",
        "        \"\"\"\n",
        "        Вычисление коэффициента соотношения активов и собственного капитала.\n",
        "        \"\"\"\n",
        "        name = \"Asset_To_Equity_Ratio\"\n",
        "        asset = self.df['close']\n",
        "        equity = self.df['low']\n",
        "        # Добавляем в DataFrame\n",
        "        self.df[name] = asset / (equity + 1e-10)\n",
        "\n",
        "    def _feat_hp_trend(self, lamb: float = 1600):\n",
        "        name = \"hp_trend\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        y    = np.log(self.df[\"close\"]).fillna(method=\"ffill\")\n",
        "        coef = lamb/(1+lamb)\n",
        "        tr   = np.empty(len(y), dtype=float)\n",
        "        tr[0] = y.iloc[0]\n",
        "        for i in range(1, len(y)):\n",
        "            tr[i] = coef*y.iloc[i] + (1-coef)*tr[i-1]\n",
        "        self.df[name] = np.append([0], np.diff(tr))\n",
        "\n",
        "    def _feat_kf_trend(self,\n",
        "        pct_window: int = 6,\n",
        "        obs_var: float = 1e-4, # σ² ε_t (шум наблюдения)\n",
        "        level_var: float = 1e-5 # σ² η_t (шум уровня)\n",
        "        ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Добавляет к DataFrame колонки:\n",
        "        kf_trend — one-sided Калман-оценка тренда доходностей\n",
        "        kf_trend_logsf — лог-survival-function (z-score) тренда\n",
        "        Полностью каузально, обновляется тик-за-тиком.\n",
        "        \"\"\"\n",
        "\n",
        "        name = 'kf_trend'\n",
        "        # 1. Доходности\n",
        "        r = self.df['close'].pct_change(pct_window).fillna(0)\n",
        "        # 2. Local-level модель: y_t = μ_t + ε_t ;  μ_t = μ_{t-1} + η_t\n",
        "        mod = sm.tsa.UnobservedComponents(r, level='llevel')\n",
        "\n",
        "        # 3. Параметры модели в log-шкале (требование statsmodels)\n",
        "        params = np.log([obs_var, level_var])\n",
        "\n",
        "        # 4. Только forward-filter → нет look-ahead bias\n",
        "        res = mod.filter(params)                       # <— односторонний Калман\n",
        "        trend = pd.Series(res.filtered_state[0], index=self.df.index)\n",
        "\n",
        "        # 5. Запись результата\n",
        "        self.df['kf_trend'] = trend\n",
        "\n",
        "    def _feat_willr(self, window=14):\n",
        "        \"\"\"\n",
        "        Вычисление %R по методу Уильямса (WILLR).\n",
        "        \"\"\"\n",
        "        name = 'WILLR'\n",
        "        high = self.df['high']\n",
        "        low = self.df['low']\n",
        "        close = self.df['close']\n",
        "\n",
        "        highest_high = high.rolling(window).max()\n",
        "        lowest_low = low.rolling(window).min()\n",
        "\n",
        "        willr = ((highest_high - close) / (highest_high - lowest_low)) * -100\n",
        "\n",
        "        # Добавляем в DataFrame\n",
        "        self.df[name] = willr\n",
        "\n",
        "    def _feat_fear_greed_index(self, window: int = 14):\n",
        "        \"\"\"\n",
        "        Расчет объема как отношение последнего объема к скользящему среднему.\n",
        "        \"\"\"\n",
        "        name = \"volume_ratio\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        s = self.df[\"volume\"]\n",
        "        self.df[name] = s / s.rolling(window).mean()\n",
        "\n",
        "    def _feat_trade_duration(self):\n",
        "        name = \"trade_bars_counter\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = np.nan\n",
        "        entries = self.df.index[self.df[\"event_time\"].notna()]\n",
        "        last    = self.df.index[-1]\n",
        "        for st in entries:\n",
        "            sell = self.df.at[st, \"event_sell_time\"]\n",
        "            ends = self.df.index[self.df[\"time\"] == sell]\n",
        "            end  = ends[0] if len(ends) else last\n",
        "            s,e  = self.df.index.get_loc(st), self.df.index.get_loc(end)\n",
        "            self.df.loc[self.df.index[s:e+1], name] = np.arange(e-s+1, dtype=np.float32)\n",
        "\n",
        "    def _feat_roc(self, window: int = 5):\n",
        "        name = \"ROC\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = self.df[\"close\"].pct_change(window)\n",
        "\n",
        "    def _feat_atr(self, atr_window: int = 14):\n",
        "        name = \"ATR_norm\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        h,l,c = self.df[\"high\"], self.df[\"low\"], self.df[\"close\"]\n",
        "        tr1 = h-l\n",
        "        tr2 = (h-c.shift()).abs()\n",
        "        tr3 = (l-c.shift()).abs()\n",
        "        tr  = pd.concat([tr1,tr2,tr3], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_window).mean()\n",
        "        self.df[name] = atr/c\n",
        "\n",
        "    def _feat_bb_width(self, bb_window: int = 20):\n",
        "        name = \"BB_Width\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        c   = self.df[\"close\"]\n",
        "        ma  = c.rolling(bb_window).mean()\n",
        "        std = c.rolling(bb_window).std()\n",
        "        self.df[name] = 2*std/ma\n",
        "\n",
        "    def _feat_asset_growth(self, window: int = 3):\n",
        "        name = \"Asset_Growth\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = self.df[\"close\"].pct_change(window).fillna(0)*100\n",
        "\n",
        "    def _feat_ema_acceleration(self, pct_window: int = 3, ema_window: int = 300):\n",
        "        name = \"ema_acceleration\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        r = self.df[\"close\"].pct_change(pct_window).fillna(0)\n",
        "        e = r.ewm(span=ema_window).mean()\n",
        "        self.df[name] = e.diff(4)\n",
        "\n",
        "    def _feat_price_change(self, window: int = 1):\n",
        "        name = \"price_change\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = self.df[\"close\"].pct_change(window).fillna(0)\n",
        "\n",
        "    def _feat_peak_exhaustion(\n",
        "        self,\n",
        "        price_win: int = 60,    # окно \"локального максимума\"\n",
        "        mom_win:   int = 10,    # окно для momentum\n",
        "        vol_win:   int = 20,\n",
        "        atr_win:   int = 14,\n",
        "        z_win:     int = 100    # z-score нормализация\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Peak-Exhaustion Score  ~ 0…1\n",
        "        1 → почти наверху, импульс затух, объём падает, ATR высок.\n",
        "        \"\"\"\n",
        "        name = \"Peak_Exhaustion_Score\"\n",
        "        c = self.df[\"close\"]\n",
        "\n",
        "        # 1) расстояние до локального max\n",
        "        roll_max = c.rolling(price_win).max()\n",
        "        dist_max = (roll_max - c) / roll_max          # 0 — на max, >0 — ниже\n",
        "\n",
        "        # 2) ослабевающий импульс\n",
        "        roc_now  = c.pct_change(mom_win)\n",
        "        roc_hist = roc_now.rolling(price_win).max()   # max импульса в окне\n",
        "        momentum_div = 1 - (roc_now / (roc_hist + 1e-12))   # 0 → свежий high\n",
        "\n",
        "        # 3) сушащийся объём\n",
        "        vol_ratio = self.df[\"volume\"] / \\\n",
        "            self.df[\"volume\"].rolling(vol_win).mean()\n",
        "\n",
        "        # 4) расширенный спред (ATR/price)\n",
        "        tr  = pd.concat([\n",
        "                self.df[\"high\"]  - self.df[\"low\"],\n",
        "                (self.df[\"high\"] - c.shift()).abs(),\n",
        "                (self.df[\"low\"]  - c.shift()).abs()\n",
        "            ], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_win).mean()\n",
        "        atr_norm = atr / c\n",
        "\n",
        "        # 5) агрегируем, переводим в z-score, squash σ → 0…1\n",
        "        raw = (dist_max + momentum_div + (1/vol_ratio) + atr_norm) / 4\n",
        "        z   = (raw - raw.rolling(z_win).mean()) / (raw.rolling(z_win).std() + 1e-9)\n",
        "        self.df[name] = 1 / (1 + np.exp(-z))   # σ(z)\n",
        "\n",
        "    def _feat_fractal_dim(self, short_win=20, long_win=40):\n",
        "        \"\"\"Вычисляет фрактальную размерность на основе отношения ATR разных периодов\"\"\"\n",
        "        name = \"Fractal_Dim\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "\n",
        "        # Вычисляем ATR для короткого периода\n",
        "        h, l, c = self.df['high'], self.df['low'], self.df['close']\n",
        "        tr1 = h - l\n",
        "        tr2 = (h - c.shift()).abs()\n",
        "        tr3 = (l - c.shift()).abs()\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        atr_short = tr.rolling(short_win).mean()\n",
        "\n",
        "        # Вычисляем ATR для длинного периода\n",
        "        atr_long = tr.rolling(long_win).mean()\n",
        "\n",
        "        # Вычисляем фрактальную размерность\n",
        "        ratio = atr_long / (atr_short + 1e-10)  # Добавляем небольшое значение для избежания деления на 0\n",
        "        self.df[name] = np.log(ratio) / np.log(2)\n",
        "\n",
        "    def _feat_bb_percent(self, window=20, std_mult=2):\n",
        "        name = \"%B_BB\"\n",
        "        if name in self.df: return\n",
        "        ma = self.df[\"close\"].rolling(window).mean()\n",
        "        std = self.df[\"close\"].rolling(window).std()\n",
        "        self.df[name] = (self.df[\"close\"] - (ma - std_mult * std)) / (4 * std)\n",
        "\n",
        "    def _feat_kurtosis_roll(self, window=50):\n",
        "        name = \"Kurtosis_roll\"\n",
        "        if name in self.df: return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0)\n",
        "        self.df[name] = ret.rolling(window).kurt()\n",
        "\n",
        "    def _feat_obv_div(self, window=10):\n",
        "        name = \"OBV_div\"\n",
        "        if name in self.df: return\n",
        "        sign = np.sign(self.df[\"close\"].diff())\n",
        "        obv = (sign * self.df[\"volume\"]).cumsum()\n",
        "        price_chg = self.df[\"close\"].pct_change(window)\n",
        "        obv_chg = obv.pct_change(window)\n",
        "        self.df[name] = price_chg - obv_chg\n",
        "\n",
        "    def _feat_rsi_slope(self, rsi_p=14, diff_win=5):\n",
        "        name = \"RSI_slope\"\n",
        "        if name in self.df: return\n",
        "        delta = self.df[\"close\"].diff()\n",
        "        gain = delta.clip(lower=0).rolling(rsi_p).mean()\n",
        "        loss = -delta.clip(lower=0).rolling(rsi_p).mean()\n",
        "        rsi = 100 - 100 / (1 + gain / (loss + 1e-10))\n",
        "        self.df[name] = rsi.diff(diff_win)\n",
        "\n",
        "    def _feat_vol_decay(self, window=20):\n",
        "        name = \"Vol_Decay\"\n",
        "        if name in self.df: return\n",
        "        vol_ema = self.df[\"volume\"].ewm(span=window).mean()\n",
        "        self.df[name] = self.df[\"volume\"] / vol_ema - 1\n",
        "\n",
        "    def _feat_accel_decay(self, window=10):\n",
        "        name = \"Accel_Decay\"\n",
        "        if name in self.df: return\n",
        "        vel = self.df[\"close\"].diff(window)\n",
        "        accel = vel.diff(window)\n",
        "        self.df[name] = accel / (vel.abs() + 1e-10)\n",
        "\n",
        "    def _feat_entropy_roll(self, window: int = 50):\n",
        "        name = \"Entropy_roll\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0.0).to_numpy(dtype=np.float32)\n",
        "        ent = _rolling_entropy_exact_numba(ret, window)\n",
        "        self.df[name] = ent\n",
        "\n",
        "    def _feat_wavelet_var(self, short_win=10, long_win=50):\n",
        "        name = \"Wavelet_Var_Ratio\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0)\n",
        "        var_short = ret.rolling(short_win).var()\n",
        "        var_long = ret.rolling(long_win).var()\n",
        "        self.df[name] = var_short / (var_long + 1e-10)\n",
        "\n",
        "    def _feat_autocorr(self, window=50):\n",
        "        name = \"Autocorr_Lag1\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0)\n",
        "        arr = ret.to_numpy()  # Use to_numpy() for compatibility\n",
        "        autocorrs = rolling_autocorr(arr, window)\n",
        "        self.df[name] = autocorrs\n",
        "\n",
        "    def _feat_beta(self, window=50):\n",
        "        name = \"Beta_Market\"\n",
        "        if name in self.df or \"market_close\" not in self.df:\n",
        "            return\n",
        "        ret_stock = self.df[\"close\"].pct_change().fillna(0)\n",
        "        ret_market = self.df[\"market_close\"].pct_change().fillna(0)\n",
        "        cov = ret_stock.rolling(window).cov(ret_market)\n",
        "        var_market = ret_market.rolling(window).var()\n",
        "        self.df[name] = cov / (var_market + 1e-10)\n",
        "\n",
        "    def _feat_peak_squeeze_curvature(self,\n",
        "                                vel_win: int = 5,\n",
        "                                acc_win: int = 5,\n",
        "                                vol_win: int = 20,\n",
        "                                atr_win: int = 14,\n",
        "                                z_win : int = 60):\n",
        "        \"\"\"\n",
        "        Возвращает 3 колонки:\n",
        "        PSC_raw, PSC_z, PSC_sigmoid ∈ [0,1]\n",
        "        \"\"\"\n",
        "        name = \"PSC\"\n",
        "        cols_need = {\"PSC_raw\",\"PSC_z\",\"PSC_sigmoid\"}\n",
        "        if cols_need.issubset(self.df.columns): return\n",
        "        c = self.df['close']\n",
        "\n",
        "        # 1) speed & accel\n",
        "        speed  = c.pct_change(vel_win).fillna(0)\n",
        "        accel  = speed.diff(acc_win).fillna(0)\n",
        "        curvature = accel / (speed.abs() + 1e-10)\n",
        "\n",
        "        # 2) squeeze = ATR_norm ↘ & HV_norm ↘\n",
        "        h,l = self.df['high'], self.df['low']\n",
        "        tr = pd.concat([h-l, (h-c.shift()).abs(), (l-c.shift()).abs()], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_win).mean()\n",
        "        hv  = c.pct_change().rolling(vol_win).std()\n",
        "        squeeze = - (atr / (c+1e-10)).diff().clip(upper=0)   # падение ATR\n",
        "        squeeze += - hv.diff().clip(upper=0)                 # падение HV\n",
        "        squeeze /= 2\n",
        "\n",
        "        # 3) агрегируем\n",
        "        raw = 0.6*curvature + 0.4*squeeze\n",
        "\n",
        "        # 4) z-score + σ(z)\n",
        "        mu  = raw.rolling(z_win).mean()\n",
        "        std = raw.rolling(z_win).std()\n",
        "        z = (raw - mu)/(std + 1e-9)\n",
        "        sigm = 1/(1+np.exp(-z))\n",
        "\n",
        "        self.df[f'{name}_raw']     = raw\n",
        "        self.df[f'{name}_z']       = z.clip(-5, 5)\n",
        "        self.df[f'{name}_sigmoid'] = sigm\n",
        "\n",
        "\n",
        "def calculate_metrics(test_data, y_test, y_pred, target_column='normalized_target'):\n",
        "    \"\"\"\n",
        "    Функция для расчета метрик по данным теста и предсказаниям модели.\n",
        "\n",
        "    Параметры:\n",
        "    - test_data: pd.DataFrame — тестовые данные с колонками batch, high, close и другими.\n",
        "    - y_test: pd.Series или np.array — фактические значения целевой переменной.\n",
        "    - y_pred: pd.Series или np.array — предсказанные моделью значения.\n",
        "    - target_column: str — название колонки целевой переменной в test_data.\n",
        "\n",
        "    Возвращает:\n",
        "    - avg_mse: float — среднеквадратическая ошибка.\n",
        "    - avg_r2: float — средняя R².\n",
        "    - std_r2: float — стандартное отклонение R².\n",
        "    - corr_mean: float — средняя корреляция.\n",
        "    - corr_std: float — стандартное отклонение корреляции.\n",
        "    - avg_missed: float — средний процент упущенной прибыли.\n",
        "    \"\"\"\n",
        "    # Инициализация метрик\n",
        "    mse_scores, r2_scores, corr_scores, missed_pnl = [], [], [], []\n",
        "\n",
        "    # Расчет корреляции целевой переменной и предсказаний\n",
        "    y_pred_series = pd.Series(y_pred, index=y_test.index)\n",
        "    corr_score = test_data[target_column].corr(y_pred_series)\n",
        "    corr_scores.append(corr_score)\n",
        "\n",
        "    # MSE и R2\n",
        "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
        "    r2_scores.append(r2_score(y_test, y_pred))\n",
        "\n",
        "    # Расчет missed_pnl для каждого batch\n",
        "    \"\"\"for batch in test_data['batch'].unique():\n",
        "        mask = test_data['batch'] == batch\n",
        "        max_high = test_data.loc[mask, 'high'].max()\n",
        "        pred = y_pred[mask]  # предполагается, что y_pred соответствует normalized_target\n",
        "        sell_idx = np.argmin(pred)  # продажа на минимальном предсказанном значении\n",
        "        sell_price = test_data.loc[mask].iloc[sell_idx]['close']\n",
        "        missed = (max_high - sell_price) / (max_high - test_data.loc[mask].iloc[0]['close'])  # % упущенной прибыли\n",
        "        missed_pnl.append(missed)\"\"\"\n",
        "\n",
        "    # Усреднение метрик\n",
        "    avg_mse = float(np.mean(mse_scores))\n",
        "    avg_r2 = float(np.mean(r2_scores))\n",
        "    std_r2 = float(np.std(r2_scores))\n",
        "    corr_mean = float(np.mean(corr_scores))\n",
        "    corr_std = float(np.std(corr_scores))\n",
        "    #avg_missed = float(np.mean(missed_pnl))\n",
        "\n",
        "    # Проверка на корректность результатов\n",
        "    if np.isfinite([avg_mse, avg_r2, std_r2, corr_mean, corr_std]).all(): #avg_missed\n",
        "        return avg_mse, avg_r2, std_r2, corr_mean, corr_std, #avg_missed\n",
        "    else:\n",
        "        return float('inf'), float('inf'), float('inf'), float('inf'), float('inf'), float('inf')\n",
        "\n",
        "def prepare_data(df, target_col):\n",
        "    \"\"\"\n",
        "    Подготавливает данные: разделяет на числовые и категориальные признаки, создает конвейер преобразования.\n",
        "    \"\"\"\n",
        "    if type(target_col) == str:\n",
        "        df.dropna(inplace=True)\n",
        "        X = df.drop([target_col, 'batch'], axis=1)\n",
        "        y = df[target_col]\n",
        "    elif type(target_col) == list:\n",
        "        df.dropna(inplace=True)\n",
        "        X = df.drop(target_col+['batch'], axis=1)\n",
        "        y = df[target_col]\n",
        "\n",
        "    # Разделение на числовые и категориальные признаки\n",
        "    numeric_features = X.select_dtypes(include=['int64', 'float64', 'float32', 'int32']).columns\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Создание конвейера преобразования\n",
        "    preprocessing = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', Pipeline([\n",
        "                ('scaler', RobustScaler()),\n",
        "                ('normalize', PowerTransformer(method='yeo-johnson')),\n",
        "            ]), numeric_features),\n",
        "            ('cat', Pipeline([\n",
        "                ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "            ]), categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return X, y, preprocessing\n",
        "\n",
        "\n",
        "def calculate_indicators_pred(df, features, params=None, ticker=None, mode=None, multy=False):\n",
        "\n",
        "    fc = FeatureCalculatorForRegression(df, ticker)\n",
        "    if mode==None:\n",
        "        df1 = fc.calculate_features(params=params, required_features=features)\n",
        "    else:\n",
        "        df1 = fc.calculate_all_possible_features()\n",
        "    features = ['open', 'close', 'high', 'low', 'volume', 'ma', 'pmax'] #time\n",
        "    df1['regime'] = df1['regime'].astype('object')\n",
        "    df1 = df1[df1['trade_bars_counter']>=0]\n",
        "    df1['trade_bars_counter'] = df1['trade_bars_counter'].astype('int')\n",
        "    df1 = df1.drop(features, axis=1)\n",
        "    #df1 = df1.dropna()\n",
        "    return df1, fc._timings\n",
        "\n",
        "def sample_feature_params(params) -> dict:\n",
        "        \"\"\"\n",
        "        Draws *one* sample of the whole feature-engineering hyper-parameter set.\n",
        "        Rule of thumb for ranges:\n",
        "          • lower bound = ‘sane minimum‘ from domain knowledge\n",
        "          • upper bound = ‘sane maximum’\n",
        "        Adjust them if you feel the search space is too wide or too narrow.\n",
        "        \"\"\"\n",
        "        # ---- helpers for monotone constraints ----------------------------------\n",
        "        fast  = params['macd_fast']\n",
        "        slow  = params['macd_slow']\n",
        "\n",
        "        slope_lag_min = params['slope_lag_min']\n",
        "        slope_lag     = params['slope_lag']\n",
        "\n",
        "        # ---- finally compose the nested dict -----------------------------------\n",
        "        return {\n",
        "            'base': {\n",
        "                'medprice': params['medprice']\n",
        "            },\n",
        "            'macd': {\n",
        "                'fast'      : fast,\n",
        "                'slow'      : slow,\n",
        "                'signal'    : params['macd_signal'],\n",
        "                'macd_roll' : params['macd_roll']\n",
        "            },\n",
        "            'overbought': {\n",
        "                'rsi_p'         : params['rsi_p'],\n",
        "                'stoch_p'       : params['stoch_p'],\n",
        "                'oversold_roll' : params['oversold_roll']\n",
        "            },\n",
        "            'madist': {\n",
        "                'span_lenght'   : params['madist_span'],\n",
        "                'madist_lenght' : params['madist_len']\n",
        "            },\n",
        "            'mean_reversion': {\n",
        "                'window' : params['mr_window']\n",
        "            },\n",
        "            'fear_greed': {\n",
        "                'greed_pct'    : params['fg_greed_pct'],\n",
        "                'volume_ratio_scr' : params['fg_vol_ratio'],\n",
        "                'window'       : params['fg_window'],\n",
        "                'greed_roll'   : params['fg_roll']\n",
        "            },\n",
        "            'price_variation': {\n",
        "                'variation_lenght': params['pv_len']\n",
        "            },\n",
        "            'pmax_ma': {\n",
        "                'pmax_ma_lenght'      : params['pmax_len'],\n",
        "                'pmax_ma_lenght_roll' : params['pmax_roll']\n",
        "            },\n",
        "            'slope': {\n",
        "                'slope_lag'     : slope_lag,\n",
        "                'slope_lag_min' : slope_lag_min,\n",
        "                'sloap_pct'     : params['slope_pct'],\n",
        "                'sloap_roll'    : params['slope_roll']\n",
        "            },\n",
        "            # _trade_duration_features – no params\n",
        "        }\n",
        "\n",
        "def build_feature_params(\n",
        "    flat_params: Dict[str, Any],\n",
        "    extra_alias: Optional[Dict[str, Tuple[str, str | None]]] = None\n",
        ") -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Преобразует «плоский» словарь от Optuna в структуру,\n",
        "    которую понимает FeatureCalculatorForRegression.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Базовая явная таблица соответствий\n",
        "    alias: Dict[str, Tuple[str, str | None]] = {\n",
        "        'hp_lamb'          : ('hp_trend'           , 'lamb'),\n",
        "        'ea_pct'           : ('ema_acceleration'   , 'pct_window'),\n",
        "        'ea_ema'           : ('ema_acceleration'   , 'ema_window'),\n",
        "        'mr_window'        : ('Mean_Reversion'     , 'window'),\n",
        "        'ag_window'        : ('Asset_Growth'       , 'window'),\n",
        "        'medprice'         : ('MEDPRICE'           , 'medprice'),\n",
        "        'bb_window'        : ('BB_Width'           , 'bb_window'),\n",
        "        'macd_fast'        : ('MACD'               , 'fast'),\n",
        "        'macd_slow'        : ('MACD'               , 'slow'),\n",
        "        'macd_signal'      : ('MACD'               , 'signal'),\n",
        "        'fg_window'        : ('Fear_Greed'         , 'window'),\n",
        "        'atr_window'       : ('ATR_norm'           , 'atr_window'),\n",
        "        'vr_window'        : ('volume_ratio'       , 'window'),\n",
        "        'madist_span'      : ('Price_MADist%'      , 'span_lenght'),\n",
        "        'slope_lag'        : ('slope_trend'        , 'slope_lag'),\n",
        "        'slope_lag_min'    : ('slope_trend'        , 'slope_lag'),\n",
        "        'rsi_p'            : ('Overbought_Oversold', 'rsi_p'),\n",
        "        'stoch_p'          : ('Overbought_Oversold', 'stoch_p'),\n",
        "        'pmax_len'         : ('pmax_norm'          , 'pmax_ma_length'),\n",
        "        'pmax_roll'        : ('pmax_norm'          , 'pmax_ma_length_roll'),\n",
        "        'pc_window'        : ('pmax_norm'          , 'pct_window'),\n",
        "        'ema_trend_span'   : ('ema_trend'          , 'span'),\n",
        "        'ema_trend_pct'    : ('ema_trend'          , 'pct_window'),\n",
        "        'stat_window'      : ('stat_window', None),\n",
        "        # --- новые алиасы ---\n",
        "        'roc_window'        : ('ROC'          , 'window'),\n",
        "        'willr_window'      : ('WILLR'          , 'window'),\n",
        "        'fractal_short_win' : ('Fractal_Dim', 'short_win'),\n",
        "        'fractal_long_win'  : ('Fractal_Dim', 'long_win'),\n",
        "        'peak_price_win'    : ('Peak_Exhaustion_Score', 'price_win'),\n",
        "        'peak_mom_win'      : ('Peak_Exhaustion_Score', 'mom_win'),\n",
        "        'peak_vol_win'      : ('Peak_Exhaustion_Score', 'vol_win'),\n",
        "        'peak_atr_win'      : ('Peak_Exhaustion_Score', 'atr_win'),\n",
        "        'peak_z_win'        : ('Peak_Exhaustion_Score', 'z_win'),\n",
        "        'bb_window'         : ('%B_BB', 'window'),\n",
        "        'bb_std_mult'       : ('%B_BB', 'std_mult'),\n",
        "        'kurt_window'       : ('Kurtosis_roll', 'window'),\n",
        "        'obv_window'        : ('OBV_div', 'window'),\n",
        "        'rsi_slope_rsi_p'   : ('RSI_slope', 'rsi_p'),\n",
        "        'rsi_diff_win'      : ('RSI_slope', 'diff_win'),\n",
        "        'voldec_window'     : ('Vol_Decay', 'window'),\n",
        "        'acceldec_window'   : ('Accel_Decay', 'window'),\n",
        "        'ent_window'        : ('Entropy_roll', 'window'),\n",
        "        'wlt_short_win'     : ('Wavelet_Var_Ratio', 'short_win'),\n",
        "        'wlt_long_win'      : ('Wavelet_Var_Ratio', 'long_win'),\n",
        "        'acorr_window'      : ('Autocorr_Lag1', 'window'),\n",
        "        'beta_window'       : ('Beta_Market', 'window'),\n",
        "        'psc_vel_win'       : ('PSC', 'vel_win'),\n",
        "        'psc_acc_win'       : ('PSC', 'acc_win'),\n",
        "        'psc_vol_win'       : ('PSC', 'vol_win'),\n",
        "        'psc_atr_win'       : ('PSC', 'atr_win'),\n",
        "        'psc_z_win'         : ('PSC', 'z_win'),\n",
        "    }\n",
        "\n",
        "    # 2. Пользовательские переопределения\n",
        "    if extra_alias:\n",
        "        alias.update(extra_alias)\n",
        "\n",
        "    # 3. Автоматический разбор префиксов (fallback)\n",
        "    prefix_map: Dict[str, str] = {\n",
        "        'macd'        : 'MACD',\n",
        "        'hp'          : 'hp_trend',\n",
        "        'ea'          : 'ema_acceleration',\n",
        "        'mr'          : 'Mean_Reversion',\n",
        "        'ag'          : 'Asset_Growth',\n",
        "        'bb'          : 'BB_Width',\n",
        "        'fg'          : 'Fear_Greed',\n",
        "        'atr'         : 'ATR_norm',\n",
        "        'vr'          : 'volume_ratio',\n",
        "        'madist'      : 'Price_MADist%',\n",
        "        'slope'       : 'slope_trend',\n",
        "        'pmax'        : 'pmax_norm',\n",
        "        'ema_trend'   : 'ema_trend',\n",
        "        'rsi'         : 'Overbought_Oversold',\n",
        "        'stoch'       : 'Overbought_Oversold',\n",
        "        'fractal'     : 'Fractal_Dim',\n",
        "        'peak'        : 'Peak_Exhaustion_Score',\n",
        "        'bb'          : '%B_BB',\n",
        "        'kurt'        : 'Kurtosis_roll',\n",
        "        'obv'         : 'OBV_div',\n",
        "        'rsi_slope'   : 'RSI_slope',\n",
        "        'voldec'      : 'Vol_Decay',\n",
        "        'acceldec'    : 'Accel_Decay',\n",
        "        'entropy'     : 'Entropy_roll',\n",
        "        'wavelet'     : 'Wavelet_Var_Ratio',\n",
        "        'acorr'       : 'Autocorr_Lag1',\n",
        "        'beta'        : 'Beta_Market',\n",
        "        'psc'         : 'PSC',\n",
        "    }\n",
        "\n",
        "    nested: Dict[str, Dict[str, Any]] = defaultdict(dict)\n",
        "\n",
        "    for key, val in flat_params.items():\n",
        "\n",
        "        # 3.1 Явное соответствие\n",
        "        if key in alias:\n",
        "            prim, arg = alias[key]\n",
        "            if prim == 'stat_window' or arg is None:\n",
        "                nested['stat_window'] = val\n",
        "            else:\n",
        "                nested[prim][arg] = val\n",
        "            continue\n",
        "\n",
        "        # 3.2 Игнорируем вспомогательные ключи вида *_min, *_max, если\n",
        "        #     они не нужны никакому примитиву.\n",
        "        if key.endswith('_min') or key.endswith('_max'):\n",
        "            continue\n",
        "\n",
        "        # 3.3 Fallback-разбор _\n",
        "        if '_' in key:\n",
        "            prefix, arg = key.split('_', 1)\n",
        "            if prefix in prefix_map:\n",
        "                nested[prefix_map[prefix]][arg] = val\n",
        "                continue\n",
        "\n",
        "        # 3.4 Неизвестный ключ — игнорируем или логируем\n",
        "        # print(f'Warning: parameter \"{key}\" was not mapped')\n",
        "\n",
        "    return {p: d for p, d in nested.items()}\n",
        "\n",
        "_ORIG_INTERP = F.interpolate\n",
        "\n",
        "\n",
        "def _collapse_pred_to_bt(y_pred: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Приводим предсказание к виду (B, T), считая последнюю ось временем (горизонтом).\n",
        "    Все промежуточные оси (кроме batch=ось 0 и time=последняя ось) усредняем.\n",
        "    Пример: (B, 1, 4, 10) -> mean по осям (1,2) -> (B,10)\n",
        "    (B, 10) -> ок\n",
        "    (B, 1, 10) -> squeeze -> (B,10)\n",
        "    \"\"\"\n",
        "    if not isinstance(y_pred, torch.Tensor):\n",
        "        raise TypeError(f\"y_pred must be a tensor, got {type(y_pred)}\")\n",
        "\n",
        "    # Сначала уберём все единичные оси\n",
        "    if any(s == 1 for s in y_pred.shape[1:-1]):\n",
        "        # squeeze не трогает последнюю ось, если она не равна 1\n",
        "        y_pred = y_pred.squeeze()\n",
        "        # Если squeeze убрал не только единичные, но и привёл к (B, T) — хорошо.\n",
        "\n",
        "    if y_pred.dim() == 1:\n",
        "        # (B,) — интерпретируем как T=1, сделаем (B,1)\n",
        "        y_pred = y_pred.unsqueeze(-1)\n",
        "        return y_pred\n",
        "\n",
        "    if y_pred.dim() == 2:\n",
        "        # (B, T) — уже как надо\n",
        "        return y_pred\n",
        "\n",
        "    # Если размерностей больше 2: считаем last dim = time, batch = 0\n",
        "    # Все промежуточные оси схлопываем усреднением\n",
        "    reduce_dims = tuple(range(1, y_pred.dim() - 1))\n",
        "    if len(reduce_dims) > 0:\n",
        "        y_pred = y_pred.mean(dim=reduce_dims)\n",
        "    # На выходе (B, T)\n",
        "    if y_pred.dim() != 2:\n",
        "        # На всякий случай добьёмся (B, T)\n",
        "        y_pred = y_pred.view(y_pred.size(0), -1)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def _install_safe_interpolate_patch():\n",
        "    \"\"\"\n",
        "    Патч делает F.interpolate детерминированным при включённом torch.use_deterministic_algorithms(True)\n",
        "    для CUDA и режимов linear/bilinear/bicubic, прогоняя вычисление на CPU.\n",
        "    Идемпотентен и не меняет сигнатуру.\n",
        "    \"\"\"\n",
        "    if getattr(F.interpolate, \"_is_deterministic_wrapper\", False):\n",
        "        return\n",
        "\n",
        "    _orig_interpolate = F.interpolate\n",
        "\n",
        "    # Какие режимы считаем потенциально недетерминируемыми на CUDA\n",
        "    _CUDA_UNSAFE_MODES = {\"linear\", \"bilinear\", \"bicubic\"}  # 1d/2d/2d\n",
        "\n",
        "    def _needs_cpu_fallback(input, mode):\n",
        "        if not torch.is_tensor(input):\n",
        "            return False\n",
        "        if input.is_cuda and mode in _CUDA_UNSAFE_MODES:\n",
        "            # upsample_linear1d_backward_out_cuda и др. — недетерминируемы\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    @functools.wraps(_orig_interpolate)\n",
        "    def _deterministic_interpolate(\n",
        "        input: torch.Tensor,\n",
        "        size=None,\n",
        "        scale_factor=None,\n",
        "        mode=\"nearest\",\n",
        "        align_corners=None,\n",
        "        recompute_scale_factor=None,\n",
        "        antialias=False,\n",
        "    ):\n",
        "        # Если не нужно, просто вызовем оригинал\n",
        "        if not _needs_cpu_fallback(input, mode):\n",
        "            return _orig_interpolate(\n",
        "                input,\n",
        "                size=size,\n",
        "                scale_factor=scale_factor,\n",
        "                mode=mode,\n",
        "                align_corners=align_corners,\n",
        "                recompute_scale_factor=recompute_scale_factor,\n",
        "                antialias=antialias,\n",
        "            )\n",
        "\n",
        "        # CUDA + linear/bilinear/bicubic → CPU fallback\n",
        "        x = input\n",
        "        dev = x.device\n",
        "        orig_dtype = x.dtype\n",
        "\n",
        "        # Для стабильности переводим в float32 на CPU\n",
        "        x_cpu = x.detach().to(\"cpu\", dtype=torch.float32).requires_grad_(x.requires_grad)\n",
        "\n",
        "        y_cpu = _orig_interpolate(\n",
        "            x_cpu,\n",
        "            size=size,\n",
        "            scale_factor=scale_factor,\n",
        "            mode=mode,\n",
        "            align_corners=align_corners,\n",
        "            recompute_scale_factor=recompute_scale_factor,\n",
        "            antialias=antialias,\n",
        "        )\n",
        "\n",
        "        # Возвращаем на исходное устройство и тип\n",
        "        y = y_cpu.to(dev, dtype=orig_dtype)\n",
        "\n",
        "        return y\n",
        "\n",
        "    _deterministic_interpolate._is_deterministic_wrapper = True  # type: ignore[attr-defined]\n",
        "    F.interpolate = _deterministic_interpolate\n",
        "\n",
        "\n",
        "_install_safe_interpolate_patch()\n",
        "\n",
        "\n",
        "def _unpack_pf_batch(batch):\n",
        "    \"\"\"\n",
        "    Унифицированная распаковка батча из TimeSeriesDataSet.to_dataloader(...)\n",
        "    Возвращает: x (dict), y (Tensor|None), weight (Tensor|None)\n",
        "    \"\"\"\n",
        "    if isinstance(batch, (list, tuple)):\n",
        "        if len(batch) == 3:\n",
        "            x, y, weight = batch\n",
        "        elif len(batch) == 2:\n",
        "            x, y = batch\n",
        "            weight = None\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected batch tuple length: {len(batch)}\")\n",
        "    elif isinstance(batch, dict):\n",
        "        # На всякий случай поддержим dict → возьмём таргет из decoder_target, если есть\n",
        "        x = batch\n",
        "        y = batch.get(\"decoder_target\", None)\n",
        "        weight = None\n",
        "    else:\n",
        "        raise TypeError(f\"Unexpected batch type: {type(batch)}\")\n",
        "    return x, y, weight\n",
        "\n",
        "\n",
        "# F.interpolate = _deterministic_interpolate\n",
        "\n",
        "\n",
        "def _extract_pred_tensor(y_pred):\n",
        "    # извлекаем тензор предикта из любых обёрток\n",
        "    if isinstance(y_pred, dict):\n",
        "        for key in (\"prediction\", \"output\", \"decoder_output\"):\n",
        "            if key in y_pred and torch.is_tensor(y_pred[key]):\n",
        "                return y_pred[key]\n",
        "        # если не нашли — попробуем fallback: первый тензор в dict\n",
        "        for v in y_pred.values():\n",
        "            if torch.is_tensor(v):\n",
        "                return v\n",
        "        raise ValueError(\"Could not extract prediction tensor from dict y_pred.\")\n",
        "\n",
        "    if isinstance(y_pred, (list, tuple)):\n",
        "        # обычно y_pred[0] — предсказание\n",
        "        return y_pred[0]\n",
        "\n",
        "    if torch.is_tensor(y_pred):\n",
        "        return y_pred\n",
        "\n",
        "    raise TypeError(f\"Unsupported y_pred type: {type(y_pred)}\")\n",
        "\n",
        "\n",
        "class EventTimeSeriesSplit(BaseCrossValidator):\n",
        "    \"\"\"\n",
        "    Кросс-валидация по событиям (batch), хронологическая, с эмбарго.\n",
        "    groups: массив той же длины, что и df, со значениями batch\n",
        "    times:  массив pd.Timestamp (или sortable), та же длина, что и df\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_splits: int = 5, embargo_events: int = 1, min_train_events: int = 5):\n",
        "        self.n_splits = n_splits\n",
        "        self.embargo_events = embargo_events\n",
        "        self.min_train_events = min_train_events\n",
        "\n",
        "    def get_n_splits(self, X=None, y=None, groups=None):\n",
        "        return self.n_splits\n",
        "\n",
        "    def split(self, X, y=None, groups=None, times: Optional[pd.Series] = None) -> Iterator[\n",
        "        Tuple[np.ndarray, np.ndarray]]:\n",
        "        if groups is None or times is None:\n",
        "            raise ValueError(\"Pass groups=batch and times=time columns\")\n",
        "\n",
        "        groups = np.asarray(groups)\n",
        "        times = pd.to_datetime(times)\n",
        "\n",
        "        # порядок событий по старт-времени\n",
        "        df_tmp = pd.DataFrame({\"group\": groups, \"time\": times}).reset_index(names=\"row_idx\")\n",
        "        first_time = df_tmp.groupby(\"group\")[\"time\"].min().sort_values()\n",
        "        uniq_groups = first_time.index.to_numpy()\n",
        "\n",
        "        n_events = len(uniq_groups)\n",
        "        if n_events < (self.n_splits + self.min_train_events):\n",
        "            # уменьшаем число сплитов, если событий мало\n",
        "            eff_splits = max(1, n_events - self.min_train_events)\n",
        "        else:\n",
        "            eff_splits = self.n_splits\n",
        "\n",
        "        # на каждой итерации расширяем train вправо\n",
        "        for split_idx in range(1, eff_splits + 1):\n",
        "            # доля событий для валидации\n",
        "            val_events = max(1, n_events // (eff_splits + 1))\n",
        "            train_end = n_events - (eff_splits - split_idx + 1) * val_events\n",
        "\n",
        "            if train_end < self.min_train_events:\n",
        "                continue\n",
        "\n",
        "            # эмбарго\n",
        "            embargoed_end = max(0, train_end - self.embargo_events)\n",
        "\n",
        "            train_groups = uniq_groups[:embargoed_end]\n",
        "            val_groups = uniq_groups[train_end: train_end + val_events]\n",
        "\n",
        "            train_idx = df_tmp.index[df_tmp[\"group\"].isin(train_groups)].to_numpy()\n",
        "            val_idx = df_tmp.index[df_tmp[\"group\"].isin(val_groups)].to_numpy()\n",
        "\n",
        "            # индексы исходной X (если это DataFrame — у вас совпадают позиции с row_idx)\n",
        "            yield (train_idx, val_idx)\n",
        "\n",
        "\n",
        "class MinimalRichProgressBar(RichProgressBar):\n",
        "    def on_validation_start(self, trainer, pl_module):\n",
        "        pass\n",
        "\n",
        "    def on_validation_batch_start(self, trainer, pl_module, batch, batch_idx):\n",
        "        pass\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        pass\n",
        "\n",
        "\n",
        "class NoValidationBar(TQDMProgressBar):\n",
        "    def init_validation_tqdm(self):\n",
        "        # возвращаем полностью отключённый tqdm для валидации\n",
        "        return tqdm_class(disable=True)\n",
        "\n",
        "class CustomTFT(TemporalFusionTransformer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.mask_prob = kwargs.pop(\"mask_prob\", 0.05)\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self._val_preds = []\n",
        "        self._val_trues = []\n",
        "        self._val_gids = []\n",
        "        self.scheduled_prob = 0.0\n",
        "\n",
        "        safe_val = torch.tensor(\n",
        "            torch.finfo(torch.float16).min,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        m = self.multihead_attn.attention\n",
        "        if hasattr(m, \"mask_bias\") and not isinstance(m.mask_bias, torch.Tensor):\n",
        "            delattr(m, \"mask_bias\")\n",
        "        m.register_buffer(\"mask_bias\", safe_val)\n",
        "\n",
        "    def on_epoch_start(self, trainer, pl_module):\n",
        "        if trainer.max_epochs > 0:\n",
        "            self.scheduled_prob = min(1.0, trainer.current_epoch / (trainer.max_epochs * 0.8))\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, weight = _unpack_pf_batch(batch)\n",
        "\n",
        "        if torch.rand(1).item() < self.mask_prob and \"encoder_target\" in x:\n",
        "            enc = x[\"encoder_target\"]\n",
        "            noise = torch.normal(0, 0.15, size=enc.shape, device=enc.device)\n",
        "            x = {**x, \"encoder_target\": noise}\n",
        "            del enc, noise\n",
        "\n",
        "        if torch.rand(1).item() < self.scheduled_prob and y is not None:\n",
        "            with torch.no_grad():\n",
        "                out = self(x)\n",
        "                y_pred = self.loss.to_prediction(out)\n",
        "                y_bt = _collapse_pred_to_bt(y_pred)\n",
        "                dec_tgt = y_bt if y_bt.dim() == 2 else y_bt.unsqueeze(-1)\n",
        "                x['decoder_target'] = dec_tgt.detach()\n",
        "                del out, y_pred, y_bt, dec_tgt\n",
        "\n",
        "        batch = (x, y, weight) if weight is not None else (x, y)\n",
        "        result = super().training_step(batch, batch_idx)\n",
        "\n",
        "        if batch_idx % 50 == 0:  # Rare for speed\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, weight = _unpack_pf_batch(batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out_temp = self(x)\n",
        "            y_pred_temp = self.loss.to_prediction(out_temp)\n",
        "            y_bt_temp = _collapse_pred_to_bt(y_pred_temp)\n",
        "            del out_temp, y_pred_temp\n",
        "\n",
        "        if \"decoder_target\" in x:\n",
        "            enc_tgt = x.get(\"encoder_target\")\n",
        "            if enc_tgt is not None:\n",
        "                batch_mean = enc_tgt.mean(dim=-1, keepdim=True)\n",
        "                batch_std = enc_tgt.std(dim=-1, keepdim=True) + 1e-8\n",
        "                mean_tensor = batch_mean.expand_as(x[\"decoder_target\"])\n",
        "                std_tensor = (0.1 * batch_std).expand_as(x[\"decoder_target\"])\n",
        "                noise_fill = torch.normal(mean_tensor, std_tensor)\n",
        "                del batch_mean, std_tensor, mean_tensor\n",
        "            else:\n",
        "                dec_tgt = x[\"decoder_target\"]\n",
        "                device = dec_tgt.device\n",
        "                noise_fill = torch.full_like(dec_tgt, self.global_target_mean)\n",
        "                batch_size = dec_tgt.size(0)\n",
        "                batch_std = torch.full((batch_size,), self.global_target_std, device=device).unsqueeze(-1)\n",
        "\n",
        "            if torch.rand(1).item() < self.scheduled_prob:\n",
        "                decoder_fill = y_bt_temp\n",
        "            else:\n",
        "                jitter_size = noise_fill.shape\n",
        "                additional_jitter = torch.randn(jitter_size, device=noise_fill.device) * (0.05 * batch_std.expand_as(noise_fill))\n",
        "                decoder_fill = noise_fill + additional_jitter\n",
        "                del additional_jitter, noise_fill\n",
        "\n",
        "            decoder_fill = torch.clamp(decoder_fill, -1.0, 1.0)\n",
        "            x[\"decoder_target\"] = decoder_fill\n",
        "            del y_bt_temp, batch_std\n",
        "\n",
        "        out = self(x)\n",
        "        y_pred_raw = self.loss.to_prediction(out)\n",
        "        del out\n",
        "\n",
        "        y_pred_metrics = torch.clamp(y_pred_raw, -1.0, 1.0)\n",
        "        del y_pred_raw\n",
        "\n",
        "        y_actual = y if y is not None else x.get(\"decoder_target\")\n",
        "        if y_actual is None:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            y_pred_aligned, y_actual_aligned = _align_pred_target(y_pred_metrics, y_actual)\n",
        "            del y_pred_metrics, y_actual\n",
        "        except Exception:\n",
        "            return\n",
        "\n",
        "        self._val_preds.append(y_pred_aligned.detach())\n",
        "        self._val_trues.append(y_actual_aligned.detach())\n",
        "        del y_pred_aligned, y_actual_aligned\n",
        "\n",
        "        gid = x.get(\"group_ids\")\n",
        "        if gid is not None and isinstance(gid, torch.Tensor):\n",
        "            self._val_gids.append(gid.detach())\n",
        "        else:\n",
        "            self._val_gids.append(None)\n",
        "\n",
        "        if batch_idx % 50 == 0:  # Rare for speed\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if len(self._val_preds) == 0:\n",
        "            return\n",
        "\n",
        "        yp = torch.cat(self._val_preds, dim=0)\n",
        "        yt = torch.cat(self._val_trues, dim=0)\n",
        "\n",
        "        self._val_preds.clear()\n",
        "        self._val_trues.clear()\n",
        "\n",
        "        se = (yp - yt) ** 2\n",
        "        val_mse = float(se.mean().item())\n",
        "        val_mse_std = float(se.std(unbiased=False).item())\n",
        "        del yp, yt\n",
        "\n",
        "        self.log(\"val_mse\", val_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_mse_std\", val_mse_std, prog_bar=False, on_step=False, on_epoch=True)\n",
        "\n",
        "        has_any_gid = any(g is not None for g in self._val_gids)\n",
        "        if has_any_gid:\n",
        "            gid_list = []\n",
        "            valid = True\n",
        "            for g in self._val_gids:\n",
        "                if g is None:\n",
        "                    valid = False\n",
        "                    break\n",
        "                gid_list.append(g)\n",
        "\n",
        "            if valid and len(gid_list) > 0:\n",
        "                gid_all = torch.cat(gid_list, dim=0).numpy().ravel()\n",
        "                se_np = se.numpy().ravel()\n",
        "                del se\n",
        "\n",
        "                if gid_all.shape[0] == se_np.shape[0]:\n",
        "                    uniq = np.unique(gid_all)\n",
        "                    g_mse = [se_np[gid_all == u].mean() for u in uniq if (gid_all == u).any()]\n",
        "                    if len(g_mse) > 0:\n",
        "                        g_mse = np.asarray(g_mse, dtype=float)\n",
        "                        val_mse_group_mean = float(g_mse.mean())\n",
        "                        val_mse_group_std = float(g_mse.std(ddof=0))\n",
        "                        self.log(\"val_mse_group_mean\", val_mse_group_mean, prog_bar=False, on_step=False, on_epoch=True)\n",
        "                        self.log(\"val_mse_group_std\", val_mse_group_std, prog_bar=True, on_step=False, on_epoch=True)\n",
        "                    del g_mse, uniq\n",
        "\n",
        "                del gid_all, se_np\n",
        "\n",
        "        self._val_gids.clear()\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    def log(self, name, value, *args, **kwargs):\n",
        "        if value is None:\n",
        "            return\n",
        "        super().log(name, value, *args, **kwargs)\n",
        "\n",
        "\n",
        "def _worker_init_fn(worker_id: int, seed: int):\n",
        "    \"\"\"\n",
        "    Глобальная функция для инициализации worker-а DataLoader-а.\n",
        "    pickle её «видит» и может передать в подпроцессы.\n",
        "    \"\"\"\n",
        "    set_seeds(seed + worker_id)\n",
        "\n",
        "\n",
        "def _extract_tensor(x, role=\"pred\"):\n",
        "    \"\"\"\n",
        "    Извлекает torch.Tensor из различных контейнеров/структур.\n",
        "    - dict: сперва пробуем ключи, характерные для предсказаний/таргета\n",
        "    - tuple/list: берём первый тензор или первый элемент, приводимый к тензору\n",
        "    - tensor: возвращаем как есть\n",
        "    \"\"\"\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x\n",
        "\n",
        "    if isinstance(x, dict):\n",
        "        # Наиболее типичные ключи в pytorch-forecasting / lightning шагах\n",
        "        preferred_keys = [\n",
        "            \"prediction\", \"pred\", \"output\", \"y_pred\", \"yhat\", \"y\", \"target\"\n",
        "        ]\n",
        "        for k in preferred_keys:\n",
        "            if k in x and isinstance(x[k], torch.Tensor):\n",
        "                return x[k]\n",
        "        # Если значения-словари/кортежи — попробуем рекурсивно\n",
        "        for v in x.values():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                return v\n",
        "            if isinstance(v, (list, tuple, dict)):\n",
        "                try:\n",
        "                    t = _extract_tensor(v, role=role)\n",
        "                    if isinstance(t, torch.Tensor):\n",
        "                        return t\n",
        "                except Exception:\n",
        "                    pass\n",
        "        raise TypeError(f\"Cannot extract tensor from dict for role={role}. Keys={list(x.keys())}\")\n",
        "\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        for item in x:\n",
        "            if isinstance(item, torch.Tensor):\n",
        "                return item\n",
        "        # если нет прямого тензора — попробуем рекурсивно\n",
        "        for item in x:\n",
        "            if isinstance(item, (list, tuple, dict)):\n",
        "                try:\n",
        "                    t = _extract_tensor(item, role=role)\n",
        "                    if isinstance(t, torch.Tensor):\n",
        "                        return t\n",
        "                except Exception:\n",
        "                    pass\n",
        "        raise TypeError(f\"Cannot extract tensor from {type(x)} for role={role}\")\n",
        "\n",
        "    # Последняя попытка — у объектов некоторых библиотек есть .values или .tensor\n",
        "    for attr in (\"values\", \"tensor\", \"data\"):\n",
        "        if hasattr(x, attr):\n",
        "            v = getattr(x, attr)\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                return v\n",
        "\n",
        "    raise TypeError(f\"Unsupported type for tensor extraction (role={role}): {type(x)}\")\n",
        "\n",
        "\n",
        "def _maybe_squeeze_last(x):\n",
        "    \"\"\"\n",
        "    Безопасно убираем последнюю размерность, если она равна 1.\n",
        "    Если x не тензор — возвращаем как есть.\n",
        "    \"\"\"\n",
        "    if not isinstance(x, torch.Tensor):\n",
        "        return x\n",
        "    if x.dim() > 0 and x.size(-1) == 1:\n",
        "        return x.squeeze(-1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _align_pred_target(y_pred, y_actual):\n",
        "    \"\"\"\n",
        "    Приводим предсказания и таргет к совместимым формам для MSE:\n",
        "    - Извлекаем тензоры из возможных контейнеров.\n",
        "    - Сводим предсказание к (B, T_pred) с последней осью как временем.\n",
        "    - Таргет сводим к (B,) или (B, T_act).\n",
        "    - Если таргет (B,) — берём последний горизонт из предсказаний.\n",
        "    - Если таргет (B, T_act) — подгоняем по времени (обрезаем/проверяем равенство).\n",
        "    \"\"\"\n",
        "    # 1) Достаём тензоры\n",
        "    y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "    y_actual = _extract_tensor(y_actual, role=\"target\")\n",
        "\n",
        "    # 2) Сжимаем последнюю единичную ось\n",
        "    y_pred = _maybe_squeeze_last(y_pred)\n",
        "    y_actual = _maybe_squeeze_last(y_actual)\n",
        "\n",
        "    # Быстрый путь: формы совпали\n",
        "    if isinstance(y_pred, torch.Tensor) and isinstance(y_actual, torch.Tensor):\n",
        "        if y_pred.shape == y_actual.shape:\n",
        "            return y_pred, y_actual\n",
        "\n",
        "    # 3) Приводим предсказание к (B, T_pred)\n",
        "    y_pred_bt = _collapse_pred_to_bt(y_pred)  # (B, T_pred)\n",
        "\n",
        "    # 4) Приведём таргет к (B,) или (B, T_act)\n",
        "    if y_actual.dim() == 1:\n",
        "        # (B,) — ожидаем 1 шаг на таргет → берём последний горизонт из предсказаний\n",
        "        if y_pred_bt.dim() != 2 or y_pred_bt.size(0) != y_actual.size(0):\n",
        "            raise ValueError(f\"Batch mismatch: pred={tuple(y_pred_bt.shape)} vs target={tuple(y_actual.shape)}\")\n",
        "        y_pred_aligned = y_pred_bt[:, -1]  # последний шаг горизонта\n",
        "        return y_pred_aligned, y_actual\n",
        "\n",
        "    if y_actual.dim() == 2:\n",
        "        # (B, T_act)\n",
        "        if y_pred_bt.size(0) != y_actual.size(0):\n",
        "            raise ValueError(f\"Batch mismatch: pred={tuple(y_pred_bt.shape)} vs target={tuple(y_actual.shape)}\")\n",
        "        T_pred = y_pred_bt.size(1)\n",
        "        T_act = y_actual.size(1)\n",
        "        if T_pred == T_act:\n",
        "            return y_pred_bt, y_actual\n",
        "        if T_pred > T_act:\n",
        "            # Обрежем последние T_act шагов, чтобы соответствовать таргету\n",
        "            y_pred_bt = y_pred_bt[:, -T_act:]\n",
        "            return y_pred_bt, y_actual\n",
        "        # Если предсказаний по времени меньше, чем в таргете — это логическая ошибка настройки\n",
        "        raise ValueError(\n",
        "            f\"Prediction horizon shorter than target: pred T={T_pred}, target T={T_act} \"\n",
        "            f\"(pred shape={tuple(y_pred_bt.shape)}, target shape={tuple(y_actual.shape)})\"\n",
        "        )\n",
        "\n",
        "    # Случай редкий: если таргет внезапно >2D — пробуем схлопнуть по всем, кроме батча\n",
        "    if y_actual.dim() > 2:\n",
        "        # Схлопнём таргет к (B, T_act) по последней оси\n",
        "        reduce_dims = tuple(range(1, y_actual.dim() - 1))\n",
        "        if len(reduce_dims) > 0:\n",
        "            y_actual_bt = y_actual.mean(dim=reduce_dims)\n",
        "        else:\n",
        "            y_actual_bt = y_actual\n",
        "        # Рекурсивно выровняем теперь как (B, ?)\n",
        "        return _align_pred_target(y_pred_bt, y_actual_bt)\n",
        "\n",
        "    # Если таргет скалярный (редко, но вдруг), расширим до (B,) повтором\n",
        "    if y_actual.dim() == 0:\n",
        "        y_actual = y_actual.expand(y_pred_bt.size(0))\n",
        "        y_pred_aligned = y_pred_bt[:, -1]\n",
        "        return y_pred_aligned, y_actual\n",
        "\n",
        "    # Если сюда дошли — что-то совсем нетипичное\n",
        "    raise ValueError(\n",
        "        f\"Shapes still mismatch after alignment: pred={tuple(y_pred.shape)} vs target={tuple(y_actual.shape)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Фиксируем seeds для воспроизводимости и стабильности\n",
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    pl.seed_everything(seed, verbose=False)\n",
        "\n",
        "\n",
        "class PeakFriendlyHuber(Metric):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        delta: float = 0.5,\n",
        "        peak_thr: float = 0.85,\n",
        "        peak_weight: float = 1.6,  # Увеличено до 1.6 для stronger поощрения пиков\n",
        "        contrast_weight: float = 0.02,\n",
        "        center_band: float = 0.3,\n",
        "        clip_scale: float = 1.5,  # Новый: scale для soft-clip (tanh * scale, чтобы не сжимать середину сильно)\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.delta = float(delta)\n",
        "        self.peak_thr = float(peak_thr)\n",
        "        self.peak_weight = float(peak_weight)\n",
        "        self.contrast_weight = float(contrast_weight)\n",
        "        self.center_band = float(center_band)\n",
        "        self.clip_scale = float(clip_scale)  # Новый параметр\n",
        "        self.mse = MeanSquaredError()\n",
        "\n",
        "    @staticmethod\n",
        "    def _smooth_l1(diff, delta):\n",
        "        absd = diff.abs()\n",
        "        return torch.where(absd < delta, 0.5 * (diff ** 2) / delta, absd - 0.5 * delta)\n",
        "\n",
        "    def to_prediction(self, y_pred):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        return super().to_prediction(y_pred)\n",
        "\n",
        "    def to_quantiles(self, y_pred, quantiles=None, **kwargs):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        return super().to_quantiles(y_pred, quantiles=quantiles, **kwargs)\n",
        "\n",
        "    def loss(self, y_pred, y_actual, **kwargs):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        y_actual = _extract_tensor(y_actual, role=\"target\")\n",
        "        y_pred, y_actual = _align_pred_target(y_pred, y_actual)\n",
        "\n",
        "        # Soft-clip (без изменений)\n",
        "        y_pred = torch.tanh(y_pred * self.clip_scale) / self.clip_scale\n",
        "\n",
        "        diff = y_pred - y_actual\n",
        "        base = self._smooth_l1(diff, self.delta)\n",
        "\n",
        "        # Адаптивный peak_weight: средний по батчу, scale от доли пиков\n",
        "        if self.peak_weight > 1.0:\n",
        "            with torch.no_grad():\n",
        "                peak_mag = torch.relu(y_actual.abs() - self.peak_thr)\n",
        "                peak_frac = (peak_mag > 0).float().mean()  # Доля пиков в батче\n",
        "                adaptive_weight = 1.0 + (self.peak_weight - 1.0) * peak_frac  # Больше веса, если много пиков\n",
        "                w = adaptive_weight * torch.clamp(peak_mag / (1.0 - self.peak_thr + 1e-8), 0.0, 1.0) + 1.0\n",
        "            huber_term = (base * w).mean()\n",
        "        else:\n",
        "            huber_term = base.mean()\n",
        "\n",
        "        # Лёгкий «anti-flatness» у центра: штрафим чрезмерно малую амплитуду,\n",
        "        # но только там, где таргет далеко от 0.\n",
        "        if self.contrast_weight > 0.0:\n",
        "            with torch.no_grad():\n",
        "                far_mask = (y_actual.abs() >= self.center_band).float()\n",
        "                near_mask = (y_actual.abs() < self.center_band).float()\n",
        "\n",
        "            # Прямая амплитуда предсказания\n",
        "            far_amp = (y_pred.abs() * far_mask).sum() / (far_mask.sum() + 1e-8)\n",
        "            near_amp = (y_pred.abs() * near_mask).sum() / (near_mask.sum() + 1e-8)\n",
        "\n",
        "            # Хотим far_amp >= near_amp + margin; введём небольшой margin\n",
        "            margin = 0.05\n",
        "            contrast = torch.relu((near_amp + margin) - far_amp)\n",
        "            loss = huber_term + self.contrast_weight * contrast\n",
        "        else:\n",
        "            loss = huber_term\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def __call__(self, y_pred, y_actual, **kwargs):\n",
        "        return self.loss(y_pred, y_actual, **kwargs)\n",
        "\n",
        "    def update(self, y_pred, y_actual, **kwargs):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        y_actual = _extract_tensor(y_actual, role=\"target\")\n",
        "        y_pred, y_actual = _align_pred_target(y_pred, y_actual)\n",
        "        self.mse.update(y_pred, y_actual)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.mse.compute()\n",
        "\n",
        "    def reset(self):\n",
        "        self.mse.reset()\n",
        "\n",
        "    def name(self):\n",
        "        return \"PeakFriendlyHuber\"\n",
        "\n",
        "class TFTAdapter(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Обёртка над TemporalFusionTransformer,\n",
        "    чтобы Trainer воспринимал модель нужного типа\n",
        "    и наш tft.training_step видел непустой self.trainer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tft: TemporalFusionTransformer):\n",
        "        super().__init__()\n",
        "        self.tft = tft\n",
        "\n",
        "    def on_fit_start(self) -> None:\n",
        "        # вызовется перед стартом Trainer.fit\n",
        "        # прикрепляем Trainer к внутреннему tft\n",
        "        self.tft.trainer = self.trainer\n",
        "        # и логгеры\n",
        "        self.tft.log = self.log\n",
        "        self.tft.log_dict = self.log_dict\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        return self.tft(*args, **kwargs)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.tft.trainer = self.trainer\n",
        "        result = self.tft.training_step(batch, batch_idx)\n",
        "        if isinstance(result, dict):\n",
        "            return result.get(\"loss\")\n",
        "        elif isinstance(result, tuple) and len(result) >= 2:\n",
        "            log_dict, out = result[:2]  # Берем первые два элемента\n",
        "            if isinstance(log_dict, dict):\n",
        "                return log_dict.get(\"loss\")\n",
        "        # Если ни один вариант не подошел\n",
        "        raise ValueError(f\"Unexpected return type from tft.training_step: {type(result)}\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # обеспечим корректную ссылку на тренер внутри tft (если нужно)\n",
        "        self.tft.trainer = self.trainer\n",
        "        self.tft.validation_step(batch, batch_idx)\n",
        "        return\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        # Просто передаём вызов внутреннему TFT, без dataloader_idx (не нужен для TFT)\n",
        "        return self.tft.predict_step(batch, batch_idx)\n",
        "\n",
        "    def predict(self, *args, **kwargs):\n",
        "        return self.tft.predict(*args, **kwargs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.tft.configure_optimizers()\n",
        "\n",
        "\n",
        "def to_dense(X):\n",
        "    \"\"\"Преобразование sparse matrix в dense numpy array\"\"\"\n",
        "    if hasattr(X, 'toarray'):\n",
        "        return X.toarray()\n",
        "    return np.asarray(X)\n",
        "\n",
        "def prepare_data_transformer(df, target_col):\n",
        "    df = df.dropna(subset=[target_col])\n",
        "    if 'time' in df.columns and 'time_idx' not in df.columns:\n",
        "        df = df.rename(columns={'time': 'time_idx'})\n",
        "    X = df.drop(columns=target_col)\n",
        "    y = df[target_col].copy()\n",
        "\n",
        "    exclude = ['time_idx', 'batch']\n",
        "    numeric_features = [\n",
        "        c for c in X.select_dtypes(include=['int64', 'float64', 'float32', 'int32']).columns\n",
        "        if c not in exclude\n",
        "    ]\n",
        "    categorical_features = [\n",
        "        c for c in X.select_dtypes(include=['object', 'category']).columns\n",
        "        if c not in exclude\n",
        "    ]\n",
        "\n",
        "    preprocessing = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', Pipeline([\n",
        "                ('scaler', RobustScaler()),\n",
        "                ('yeo', PowerTransformer(method='yeo-johnson'))\n",
        "            ]), numeric_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ],\n",
        "        remainder='passthrough'  # passthrough → тут окажутся сначала все num→cat, а потом time_idx и batch\n",
        "    )\n",
        "    # Возвращаем дополнительные списки для передачи в модель\n",
        "    return X, y, preprocessing, numeric_features, categorical_features\n",
        "\n",
        "def split_features_batch_time(X_array, n_transformed):\n",
        "    \"\"\"\n",
        "    X_array: np.ndarray после преобразований shape=(N, n_transformed + 2)\n",
        "    n_transformed: сколько колонок ушло на num+cat\n",
        "    возвращает (features, time_raw, batch_raw)\n",
        "    \"\"\"\n",
        "    features = X_array[:, :n_transformed]\n",
        "    batch_raw = X_array[:, n_transformed].ravel()\n",
        "    time_raw = X_array[:, n_transformed + 1].ravel()\n",
        "    return features, batch_raw, time_raw\n",
        "\n",
        "\n",
        "def tft_output_transformer(x):\n",
        "    # Больше НЕ клипуем внутри графа. Пусть модель учится выходить за [-1,1],\n",
        "    # а мы ограничим при расчёте метрик и при возврате пользователю.\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_early_stopping_callback(patience=10, min_delta=0.001):\n",
        "    return EarlyStopping(\n",
        "        monitor=\"train_loss\",\n",
        "        patience=patience,\n",
        "        min_delta=min_delta,\n",
        "        mode=\"min\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "\n",
        "class SequenceTransformerRegressor(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"\n",
        "    Temporal Fusion Transformer для последовательностей.\n",
        "    Интегрируется в Pipeline аналогично LSTM.\n",
        "    Адаптировано для стабильного обучения и алготрейдинга (реального времени).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq_len: int = 10,\n",
        "                 pred_len: int = 1,\n",
        "                 hidden_size: int = 64,  # Увеличено для лучшей емкости\n",
        "                 hidden_continuous_size: int = 24,\n",
        "                 epochs: int = 100,  # Увеличено для более долгого обучения\n",
        "                 batch_size: int = 128,  # Увеличено для стабильности\n",
        "                 learning_rate: float = 1e-3,  # Увеличено для более быстрого старта\n",
        "                 patience: int = 15,  # Увеличено для терпимости\n",
        "                 seed: int = 42,\n",
        "                 dropout: float = 0.25,  # Уменьшено для меньшей регуляризации\n",
        "                 weight_decay: float = 1e-4,  # Новый: для регуляризации\n",
        "                 verbose: int = 2,\n",
        "                 mask_prob: float = 0.1,  # Уменьшено, чтобы меньше шумить\n",
        "                 infer_stride: int = 2,\n",
        "                 ckpt_path=None,\n",
        "                 preprocessing=None,\n",
        "                 numeric_features=None,\n",
        "                 categorical_features=None,\n",
        "                 remainder_columns=None,\n",
        "                 min_encoder_length: int = 1):  # Больше логов\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_continuous_size = hidden_continuous_size\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.patience = patience\n",
        "        self.seed = seed\n",
        "        self.verbose = verbose\n",
        "        self._model = None\n",
        "        self._trainer = None\n",
        "        self._n_transformed = None\n",
        "        self._n_feat = None\n",
        "        self._train_dataset = None\n",
        "        self._feature_columns = None\n",
        "        self._dropout = dropout\n",
        "        self.norm_eps = 1e-6\n",
        "        self.norm_window = max(10, self.seq_len // 2)\n",
        "        self.ckpt_path = ckpt_path\n",
        "        self.weight_decay = weight_decay  # Новый\n",
        "        self.mask_prob = mask_prob\n",
        "        self.infer_stride = infer_stride\n",
        "        self.global_target_mean = 0.0  # Будем вычислять в fit\n",
        "        self.global_target_std = 1.0  # Fallback global scale\n",
        "        self.global_target_min = None\n",
        "        self.global_target_max = None\n",
        "        self.global_range = None\n",
        "        self.soft_clip_scale =  None\n",
        "        self.preprocessing = preprocessing\n",
        "        self.numeric_features = numeric_features or []\n",
        "        self.categorical_features = categorical_features or []\n",
        "        self.remainder_columns = remainder_columns or ['batch', 'time']\n",
        "        self.use_tanh_post = False\n",
        "        self.train_q_lo = None\n",
        "        self.train_q_hi = None\n",
        "        self.clip_scale = 1.5\n",
        "        self.future_fill_mode = \"repeat\"\n",
        "        self.smooth_window = max(5, self.seq_len // 5)  # For savgol\n",
        "        self.smooth_poly = 2\n",
        "        self.ema_alpha = 0.1\n",
        "        self.infer_batch_size = 512  # Новый: большой батч для inference\n",
        "        self.infer_stride = infer_stride if infer_stride is not None else 4\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'# Добавьте это, если нужно tanh в предикте\n",
        "        self.min_encoder_length = max(1, min_encoder_length)  # Не меньше 1\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        set_seeds(self.seed)\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        if self._n_transformed is None:\n",
        "            self._n_transformed = X.shape[1] - 2\n",
        "            self._n_feat = X.shape[1]\n",
        "\n",
        "        feat, batch_raw, time_raw = split_features_batch_time(X, self._n_transformed)\n",
        "\n",
        "        df = pd.DataFrame(feat, columns=[f\"f{i}\" for i in range(feat.shape[1])])\n",
        "        self._feature_columns = df.columns.tolist()\n",
        "\n",
        "        df[\"batch\"] = pd.Series(batch_raw).astype(\"int64\")\n",
        "        df[\"time_raw\"] = pd.to_datetime(time_raw, utc=True, errors=\"coerce\")\n",
        "\n",
        "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
        "            y = y.reset_index(drop=True)\n",
        "        df[\"target\"] = pd.Series(y, index=df.index).astype(float)\n",
        "\n",
        "        before = len(df)\n",
        "        df = df.dropna(subset=[\"time_raw\", \"target\"]).reset_index(drop=True)\n",
        "        if self.verbose and len(df) < before:\n",
        "            print(f\"Dropped {before - len(df)} rows with invalid time/target\")\n",
        "\n",
        "        df = df.sort_values([\"batch\", \"time_raw\"]).reset_index(drop=True)\n",
        "        df[\"time_idx\"] = df.groupby(\"batch\").cumcount()\n",
        "\n",
        "        min_len = max(1, int(self.pred_len))  # Изменено: позволяем короткие батчи (encoder может быть < seq_len)\n",
        "        gsize = df.groupby(\"batch\").size()\n",
        "        valid_batches = gsize[gsize >= min_len].index\n",
        "        if len(valid_batches) == 0:\n",
        "            raise ValueError(f\"No batches with length >= {min_len}. Reduce pred_len.\")\n",
        "        if self.verbose and len(valid_batches) < gsize.index.nunique():\n",
        "            dropped = sorted(list(set(gsize.index) - set(valid_batches)))\n",
        "            print(f\"Warning: dropped {len(dropped)} short batches: {dropped[:8]}{' ...' if len(dropped) > 8 else ''}\")\n",
        "        df = df[df[\"batch\"].isin(valid_batches)].reset_index(drop=True)\n",
        "\n",
        "        batch_starts = df.groupby(\"batch\")[\"time_raw\"].min().sort_values()\n",
        "        uniq_batches = batch_starts.index.to_numpy()\n",
        "        n_total = len(uniq_batches)\n",
        "        val_frac = 0.3 if n_total >= 10 else 0.1  # Увеличено для лучшего обобщения\n",
        "        n_val = max(1, int(round(n_total * val_frac)))\n",
        "\n",
        "        embargo = 1 if n_total >= 8 else 0\n",
        "\n",
        "        train_end = max(0, n_total - n_val - embargo)\n",
        "        train_batches = uniq_batches[:train_end]\n",
        "        val_batches = uniq_batches[-n_val:]\n",
        "\n",
        "        if len(train_batches) == 0 and n_total > 1:\n",
        "            train_batches = uniq_batches[:-1]\n",
        "            val_batches = uniq_batches[-1:]\n",
        "\n",
        "        train_df = df[df[\"batch\"].isin(train_batches)].copy()\n",
        "        val_df = df[df[\"batch\"].isin(val_batches)].copy()\n",
        "\n",
        "        self.global_target_mean = train_df[\"target\"].mean()\n",
        "        self.global_target_std = train_df[\"target\"].std() + 1e-8\n",
        "        self.global_target_min = train_df[\"target\"].min()\n",
        "        self.global_target_max = train_df[\"target\"].max()\n",
        "        self.global_range = self.global_target_max - self.global_target_min + 1e-8\n",
        "        self.soft_clip_scale = max(1.0, self.global_target_std * 1.5)  # Adaptive soft clip for stable [-1,1] without compression\n",
        "\n",
        "        #self.clip_scale = max(1.0, self.global_target_std * 1.2)   # Adaptive to train variance\n",
        "\n",
        "        train_targets = train_df[\"target\"].values\n",
        "        #if len(train_targets) > 0:\n",
        "        #   self.train_q_lo, self.train_q_hi = np.quantile(train_targets, [0.01, 0.99])\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Train batches: {len(np.unique(train_batches))}\")\n",
        "            print(f\"Val batches: {len(np.unique(val_batches))}\")\n",
        "            print(f\"Train rows: {len(train_df)}, Val rows: {len(val_df)}\")\n",
        "\n",
        "        full_dataset = TimeSeriesDataSet(\n",
        "            df,\n",
        "            time_idx=\"time_idx\",\n",
        "            target=\"target\",\n",
        "            group_ids=[\"batch\"],\n",
        "            max_encoder_length=int(self.seq_len),\n",
        "            min_encoder_length=0,#int(self.min_encoder_length),  # Новый: позволяем короткие encoder\n",
        "            max_prediction_length=int(self.pred_len),\n",
        "            time_varying_unknown_reals=self._feature_columns,\n",
        "            target_normalizer=None,\n",
        "            allow_missing_timesteps=True,\n",
        "            add_relative_time_idx=True,\n",
        "            add_target_scales=False,\n",
        "            add_encoder_length=True,\n",
        "            min_prediction_length=1,\n",
        "        )\n",
        "\n",
        "        train_dataset = TimeSeriesDataSet.from_dataset(\n",
        "            full_dataset, train_df, predict=False, stop_randomization=True\n",
        "        )\n",
        "        val_dataset = TimeSeriesDataSet.from_dataset(\n",
        "            full_dataset, val_df, predict=False, stop_randomization=True\n",
        "        ) if len(val_df) > 0 else None\n",
        "\n",
        "        train_dl = train_dataset.to_dataloader(\n",
        "            train=True,\n",
        "            batch_size=int(self.batch_size),\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            worker_init_fn=None,\n",
        "            drop_last=False,\n",
        "            persistent_workers=False,\n",
        "        )\n",
        "        val_dl = None\n",
        "        if val_dataset is not None and len(val_dataset) > 0:\n",
        "            val_dl = val_dataset.to_dataloader(\n",
        "                train=False,\n",
        "                batch_size=int(self.batch_size),\n",
        "                shuffle=False,\n",
        "                num_workers=0,\n",
        "                worker_init_fn=None,\n",
        "                drop_last=False,\n",
        "                persistent_workers=False,\n",
        "            )\n",
        "\n",
        "        tft = CustomTFT.from_dataset(\n",
        "            train_dataset,\n",
        "            hidden_size=int(self.hidden_size),\n",
        "            output_size=1,\n",
        "            loss=PeakFriendlyHuber(\n",
        "                delta=0.5,\n",
        "                peak_thr=0.85,  # можно затем подвинуть 0.8..0.9\n",
        "                peak_weight=1.3,  # аккуратно: 1.3..1.6\n",
        "                contrast_weight=0.03,  # очень маленькая добавка\n",
        "                center_band=0.3,  # что считать «центром»\n",
        "                clip_scale=1.5\n",
        "            ),\n",
        "            optimizer=\"adam\",\n",
        "            learning_rate=float(self.learning_rate),  # оставьте тот, на котором MSE был лучше (у вас 1e-4 давал ~0.186)\n",
        "            lstm_layers=3,\n",
        "            hidden_continuous_size=self.hidden_continuous_size,\n",
        "            attention_head_size=4,\n",
        "            dropout=float(self._dropout),\n",
        "            reduce_on_plateau_patience=5,\n",
        "            reduce_on_plateau_min_lr=1e-6,\n",
        "            weight_decay=float(self.weight_decay),\n",
        "            mask_prob=float(self.mask_prob),\n",
        "            output_transformer=tft_output_transformer,\n",
        "        )\n",
        "\n",
        "        class GCCallback(pl.Callback):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.last_mem = psutil.Process().memory_info().rss / 1e6\n",
        "\n",
        "            def _check_gc(self):\n",
        "                current_mem = psutil.Process().memory_info().rss / 1e6\n",
        "                if current_mem - self.last_mem > 50:\n",
        "                    gc.collect()\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                self.last_mem = current_mem\n",
        "\n",
        "            def on_train_epoch_end(self, trainer, pl_module):\n",
        "                self._check_gc()\n",
        "\n",
        "            def on_validation_epoch_end(self, trainer, pl_module):\n",
        "                self._check_gc()\n",
        "\n",
        "            def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "                if batch_idx % 10 == 0:\n",
        "                    self._check_gc()\n",
        "\n",
        "            def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "                if batch_idx % 10 == 0:\n",
        "                    self._check_gc()\n",
        "\n",
        "        callbacks = []\n",
        "        if val_dl is not None:\n",
        "            callbacks.append(\n",
        "                get_early_stopping_callback(patience=self.patience, min_delta=1e-3))  # Новый: больше patience\n",
        "            checkpoint_callback = ModelCheckpoint(monitor=\"train_loss\", mode=\"min\", save_top_k=1, verbose=True)\n",
        "            callbacks.append(checkpoint_callback)\n",
        "        else:\n",
        "            checkpoint_callback = None\n",
        "\n",
        "        logger = TensorBoardLogger(save_dir=\"lightning_logs/\", name=\"my_model\") if self.verbose > 0 else False\n",
        "        if self.verbose > 0:\n",
        "            callbacks.append(LearningRateMonitor(logging_interval=\"step\"))\n",
        "            callbacks.append(NoValidationBar(refresh_rate=20))\n",
        "        callbacks.append(GCCallback())\n",
        "\n",
        "        self._model = TFTAdapter(tft)\n",
        "        self._trainer = pl.Trainer(\n",
        "            max_epochs=int(self.epochs),\n",
        "            enable_checkpointing=(checkpoint_callback is not None),\n",
        "            callbacks=callbacks,\n",
        "            logger=logger,\n",
        "            enable_model_summary=True,\n",
        "            gradient_clip_val=1.0,\n",
        "            gradient_clip_algorithm=\"norm\",\n",
        "            deterministic=True,\n",
        "            benchmark=False,\n",
        "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "            precision=32,\n",
        "            limit_val_batches=1.0 if val_dl is not None else 0.0,\n",
        "            enable_progress_bar=self.verbose > 0,\n",
        "            log_every_n_steps=50,\n",
        "            num_sanity_val_steps=0,\n",
        "        )\n",
        "\n",
        "        self._trainer.fit(\n",
        "            self._model,\n",
        "            train_dataloaders=train_dl,\n",
        "            val_dataloaders=val_dl if val_dl is not None else None,\n",
        "            ckpt_path=self.ckpt_path if self.ckpt_path and self.epochs > 0 else None,\n",
        "        )\n",
        "\n",
        "        if checkpoint_callback is not None and checkpoint_callback.best_model_path:\n",
        "            best_path = checkpoint_callback.best_model_path\n",
        "            if self.verbose:\n",
        "                print(f\"Loaded best model from {best_path} with val_loss={checkpoint_callback.best_model_score}\")\n",
        "            self._model = TFTAdapter.load_from_checkpoint(best_path, tft=tft)\n",
        "\n",
        "        self._train_dataset = full_dataset\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        #return self\n",
        "        try:\n",
        "            y_train = train_df[\"target\"].to_numpy(dtype=float)\n",
        "            # robust percentiles — перестрахуемся от выносов: 1% и 99%\n",
        "            self._cal_p_low = float(np.nanpercentile(y_train, 1))\n",
        "            self._cal_p_high = float(np.nanpercentile(y_train, 99))\n",
        "            # амплитуды «типичных пиков»\n",
        "            top_mask = y_train >= self._cal_p_high\n",
        "            bot_mask = y_train <= self._cal_p_low\n",
        "            self._cal_mean_top = float(np.nanmean(y_train[top_mask])) if np.any(top_mask) else float(self.global_target_max)\n",
        "            self._cal_mean_bot = float(np.nanmean(y_train[bot_mask])) if np.any(bot_mask) else float(self.global_target_min)\n",
        "            # защита от вырождения\n",
        "            if not np.isfinite(self._cal_mean_top): self._cal_mean_top = float(self.global_target_max)\n",
        "            if not np.isfinite(self._cal_mean_bot): self._cal_mean_bot = float(self.global_target_min)\n",
        "        except Exception:\n",
        "            # безопасные фолбэки\n",
        "            self._cal_p_low, self._cal_p_high = self.global_target_min, self.global_target_max\n",
        "            self._cal_mean_top, self._cal_mean_bot = self.global_target_max, self.global_target_min\n",
        "        # ----------------------------------------------\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self._train_dataset is None or self._model is None:\n",
        "            raise RuntimeError(\"Model is not fitted yet\")\n",
        "\n",
        "        # Full suppress context (no logs/output, including PL/Torch/PF/Seed/GPU/TPU/HPU messages)\n",
        "        @contextlib.contextmanager\n",
        "        def suppress_all():\n",
        "            with open(os.devnull, \"w\") as devnull, contextlib.redirect_stdout(devnull), contextlib.redirect_stderr(devnull):\n",
        "                # Подавление всех возможных логгеров\n",
        "                root_logger = logging.getLogger()\n",
        "                old_level = root_logger.level\n",
        "                root_logger.setLevel(logging.CRITICAL + 1)  # Выше CRITICAL, чтобы ничего не логировалось\n",
        "\n",
        "                # Специфические логгеры (расширенный список)\n",
        "                for logger_name in [\n",
        "                    \"pytorch_lightning\", \"lightning.pytorch\", \"lightning\",\n",
        "                    \"torch\", \"pytorch_forecasting\", \"optuna\",\n",
        "                    \"sklearn\", \"joblib\", \"numpy\", \"pandas\",\n",
        "                    \"scipy\", \"matplotlib\", \"seaborn\", \"plotly\",\n",
        "                    \"shap\", \"statsmodels\", \"torchmetrics\",\n",
        "                    \"lightning.pytorch.utilities.migration.utils\",  # Для Attribute 'loss' warnings\n",
        "                    \"lightning.pytorch.utilities.migration\",\n",
        "                    \"lightning.pytorch.utilities\",\n",
        "                    \"lightning.pytorch\"\n",
        "                ]:\n",
        "                    logging.getLogger(logger_name).setLevel(logging.CRITICAL + 1)\n",
        "\n",
        "                # Подавление всех предупреждений (расширенный список)\n",
        "                warnings.filterwarnings(\"ignore\")\n",
        "                warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "                warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "                warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*Attribute 'loss' is an instance of nn.Module.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*Attribute 'logging_metrics' is an instance of nn.Module.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*GPU available.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*TPU available.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*HPU available.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*This Pipeline instance is not fitted yet.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*Using an existing study with name.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*A value is trying to be set on a copy of a slice.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*The behavior of DataFrame concatenation.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*torch.utils.checkpoint: the use_reentrant parameter.*\")\n",
        "\n",
        "                # Окружение (расширенное)\n",
        "                os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "                os.environ['LITMODELS_DISABLE_TIP'] = '1'\n",
        "                os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "                os.environ['TQDM_DISABLE'] = '0'  # Не подавлять tqdm (если вызван снаружи)\n",
        "                os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Для синхронизации CUDA, но без логов\n",
        "                os.environ['TORCH_USE_DETERMINISTIC_ALGORITHMS'] = '1'  # Без логов\n",
        "\n",
        "                try:\n",
        "                    yield\n",
        "                finally:\n",
        "                    root_logger.setLevel(old_level)\n",
        "                    warnings.resetwarnings()\n",
        "\n",
        "        with suppress_all():\n",
        "            set_seeds(self.seed)\n",
        "            pl.seed_everything(self.seed, verbose=False, workers=True)\n",
        "\n",
        "            if self.preprocessing is not None and not isinstance(X, np.ndarray):\n",
        "                X = self.preprocessing.transform(X)\n",
        "\n",
        "            X = np.asarray(X)\n",
        "            N = X.shape[0]\n",
        "            if N < self.min_encoder_length:\n",
        "                return [float(np.nan)] * N\n",
        "\n",
        "            feat, _, time_raw = split_features_batch_time(X, self._n_transformed)\n",
        "            df = pd.DataFrame(feat, columns=self._feature_columns)\n",
        "            df[\"__row_id\"] = np.arange(N)\n",
        "            df[\"time_raw\"] = pd.to_datetime(time_raw, utc=True, errors=\"coerce\")\n",
        "            df[\"batch\"] = np.int64(0)\n",
        "            df[\"target\"] = self.global_target_mean\n",
        "\n",
        "            df = df.dropna(subset=[\"time_raw\"]).reset_index(drop=True)\n",
        "            df_sorted = df.sort_values(\"time_raw\").reset_index(drop=True)\n",
        "            df_sorted[\"time_idx\"] = np.arange(len(df_sorted), dtype=np.int64)\n",
        "\n",
        "            eff_N = len(df_sorted)\n",
        "            if eff_N < self.min_encoder_length:\n",
        "                out = np.full(N, np.nan, dtype=float)\n",
        "                return out.tolist()\n",
        "\n",
        "            step_ns = int(60 * 1e9)\n",
        "            if eff_N >= 2:\n",
        "                diffs = df_sorted[\"time_raw\"].view(\"int64\").astype(\"int64\").to_numpy()\n",
        "                diffs = np.diff(diffs)\n",
        "                step_ns = int(np.nan_to_num(np.median(diffs), nan=step_ns))\n",
        "                if step_ns <= 0:\n",
        "                    step_ns = int(60 * 1e9)\n",
        "\n",
        "            out_raw = np.full(eff_N, np.nan, dtype=float)\n",
        "\n",
        "            tft = self._model.tft\n",
        "            orig_log = tft.log\n",
        "            tft.log = lambda *args, **kwargs: None\n",
        "\n",
        "            try:\n",
        "                eff_encoder_len = min(self.seq_len, eff_N)\n",
        "                M = max(0, eff_N - eff_encoder_len + 1)\n",
        "                stride = self.pred_len  # Keep original stride to preserve logic\n",
        "                window_starts = np.arange(0, M, stride)\n",
        "                K = len(window_starts)\n",
        "\n",
        "                if K == 0:\n",
        "                    K = 1\n",
        "                    window_starts = np.array([0])\n",
        "                    eff_encoder_len = eff_N\n",
        "\n",
        "                num_feat_cols = len(self._feature_columns)\n",
        "\n",
        "                # Vectorized construction of all_feats\n",
        "                enc_indices = window_starts[:, np.newaxis] + np.arange(eff_encoder_len)\n",
        "                all_enc_feats = feat[enc_indices]  # (K, eff_encoder_len, num_feat_cols)\n",
        "                last_enc_feats = all_enc_feats[:, -1, :]\n",
        "                all_fut_feats = np.repeat(last_enc_feats[:, np.newaxis, :], self.pred_len, axis=1)  # (K, pred_len, num_feat_cols)\n",
        "                all_feats = np.concatenate([all_enc_feats, all_fut_feats], axis=1).reshape(-1, num_feat_cols)\n",
        "\n",
        "                # Vectorized all_time_idx\n",
        "                orig_time_idx = df_sorted[\"time_idx\"].values\n",
        "                all_enc_time_idx = orig_time_idx[enc_indices]  # (K, eff_encoder_len)\n",
        "                last_time_idx = all_enc_time_idx[:, -1]\n",
        "                fut_offsets = np.arange(1, self.pred_len + 1)\n",
        "                all_fut_time_idx = last_time_idx[:, np.newaxis] + fut_offsets  # (K, pred_len)\n",
        "                all_time_idx = np.concatenate([all_enc_time_idx, all_fut_time_idx], axis=1).reshape(-1)\n",
        "\n",
        "                # Vectorized all_batch\n",
        "                batch_per_window = np.arange(K)[:, np.newaxis]\n",
        "                all_enc_batch = np.repeat(batch_per_window, eff_encoder_len, axis=1)  # (K, eff_encoder_len)\n",
        "                all_fut_batch = np.repeat(batch_per_window, self.pred_len, axis=1)  # (K, pred_len)\n",
        "                all_batch = np.concatenate([all_enc_batch, all_fut_batch], axis=1).reshape(-1)\n",
        "\n",
        "                # all_target (constant)\n",
        "                all_target = np.full(K * (eff_encoder_len + self.pred_len), self.global_target_mean, dtype=np.float32)\n",
        "\n",
        "                # Vectorized all_time_raw using int64 ns\n",
        "                orig_time_raw_int = df_sorted[\"time_raw\"].view(\"int64\").values\n",
        "                all_enc_time_int = orig_time_raw_int[enc_indices]  # (K, eff_encoder_len)\n",
        "                last_time_int = all_enc_time_int[:, -1]\n",
        "                fut_offsets_ns = fut_offsets * step_ns\n",
        "                all_fut_time_int = last_time_int[:, np.newaxis] + fut_offsets_ns  # (K, pred_len)\n",
        "                all_time_int_flat = np.concatenate([all_enc_time_int.reshape(-1), all_fut_time_int.reshape(-1)])\n",
        "                all_time_raw = pd.to_datetime(all_time_int_flat, unit='ns', utc=True).values  # object array of Timestamp\n",
        "\n",
        "                pred_df = pd.DataFrame(all_feats, columns=self._feature_columns)\n",
        "                pred_df[\"time_idx\"] = all_time_idx\n",
        "                pred_df[\"batch\"] = all_batch\n",
        "                pred_df[\"target\"] = all_target\n",
        "                pred_df[\"time_raw\"] = all_time_raw\n",
        "\n",
        "                pred_df[\"batch\"] = pred_df[\"batch\"].astype(\"int64\")\n",
        "                pred_df[\"time_idx\"] = pred_df[\"time_idx\"].astype(\"int64\")\n",
        "                pred_df[\"target\"] = pred_df[\"target\"].astype(\"float32\")\n",
        "\n",
        "                sliding_dataset = TimeSeriesDataSet.from_dataset(\n",
        "                    self._train_dataset,\n",
        "                    pred_df,\n",
        "                    predict=True,\n",
        "                    stop_randomization=True,\n",
        "                    min_prediction_length=self.pred_len,\n",
        "                    max_prediction_length=self.pred_len,\n",
        "                )\n",
        "\n",
        "                test_dl = sliding_dataset.to_dataloader(\n",
        "                    train=False,\n",
        "                    batch_size=K,  # Full batch for max speed (K small due to stride=pred_len)\n",
        "                    num_workers=0,\n",
        "                    persistent_workers=False,\n",
        "                    pin_memory=False,\n",
        "                )\n",
        "\n",
        "                preds = tft.predict(\n",
        "                    test_dl,\n",
        "                    mode=\"prediction\",\n",
        "                    return_x=False,\n",
        "                    trainer_kwargs={\n",
        "                        \"logger\": False,\n",
        "                        \"enable_progress_bar\": False,\n",
        "                        \"enable_model_summary\": False,\n",
        "                        \"enable_checkpointing\": False,\n",
        "                        \"accelerator\": \"gpu\" if self.device == \"cuda\" else \"cpu\"\n",
        "                    },\n",
        "                )\n",
        "\n",
        "                if isinstance(preds, torch.Tensor):\n",
        "                    preds = preds.detach().cpu()\n",
        "                    if preds.dim() == 3 and preds.size(-1) == 1:\n",
        "                        preds = preds.squeeze(-1)\n",
        "                    if preds.dim() == 2:\n",
        "                        yhat_stride = preds[:, 0].numpy()  # First step per window\n",
        "                    elif preds.dim() == 1:\n",
        "                        yhat_stride = preds.numpy()\n",
        "                    elif preds.dim() == 0:\n",
        "                        yhat_stride = np.array([preds.item()])\n",
        "                    else:\n",
        "                        yhat_stride = np.full(K, self.global_target_mean)\n",
        "                else:\n",
        "                    yhat_stride = np.full(K, self.global_target_mean)\n",
        "\n",
        "                # Fill out_raw at window ends\n",
        "                for j, i in enumerate(window_starts):\n",
        "                    out_raw[i + eff_encoder_len - 1] = yhat_stride[j]\n",
        "\n",
        "                # Causal interpolation for missed points (linear from past, no future look)\n",
        "                s = pd.Series(out_raw)\n",
        "                s = s.interpolate(method='linear', limit_direction='forward')  # Only forward for causality\n",
        "                s = s.ffill()  # Fill initial with first pred\n",
        "                out_raw = s.values\n",
        "\n",
        "                # Global map to [-1,1] (consistent scale, preserves relative peaks)\n",
        "                out = (out_raw - self.global_target_min) / self.global_range * 2 - 1\n",
        "                out = np.tanh(out * self.soft_clip_scale) / np.tanh(self.soft_clip_scale)\n",
        "                out = np.clip(out, -1.0, 1.0)\n",
        "\n",
        "                # Fill any remaining nans (unlikely) with mapped mean\n",
        "                nan_mask = np.isnan(out)\n",
        "                mapped_mean = (self.global_target_mean - self.global_target_min) / self.global_range * 2 - 1\n",
        "                out[nan_mask] = mapped_mean\n",
        "\n",
        "            finally:\n",
        "                tft.log = orig_log\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            original_pos = df_sorted[\"__row_id\"].to_numpy()\n",
        "            out_final = np.full(N, np.nan, dtype=float)\n",
        "            out_final[original_pos] = out\n",
        "\n",
        "            return out_final.tolist()\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        # Чтобы sklearn корректно передавал параметры в Pipeline\n",
        "        return {\n",
        "            \"seq_len\": self.seq_len,\n",
        "            \"pred_len\": self.pred_len,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"epochs\": self.epochs,\n",
        "            \"batch_size\": self.batch_size,\n",
        "            \"learning_rate\": self.learning_rate,\n",
        "            \"patience\": self.patience,\n",
        "            \"seed\": self.seed,\n",
        "            \"dropout\": self._dropout,\n",
        "            \"weight_decay\": self.weight_decay,\n",
        "            \"verbose\": self.verbose,\n",
        "            \"ckpt_path\": self.ckpt_path\n",
        "        }\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self\n",
        "\n",
        "def _tensor_state_dict_to(dtype: torch.dtype, state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "    out = {}\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            # важно: сохраняем в CPU и ровно в dtype (float32 для идентичности)\n",
        "            out[k] = v.detach().to('cpu', dtype=dtype)\n",
        "        else:\n",
        "            out[k] = v\n",
        "    return out\n",
        "\n",
        "\n",
        "def _save_bytes_compressed_zip(file_path: str, bytes_map: Dict[str, bytes], compression=zipfile.ZIP_DEFLATED, compresslevel=9):\n",
        "    with zipfile.ZipFile(file_path, mode='w', compression=compression, compresslevel=compresslevel) as zf:\n",
        "        for name, b in bytes_map.items():\n",
        "            zf.writestr(name, b)\n",
        "\n",
        "\n",
        "def _load_bytes_from_zip(file_path: str) -> Dict[str, bytes]:\n",
        "    out = {}\n",
        "    with zipfile.ZipFile(file_path, mode='r') as zf:\n",
        "        for name in zf.namelist():\n",
        "            out[name] = zf.read(name)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _safe_json_dump(obj: Dict[str, Any]) -> bytes:\n",
        "    def to_builtin(x):\n",
        "        import numpy as _np\n",
        "        import pandas as _pd\n",
        "        if isinstance(x, (_np.integer,)):\n",
        "            return int(x)\n",
        "        if isinstance(x, (_np.floating,)):\n",
        "            return float(x)\n",
        "        if isinstance(x, (_np.ndarray,)):\n",
        "            return x.tolist()\n",
        "        if isinstance(x, (_pd.Timestamp,)):\n",
        "            return x.isoformat()\n",
        "        return x\n",
        "\n",
        "    def convert(v):\n",
        "        if isinstance(v, dict):\n",
        "            return {k: convert(val) for k, val in v.items()}\n",
        "        if isinstance(v, (list, tuple)):\n",
        "            return [convert(i) for i in v]\n",
        "        return to_builtin(v)\n",
        "\n",
        "    return json.dumps(convert(obj), ensure_ascii=False, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "\n",
        "\n",
        "def _safe_json_load(b: bytes) -> Dict[str, Any]:\n",
        "    return json.loads(b.decode(\"utf-8\"))\n",
        "\n",
        "\n",
        "def _extract_tsd_feature_lists(tds) -> Dict[str, Any]:\n",
        "    def g(name, default=None):\n",
        "        return getattr(tds, name, default)\n",
        "\n",
        "    lists = {}\n",
        "    for name in [\n",
        "        \"time_varying_known_reals\",\n",
        "        \"time_varying_unknown_reals\",\n",
        "        \"static_reals\",\n",
        "        \"time_varying_known_categoricals\",\n",
        "        \"time_varying_unknown_categoricals\",\n",
        "        \"static_categoricals\",\n",
        "        \"target_categoricals\",\n",
        "        \"known_reals\",\n",
        "        \"unknown_reals\",\n",
        "        \"known_categoricals\",\n",
        "        \"unknown_categoricals\",\n",
        "        \"reals\",\n",
        "        \"categoricals\",\n",
        "    ]:\n",
        "        val = g(name, None)\n",
        "        if val is not None:\n",
        "            try:\n",
        "                lists[name] = list(val)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return lists\n",
        "\n",
        "\n",
        "def save_transformer(\n",
        "    pipeline: Pipeline,\n",
        "    path: str,\n",
        "    *,\n",
        "    # ЖЁСТКО: float32 по умолчанию для идентичности. Не выставляйте True, пока не сравните предикты.\n",
        "    float16_weights: bool = False,\n",
        "    preprocessing_filename: str = \"preprocessing.joblib.lzma\",\n",
        "    model_zip_filename: str = \"model_weights.zip\",\n",
        "    meta_json_filename: str = \"meta.json\"\n",
        "):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    if not isinstance(pipeline, Pipeline):\n",
        "        raise TypeError(\"Expected sklearn Pipeline\")\n",
        "\n",
        "    steps_dict = dict(pipeline.named_steps)\n",
        "    if \"preprocessing\" not in steps_dict or \"model\" not in steps_dict:\n",
        "        raise ValueError(\"Pipeline must have 'preprocessing' and 'model' steps\")\n",
        "\n",
        "    preprocessing = steps_dict[\"preprocessing\"]\n",
        "    model: SequenceTransformerRegressor = steps_dict[\"model\"]\n",
        "\n",
        "    if model._model is None or model._train_dataset is None:\n",
        "        raise RuntimeError(\"Model must be fitted before saving\")\n",
        "\n",
        "    # 1) preprocessing\n",
        "    prep_path = os.path.join(path, preprocessing_filename)\n",
        "    with lzma.open(prep_path, \"wb\", preset=9) as f:\n",
        "        joblib.dump(preprocessing, f)\n",
        "\n",
        "    # 2) параметры TDS\n",
        "    tds = model._train_dataset\n",
        "    def g(name, default=None):\n",
        "        return getattr(tds, name, default)\n",
        "\n",
        "    train_dataset_params = {\n",
        "        \"time_idx\": g(\"time_idx\", \"time_idx\"),\n",
        "        \"target\": g(\"target\", \"target\"),\n",
        "        \"group_ids\": list(g(\"group_ids\", [\"batch\"])),\n",
        "        \"max_encoder_length\": int(g(\"max_encoder_length\", model.seq_len)),\n",
        "        \"max_prediction_length\": int(g(\"max_prediction_length\", model.pred_len)),\n",
        "        \"target_normalizer\": None,\n",
        "        \"allow_missing_timesteps\": bool(g(\"allow_missing_timesteps\", True)),\n",
        "        \"add_relative_time_idx\": bool(g(\"add_relative_time_idx\", True)),\n",
        "        \"add_target_scales\": bool(g(\"add_target_scales\", False)),\n",
        "        \"add_encoder_length\": bool(g(\"add_encoder_length\", True)),\n",
        "        \"min_prediction_length\": int(g(\"min_prediction_length\", 1)),\n",
        "        \"min_encoder_length\": int(g(\"min_encoder_length\", 0)),\n",
        "    }\n",
        "    feature_lists = _extract_tsd_feature_lists(tds)\n",
        "\n",
        "    # 3) веса TFT — строго в float32 (если float16_weights=False)\n",
        "    tft = model._model.tft\n",
        "    state = tft.state_dict()\n",
        "    dtype = torch.float16 if float16_weights else torch.float32\n",
        "    state = _tensor_state_dict_to(dtype, state)\n",
        "    buf = io.BytesIO()\n",
        "    torch.save(state, buf, _use_new_zipfile_serialization=True)\n",
        "    buf.seek(0)\n",
        "    weights_zip_path = os.path.join(path, model_zip_filename)\n",
        "    _save_bytes_compressed_zip(weights_zip_path, {\"tft_state_dict.pt\": buf.getvalue()})\n",
        "\n",
        "    # 4) метаданные\n",
        "    meta = {\n",
        "        \"class\": \"SequenceTransformerRegressor\",\n",
        "        \"params\": {\n",
        "            \"seq_len\": model.seq_len,\n",
        "            \"pred_len\": model.pred_len,\n",
        "            \"hidden_size\": model.hidden_size,\n",
        "            \"hidden_continuous_size\": model.hidden_continuous_size,\n",
        "            \"epochs\": model.epochs,\n",
        "            \"batch_size\": model.batch_size,\n",
        "            \"learning_rate\": model.learning_rate,\n",
        "            \"patience\": model.patience,\n",
        "            \"seed\": model.seed,\n",
        "            \"dropout\": model._dropout,\n",
        "            \"weight_decay\": model.weight_decay,\n",
        "            \"verbose\": model.verbose,\n",
        "            \"mask_prob\": model.mask_prob,\n",
        "            \"infer_stride\": model.infer_stride,\n",
        "            \"ckpt_path\": None,\n",
        "            \"min_encoder_length\": model.min_encoder_length,\n",
        "            \"lstm_layers\": 3,\n",
        "            \"attention_head_size\": 4,\n",
        "            \"output_size\": 1,\n",
        "        },\n",
        "        \"feature_columns\": model._feature_columns,\n",
        "        \"n_transformed\": model._n_transformed,\n",
        "        \"n_feat\": model._n_feat,\n",
        "        \"global_stats\": {\n",
        "            \"global_target_mean\": model.global_target_mean,\n",
        "            \"global_target_std\": model.global_target_std,\n",
        "            \"global_target_min\": model.global_target_min,\n",
        "            \"global_target_max\": model.global_target_max,\n",
        "            \"global_range\": model.global_range,\n",
        "            \"soft_clip_scale\": model.soft_clip_scale,\n",
        "            \"clip_scale\": model.clip_scale,\n",
        "        },\n",
        "        \"train_dataset_params\": train_dataset_params,\n",
        "        \"feature_lists\": feature_lists,\n",
        "        \"torch_dtype\": \"float16\" if float16_weights else \"float32\",\n",
        "        \"preproc_feature_names_out\": list(getattr(preprocessing, \"get_feature_names_out\", lambda: [])()),\n",
        "    }\n",
        "\n",
        "    meta_path = os.path.join(path, meta_json_filename)\n",
        "    with open(meta_path, \"wb\") as f:\n",
        "        f.write(_safe_json_dump(meta))\n",
        "\n",
        "    weights_size_mb = os.path.getsize(weights_zip_path) / (1024 * 1024)\n",
        "    prep_size_mb = os.path.getsize(prep_path) / (1024 * 1024)\n",
        "    meta_size_kb = os.path.getsize(meta_path) / 1024.0\n",
        "    print(f\"Saved: weights={weights_size_mb:.2f} MB, preprocessing={prep_size_mb:.2f} MB, meta={meta_size_kb:.1f} KB → dir={path}\")\n",
        "\n",
        "# Требуется наличие в окружении:\n",
        "# - SequenceTransformerRegressor\n",
        "# - TimeSeriesDataSet\n",
        "# - CustomTFT, TFTAdapter\n",
        "# - tft_output_transformer\n",
        "# - PeakFriendlyHuber\n",
        "# - to_dense\n",
        "# - вспомогательные функции _load_bytes_from_zip, _safe_json_load из предыдущей версии\n",
        "\n",
        "\n",
        "def load_transformer_exact(\n",
        "    path: str,\n",
        "    *,\n",
        "    preprocessing_filename: str = \"preprocessing.joblib.lzma\",\n",
        "    model_zip_filename: str = \"model_weights.zip\",\n",
        "    meta_json_filename: str = \"meta.json\",\n",
        "    device: Optional[str] = None,\n",
        ") -> Pipeline:\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\", message=\".*Attribute 'loss' is an instance of `nn.Module`.*\")\n",
        "    warnings.filterwarnings(\"ignore\", message=\".*Attribute 'logging_metrics' is an instance of `nn.Module`.*\")\n",
        "\n",
        "    # 1) preprocessing\n",
        "    prep_path = os.path.join(path, preprocessing_filename)\n",
        "    with lzma.open(prep_path, \"rb\") as f:\n",
        "        preprocessing = joblib.load(f)\n",
        "\n",
        "    # 2) meta\n",
        "    meta_path = os.path.join(path, meta_json_filename)\n",
        "    if not os.path.isfile(meta_path):\n",
        "        raise FileNotFoundError(meta_path)\n",
        "    with open(meta_path, \"rb\") as f:\n",
        "        meta = json.loads(f.read().decode(\"utf-8\"))\n",
        "\n",
        "    params = meta[\"params\"]\n",
        "    feature_columns = meta[\"feature_columns\"]\n",
        "    n_transformed = meta[\"n_transformed\"]\n",
        "    n_feat = meta[\"n_feat\"]\n",
        "    global_stats = meta[\"global_stats\"]\n",
        "    tds_params = meta[\"train_dataset_params\"]\n",
        "    feature_lists = meta.get(\"feature_lists\", {})\n",
        "    saved_torch_dtype = meta.get(\"torch_dtype\", \"float32\")\n",
        "\n",
        "    # 3) регрессор\n",
        "    model = SequenceTransformerRegressor(\n",
        "        seq_len=params[\"seq_len\"],\n",
        "        pred_len=params[\"pred_len\"],\n",
        "        hidden_size=params[\"hidden_size\"],\n",
        "        hidden_continuous_size=params[\"hidden_continuous_size\"],\n",
        "        epochs=params[\"epochs\"],\n",
        "        batch_size=params[\"batch_size\"],\n",
        "        learning_rate=params[\"learning_rate\"],\n",
        "        patience=params[\"patience\"],\n",
        "        seed=params[\"seed\"],\n",
        "        dropout=params[\"dropout\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        verbose=params[\"verbose\"],\n",
        "        mask_prob=params[\"mask_prob\"],\n",
        "        infer_stride=params[\"infer_stride\"],\n",
        "        ckpt_path=None,\n",
        "        preprocessing=preprocessing,\n",
        "        min_encoder_length=params.get(\"min_encoder_length\", 1),\n",
        "    )\n",
        "\n",
        "    model._feature_columns = feature_columns\n",
        "    model._n_transformed = n_transformed\n",
        "    model._n_feat = n_feat\n",
        "    model.global_target_mean = float(global_stats[\"global_target_mean\"])\n",
        "    model.global_target_std = float(global_stats[\"global_target_std\"])\n",
        "    model.global_target_min = float(global_stats[\"global_target_min\"])\n",
        "    model.global_target_max = float(global_stats[\"global_target_max\"])\n",
        "    model.global_range = float(global_stats[\"global_range\"])\n",
        "    model.soft_clip_scale = float(global_stats[\"soft_clip_scale\"])\n",
        "    model.clip_scale = float(global_stats.get(\"clip_scale\", 1.5))\n",
        "    model.device = device\n",
        "\n",
        "    # 4) синтетический df\n",
        "    max_enc = int(tds_params[\"max_encoder_length\"])\n",
        "    max_pred = int(tds_params[\"max_prediction_length\"])\n",
        "    num_feat_cols = len(feature_columns)\n",
        "    rows = max_enc + max_pred\n",
        "\n",
        "    synth_df_base = pd.DataFrame(\n",
        "        np.zeros((rows, num_feat_cols), dtype=np.float32),\n",
        "        columns=feature_columns,\n",
        "    )\n",
        "    synth_df_base[\"time_idx\"] = np.arange(rows, dtype=np.int64)\n",
        "    synth_df_base[\"target\"] = np.zeros(rows, dtype=np.float32)\n",
        "    synth_df_base[\"batch\"] = 0\n",
        "\n",
        "    # Попытка №1: «обычная» конструкция TDS как при обучении\n",
        "    tds_kwargs = dict(\n",
        "        time_idx=tds_params[\"time_idx\"],\n",
        "        target=tds_params[\"target\"],\n",
        "        group_ids=tds_params[\"group_ids\"],\n",
        "        max_encoder_length=tds_params[\"max_encoder_length\"],\n",
        "        max_prediction_length=tds_params[\"max_prediction_length\"],\n",
        "        target_normalizer=None,\n",
        "        allow_missing_timesteps=tds_params[\"allow_missing_timesteps\"],\n",
        "        add_relative_time_idx=tds_params[\"add_relative_time_idx\"],\n",
        "        add_target_scales=tds_params[\"add_target_scales\"],\n",
        "        add_encoder_length=tds_params[\"add_encoder_length\"],\n",
        "        min_prediction_length=tds_params[\"min_prediction_length\"],\n",
        "        min_encoder_length=tds_params.get(\"min_encoder_length\", 0),\n",
        "    )\n",
        "\n",
        "    if \"time_varying_unknown_reals\" in feature_lists:\n",
        "        tds_kwargs[\"time_varying_unknown_reals\"] = list(feature_lists[\"time_varying_unknown_reals\"])\n",
        "    else:\n",
        "        tds_kwargs[\"time_varying_unknown_reals\"] = list(feature_columns)\n",
        "\n",
        "    for key in [\n",
        "        \"time_varying_known_reals\",\n",
        "        \"static_reals\",\n",
        "        \"time_varying_known_categoricals\",\n",
        "        \"time_varying_unknown_categoricals\",\n",
        "        \"static_categoricals\",\n",
        "        \"known_reals\",\n",
        "        \"unknown_reals\",\n",
        "        \"known_categoricals\",\n",
        "        \"unknown_categoricals\",\n",
        "    ]:\n",
        "        if key in feature_lists:\n",
        "            tds_kwargs[key] = list(feature_lists[key])\n",
        "\n",
        "    dataset = TimeSeriesDataSet(synth_df_base.copy(), **tds_kwargs)\n",
        "\n",
        "    # Проверяем порядок reals\n",
        "    saved_reals = feature_lists.get(\"reals\")\n",
        "    rebuild_forced = False\n",
        "    if saved_reals is not None:\n",
        "        # В PF список dataset.reals может быть кортежами/объектами -- приводим к строкам\n",
        "        ds_reals = list(getattr(dataset, \"reals\", []))\n",
        "        ds_reals = [str(x) for x in ds_reals]\n",
        "        saved_reals_str = [str(x) for x in saved_reals]\n",
        "        if ds_reals != saved_reals_str:\n",
        "            rebuild_forced = True\n",
        "\n",
        "    if rebuild_forced:\n",
        "        # Попытка №2: Форсируем порядок каналов reals.\n",
        "        # Для этого отключим автоматические добавления и сами сгенерируем служебные колонки\n",
        "        # encoder_length и relative_time_idx в synth_df.\n",
        "        synth_df = synth_df_base.copy()\n",
        "        # relative_time_idx: от 0 до rows-1\n",
        "        synth_df[\"relative_time_idx\"] = np.arange(rows, dtype=np.int64)\n",
        "        # encoder_length: длина encoder для каждой позиции; для синтетики можно установить константу max_enc\n",
        "        # PF ожидает целочисленную encoder_length, соответствующую длине энкодера на каждом шаге.\n",
        "        # Для инициализации архитектуры достаточно положить валидные числа.\n",
        "        enc_len = np.zeros(rows, dtype=np.int64)\n",
        "        enc_len[:max_enc] = np.arange(1, max_enc + 1, dtype=np.int64)\n",
        "        enc_len[max_enc:] = max_enc\n",
        "        synth_df[\"encoder_length\"] = enc_len\n",
        "\n",
        "        # Теперь задаём TDS без add_* фичей, и передаём time_varying_unknown_reals в порядке saved_reals.\n",
        "        # saved_reals начинается с [\"encoder_length\",\"relative_time_idx\", ... f0..fN]\n",
        "        tds_kwargs_forced = dict(\n",
        "            time_idx=tds_params[\"time_idx\"],\n",
        "            target=tds_params[\"target\"],\n",
        "            group_ids=tds_params[\"group_ids\"],\n",
        "            max_encoder_length=tds_params[\"max_encoder_length\"],\n",
        "            max_prediction_length=tds_params[\"max_prediction_length\"],\n",
        "            target_normalizer=None,\n",
        "            allow_missing_timesteps=tds_params[\"allow_missing_timesteps\"],\n",
        "            add_relative_time_idx=False,\n",
        "            add_target_scales=tds_params[\"add_target_scales\"],\n",
        "            add_encoder_length=False,\n",
        "            min_prediction_length=tds_params[\"min_prediction_length\"],\n",
        "            min_encoder_length=tds_params.get(\"min_encoder_length\", 0),\n",
        "            time_varying_unknown_reals=list(saved_reals),  # порядок каналов фиксируем здесь\n",
        "            # Не задаём known/unknown cats/reals дополнительно, чтобы не нарушить порядок\n",
        "        )\n",
        "        dataset = TimeSeriesDataSet(synth_df, **tds_kwargs_forced)\n",
        "\n",
        "        # Контроль: проверим снова порядок\n",
        "        ds_reals2 = [str(x) for x in list(getattr(dataset, \"reals\", []))]\n",
        "        if ds_reals2 != [str(x) for x in saved_reals]:\n",
        "            raise RuntimeError(\n",
        "                f\"Failed to force reals order. Got {ds_reals2[:8]}..., expected {list(saved_reals)[:8]}...\"\n",
        "            )\n",
        "\n",
        "    # 5) TFT 1-в-1\n",
        "    tft = CustomTFT.from_dataset(\n",
        "        dataset,\n",
        "        hidden_size=int(model.hidden_size),\n",
        "        output_size=int(params.get(\"output_size\", 1)),\n",
        "        loss=PeakFriendlyHuber(\n",
        "            delta=0.5,\n",
        "            peak_thr=0.85,\n",
        "            peak_weight=1.3,\n",
        "            contrast_weight=0.03,\n",
        "            center_band=0.3,\n",
        "            clip_scale=1.5,\n",
        "        ),\n",
        "        optimizer=\"adam\",\n",
        "        learning_rate=float(model.learning_rate),\n",
        "        lstm_layers=int(params.get(\"lstm_layers\", 3)),\n",
        "        hidden_continuous_size=int(model.hidden_continuous_size),\n",
        "        attention_head_size=int(params.get(\"attention_head_size\", 4)),\n",
        "        dropout=float(model._dropout),\n",
        "        reduce_on_plateau_patience=5,\n",
        "        reduce_on_plateau_min_lr=1e-6,\n",
        "        weight_decay=float(model.weight_decay),\n",
        "        mask_prob=float(model.mask_prob),\n",
        "        output_transformer=tft_output_transformer,\n",
        "    )\n",
        "\n",
        "    model._model = TFTAdapter(tft)\n",
        "    model._train_dataset = dataset\n",
        "\n",
        "    # 6) загрузка весов\n",
        "    weights_zip_path = os.path.join(path, model_zip_filename)\n",
        "    with zipfile.ZipFile(weights_zip_path, mode='r') as zf:\n",
        "        if \"tft_state_dict.pt\" not in zf.namelist():\n",
        "            raise RuntimeError(\"tft_state_dict.pt not found in weights zip\")\n",
        "        state = torch.load(io.BytesIO(zf.read(\"tft_state_dict.pt\")), map_location=\"cpu\")\n",
        "\n",
        "    missing, unexpected = tft.load_state_dict(state, strict=False)\n",
        "    if missing or unexpected:\n",
        "        warnings.warn(f\"load_state_dict: missing={missing}, unexpected={unexpected}\")\n",
        "\n",
        "    # 7) eval + dropout off\n",
        "    tft.eval()\n",
        "    for m in tft.modules():\n",
        "        if isinstance(m, torch.nn.Dropout):\n",
        "            m.p = 0.0\n",
        "\n",
        "    model._model.to(device)\n",
        "\n",
        "    restored = Pipeline([\n",
        "        (\"preprocessing\", preprocessing),\n",
        "        (\"to_dense\", FunctionTransformer(to_dense)),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "    return restored\n",
        "\n",
        "def apply_linear_calibration(y_pred: np.ndarray, calib: dict) -> np.ndarray:\n",
        "    a, b = calib.get('a', 1.0), calib.get('b', 0.0)\n",
        "    return a * np.ravel(y_pred) + b\n",
        "\n",
        "def ranker_postprocess_minus1_1(y_pred_ranker: np.ndarray) -> np.ndarray:\n",
        "    yp = np.ravel(y_pred_ranker)\n",
        "    return 2.0 * ((yp + 15.0) / (5.0 + 15.0)) - 1.0\n",
        "\n",
        "def load_optimized_pipeline(out_dir, model_type='regressor'):\n",
        "    \"\"\"\n",
        "    Загружает оптимизированный pipeline.\n",
        "    Возвращает полный pipe.\n",
        "    \"\"\"\n",
        "    # Загружаем preproc\n",
        "    preproc_file = f'preproc_{model_type}.pkl' if model_type == 'ranker' else 'preproc.pkl'\n",
        "    preproc = joblib.load(os.path.join(out_dir, preproc_file))\n",
        "\n",
        "    # Booster из gz\n",
        "    gz_file = os.path.join(out_dir, f'{model_type}.txt.gz')\n",
        "    temp_file = os.path.join(out_dir, f'temp_{model_type}.txt')\n",
        "    with gzip.open(gz_file, 'rb') as f_in:\n",
        "        with open(temp_file, 'wb') as f_out:\n",
        "            f_out.write(f_in.read())\n",
        "    booster = lgb.Booster(model_file=temp_file)\n",
        "    os.remove(temp_file)\n",
        "\n",
        "    # Реконструируем модель (LGBM wrapper)\n",
        "    step_name = 'model' if model_type == 'regressor' else 'ranker'\n",
        "    if model_type == 'regressor':\n",
        "        model = lgb.LGBMRegressor()\n",
        "    elif model_type == 'ranker':\n",
        "        model = lgb.LGBMRanker()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model_type\")\n",
        "\n",
        "    model._Booster = booster\n",
        "    model.fitted_ = True  # Отметить как обученную\n",
        "    # Устанавливаем n_features_in_ из booster\n",
        "    model.n_features_in_ = booster.num_feature()\n",
        "\n",
        "    # Полный pipe\n",
        "    pipe = Pipeline([\n",
        "        ('preprocessing', preproc),\n",
        "        ('to_dense', FunctionTransformer(to_dense, feature_names_out=\"one-to-one\")),\n",
        "        (step_name, model),\n",
        "    ])\n",
        "\n",
        "    return pipe\n",
        "\n",
        "def load_model_for_ticker(ticker, models_dir=r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\models'):\n",
        "    \"\"\"\n",
        "    Загружает модель(и) для тикера из директории models//.\n",
        "    Возвращает dict с: pipe_reg, pipe_rank (если combined), meta, threshold.\n",
        "    \"\"\"\n",
        "    out_dir = os.path.join(models_dir, ticker)\n",
        "    if not os.path.exists(out_dir):\n",
        "        raise FileNotFoundError(f\"Directory for {ticker} not found: {out_dir}\")\n",
        "\n",
        "    # Загружаем meta\n",
        "    with open(os.path.join(out_dir, 'meta.json'), 'r') as f:\n",
        "        meta = json.load(f)\n",
        "\n",
        "    best_method = meta['best_method']\n",
        "    thresh = meta.get('sell_threshold', 0.0)  # Fallback\n",
        "\n",
        "    pipe_reg = None\n",
        "    pipe_rank = None\n",
        "\n",
        "    if best_method == 'regressor':\n",
        "        pipe_reg = load_optimized_pipeline(out_dir, 'regressor')\n",
        "\n",
        "    elif best_method == 'ranker':\n",
        "        pipe_rank = load_optimized_pipeline(out_dir, 'ranker')\n",
        "\n",
        "    elif best_method == 'combined':\n",
        "        pipe_reg = load_optimized_pipeline(out_dir, 'regressor')\n",
        "        pipe_rank = load_optimized_pipeline(out_dir, 'ranker')\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown best_method: {best_method}\")\n",
        "\n",
        "    return {\n",
        "        'best_method': best_method,\n",
        "        'pipe_reg': pipe_reg,\n",
        "        'pipe_rank': pipe_rank,\n",
        "        'meta': meta,\n",
        "        'threshold': thresh,\n",
        "        'calib_reg': meta.get('reg_calibration', {'a': 1.0, 'b': 0.0}),\n",
        "        'w_reg': meta.get('best_w_reg', 0.5) if best_method == 'combined' else None\n",
        "    }\n",
        "\n",
        "def extract_features(df: pd.DataFrame, window: int = 126):\n",
        "    \"\"\"\n",
        "    Вычисляет устойчивые признаки для кластеризации рыночных режимов.\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate_macd(df, macd_fast_periods=[12], macd_slow_periods=[26], macd_signal_periods=[9]):\n",
        "        \"\"\"\n",
        "        Быстрый расчет нормализованного MACD с использованием векторизованных операций\n",
        "        \"\"\"\n",
        "        close = df['close']\n",
        "\n",
        "        # Создаем множества для уникальных периодов\n",
        "        unique_fast = set(macd_fast_periods)\n",
        "        unique_slow = set(macd_slow_periods)\n",
        "\n",
        "\n",
        "        # Предварительно вычисляем все необходимые EMA и скользящие средние\n",
        "        ema_cache = {}\n",
        "        rolling_cache = {}\n",
        "\n",
        "        # Кешируем быстрые EMA\n",
        "        for fp in unique_fast:\n",
        "            ema_cache[f'ema_{fp}'] = close.ewm(span=fp, adjust=False).mean()\n",
        "\n",
        "        # Кешируем медленные EMA и скользящие средние\n",
        "        for sp in unique_slow:\n",
        "            ema_cache[f'ema_{sp}'] = close.ewm(span=sp, adjust=False).mean()\n",
        "            rolling_cache[f'rolling_{sp}'] = close.rolling(window=sp).mean()\n",
        "\n",
        "        # Основной цикл вычислений\n",
        "        for fp in macd_fast_periods:\n",
        "            ema_fast = ema_cache[f'ema_{fp}']\n",
        "            for sp in macd_slow_periods:\n",
        "                ema_slow = ema_cache[f'ema_{sp}']\n",
        "                rolling_mean = rolling_cache[f'rolling_{sp}']\n",
        "\n",
        "                # Вычисляем MACD и нормализацию\n",
        "                macd = ema_fast - ema_slow\n",
        "                macd_norm = macd / rolling_mean\n",
        "\n",
        "                # Сохраняем MACD только один раз для комбинации fp/sp\n",
        "\n",
        "                # Обрабатываем сигнальные периоды\n",
        "                for sig in macd_signal_periods:\n",
        "                    # Вычисляем сигнальную линию\n",
        "                    signal = macd.ewm(span=sig, adjust=False).mean()\n",
        "                    signal_norm = signal / rolling_mean\n",
        "\n",
        "        return pd.DataFrame([macd_norm, signal_norm, macd_norm - signal_norm]).T.fillna(0)\n",
        "\n",
        "    def calculate_atr(df, atr_window=14):\n",
        "        \"\"\"\n",
        "        Расчет ATR и его сдвигов.\n",
        "        \"\"\"\n",
        "        high = df['high']\n",
        "        low = df['low']\n",
        "        close = df['close']\n",
        "\n",
        "        tr1 = high - low\n",
        "        tr2 = np.abs(high - close.shift(1))\n",
        "        tr3 = np.abs(low - close.shift(1))\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_window).mean()\n",
        "\n",
        "        return pd.Series(atr).fillna(0)\n",
        "\n",
        "    def calculate_rsi(df, rsi_period=14):\n",
        "        \"\"\"\n",
        "        Расчет RSI и его сдвиги.\n",
        "        \"\"\"\n",
        "        close = df['close']\n",
        "        delta = close.diff()\n",
        "        gain = delta.where(delta > 0, 0)\n",
        "        loss = -delta.where(delta < 0, 0)\n",
        "        avg_gain = gain.rolling(rsi_period).mean()\n",
        "        avg_loss = loss.rolling(rsi_period).mean()\n",
        "        rs = avg_gain / (avg_loss + 1e-10)\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "        return pd.Series(rsi).fillna(0)\n",
        "\n",
        "    def calculate_bollinger_bands(df, bollinger_window=20):\n",
        "        \"\"\"\n",
        "        Расчет Bollinger Bands (ширины полос) и сдвигов.\n",
        "        \"\"\"\n",
        "        close = df['close']\n",
        "        ma = close.rolling(bollinger_window).mean()\n",
        "        std = close.rolling(bollinger_window).std()\n",
        "        bb_width = (2 * std) / ma\n",
        "\n",
        "        return pd.Series(bb_width).fillna(0)\n",
        "\n",
        "    macd_trend = calculate_macd(df, macd_slow_periods=[window], macd_fast_periods=[window//3],\n",
        "                                 macd_signal_periods=[window//6])\n",
        "    atr = calculate_atr(df, atr_window=window)\n",
        "    rel_volatility = atr / df[\"close\"]\n",
        "    rsi_ind = calculate_rsi(df, rsi_period=window//2)\n",
        "    volume_ratio = df['volume'].rolling(window).apply(\n",
        "        lambda x: x[-1]/x.mean(), raw=True\n",
        "    ).fillna(1).values\n",
        "\n",
        "    features = np.column_stack([\n",
        "        macd_trend,\n",
        "        rel_volatility,\n",
        "        rsi_ind,\n",
        "        volume_ratio\n",
        "    ])\n",
        "\n",
        "    return features\n",
        "\n",
        "def prepare_regime_params(optuna_params):\n",
        "    \"\"\"\n",
        "    Преобразует параметры из формата Optuna в два словаря: базовые параметры режимов и параметры расчета.\n",
        "\n",
        "    Args:\n",
        "        optuna_params (dict): Словарь с параметрами из Optuna\n",
        "\n",
        "    Returns:\n",
        "        dict: Словарь с двумя ключами: 'base_params' (параметры режимов) и 'calc_params' (остальные параметры)\n",
        "    \"\"\"\n",
        "    # Инициализируем словари для базовых параметров и параметров расчета\n",
        "    start_params = {}\n",
        "    base_params = {}\n",
        "    calc_params = {}\n",
        "\n",
        "    # Сначала обрабатываем параметры режимов (0-4)\n",
        "\n",
        "    start_params['moving_average_length'] = optuna_params.get('moving_average_length', 14)\n",
        "    start_params['atr_period'] = optuna_params.get('atr_period', 10)\n",
        "    for regime in range(5):\n",
        "        regime_key = f'regime_{regime}_'\n",
        "        regime_params = {}\n",
        "\n",
        "        # Основные параметры режима\n",
        "        regime_params['average_type'] = optuna_params.get(f'{regime_key}average_type', 'SMA')\n",
        "        regime_params['moving_average_length'] = optuna_params.get(f'{regime_key}ma_length', 50)\n",
        "        regime_params['atr_period'] = optuna_params.get(f'{regime_key}atr_period', 14)\n",
        "        regime_params['atr_multiplier'] = optuna_params.get(f'{regime_key}atr_multiplier', 3.0)\n",
        "\n",
        "        # Параметры AMA, если они есть\n",
        "        ama_atr_period = optuna_params.get(f'{regime_key}ama_atr_period')\n",
        "        ama_min_period = optuna_params.get(f'{regime_key}ama_min_period')\n",
        "        ama_max_period = optuna_params.get(f'{regime_key}ama_max_period')\n",
        "\n",
        "        if regime_params['average_type'] == 'AMA' and all(p is not None for p in [ama_atr_period, ama_min_period, ama_max_period]):\n",
        "            regime_params['ama_params'] = {\n",
        "                'atr_period': int(ama_atr_period),\n",
        "                'min_period': int(ama_min_period),\n",
        "                'max_period': int(ama_max_period)\n",
        "            }\n",
        "\n",
        "        base_params[regime] = regime_params\n",
        "\n",
        "    # Теперь собираем все остальные параметры в calc_params\n",
        "    other_params = [\n",
        "        'rsi_length', 'use_smoothing', 'smoothing_length', 'smoothing_type',\n",
        "        'alma_sigma', 'rsi_overbought', 'rsi_oversold', 'use_knn',\n",
        "        'knn_neighbors', 'knn_lookback', 'knn_weight', 'feature_count',\n",
        "        'use_filter', 'filter_method', 'filter_strength', 'sma_length',\n",
        "        'ema_length', 'rsi_helbuth'\n",
        "    ]\n",
        "\n",
        "    for param in other_params:\n",
        "        if param in optuna_params:\n",
        "            calc_params[param] = optuna_params[param]\n",
        "\n",
        "    return {\n",
        "        'start_params': start_params,\n",
        "        'base_params': base_params,\n",
        "        'calc_params': calc_params\n",
        "    }\n",
        "\n",
        "class FastRollingMode:\n",
        "    def __init__(self, window_size):\n",
        "        self.window = deque(maxlen=window_size)\n",
        "        self.counts = {}\n",
        "\n",
        "    def update(self, new_val):\n",
        "        if len(self.window) == self.window.maxlen:\n",
        "            old_val = self.window.popleft()\n",
        "            self.counts[old_val] -= 1\n",
        "            if self.counts[old_val] == 0:\n",
        "                del self.counts[old_val]\n",
        "\n",
        "        self.window.append(new_val)\n",
        "        self.counts[new_val] = self.counts.get(new_val, 0) + 1\n",
        "        return max(self.counts.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "MODELS_CACHE = ModelsRuntimeCache()\n",
        "\n",
        "class TradingBot:\n",
        "    def __init__(self, token, tickers, data_path, interval, timeframe_minutes, data_points):\n",
        "        self.token = token\n",
        "        self.tickers = tickers\n",
        "        self.data_path = data_path\n",
        "        self.interval = interval\n",
        "        self.timeframe_minutes = timeframe_minutes\n",
        "        self.data_points = data_points\n",
        "\n",
        "        # Маппинг тикеров и FIGI\n",
        "        self.ticker_to_figi = {}\n",
        "        self.figi_to_ticker = {}\n",
        "\n",
        "        # Исторические данные\n",
        "        self.open_price = open_price\n",
        "        self.close_price = close_price\n",
        "        self.high_price = high_price\n",
        "        self.low_price = low_price\n",
        "        self.volume = volume\n",
        "        self.time_last_kline_start = time_last_kline_start\n",
        "        self.time_last_kline_end = time_last_kline_end\n",
        "        self.ma = ma\n",
        "        self.pmax = pmax\n",
        "        self.signals = signals\n",
        "        self.close_preds = close_preds\n",
        "\n",
        "        self.active_tickers = {}\n",
        "\n",
        "        self._smoothers       = {}    # ticker → FastRollingMode\n",
        "        self._regime_history  = {}    # ticker → deque[int]\n",
        "        self._adaptive_params = {}\n",
        "        self._regime_hist    = {}\n",
        "\n",
        "\n",
        "        self.api_limits = {\n",
        "            'remaining': 600,\n",
        "            'reset_time': None,\n",
        "            'last_request': None\n",
        "        }\n",
        "\n",
        "        # Создать папку для сохранения данных, если её нет\n",
        "        if not os.path.exists(self.data_path):\n",
        "            os.makedirs(self.data_path)\n",
        "\n",
        "    async def calculate_indicators_and_signals(self, df, ticker):\n",
        "        # 0) Читаем цену\n",
        "        high_arr = df['high'].copy()\n",
        "        low_arr = df['low'].copy()\n",
        "        close_arr = df['close'].copy()\n",
        "        vol_arr = df['volume'].copy()\n",
        "\n",
        "        logging.debug(f\"high_data: {high_arr}\")\n",
        "        logging.debug(f\"low_data: {low_arr}\")\n",
        "        logging.debug(f\"close_data: {close_arr}\")\n",
        "\n",
        "        if len(high_arr) < 2 or len(low_arr) < 2 or len(close_arr) < 2:\n",
        "            return\n",
        "\n",
        "        n = high_arr.shape[0]\n",
        "\n",
        "        # 1) Режимная часть: кластерим + сглаживаем\n",
        "        params       = ticker_params[ticker]['params']\n",
        "        # размер окна для признаков\n",
        "        window_feat  = int(params['moving_average_length'] * 9.5)\n",
        "        # формируем DataFrame-мини-окно для extract_features\n",
        "        import pandas as pd\n",
        "        hist_df = pd.DataFrame({\n",
        "            'high':   high_arr,\n",
        "            'low':    low_arr,\n",
        "            'close':  close_arr,\n",
        "            'volume': vol_arr\n",
        "        })\n",
        "        features = extract_features(hist_df, window=window_feat)  # ваша функция\n",
        "        # scale + predict\n",
        "        scaled = scaler_global.transform(features)\n",
        "        labels = kmeans_global.predict(scaled)\n",
        "\n",
        "        # сглаживаем\n",
        "        window_smooth = int(params['atr_period'] * 5.5)\n",
        "        smoother = FastRollingMode(window_size=window_smooth)\n",
        "        regimes = np.array([smoother.update(l) for l in labels], dtype=int)\n",
        "\n",
        "        # 2) Готовим базовые параметры по режиму\n",
        "        regime_params = prepare_regime_params(params)['base_params']\n",
        "\n",
        "        # 3) PRE-COMPUTE MA & ATR для каждого режима\n",
        "        ma_cache  = {}\n",
        "        atr_cache = {}\n",
        "        for regime, p in regime_params.items():\n",
        "            atype = p['average_type']\n",
        "            L     = p['moving_average_length']\n",
        "            P     = p['atr_period']\n",
        "\n",
        "            if atype == 'SMA':\n",
        "                ma = self.generateSma(high_arr, low_arr, window=L)\n",
        "            elif atype == 'VAR':\n",
        "                ma = self.generateVar(high_arr, low_arr, moving_average_length=L)\n",
        "            elif atype == 'EMA':\n",
        "                ma = self.generateEma(high_arr, low_arr, moving_average_length=L)\n",
        "            elif atype == 'AMA':\n",
        "                ama_p = p.get('ama_params', {'atr_period':14,'min_period':5,'max_period':50})\n",
        "                ma = self.generateAma(\n",
        "                    high_arr, low_arr, close_arr,\n",
        "                    atr_period=ama_p['atr_period'],\n",
        "                    min_period=ama_p['min_period'],\n",
        "                    max_period=ama_p['max_period']\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown MA type {atype!r}\")\n",
        "\n",
        "            ma_cache[regime]  = ma\n",
        "            atr_cache[regime] = self.generateAtr(high_arr, low_arr, close_arr, length=P)\n",
        "\n",
        "        # 4) MERGE по маске режимов\n",
        "        var_all = np.empty(n, dtype=float)\n",
        "        atr_all = np.empty(n, dtype=float)\n",
        "        mul_all = np.empty(n, dtype=float)\n",
        "\n",
        "        for regime, p in regime_params.items():\n",
        "            mask = (regimes == regime)\n",
        "            var_all[mask] = ma_cache[regime][mask]\n",
        "            atr_all[mask] = atr_cache[regime][mask]\n",
        "            mul_all[mask] = p['atr_multiplier']\n",
        "\n",
        "        # Заполняем NAN в начале var_all\n",
        "        if np.isnan(var_all[0]):\n",
        "            first = var_all[~np.isnan(var_all)][0]\n",
        "            var_all[np.isnan(var_all)] = first\n",
        "\n",
        "        # 5) PMax state machine\n",
        "        atr_all = np.nan_to_num(atr_all, nan=0.0)\n",
        "        first_var = var_all[~np.isnan(var_all)][0]\n",
        "        var_all = np.nan_to_num(var_all, nan=first_var)\n",
        "        pmax_all = np.empty(n, dtype=float)\n",
        "        prev_v   = var_all[0]\n",
        "        prev_a   = atr_all[0]\n",
        "        prev_m   = mul_all[0]\n",
        "        prev_fu  = prev_v + prev_m * prev_a\n",
        "        prev_fl  = prev_v - prev_m * prev_a\n",
        "        prev_p   = prev_fl\n",
        "        pmax_all[0] = prev_p\n",
        "\n",
        "        for i in range(1, n):\n",
        "            v = var_all[i]; a = atr_all[i]; m = mul_all[i]\n",
        "            bu = v + m * a\n",
        "            bl = v - m * a\n",
        "\n",
        "            fu = bu if (bu < prev_fu or prev_v > prev_fu) else prev_fu\n",
        "            fl = bl if (bl > prev_fl or prev_v < prev_fl) else prev_fl\n",
        "\n",
        "            if prev_p == prev_fu:\n",
        "                p = fu if v <= fu else fl\n",
        "            else:\n",
        "                p = fl if v >= fl else fu\n",
        "\n",
        "            pmax_all[i] = p\n",
        "            prev_v, prev_fu, prev_fl, prev_p = v, fu, fl, p\n",
        "\n",
        "        # 7. Сигналы\n",
        "        v_prev = np.concatenate(([var_all[0]], var_all[:-1]))\n",
        "        p_prev = np.concatenate(([pmax_all[0]], pmax_all[:-1]))\n",
        "        buy = (v_prev < p_prev) & (var_all > pmax_all)\n",
        "        sell = (v_prev > p_prev) & (var_all < pmax_all)\n",
        "\n",
        "\n",
        "        self.ma[ticker] = var_all\n",
        "        self.pmax[ticker] = pmax_all\n",
        "\n",
        "\n",
        "        try:\n",
        "            signal = self.generate_signal(var_all[-2:], pmax_all[-2:])\n",
        "            logging.debug(f\"Сигнал для {ticker}: {signal}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при генерации сигнала для тикера {ticker}: {e}\")\n",
        "            return\n",
        "\n",
        "        # Сохраняем сигнал\n",
        "        self.signals[ticker] = signal\n",
        "        logging.debug(f\"Сигнал сохранен для {ticker}: {signal}\")\n",
        "\n",
        "    async def calculate_indicators_and_signals1(self, df, ticker):\n",
        "        \"\"\"\n",
        "        Вычисление индикаторов и сигналов для каждого тикера.\n",
        "\n",
        "        \"\"\"\n",
        "        # Получаем последние данные для тикера\n",
        "\n",
        "        #Paramsticker_params\n",
        "        params = ticker_params[ticker]['params']\n",
        "        MOVING_AVERAGE_LENGHT = params['moving_average_length']\n",
        "        ATR_PERIOD = params['atr_period']\n",
        "        ATR_MULTIPLIER = params['atr_multiplier']\n",
        "        average_type = params['average_type']\n",
        "        if average_type == 'AMA':\n",
        "          ama_params = {\n",
        "          'atr_period': int(params['ama_atr_period']),\n",
        "          'min_period': int(params['ama_min_period']),\n",
        "          'max_period': int(params['ama_max_period'])\n",
        "          }\n",
        "\n",
        "\n",
        "        high_data = df['high'].copy()\n",
        "        low_data = df['low'].copy()\n",
        "        close_data = df['close'].copy()\n",
        "\n",
        "        logging.debug(f\"high_data: {high_data}\")\n",
        "        logging.debug(f\"low_data: {low_data}\")\n",
        "        logging.debug(f\"close_data: {close_data}\")\n",
        "\n",
        "        # Проверяем, есть ли данные\n",
        "        if high_data.empty or low_data.empty or close_data.empty:\n",
        "            logging.warning(f\"Пустые данные для тикера {ticker}\")\n",
        "            return\n",
        "\n",
        "        # Генерация индикаторов\n",
        "\n",
        "        try:\n",
        "          if average_type == 'SMA':\n",
        "              ma_data = self.generateSma(high_data, low_data, MOVING_AVERAGE_LENGHT)\n",
        "          elif average_type == 'VAR':\n",
        "              ma_data = self.generateVar(high_data, low_data, MOVING_AVERAGE_LENGHT)\n",
        "          elif average_type == 'AMA':\n",
        "              if ama_params is None:\n",
        "                  raise ValueError(\"Для AMA необходимо указать параметры ama_params.\")\n",
        "              ma_data = self.generateAma(high_data, low_data, close_data, **ama_params)\n",
        "          else:\n",
        "              raise ValueError(\"Неподдерживаемый тип скользящего среднего.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при вычислении линий средних для тикера {ticker}: {e}\")\n",
        "            return\n",
        "        try:\n",
        "            logging.debug(f\"ma_data: {ma_data}\")\n",
        "\n",
        "            pmax_data = self.generatePMax(ma_data, close_data, high_data, low_data, atr_period=ATR_PERIOD,\n",
        "                                          atr_multiplier=ATR_MULTIPLIER)\n",
        "            logging.debug(f\"pmax_data: {pmax_data}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при вычислении индикаторов для тикера {ticker}: {e}\")\n",
        "            return\n",
        "\n",
        "        # Обновляем словари с индикаторами\n",
        "        self.ma[ticker] = ma_data\n",
        "        self.pmax[ticker] = pmax_data\n",
        "\n",
        "        # Вычисляем сигналы\n",
        "        try:\n",
        "            signal = self.generate_signal(ma_data[-2:], pmax_data[-2:])\n",
        "            logging.debug(f\"Сигнал для {ticker}: {signal}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при генерации сигнала для тикера {ticker}: {e}\")\n",
        "            return\n",
        "\n",
        "        # Сохраняем сигнал\n",
        "        self.signals[ticker] = signal\n",
        "        logging.debug(f\"Сигнал сохранен для {ticker}: {signal}\")\n",
        "\n",
        "        '''# Отправляем сигнал в Telegram если необходимо\n",
        "        if signal == 'buy':\n",
        "            send_buy_signal_to_telegram(ticker, close_data[-1])\n",
        "        elif signal == 'sell':\n",
        "            send_sell_signal_to_telegram(ticker, close_data[-1])'''\n",
        "\n",
        "    def generateVar(self, high_array, low_array, moving_average_length=14):\n",
        "        \"\"\"\n",
        "        Генерация VAR (Volatility Adjusted Ratio).\n",
        "\n",
        "        :param high_array: Массив значений high.\n",
        "        :param low_array: Массив значений low.\n",
        "        :param moving_average_length: Период для расчета VAR.\n",
        "        :return: Массив значений VAR.\n",
        "        \"\"\"\n",
        "        # Константа alpha\n",
        "        valpha = 2 / (moving_average_length + 1)\n",
        "\n",
        "        # Вычисляем среднее значение между high и low\n",
        "        hl2 = (high_array + low_array) / 2\n",
        "\n",
        "        # Вычисляем разницы для vud1 и vdd1\n",
        "        diff = np.diff(hl2, prepend=hl2[0])\n",
        "        vud1 = np.where(diff > 0, diff, 0)\n",
        "        vdd1 = np.where(diff < 0, -diff, 0)\n",
        "\n",
        "        # Функция для расчета скользящих сумм\n",
        "        def calculate_window_sums(arr, window_size=9):\n",
        "            cumsum = np.cumsum(arr)\n",
        "            return cumsum - np.concatenate((np.zeros(window_size), cumsum[:-window_size]))\n",
        "\n",
        "        # Вычисляем vUD и vDD\n",
        "        vUD = calculate_window_sums(vud1, 9)\n",
        "        vDD = calculate_window_sums(vdd1, 9)\n",
        "\n",
        "        # Вычисляем vCMO\n",
        "        epsilon = 1e-10\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            vCMO = np.divide(vUD - vDD, vUD + vDD + epsilon)\n",
        "        vCMO = np.nan_to_num(vCMO, nan=0.0)\n",
        "\n",
        "        # Вычисляем VAR\n",
        "        cmo_abs = np.abs(vCMO)\n",
        "        var = np.zeros_like(hl2)\n",
        "        var_before = 0.0\n",
        "        for i in range(len(hl2)):\n",
        "            if i < len(cmo_abs):\n",
        "                var[i] = (valpha * cmo_abs[i] * hl2[i]) + (1 - valpha * cmo_abs[i]) * var_before\n",
        "            else:\n",
        "                var[i] = var_before\n",
        "            var_before = var[i]\n",
        "        del valpha, hl2, vud1, vdd1, var_before, vUD, vDD, vCMO\n",
        "        return var\n",
        "\n",
        "    def generateAma(self, high_array, low_array, close_array, atr_period=14, min_period=5, max_period=50):\n",
        "        \"\"\"\n",
        "        Генерация адаптивного скользящего среднего на основе волатильности.\n",
        "\n",
        "        :param high_array: Массив значений high.\n",
        "        :param low_array: Массив значений low.\n",
        "        :param close_array: Массив значений close.\n",
        "        :param atr_period: Период для расчета ATR.\n",
        "        :param min_period: Минимальный период скользящего среднего.\n",
        "        :param max_period: Максимальный период скользящего среднего.\n",
        "        :return: Массив значений адаптивного скользящего среднего.\n",
        "        \"\"\"\n",
        "        # Рассчитываем ATR\n",
        "        atr = self._calculate_atr(high_array, low_array, close_array, atr_period)\n",
        "\n",
        "        # Нормализуем ATR для использования в качестве коэффициента\n",
        "        normalized_atr = (atr - np.min(atr)) / (np.max(atr) - np.min(atr) + 1e-10)\n",
        "\n",
        "        # Рассчитываем динамический период\n",
        "        dynamic_period = min_period + (max_period - min_period) * normalized_atr\n",
        "\n",
        "        # Рассчитываем адаптивное скользящее среднее (гибрид SMA и EMA)\n",
        "        adaptive_ma = np.zeros_like(close_array)\n",
        "        for i in range(len(close_array)):\n",
        "            if i < int(dynamic_period[i]):\n",
        "                adaptive_ma[i] = np.mean(close_array[:i+1])  # SMA для начальных значений\n",
        "            else:\n",
        "                period = int(dynamic_period[i])\n",
        "                alpha = 2 / (period + 1)\n",
        "                adaptive_ma[i] = alpha * close_array[i] + (1 - alpha) * adaptive_ma[i-1]  # EMA\n",
        "\n",
        "        return adaptive_ma\n",
        "\n",
        "    def _calculate_atr(self, high_array, low_array, close_array, period=14):\n",
        "        \"\"\"\n",
        "        Рассчитывает Average True Range (ATR).\n",
        "\n",
        "        :param high_array: Массив значений high.\n",
        "        :param low_array: Массив значений low.\n",
        "        :param close_array: Массив значений close.\n",
        "        :param period: Период для расчета ATR.\n",
        "        :return: Массив значений ATR.\n",
        "        \"\"\"\n",
        "        tr = np.zeros_like(high_array)\n",
        "        tr[0] = high_array[0] - low_array[0]\n",
        "\n",
        "        for i in range(1, len(high_array)):\n",
        "            hl = high_array[i] - low_array[i]\n",
        "            hc = abs(high_array[i] - close_array[i-1])\n",
        "            lc = abs(low_array[i] - close_array[i-1])\n",
        "            tr[i] = max(hl, hc, lc)\n",
        "\n",
        "        atr = np.zeros_like(tr)\n",
        "        atr[period-1] = np.mean(tr[:period])\n",
        "\n",
        "        for i in range(period, len(tr)):\n",
        "            atr[i] = (atr[i-1] * (period-1) + tr[i]) / period\n",
        "\n",
        "        return atr\n",
        "\n",
        "    def generateEma(self, high_array, low_array, moving_average_length=14):\n",
        "        \"\"\"Вычисление EMA.\"\"\"\n",
        "        if high_array.empty or low_array.empty:\n",
        "            return []\n",
        "\n",
        "        hl2 = [(high + low) / 2 for high, low in zip(high_array, low_array)]\n",
        "        ema = np.full_like(hl2, np.nan)\n",
        "        alpha = 2 / (moving_average_length + 1)\n",
        "\n",
        "        if moving_average_length <= 1:\n",
        "            return hl2\n",
        "\n",
        "        start_idx = moving_average_length - 1\n",
        "        sma = np.mean(hl2[:moving_average_length])\n",
        "        ema[start_idx] = sma\n",
        "\n",
        "        for i in range(start_idx + 1, len(hl2)):\n",
        "            ema[i] = alpha * hl2[i] + (1 - alpha) * ema[i - 1]\n",
        "\n",
        "        del hl2, alpha, start_idx, sma\n",
        "        return ema\n",
        "\n",
        "    def generateAtr(self, high_array, low_array, close_array, length=14):\n",
        "        \"\"\"Вычисление ATR.\"\"\"\n",
        "        if high_array.empty or low_array.empty or close_array.empty:\n",
        "            return []\n",
        "\n",
        "        n = len(high_array)\n",
        "        if n == 0 or length > n:\n",
        "            return []\n",
        "\n",
        "        tr = np.zeros(n)\n",
        "        atr = np.full(n, np.nan)\n",
        "\n",
        "        prev_close = np.roll(close_array, 1)\n",
        "        prev_close[0] = np.nan\n",
        "\n",
        "        tr[0] = high_array[0] - low_array[0]\n",
        "\n",
        "        for i in range(1, n):\n",
        "            hl = high_array[i] - low_array[i]\n",
        "            hc = abs(high_array[i] - prev_close[i])\n",
        "            lc = abs(low_array[i] - prev_close[i])\n",
        "            tr[i] = max(hl, hc, lc)\n",
        "\n",
        "        if n >= length:\n",
        "            atr[length - 1] = np.mean(tr[:length])\n",
        "            alpha = 1.0 / length\n",
        "            for i in range(length, n):\n",
        "                atr[i] = alpha * tr[i] + (1 - alpha) * atr[i - 1]\n",
        "\n",
        "        del n, tr, prev_close, hl, hc, lc, alpha\n",
        "        return atr\n",
        "\n",
        "    def generateSma(self, high_array, low_array, window=14):\n",
        "        if len(high_array) < window or len(low_array) < window:\n",
        "            return np.full(len(high_array), np.nan)\n",
        "\n",
        "        hl2 = (high_array + low_array) * 0.5\n",
        "        sma = np.full_like(hl2, np.nan)\n",
        "        cumsum = np.cumsum(hl2)\n",
        "        shifted_cumsum = np.zeros_like(cumsum)\n",
        "        shifted_cumsum[window:] = cumsum[:-window]\n",
        "        valid = slice(window - 1, None)\n",
        "        sma[valid] = (cumsum[valid] - shifted_cumsum[valid]) / window\n",
        "\n",
        "        return sma\n",
        "\n",
        "    def generatePMax(self, var_array, close_array, high_array, low_array, atr_period=14, atr_multiplier=3):\n",
        "        \"\"\"Вычисление PMAX.\"\"\"\n",
        "        if high_array.size==0 or low_array.size==0 or close_array.size==0 or len(var_array) == 0:\n",
        "            return []\n",
        "\n",
        "        atr = self.generateAtr(high_array, low_array, close_array, length=atr_period)\n",
        "        pmax = []\n",
        "        previous_final_upperband = 0\n",
        "        previous_final_lowerband = 0\n",
        "        previous_var = 0\n",
        "        previous_pmax = 0\n",
        "\n",
        "        for i in range(len(close_array)):\n",
        "            atrc = atr[i] if i < len(atr) and not np.isnan(atr[i]) else 0\n",
        "            varc = var_array[i] if i < len(var_array) else 0\n",
        "\n",
        "            basic_upperband = varc + atr_multiplier * atrc\n",
        "            basic_lowerband = varc - atr_multiplier * atrc\n",
        "\n",
        "            final_upperband = basic_upperband if (\n",
        "                    basic_upperband < previous_final_upperband or previous_var > previous_final_upperband) else previous_final_upperband\n",
        "            final_lowerband = basic_lowerband if (\n",
        "                    basic_lowerband > previous_final_lowerband or previous_var < previous_final_lowerband) else previous_final_lowerband\n",
        "\n",
        "            if previous_pmax == previous_final_upperband:\n",
        "                pmaxc = final_upperband if varc <= final_upperband else final_lowerband\n",
        "            else:\n",
        "                pmaxc = final_lowerband if varc >= final_lowerband else final_upperband\n",
        "\n",
        "            pmax.append(pmaxc)\n",
        "            previous_var = varc\n",
        "            previous_final_upperband = final_upperband\n",
        "            previous_final_lowerband = final_lowerband\n",
        "            previous_pmax = pmaxc\n",
        "\n",
        "        del atr, previous_final_upperband, previous_final_lowerband, previous_var, previous_pmax, pmaxc\n",
        "        return pmax\n",
        "\n",
        "    def generate_signal(self, var, pmax):\n",
        "        \"\"\"Генерация сигнала на основе VAR и PMAX.\"\"\"\n",
        "        if var.size!= 0 or not pmax:\n",
        "            return None\n",
        "\n",
        "        last_var = var[-1]\n",
        "\n",
        "        previous_var = var[-2] if len(var) >= 2 else last_var\n",
        "        last_pmax = pmax[-1]\n",
        "        previous_pmax = pmax[-2] if len(pmax) >= 2 else last_pmax\n",
        "\n",
        "        if last_var > last_pmax and previous_var < previous_pmax:\n",
        "            del last_var, previous_var, last_pmax, previous_pmax\n",
        "            return 'buy'\n",
        "        elif last_var < last_pmax and previous_var > previous_pmax:\n",
        "            del last_var, previous_var, last_pmax, previous_pmax\n",
        "            return 'sell'\n",
        "        else:\n",
        "            del last_var, previous_var, last_pmax, previous_pmax\n",
        "            return 'hold'\n",
        "\n",
        "    async def initialize_tickers(self):\n",
        "        \"\"\"Инициализация тикеров и проверка их торгового статуса.\"\"\"\n",
        "        async with AsyncClient(self.token) as client:\n",
        "            instruments = await client.instruments.shares()\n",
        "            for share in instruments.instruments:\n",
        "                if share.ticker in self.tickers:\n",
        "                    status = await client.market_data.get_trading_status(figi=share.figi)\n",
        "                    if status.api_trade_available_flag and share.ticker in ticker_params.keys():\n",
        "                        self.ticker_to_figi[share.ticker] = share.figi\n",
        "                        self.figi_to_ticker[share.figi] = share.ticker\n",
        "                        self.active_tickers[share.ticker] = {\n",
        "                            'figi': share.figi,\n",
        "                            'name': share.name,\n",
        "                            'status': status.market_order_available_flag\n",
        "                        }\n",
        "            print(f\"[INIT] Активных тикеров: {len(self.ticker_to_figi)}\")\n",
        "\n",
        "    '''async def fetch_historical_data(self, days=365):\n",
        "        \"\"\"Получить исторические данные и обработать каждый тикер последовательно\"\"\"\n",
        "        now = dt.utcnow()\n",
        "\n",
        "        async with AsyncClient(self.token) as client:\n",
        "            tickers_list = list(self.active_tickers.items())\n",
        "            total_tickers = len(tickers_list)\n",
        "\n",
        "            for idx, (ticker, figi) in enumerate(tickers_list, 1):\n",
        "                try:\n",
        "                    print(f\"\\nОбработка тикера {ticker} ({idx}/{total_tickers})\")\n",
        "\n",
        "                    # Загрузка данных для текущего тикера\n",
        "                    df = await self._load_ticker_data(client, figi['figi'], now, days)\n",
        "                    if df.empty:\n",
        "                        continue\n",
        "\n",
        "                    await self.calculate_indicators_and_signals(df, ticker)\n",
        "\n",
        "                    # Инициализируем списки данных\n",
        "                    self.time_last_kline_start[ticker] = [ts.isoformat() for ts in df['time'].tail(self.data_points).tolist()]\n",
        "                    self.time_last_kline_end[ticker] = [ts.isoformat() for ts in df['time_close'].tail(self.data_points).tolist()]\n",
        "                    self.open_price[ticker] = df['open'].tail(self.data_points).tolist()\n",
        "                    self.close_price[ticker] = df['close'].tail(self.data_points).tolist()\n",
        "                    self.high_price[ticker] = df['high'].tail(self.data_points).tolist()\n",
        "                    self.low_price[ticker] = df['low'].tail(self.data_points).tolist()\n",
        "                    self.volume[ticker] = df['volume'].tail(self.data_points).tolist()\n",
        "\n",
        "                    self.ma[ticker] = self.ma[ticker][-self.data_points:].tolist()\n",
        "                    self.pmax[ticker] = self.pmax[ticker][-self.data_points:]\n",
        "\n",
        "                    await self.save_data()\n",
        "\n",
        "\n",
        "\n",
        "                    # Явная очистка памяти\n",
        "                    del df\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Ошибка при обработке {ticker}: {str(e)}\")\n",
        "                finally:\n",
        "                    # Задержка для соблюдения лимитов API\n",
        "                    await asyncio.sleep(0.5)'''\n",
        "\n",
        "    async def compute_predictions_full(self, df, ticker: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Глобальный расчёт предиктов для стартового бота:\n",
        "          - не пересчитывает MA/PMax;\n",
        "          - формирует buy/sell интервалы через event_time/event_sell_time,\n",
        "            trade_bars_counter и batch, как в FeatureCalculatorForRegression;\n",
        "          - предсказания только внутри батчей (интервалы buy→sell, либо buy→конец);\n",
        "          - вне батчей — np.nan;\n",
        "          - обрезает хвост до self.data_points и сохраняет в self.predictions[ticker].\n",
        "        \"\"\"\n",
        "        try:\n",
        "            df['ma'] = self.ma[ticker]\n",
        "            df['pmax'] = self.pmax[ticker]\n",
        "\n",
        "            n_total = len(df)\n",
        "\n",
        "            if len(df) == 0:\n",
        "               self.close_preds[ticker] = np.array([], dtype=float)\n",
        "               return self.close_preds[ticker]\n",
        "\n",
        "            # 2) Режимы (кластеризация + сглаживание)\n",
        "            params_phase = phase_ticker_params[ticker]['params']\n",
        "            window_feat = int(params_phase['moving_average_length'] * 9.5)\n",
        "            scaler_global = MODELS_CACHE.scaler_global\n",
        "            kmeans_global = MODELS_CACHE.kmeans_global\n",
        "\n",
        "            # extract_features ожидает high/low/close/volume\n",
        "            feat_for_cluster = extract_features(\n",
        "                df[['high', 'low', 'close', 'volume']].copy(),\n",
        "                window=window_feat\n",
        "            )\n",
        "            if len(feat_for_cluster) == 0:\n",
        "                out = np.full(n_total, np.nan, dtype=float)\n",
        "                out = out[-self.data_points:] if hasattr(self, 'data_points') and self.data_points > 0 else out\n",
        "                if not hasattr(self, 'predictions'):\n",
        "                    self.close_preds = {}\n",
        "                self.close_preds[ticker] = out\n",
        "                return out\n",
        "\n",
        "            labels = kmeans_global.predict(scaler_global.transform(feat_for_cluster))\n",
        "            window_smooth = int(params_phase['atr_period'] * 5.5)\n",
        "            smoother = FastRollingMode(window_size=window_smooth)\n",
        "            regimes_smoothed = np.array([smoother.update(int(x)) for x in labels], dtype=int)\n",
        "            df['regime'] = regimes_smoothed\n",
        "\n",
        "            # 3) Восстановление buy/sell и событий\n",
        "            # 3.0: первичные buy/sell по ma/pmax, как в calculate_indicators_and_signals\n",
        "            v = df['ma'].to_numpy()\n",
        "            p = df['pmax'].to_numpy()\n",
        "            v_prev = np.concatenate(([v[0]], v[:-1]))\n",
        "            p_prev = np.concatenate(([p[0]], p[:-1]))\n",
        "            df['buy_signal'] = (v_prev < p_prev) & (v > p)\n",
        "            df['sell_signal'] = (v_prev > p_prev) & (v < p)\n",
        "\n",
        "            # 3.1: Проставляем event_time/event_sell_time (если ещё не готовы в вашем объекте)\n",
        "            # Если у вас уже есть эти колонки — закомментируйте этот блок и присвойте из ваших структур.\n",
        "            df['event_time'] = pd.NaT\n",
        "            df['event_price'] = np.nan\n",
        "            df['event_sell_time'] = pd.NaT\n",
        "            df['event_sell_price'] = np.nan\n",
        "\n",
        "            buy_rows = df.index[df['buy_signal'] == True]\n",
        "            sell_rows = df.index[df['sell_signal'] == True]\n",
        "            sell_times = df.loc[sell_rows, 'time']\n",
        "\n",
        "            for st in buy_rows:\n",
        "                # находим первый sell после buy\n",
        "                later_sell = sell_times[sell_times > df.at[st, 'time']]\n",
        "                if len(later_sell) > 0:\n",
        "                    end_time = later_sell.iloc[0]\n",
        "                    end_idx = int(df.index[df['time'] == end_time][0])\n",
        "                    df.at[st, 'event_time'] = df.at[st, 'time']\n",
        "                    df.at[st, 'event_price'] = df.at[st, 'close']\n",
        "                    df.at[st, 'event_sell_time'] = df.at[end_idx, 'time']\n",
        "                    df.at[st, 'event_sell_price'] = df.at[end_idx, 'close']\n",
        "                else:\n",
        "                    # активная сделка до конца — sell_time = NaT (это важно для _feat_trade_duration)\n",
        "                    df.at[st, 'event_time'] = df.at[st, 'time']\n",
        "                    df.at[st, 'event_price'] = df.at[st, 'close']\n",
        "                    # event_sell_time останется NaT\n",
        "\n",
        "            # 3.2: PnL чисто для совместимости с вашими функциями (не обязателен для прогнозов)\n",
        "            # Если есть пара buy→sell — расчёт как у вас:\n",
        "            with np.errstate(divide='ignore', invalid='ignore'):\n",
        "                df['pnl'] = ((df['event_sell_price'] * (1 - 0.003)) /\n",
        "                            (df['event_price'] * (1 + 0.003)) - 1) * 100\n",
        "\n",
        "            # 3.4: Нормализованный таргет + batch, как в calculate_smoothed_target_qnorm\n",
        "            # Эта функция назначает batch для каждого интервала buy→sell и создаёт normalized_target.\n",
        "            df_q = calculate_smoothed_target_qnorm(\n",
        "                df.copy(),\n",
        "                smooth_method='whittaker',\n",
        "                whittaker_lambda=10,\n",
        "                savgol_window=15,\n",
        "                savgol_poly=3,\n",
        "                per_batch_equalize=True,\n",
        "                per_batch_q=0.01\n",
        "            )\n",
        "            # переносим batch и normalized_target обратно\n",
        "            df['batch'] = df_q['batch']\n",
        "            df['normalized_target'] = df_q['normalized_target']\n",
        "\n",
        "            # 4) Готовим финальные признаки через calculate_indicators (строго как у вас)\n",
        "            final_cols = MODELS_CACHE.final_cols\n",
        "            final_params = MODELS_CACHE.final_params\n",
        "            feats_list = final_cols[ticker]\n",
        "            params = build_feature_params(final_params[ticker])\n",
        "\n",
        "            # calculate_indicators внутри себя применит:\n",
        "            # - FeatureCalculatorForRegression\n",
        "            # - отфильтрует строки по trade_bars_counter >= 0\n",
        "            # - приведет типы и удалит служебные колонки\n",
        "            gh, _ = calculate_indicators_pred(\n",
        "                df.copy(),\n",
        "                features=feats_list,\n",
        "                params=params,\n",
        "                multy=False\n",
        "            )\n",
        "\n",
        "            if len(gh) == 0:\n",
        "                out = np.full(n_total, np.nan, dtype=float)\n",
        "                out = out[-self.data_points:] if hasattr(self, 'data_points') and self.data_points > 0 else out\n",
        "                if not hasattr(self, 'predictions'):\n",
        "                    self.close_preds = {}\n",
        "                self.close_preds[ticker] = out\n",
        "                return out\n",
        "\n",
        "            # 5) Прогон через transformer\n",
        "            pipeline_trans = MODELS_CACHE.load_transformer_for(ticker, device='cpu')\n",
        "\n",
        "            # Собираем вход для transformer: feats_list + ['batch','regime','time_idx']\n",
        "            # В gh уже есть 'regime' (object) и 'batch' (int), но time мы удалили раньше — вернём time в gh\n",
        "            # 1) Подготовка входа для трансформера\n",
        "            gh = gh.rename(columns={'time': 'time_idx'})\n",
        "            indexes = gh.index\n",
        "            columns_for_neuro = feats_list + ['batch', 'regime', 'time_idx']\n",
        "            gh_test = gh[columns_for_neuro].copy()\n",
        "\n",
        "            # 2) Маска валидных строк для pipeline_trans (нет пропусков во входных признаках)\n",
        "            valid_mask = ~gh_test.isna().any(axis=1)\n",
        "\n",
        "            # 3) Предсказываем только по валидным строкам\n",
        "            predd_full = np.full(len(gh_test), np.nan, dtype=float)\n",
        "            if valid_mask.any():\n",
        "                with warnings.catch_warnings(record=True):\n",
        "                    warnings.simplefilter(\"always\")\n",
        "                    predd_valid = pipeline_trans.predict(gh_test.loc[valid_mask])\n",
        "                predd_full[valid_mask.values] = np.asarray(predd_valid, dtype=float)\n",
        "\n",
        "            # 4) Записываем ровно в gh той же длины\n",
        "            gh['predd'] = predd_full\n",
        "\n",
        "            # 5) Производные признаки из предсказаний\n",
        "            gh['predd_shift_5'] = gh['predd'].shift(5).fillna(0.0)\n",
        "            gh['predd_pct'] = gh['predd'].pct_change(3).fillna(0.0)\n",
        "            gh['predd_var'] = gh['predd'].rolling(10).var().fillna(0.0)\n",
        "\n",
        "            # 6) Модель (LightGBM/Ranker/Combined)\n",
        "            model_data = MODELS_CACHE.load_lgb_for(ticker)\n",
        "            columns_for_model = feats_list + ['regime', 'predd', 'predd_var', 'predd_shift_5', 'predd_pct']\n",
        "            X_pred_all = gh[columns_for_model].copy()\n",
        "\n",
        "            best_method = getattr(model_data, 'best_method', 'combined')\n",
        "            if best_method == 'regressor':\n",
        "                pred_all = model_data.pipe_reg.predict(X_pred_all)\n",
        "                pred_all = apply_linear_calibration(pred_all, model_data.calib_reg)\n",
        "            elif best_method == 'ranker':\n",
        "                pred_all = model_data.pipe_rank.predict(X_pred_all)\n",
        "                pred_all = ranker_postprocess_minus1_1(pred_all)\n",
        "            elif best_method == 'combined':\n",
        "                pred_reg = model_data.pipe_reg.predict(X_pred_all)\n",
        "                pred_reg = apply_linear_calibration(pred_reg, model_data.calib_reg)\n",
        "                pred_rank = model_data.pipe_rank.predict(X_pred_all)\n",
        "                pred_rank = ranker_postprocess_minus1_1(pred_rank)\n",
        "                w = model_data.w_reg if getattr(model_data, 'w_reg', None) is not None else 0.5\n",
        "                pred_all = pred_reg * w + pred_rank * (1 - w)\n",
        "            else:\n",
        "                pred_all = np.full(len(X_pred_all), np.nan, dtype=float)\n",
        "\n",
        "            pred_all = np.asarray(pred_all, dtype=float).ravel()\n",
        "\n",
        "            # 7) Сведение к исходному df по времени\n",
        "            out_full = np.full(n_total, np.nan, dtype=float)\n",
        "            gh_times = pd.to_datetime(gh['time_idx'], utc=True)\n",
        "            df_times = df['time']\n",
        "            pos_in_df = pd.Index(df_times).get_indexer(gh_times)\n",
        "            valid = pos_in_df >= 0\n",
        "            out_full[pos_in_df[valid]] = pred_all[valid]\n",
        "            self.close_preds[ticker] = out_full\n",
        "\n",
        "        except Exception as e:\n",
        "            # Лог и безопасный возврат\n",
        "            logging.exception(f\"[{ticker}] Ошибка compute_predictions_full: {e}\")\n",
        "            if not hasattr(self, 'predictions'):\n",
        "                self.close_preds = {}\n",
        "            self.close_preds[ticker] = np.array([], dtype=float)\n",
        "            return self.close_preds[ticker]\n",
        "\n",
        "\n",
        "    def _compute_buy_sell_ranges_from_ma_pmax(self, ma_arr: Sequence[float], pmax_arr: Sequence[float]) -> list[tuple[int, typing.Optional[int]]]:\n",
        "        \"\"\"\n",
        "        Восстанавливает интервалы сделок по логике пересечений var=pmax:\n",
        "        - buy, когда var пересекает pmax снизу вверх (v_prev < p_prev) & (v_now > p_now)\n",
        "        - sell, когда var пересекает pmax сверху вниз (v_prev > p_prev) & (v_now < p_now)\n",
        "        Возвращает список кортежей (buy_idx, sell_idx_or_None), где sell_idx None если сделка не закрыта до конца.\n",
        "        \"\"\"\n",
        "        v = np.asarray(ma_arr, dtype=float)\n",
        "        p = np.asarray(pmax_arr, dtype=float)\n",
        "        n = len(v)\n",
        "        if n == 0:\n",
        "            return []\n",
        "\n",
        "        v_prev = np.concatenate(([v[0]], v[:-1]))\n",
        "        p_prev = np.concatenate(([p[0]], p[:-1]))\n",
        "\n",
        "        buy_mask = (v_prev < p_prev) & (v > p)\n",
        "        sell_mask = (v_prev > p_prev) & (v < p)\n",
        "\n",
        "        buy_idx = np.where(buy_mask)[0].tolist()\n",
        "        sell_idx = np.where(sell_mask)[0].tolist()\n",
        "\n",
        "        ranges = []\n",
        "        si = 0\n",
        "        for b in buy_idx:\n",
        "            # ищем первый sell строго после b\n",
        "            s = None\n",
        "            while si < len(sell_idx) and sell_idx[si] <= b:\n",
        "                si += 1\n",
        "            if si < len(sell_idx):\n",
        "                s = sell_idx[si]\n",
        "                si += 1\n",
        "            ranges.append((b, s))\n",
        "        # если первых событий sell больше, чем buy, они игнорируются (нет открытой сделки до них)\n",
        "        return ranges\n",
        "\n",
        "    async def fetch_historical_data(self, days=800):\n",
        "          \"\"\"Получить исторические данные и обработать каждый тикер с контролем длительности.\"\"\"\n",
        "          now = dt.utcnow()\n",
        "\n",
        "          async with AsyncClient(self.token) as client:\n",
        "              tickers_list = list(self.active_tickers.items())\n",
        "              total_tickers = len(tickers_list)\n",
        "\n",
        "              for idx, (ticker, figi) in enumerate(tickers_list, 1):\n",
        "                  start_time = time.monotonic()  # Зафиксируем старт времени\n",
        "\n",
        "                  try:\n",
        "                      print(f\"\\nОбработка тикера {ticker} ({idx}/{total_tickers})\")\n",
        "\n",
        "                      # Загрузка данных\n",
        "                      df = await self._load_ticker_data(client, figi['figi'], now, days)\n",
        "                      if df.empty:\n",
        "                          continue\n",
        "\n",
        "                      await self.calculate_indicators_and_signals(df, ticker)\n",
        "\n",
        "                      await self.compute_predictions_full(df, ticker)\n",
        "\n",
        "                      # Инициализация списков\n",
        "                      self.time_last_kline_start[ticker] = [ts.isoformat() for ts in df['time'].tail(self.data_points).tolist()]\n",
        "                      self.time_last_kline_end[ticker] = [ts.isoformat() for ts in df['time_close'].tail(self.data_points).tolist()]\n",
        "                      self.open_price[ticker] = df['open'].tail(self.data_points).tolist()\n",
        "                      self.close_price[ticker] = df['close'].tail(self.data_points).tolist()\n",
        "                      self.high_price[ticker] = df['high'].tail(self.data_points).tolist()\n",
        "                      self.low_price[ticker] = df['low'].tail(self.data_points).tolist()\n",
        "                      self.volume[ticker] = df['volume'].tail(self.data_points).tolist()\n",
        "\n",
        "                      self.ma[ticker] = self.ma[ticker][-self.data_points:].tolist()\n",
        "                      self.pmax[ticker] = self.pmax[ticker][-self.data_points:].tolist()\n",
        "\n",
        "                      self.close_preds[ticker] = self.close_preds[ticker][-self.data_points:].tolist()\n",
        "\n",
        "                      '''ress[ticker] = pd.DataFrame({\n",
        "                        'time': self.time_last_kline_start[ticker],\n",
        "                        'time_close': self.time_last_kline_end[ticker],\n",
        "                        'open':self.open_price[ticker],\n",
        "                        'high':self.high_price[ticker],\n",
        "                        'low':self.low_price[ticker],\n",
        "                        'close':self.close_price[ticker],\n",
        "                        'volume':self.volume[ticker],\n",
        "                        'ma':self.ma[ticker],\n",
        "                        'pmax':self.pmax[ticker],\n",
        "                        'preds':self.close_preds[ticker]\n",
        "                      }\n",
        "                      )'''\n",
        "\n",
        "                      await self.save_data()\n",
        "\n",
        "                      del df  # Очистка памяти\n",
        "\n",
        "                  except Exception as e:\n",
        "                      print(f\"Ошибка при обработке {ticker}: {str(e)}\")\n",
        "\n",
        "                  finally:\n",
        "                      elapsed = time.monotonic() - start_time\n",
        "                      remaining = 60 - elapsed\n",
        "                      if remaining > 0:\n",
        "                          # Обеспечим, чтобы обработка одного тикера занимала не менее 60 секунд\n",
        "                          await asyncio.sleep(remaining)\n",
        "\n",
        "\n",
        "\n",
        "    async def _load_ticker_data(self, client, figi, now, days, retries=3):\n",
        "        candles = []\n",
        "        total_blocks = (days // 90) + (1 if days % 90 else 0)\n",
        "\n",
        "        for block in range(total_blocks):\n",
        "            for attempt in range(retries):\n",
        "                try:\n",
        "                    from_time = now - timedelta(days=(block+1)*90)\n",
        "                    to_time = now - timedelta(days=block*90)\n",
        "\n",
        "                    async for candle in client.get_all_candles(\n",
        "                        figi=figi,\n",
        "                        from_=from_time,\n",
        "                        to=to_time,\n",
        "                        interval=self.interval\n",
        "                    ):\n",
        "                        candles.append({\n",
        "                            \"time\": candle.time + timedelta(hours=3),\n",
        "                            \"time_close\": candle.time + timedelta(hours=3)+timedelta(minutes=self.timeframe_minutes),\n",
        "                            \"open\": float(candle.open.units + candle.open.nano * 1e-9),\n",
        "                            \"close\": float(candle.close.units + candle.close.nano * 1e-9),\n",
        "                            \"high\": float(candle.high.units + candle.high.nano * 1e-9),\n",
        "                            \"low\": float(candle.low.units + candle.low.nano * 1e-9),\n",
        "                            \"volume\": candle.volume,\n",
        "                        })\n",
        "\n",
        "                    break  # успешная попытка — выходим из цикла retry\n",
        "                except RequestError as e:\n",
        "                    if e.status == StatusCode.INTERNAL and attempt < retries - 1:\n",
        "                        logging.warning(f\"[{figi}] INTERNAL ERROR. Повтор {attempt+1}/{retries}\")\n",
        "                        await asyncio.sleep(1 + attempt)\n",
        "                    else:\n",
        "                        raise\n",
        "        return self._clean_data(candles)\n",
        "\n",
        "    async def _load_ticker_data_back(self, client, figi, now, days):\n",
        "        \"\"\"Загрузка данных для одного тикера\"\"\"\n",
        "        candles = []\n",
        "        total_blocks = (days // 90) + (1 if days % 90 else 0)\n",
        "\n",
        "        try:\n",
        "            for block in range(total_blocks):\n",
        "                from_time = now - timedelta(days=(block+1)*90)\n",
        "                to_time = now - timedelta(days=block*90)\n",
        "\n",
        "                async for candle in client.get_all_candles(\n",
        "                    figi=figi,\n",
        "                    from_=from_time,\n",
        "                    to=to_time,\n",
        "                    interval=self.interval\n",
        "                ):\n",
        "                    candles.append({\n",
        "                        \"time\": candle.time + timedelta(hours=3),\n",
        "                        \"time_close\": candle.time + timedelta(hours=3)+timedelta(minutes=self.timeframe_minutes),\n",
        "                        \"open\": float(candle.open.units + candle.open.nano * 1e-9),\n",
        "                        \"close\": float(candle.close.units + candle.close.nano * 1e-9),\n",
        "                        \"high\": float(candle.high.units + candle.high.nano * 1e-9),\n",
        "                        \"low\": float(candle.low.units + candle.low.nano * 1e-9),\n",
        "                        \"volume\": candle.volume,\n",
        "                    })\n",
        "\n",
        "                # Обновление прогресса\n",
        "                print(f\"Загружено блоков: {block+1}/{total_blocks}\", end='\\r')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки данных: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        return self._clean_data(candles)\n",
        "\n",
        "    def _clean_data(self, candles):\n",
        "        \"\"\"Очистка и преобразование данных\"\"\"\n",
        "        if not candles:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame(candles)\n",
        "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "        return df.sort_values(\"time\").drop_duplicates(\"time\").reset_index(drop=True)\n",
        "\n",
        "    async def process_candle_stream(self, candle: Candle):\n",
        "        \"\"\"Обработка новых свечей в реальном времени.\"\"\"\n",
        "        ticker = self.figi_to_ticker.get(candle.figi)\n",
        "        if not ticker:\n",
        "            return\n",
        "\n",
        "\n",
        "        ts = int(candle.time.timestamp() * 1000)\n",
        "        self.open_price[ticker] = self.open_price[ticker][1:] + [float(candle.open.units + candle.open.nano * 1e-9)]\n",
        "        self.close_price[ticker] = self.close_price[ticker][1:] + [float(candle.close.units + candle.close.nano * 1e-9)]\n",
        "        self.high_price[ticker] = self.high_price[ticker][1:] + [float(candle.high.units + candle.high.nano * 1e-9)]\n",
        "        self.low_price[ticker] = self.low_price[ticker][1:] + [float(candle.low.units + candle.low.nano * 1e-9)]\n",
        "        self.volume[ticker] = self.volume[ticker][1:] + [candle.volume]\n",
        "        self.time_last_kline_start[ticker] = time_last_kline_start[ticker][1:] + [ts]\n",
        "        self.time_last_kline_end[ticker] = self.time_last_kline_end[ticker][1:] + [ts + 60000 * self.timeframe_minutes]\n",
        "\n",
        "        print(f\"[{ticker}] Time: {candle.time:%Y-%m-%d %H:%M} \"\n",
        "              f\"O: {self.open_price[ticker][-1]:.2f} H: {self.high_price[ticker][-1]:.2f} \"\n",
        "              f\"L: {self.low_price[ticker][-1]:.2f} C: {self.close_price[ticker][-1]:.2f}\")\n",
        "\n",
        "    async def candle_stream_handler(self):\n",
        "        \"\"\"Обработка реального потока данных.\"\"\"\n",
        "        async with AsyncClient(self.token) as client:\n",
        "            figi_list = list(self.figi_to_ticker.keys())\n",
        "\n",
        "            async def request_iterator():\n",
        "                yield MarketDataRequest(\n",
        "                    subscribe_candles_request=SubscribeCandlesRequest(\n",
        "                        subscription_action=SubscriptionAction.SUBSCRIPTION_ACTION_SUBSCRIBE,\n",
        "                        instruments=[\n",
        "                            CandleInstrument(\n",
        "                                figi=figi,\n",
        "                                interval=self.interval\n",
        "                            ) for figi in figi_list\n",
        "                        ],\n",
        "                        waiting_close=True\n",
        "                    )\n",
        "                )\n",
        "                while True:\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "            try:\n",
        "                stream = client.market_data_stream.market_data_stream(request_iterator())\n",
        "                async for response in stream:\n",
        "                    if response.candle:\n",
        "                        await self.process_candle_stream(response.candle)\n",
        "            except Exception as e:\n",
        "                print(f\"[Stream Error] {e}\")\n",
        "                await asyncio.sleep(10)\n",
        "\n",
        "    async def save_data(self):\n",
        "        \"\"\"Save data to files periodically.\"\"\"\n",
        "        try:\n",
        "            with open(f'{self.data_path}open_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.open_price))\n",
        "\n",
        "            with open(f'{self.data_path}close_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.close_price))\n",
        "\n",
        "            with open(f'{self.data_path}high_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.high_price))\n",
        "\n",
        "            with open(f'{self.data_path}low_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.low_price))\n",
        "\n",
        "            with open(f'{self.data_path}volume.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.volume))\n",
        "\n",
        "            with open(f'{self.data_path}ma.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.ma))\n",
        "\n",
        "            with open(f'{self.data_path}pmax.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.pmax))\n",
        "\n",
        "            with open(f'{self.data_path}close_preds.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.close_preds))\n",
        "\n",
        "            with open(f'{self.data_path}time_last_kline_start.txt', 'w') as f:\n",
        "                json.dump(self.time_last_kline_start, f)\n",
        "\n",
        "            with open(f'{self.data_path}time_last_kline_end.txt', 'w') as f:\n",
        "                json.dump(self.time_last_kline_end, f)\n",
        "\n",
        "            print(\"Данные успешно сохранены.\")\n",
        "        except Exception as e:\n",
        "            print(f'Ошибка сохранения в {e}')\n",
        "            await asyncio.sleep(0.5)\n",
        "\n",
        "    async def run(self):\n",
        "        \"\"\"Запуск бота.\"\"\"\n",
        "\n",
        "        await self.initialize_tickers()\n",
        "        MODELS_CACHE.init_metadata(path_to_save=self.data_path)\n",
        "        await self.fetch_historical_data()\n",
        "\n",
        "\n",
        "# Запуск бота\n",
        "if __name__ == \"__main__\":\n",
        "    bot = TradingBot(\n",
        "        token=TOKEN,\n",
        "        tickers=TICKERS,\n",
        "        data_path=DATA_PATH,\n",
        "        interval=CANDLE_INTERVAL,\n",
        "        timeframe_minutes=TIMEFRAME_MINUTES,\n",
        "        data_points=HISTORY_DATA_POINTS\n",
        "    )\n",
        "    asyncio.run(bot.run())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ress['MRKV']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MWCGCf0mId3e",
        "outputId": "b1c6b110-1f85-46f8-b80d-eb6c30a6e681"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           time                 time_close     open     high  \\\n",
              "0     2025-08-06T17:00:00+00:00  2025-08-06T17:15:00+00:00  0.12365  0.12435   \n",
              "1     2025-08-06T17:15:00+00:00  2025-08-06T17:30:00+00:00  0.12260  0.12495   \n",
              "2     2025-08-06T17:30:00+00:00  2025-08-06T17:45:00+00:00  0.12475  0.12490   \n",
              "3     2025-08-06T17:45:00+00:00  2025-08-06T18:00:00+00:00  0.12485  0.12515   \n",
              "4     2025-08-06T18:00:00+00:00  2025-08-06T18:15:00+00:00  0.12500  0.12510   \n",
              "...                         ...                        ...      ...      ...   \n",
              "4995  2025-10-23T15:30:00+00:00  2025-10-23T15:45:00+00:00  0.11170  0.11180   \n",
              "4996  2025-10-23T15:45:00+00:00  2025-10-23T16:00:00+00:00  0.11140  0.11170   \n",
              "4997  2025-10-23T16:00:00+00:00  2025-10-23T16:15:00+00:00  0.11165  0.11170   \n",
              "4998  2025-10-23T16:15:00+00:00  2025-10-23T16:30:00+00:00  0.11135  0.11135   \n",
              "4999  2025-10-23T16:30:00+00:00  2025-10-23T16:45:00+00:00  0.11135  0.11150   \n",
              "\n",
              "          low    close  volume        ma      pmax     preds  \n",
              "0     0.12250  0.12265    5014  0.127045  0.125612  0.035311  \n",
              "1     0.12220  0.12475    5141  0.126966  0.125612 -0.013451  \n",
              "2     0.12400  0.12485     864  0.126899  0.125612 -0.064195  \n",
              "3     0.12455  0.12515     730  0.126844  0.125612 -0.096257  \n",
              "4     0.12460  0.12485     393  0.126796  0.125612 -0.123699  \n",
              "...       ...      ...     ...       ...       ...       ...  \n",
              "4995  0.11135  0.11135     123  0.112422  0.115028       NaN  \n",
              "4996  0.11140  0.11170     161  0.112342  0.114837       NaN  \n",
              "4997  0.11135  0.11165     208  0.112264  0.114655       NaN  \n",
              "4998  0.11135  0.11135       3  0.112186  0.114471       NaN  \n",
              "4999  0.11100  0.11115      25  0.112106  0.114335       NaN  \n",
              "\n",
              "[5000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcedfc9a-091b-40f5-875e-1891e52364fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>time_close</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>ma</th>\n",
              "      <th>pmax</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-08-06T17:00:00+00:00</td>\n",
              "      <td>2025-08-06T17:15:00+00:00</td>\n",
              "      <td>0.12365</td>\n",
              "      <td>0.12435</td>\n",
              "      <td>0.12250</td>\n",
              "      <td>0.12265</td>\n",
              "      <td>5014</td>\n",
              "      <td>0.127045</td>\n",
              "      <td>0.125612</td>\n",
              "      <td>0.035311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-08-06T17:15:00+00:00</td>\n",
              "      <td>2025-08-06T17:30:00+00:00</td>\n",
              "      <td>0.12260</td>\n",
              "      <td>0.12495</td>\n",
              "      <td>0.12220</td>\n",
              "      <td>0.12475</td>\n",
              "      <td>5141</td>\n",
              "      <td>0.126966</td>\n",
              "      <td>0.125612</td>\n",
              "      <td>-0.013451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-08-06T17:30:00+00:00</td>\n",
              "      <td>2025-08-06T17:45:00+00:00</td>\n",
              "      <td>0.12475</td>\n",
              "      <td>0.12490</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.12485</td>\n",
              "      <td>864</td>\n",
              "      <td>0.126899</td>\n",
              "      <td>0.125612</td>\n",
              "      <td>-0.064195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-08-06T17:45:00+00:00</td>\n",
              "      <td>2025-08-06T18:00:00+00:00</td>\n",
              "      <td>0.12485</td>\n",
              "      <td>0.12515</td>\n",
              "      <td>0.12455</td>\n",
              "      <td>0.12515</td>\n",
              "      <td>730</td>\n",
              "      <td>0.126844</td>\n",
              "      <td>0.125612</td>\n",
              "      <td>-0.096257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-08-06T18:00:00+00:00</td>\n",
              "      <td>2025-08-06T18:15:00+00:00</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.12510</td>\n",
              "      <td>0.12460</td>\n",
              "      <td>0.12485</td>\n",
              "      <td>393</td>\n",
              "      <td>0.126796</td>\n",
              "      <td>0.125612</td>\n",
              "      <td>-0.123699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>2025-10-23T15:30:00+00:00</td>\n",
              "      <td>2025-10-23T15:45:00+00:00</td>\n",
              "      <td>0.11170</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>123</td>\n",
              "      <td>0.112422</td>\n",
              "      <td>0.115028</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>2025-10-23T15:45:00+00:00</td>\n",
              "      <td>2025-10-23T16:00:00+00:00</td>\n",
              "      <td>0.11140</td>\n",
              "      <td>0.11170</td>\n",
              "      <td>0.11140</td>\n",
              "      <td>0.11170</td>\n",
              "      <td>161</td>\n",
              "      <td>0.112342</td>\n",
              "      <td>0.114837</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>2025-10-23T16:00:00+00:00</td>\n",
              "      <td>2025-10-23T16:15:00+00:00</td>\n",
              "      <td>0.11165</td>\n",
              "      <td>0.11170</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11165</td>\n",
              "      <td>208</td>\n",
              "      <td>0.112264</td>\n",
              "      <td>0.114655</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>2025-10-23T16:15:00+00:00</td>\n",
              "      <td>2025-10-23T16:30:00+00:00</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>3</td>\n",
              "      <td>0.112186</td>\n",
              "      <td>0.114471</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>2025-10-23T16:30:00+00:00</td>\n",
              "      <td>2025-10-23T16:45:00+00:00</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11150</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11115</td>\n",
              "      <td>25</td>\n",
              "      <td>0.112106</td>\n",
              "      <td>0.114335</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcedfc9a-091b-40f5-875e-1891e52364fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dcedfc9a-091b-40f5-875e-1891e52364fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dcedfc9a-091b-40f5-875e-1891e52364fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4be84422-da09-4dc1-adbe-0067223a0fa7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4be84422-da09-4dc1-adbe-0067223a0fa7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4be84422-da09-4dc1-adbe-0067223a0fa7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"ress['MRKV']\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"2025-08-29T10:30:00+00:00\",\n          \"2025-09-15T15:30:00+00:00\",\n          \"2025-09-16T15:30:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_close\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"2025-08-29T10:45:00+00:00\",\n          \"2025-09-15T15:45:00+00:00\",\n          \"2025-09-16T15:45:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007055228447554978,\n        \"min\": 0.0956,\n        \"max\": 0.136,\n        \"num_unique_values\": 607,\n        \"samples\": [\n          0.11370000000000001,\n          0.11955,\n          0.12865000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006999950592622756,\n        \"min\": 0.09745000000000001,\n        \"max\": 0.136,\n        \"num_unique_values\": 586,\n        \"samples\": [\n          0.11530000000000001,\n          0.12110000000000001,\n          0.10005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007108264159115854,\n        \"min\": 0.09475,\n        \"max\": 0.13590000000000002,\n        \"num_unique_values\": 611,\n        \"samples\": [\n          0.12775,\n          0.13385,\n          0.12655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007056824703368982,\n        \"min\": 0.0956,\n        \"max\": 0.13595000000000002,\n        \"num_unique_values\": 611,\n        \"samples\": [\n          0.12725,\n          0.13195,\n          0.128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1028,\n        \"min\": 1,\n        \"max\": 29705,\n        \"num_unique_values\": 994,\n        \"samples\": [\n          8903,\n          1392,\n          332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006921486071542504,\n        \"min\": 0.09951450000001387,\n        \"max\": 0.1351494999999977,\n        \"num_unique_values\": 4868,\n        \"samples\": [\n          0.12747800000001008,\n          0.11455599999995685,\n          0.1288824999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006759918431487686,\n        \"min\": 0.09748932409994146,\n        \"max\": 0.13545028486438537,\n        \"num_unique_values\": 1466,\n        \"samples\": [\n          0.11078029442118244,\n          0.13228373853711728,\n          0.10649819465366078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29247038564026706,\n        \"min\": -0.7764187852701046,\n        \"max\": 0.5639949469387356,\n        \"num_unique_values\": 2006,\n        \"samples\": [\n          -0.5450215492024894,\n          -0.2296427533188099,\n          -0.2078943057562217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.use(\"agg\")\n",
        "%matplotlib inline\n",
        "plot_price_with_indicators_mplfinance1(ress['MRKV'].iloc[-530:], 'MRKV')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "IEranmM5Ki3j",
        "outputId": "0985fa60-4d0f-4656-bcfb-c0028ec2c159"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_price_with_indicators_mplfinance1(df, ticker, save_path=None):\n",
        "    \"\"\"\n",
        "    Отрисовывает график движения цены с индикаторами, используя mplfinance.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame с данными о цене и индикаторах.\n",
        "        ticker (str): Тикер акции для заголовка графика.\n",
        "        save_path (str, optional): Путь для сохранения графика. Если None, то график покажется.\n",
        "    \"\"\"\n",
        "    # Копируем DataFrame, чтобы не менять оригинал\n",
        "    df = df.copy()\n",
        "\n",
        "    # Преобразуем столбец time в datetime и делаем индексом\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "    df = df.set_index(\"time\")\n",
        "\n",
        "    # Проверяем, что необходимые столбцы существуют\n",
        "    required_columns = [\"open\", \"high\", \"low\", \"close\"]\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Отсутствует необходимый столбец: {col}\")\n",
        "\n",
        "    # Создаем список дополнительных панелей для индикаторов\n",
        "    apds = []\n",
        "    #if \"pmax_f\" in df.columns:\n",
        "    #    apds.append(mpf.make_addplot(df[\"pmax_f\"], color=\"red\", ylabel=\"PMAX\", panel=0))\n",
        "    #if \"ma_f\" in df.columns:\n",
        "    #    apds.append(mpf.make_addplot(df[\"ma_f\"], color=\"blue\", ylabel=\"MA\", panel=0))\n",
        "    if \"pmax_adaptive\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"pmax_adaptive\"], color=\"red\", ylabel=\"PMAX\", panel=0))\n",
        "    if \"ma_adaptive\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"ma_adaptive\"], color=\"blue\", ylabel=\"MA\", panel=0))\n",
        "    if \"pmax\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"pmax\"], color=\"black\", ylabel=\"PMAX\", panel=0))\n",
        "    if \"ma\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"ma\"], color=\"green\", ylabel=\"MA\", panel=0))\n",
        "    if \"preds\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"preds\"], color=\"black\", panel=2, ylabel='close_preds',width=1.0))\n",
        "\n",
        "    # Отрисовка графика с mplfinance\n",
        "    plot_kwargs = dict(\n",
        "        type=\"candle\",\n",
        "        style=\"yahoo\",\n",
        "        title=f\"График цены {ticker} с индикаторами\",\n",
        "        ylabel=\"Цена\",\n",
        "        addplot=apds,\n",
        "        show_nontrading=False,\n",
        "        figsize=(18, 10),\n",
        "    )\n",
        "\n",
        "    if \"volume\" in df.columns:\n",
        "        plot_kwargs[\"volume\"] = True\n",
        "        plot_kwargs[\"panel_ratios\"] = (6, 3)\n",
        "\n",
        "    if save_path:\n",
        "        plot_kwargs[\"savefig\"] = save_path\n",
        "        mpf.plot(df, **plot_kwargs)\n",
        "    else:\n",
        "        mpf.plot(df, **plot_kwargs)\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "4x3jOSGNGEZe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FhlkyZXiq94"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Dmu2HvYTI77CkgCzZ9gSxz4FHKD08DcI",
      "authorship_tag": "ABX9TyOSe/SJ81KZmZx3jmjCMxzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}