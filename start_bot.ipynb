{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Necrotox/Necrotox/blob/main/start_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8-zPSBcWmQl",
        "outputId": "ccc6dffe-8716-4e7a-c0ae-895eddd87713"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu \\\n",
        "  torch==2.7.1+cpu > /dev/null 2>&1\n",
        "\n",
        "!pip install -q --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu \\\n",
        "  torchvision==0.22.0+cpu > /dev/null 2>&1\n",
        "!pip install -q --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu \\\n",
        "  torchaudio==2.7.1+cpu > /dev/null 2>&1\n",
        "\n",
        "!pip install -q --no-warn-script-location \\\n",
        "  pytorch-lightning==2.5.2 pytorch-forecasting==1.4.0 > /dev/null 2>&1\n",
        "\n",
        "!pip install -q tinkoff-investments dill telebot --upgrade mplfinance > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "g3YVzfjxJVAK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1mri67_vog8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504444ba-3669-4198-82d4-4c04f8ea3309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные 1 успешно загружены.\n",
            "Данные 2 успешно загружены.\n",
            "Данные 3 успешно загружены.\n",
            "Загрузка Моделей Память: 3227.54 МБ\n",
            "Модель MiniBatchKMeans успешно загруженна Память: 3227.54 МБ\n",
            "Скалер успешно загружен Память: 3227.54 МБ\n",
            "Параметры для тикетов загруженны Память: 3227.59 МБ\n",
            "Параметры для тикетов с фазами загруженны Память: 3227.71 МБ\n",
            "[INIT] Активных тикеров: 1\n",
            "\n",
            "Обработка тикера MRKV (1/1)\n",
            "Данные успешно сохранены.\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import contextlib\n",
        "import functools\n",
        "import statsmodels.api as sm\n",
        "import inspect\n",
        "import zipfile\n",
        "import pickle\n",
        "import json\n",
        "import gc\n",
        "import re\n",
        "import io\n",
        "import time\n",
        "import typing\n",
        "import logging\n",
        "import pytz\n",
        "import gzip\n",
        "import dill\n",
        "import lzma\n",
        "import pandas as pd\n",
        "import nest_asyncio\n",
        "import hashlib\n",
        "import random\n",
        "import joblib\n",
        "import math\n",
        "import psutil\n",
        "\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spla\n",
        "\n",
        "\n",
        "from numba import jit, njit\n",
        "from grpc import StatusCode\n",
        "from grpc.aio import AioRpcError\n",
        "from dataclasses import dataclass\n",
        "from contextlib import redirect_stderr, redirect_stdout\n",
        "from collections.abc import Sequence\n",
        "from tinkoff.invest import AsyncClient, CandleInterval\n",
        "from tinkoff.invest.exceptions import RequestError\n",
        "from tinkoff.invest import (\n",
        "    AsyncClient,\n",
        "    #CandleInstrument,\n",
        "    MarketDataRequest,\n",
        "    #SubscribeCandlesRequest,\n",
        "    #SubscriptionAction,\n",
        "    SubscriptionInterval,\n",
        ")\n",
        "from tinkoff.invest.schemas import (\n",
        "    SubscribeCandlesRequest,\n",
        "    SubscriptionAction,\n",
        "    CandleInstrument,\n",
        ")\n",
        "from tinkoff.invest.market_data_stream.market_data_stream_manager import MarketDataRequest\n",
        "from tinkoff.invest.schemas import Candle\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "from scipy.stats import norm\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from collections import defaultdict, deque\n",
        "from multiprocessing import Process\n",
        "from multiprocessing import Process\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "import mplfinance as mpf\n",
        "import telebot\n",
        "import datetime\n",
        "import matplotlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats import norm, pearsonr\n",
        "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import BaseCrossValidator\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, PowerTransformer, QuantileTransformer, RobustScaler, StandardScaler\n",
        "\n",
        "from sklearn.neighbors import BallTree\n",
        "\n",
        "from bisect import bisect_left\n",
        "\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data.encoders import EncoderNormalizer\n",
        "from pytorch_forecasting.metrics import Metric, QuantileLoss\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import RichProgressBar, TQDMProgressBar\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from torchmetrics import MeanSquaredError\n",
        "from torchmetrics.functional import mean_squared_error as torchmetrics_mse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from typing import Any, Dict, Iterable, Iterator, List, Literal, Mapping, Optional, Tuple\n",
        "import os, gc, warnings, typing as tp\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "matplotlib.use(\"agg\")\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import psutil\n",
        "import os.path\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Настройка логирования\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "TOKEN = 't.bWjxPlU6vz77qoqS754OKy0QorLDaZP-CE091dhGl56v7GHrqgF-mQAdWaeRg2kDRJmmxzvaaOwKUTxW6dnOKg'\n",
        "\n",
        "TICKERS1 =  ['RAGR', 'MGNT', 'MSTT', 'VRSB', 'PRFN', 'MTLR', 'LIFE', 'UPRO', 'GECO',\n",
        "       'BANE', 'MTLRP', 'GEMC', 'NVTK', 'TRNFP', 'TRMK', 'LSNGP', 'OBNEP',\n",
        "       'SNGSP', 'UWGN', 'MRKP', 'KZOSP', 'YDEX', 'NLMK', 'IRKT', 'CNTLP',\n",
        "       'LENT', 'KLSB', 'SELG', 'NMTP', 'UNAC', 'VKCO', 'MRKU', 'UGLD', 'NTZL',\n",
        "       'BANEP', 'FLOT', 'TGKJ', 'MAGN', 'ROSN', 'TGKB', 'AFKS', 'TTLK', 'HEAD',\n",
        "       'KZIZ', 'NOMP', 'OKEY', 'ABRD', 'NSVZ', 'MRKV', 'LSNG', 'MRKC', 'SVAV',\n",
        "       'ETLN', 'MRKZ', 'LNZL', 'CNRU', 'BSPB', 'RBCM', 'PMSB', 'LSRG', 'RNFT',\n",
        "       'MOEX', 'GTRK', 'NKHP', 'LKOH', 'SBERP', 'SBER', 'PLZL', 'RENI', 'MDMG',\n",
        "       'AFLT', 'FESH', 'OBNE', 'X5', 'MGTSP', 'DVEC', 'KROT', 'TATNP', 'OZPH',\n",
        "       'TGKN', 'TATN', 'PMSBP', 'TGKBP', 'SPBE', 'LNZLP', 'CHMK', 'KZIZP',\n",
        "       'RKKE', 'FRHC']\n",
        "\n",
        "TICKERS = ['MRKV']#, 'NOMP', 'OBNEP']\n",
        "\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/t_ml/data/'\n",
        "path_to_save = '/content/drive/MyDrive/t_ml/data/'\n",
        "CANDLE_INTERVAL = CandleInterval.CANDLE_INTERVAL_15_MIN\n",
        "TIMEFRAME_MINUTES = 15\n",
        "HISTORY_DATA_POINTS = 5000\n",
        "\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}open_price.txt', 'r') as f:\n",
        "        open_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}close_price.txt', 'r') as f:\n",
        "        close_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}high_price.txt', 'r') as f:\n",
        "        high_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}low_price.txt', 'r') as f:\n",
        "        low_price = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}volume.txt', 'r') as f:\n",
        "        volume = json.loads(f.read())\n",
        "\n",
        "    print(\"Данные 1 успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке данных: {e}\")\n",
        "    open_price, close_price, high_price, low_price, volume = {}, {}, {}, {}, {}\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}time_last_kline_start.txt', 'r') as f:\n",
        "        time_last_kline_start = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}time_last_kline_end.txt', 'r') as f:\n",
        "        time_last_kline_end = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}ma.txt', 'r') as f:\n",
        "        ma = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}open_trades.txt', 'r') as f:\n",
        "        open_trades = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}trading_data.txt', 'r') as f:\n",
        "        trading_data = json.loads(f.read())\n",
        "\n",
        "    print(\"Данные 2 успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке данных: {e}\")\n",
        "    time_last_kline_start, time_last_kline_end, ma, open_trades, trading_data = {}, {}, {}, {}, {}\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "\n",
        "    with open(f'{path_to_save}pmax.txt', 'r') as f:\n",
        "        pmax = json.loads(f.read())\n",
        "\n",
        "    with open(f'{path_to_save}signals.txt', 'r') as f:\n",
        "        signals = json.loads(f.read())\n",
        "\n",
        "    print(\"Данные 3 успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке данных: {e}\")\n",
        "    pmax, signals = {}, {}\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "print('Загрузка Моделей', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "\n",
        "try:\n",
        "    kmeans_global = joblib.load(f'{path_to_save}models/kmeans_global.pkl')\n",
        "    print('Модель MiniBatchKMeans успешно загруженна', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели MiniBatchKMeans: {e}\")\n",
        "    kmeans_global = joblib.load(f'{path_to_save}models/kmeans_global.pkl')\n",
        "    print('Модель MiniBatchKMeans загруженна со второй попытки', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    scaler_global = joblib.load(f'{path_to_save}models/scaler_global.pkl')\n",
        "    print('Скалер успешно загружен', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели MiniBatchKMeans: {e}\")\n",
        "    scaler_global = joblib.load(f'{path_to_save}models/scaler_global.pkl')\n",
        "    print('Скалер загружен со второй попытки', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "'''\n",
        "try:\n",
        "    with open(f'{path_to_save}/models/regression_model_general.dill', 'rb') as file:\n",
        "        regression_model = dill.load(file)\n",
        "        print('Модель выхода из сделки загруженна', f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели регрессии: {e}\")\n",
        "    with open(f'{path_to_save}/models/regression_model_general.dill', 'rb') as file:\n",
        "        regression_model = dill.load(file)\n",
        "        print('Модель выхода из сделки загруженна с второйпопытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "try:\n",
        "    with open(f'{path_to_save}/models/global_model.dill', 'rb') as file:\n",
        "        classifier_model = dill.load(file)\n",
        "        print('Глобальная модель поиска входа для всех кластеров заргуженна',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке модели поиска входа для 0 кластера: {e}\")\n",
        "    with open(f'{path_to_save}/ful_tickers_params.txt', 'rb') as file:\n",
        "        classifier_model = dill.load(file)\n",
        "        print('Глобальная модель поиска входа для всех кластеров загруженна с второй попытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "'''\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}/ful_tickers_params_new.txt', 'r') as file:\n",
        "      ticker_params = json.load(file)\n",
        "      print('Параметры для тикетов загруженны',\n",
        "            f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке параметров тикетов: {e}\")\n",
        "    with open(f'{path_to_save}/ful_tickers_params_new.txt', 'r') as file:\n",
        "        ticker_params = json.load(file)\n",
        "        print('Параметры для тикетов загруженны со второй попытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    #transformers_path = f'{path_to_save}/models/neuros/'\n",
        "    #models_path = f'{path_to_save}/models/final_models/'\n",
        "\n",
        "    with open(f'{path_to_save}/models/final_cols.pkl', 'rb') as f:\n",
        "        final_cols = pickle.load(f)\n",
        "\n",
        "    with open(f'{path_to_save}/models/final_params.pkl', 'rb') as f:\n",
        "        final_params = pickle.load(f)\n",
        "\n",
        "    with open(f'{path_to_save}/models/best_methods.json', 'rb') as f:\n",
        "        methods = json.load(f)\n",
        "\n",
        "    with open(f'{path_to_save}close_preds.txt', 'r') as f:\n",
        "        close_preds = json.loads(f.read())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при определении пути на модели и трансформеры: {e}\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "try:\n",
        "    with open(f'{path_to_save}/phase_ful_tickers_params.txt', 'r') as file:\n",
        "      phase_ticker_params = json.load(file)\n",
        "      print('Параметры для тикетов с фазами загруженны',\n",
        "            f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка при загрузке параметров тикетов с фазами: {e}\")\n",
        "    with open(f'{path_to_save}/phase_ful_tickers_params.txt', 'r') as file:\n",
        "        phase_ticker_params = json.load(file)\n",
        "        print('Параметры для тикетов с фазами загруженны со второй попытки',\n",
        "              f\"Память: {psutil.Process().memory_info().rss / 1024 ** 2:.2f} МБ\")\n",
        "    await asyncio.sleep(60)\n",
        "\n",
        "\n",
        "def _whittaker_smooth(y: np.ndarray, lam: float = 50.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Whittaker–Eilers smoothing (penalized least squares, D2).\n",
        "    Линейный безфазовый фильтр, хорошо убирает шум, не смещая тренд.\n",
        "    \"\"\"\n",
        "    import scipy.sparse as sp\n",
        "    import scipy.sparse.linalg as spla\n",
        "\n",
        "    n = len(y)\n",
        "    if n <= 2:\n",
        "        return y.copy()\n",
        "\n",
        "    E = sp.eye(n, format=\"csc\")\n",
        "    # Вторая разность (D2): размер (n-2) x n\n",
        "    diagonals = [np.ones(n), -2*np.ones(n), np.ones(n)]\n",
        "    D2 = sp.diags(diagonals, [0, 1, 2], shape=(n-2, n), format=\"csc\")\n",
        "    coef = E + lam * (D2.T @ D2)\n",
        "    z = spla.spsolve(coef, y.astype(float))\n",
        "    return z\n",
        "\n",
        "def _rearrange_preserving_marginal(z_raw: np.ndarray, z_smooth: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Distribution-preserving smoothing via monotone rearrangement:\n",
        "    - сортируем исходный z_raw -> z_sorted,\n",
        "    - берём порядок (argsort) сглаженного z_smooth,\n",
        "    - раскладываем z_sorted по этому порядку.\n",
        "    В итоге: гладко по времени (за счёт порядка z_smooth), но эмпирическое\n",
        "    распределение строго совпадает с исходным (z_raw).\n",
        "    \"\"\"\n",
        "    if len(z_raw) == 0:\n",
        "        return z_raw\n",
        "    order = np.argsort(z_smooth)\n",
        "    z_sorted = np.sort(z_raw)\n",
        "    out = np.empty_like(z_raw)\n",
        "    out[order] = z_sorted\n",
        "    return out\n",
        "\n",
        "def calculate_smoothed_target_qnorm(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    batch_start: int = 0,\n",
        "    epsilon: float = 1e-6,\n",
        "    round_decimals: int = 1,\n",
        "\n",
        "    # базовая нормализация по окну (buy->sell)\n",
        "    tight_spread_thr: float = 1e-4,\n",
        "\n",
        "    # сглаживание в z-домене\n",
        "    smooth_method: Literal[\"gauss\", \"savgol\", \"whittaker\"] = \"gauss\",\n",
        "    gauss_sigma: float = 2.0,\n",
        "    savgol_window: int = 11,   # нечётное\n",
        "    savgol_poly: int = 3,\n",
        "    whittaker_lambda: float = 50.0,\n",
        "\n",
        "    # квантильная нормализация и глобальный маппинг\n",
        "    clip_z: float = 2.5,       # клип в z-подобной шкале перед [-1,1]\n",
        "    tanh_scale: float | None = None,\n",
        "\n",
        "    # джиттер перед ECDF\n",
        "    dequant_jitter: float = 1e-4,\n",
        "\n",
        "    # опция \"обязательно растянуть каждый батч\" (робастная эквализация по квантилям)\n",
        "    per_batch_equalize: bool = False,\n",
        "    per_batch_q: float = 0.01,  # напр. 1% и 99% -> [-1, 1]\n",
        "\n",
        "    random_state: int | None = 42,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Возвращает df с колонками:\n",
        "      - normalized_target ∈ [-1, 1] (единая глобальная шкала)\n",
        "      - batch (int64): идентификатор события (buy→sell)\n",
        "\n",
        "    Алгоритм:\n",
        "      1) Внутри каждого события: base(0..1) -> ECDF -> z_raw ~ N(0,1).\n",
        "      2) Сглаживаем (Gaussian/Savitzky–Golay/Whittaker) -> z_smooth.\n",
        "      3) Rearrangement: z_preserved = rearrange(z_raw, order-of z_smooth).\n",
        "         Это убирает шум, но полностью сохраняет исходное распределение.\n",
        "      4) Глобальная квантильная нормализация: приводим все батчи к общей\n",
        "         маргинальной функции Q_global(p).\n",
        "      5) Единая глобальная шкала (median/MAD), клип до [-clip_z, clip_z],\n",
        "         линейный маппинг в [-1, 1], опционально tanh.\n",
        "      6) (Опционально) per-batch эквализация по квантилям до [-1, 1].\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    df = df.copy()\n",
        "    df[\"normalized_target\"] = np.nan\n",
        "    df[\"batch\"] = np.nan\n",
        "    df[\"event_sell_time\"] = pd.to_datetime(df[\"event_sell_time\"], utc=True)\n",
        "\n",
        "    if savgol_window % 2 == 0:\n",
        "        savgol_window += 1\n",
        "    use_savgol = (savgol_window >= savgol_poly + 2)\n",
        "\n",
        "    all_indices: list[np.ndarray] = []\n",
        "    all_z_preserved: list[np.ndarray] = []\n",
        "    batch = batch_start\n",
        "\n",
        "    buy_rows = df.index[df[\"buy_signal\"] == True]\n",
        "    for start_i in buy_rows:\n",
        "        sell_time = df.at[start_i, \"event_sell_time\"]\n",
        "        if pd.isna(sell_time):\n",
        "            continue\n",
        "        sell_rows = df.index[df[\"time\"] == sell_time]\n",
        "        if len(sell_rows) == 0:\n",
        "            continue\n",
        "        end_i = sell_rows[0]\n",
        "\n",
        "        mask = (df.index >= start_i) & (df.index <= end_i)\n",
        "        idx = df.index[mask]\n",
        "        if idx.empty:\n",
        "            continue\n",
        "\n",
        "        high_s = df.loc[idx, \"high\"]\n",
        "        low_s  = df.loc[idx, \"low\"]\n",
        "\n",
        "        # Робастные полки только для базовой формы (0..1)\n",
        "        max_p = np.round(high_s.quantile(0.92), round_decimals)\n",
        "        min_p = np.round(low_s .quantile(0.08), round_decimals)\n",
        "        if max_p - min_p < tight_spread_thr:\n",
        "            max_p, min_p = float(high_s.max()), float(low_s.min())\n",
        "\n",
        "        use_profit_norm = (max_p - min_p) < tight_spread_thr\n",
        "\n",
        "        # 1) base 0..1\n",
        "        if not use_profit_norm:\n",
        "            base = (df.loc[idx, \"close\"] - min_p) / (max_p - min_p + 1e-12)\n",
        "        else:\n",
        "            buy_price = df.at[start_i, \"close\"]\n",
        "            max_prof = (high_s.max() - buy_price) / max(buy_price, 1e-12)\n",
        "            max_prof = max(max_prof, epsilon)\n",
        "            base = (df.loc[idx, \"close\"] - buy_price) / (buy_price * max_prof)\n",
        "            base = 0.5 + 0.5 * base\n",
        "\n",
        "        base = np.clip(base.to_numpy(float), epsilon, 1 - epsilon)\n",
        "\n",
        "        # Разбиваем дубликаты\n",
        "        if dequant_jitter and len(base) > 0:\n",
        "            base = base + rng.normal(scale=dequant_jitter, size=base.shape)\n",
        "            base = np.clip(base, epsilon, 1 - epsilon)\n",
        "\n",
        "        # 2) ECDF -> z_raw ~ N(0,1)\n",
        "        n = len(base)\n",
        "        ranks = pd.Series(base, index=idx).rank(method=\"first\").to_numpy()\n",
        "        ecdf = (ranks - 0.5) / max(n, 1)\n",
        "        ecdf = np.clip(ecdf, epsilon, 1 - epsilon)\n",
        "        z_raw = norm.ppf(ecdf)\n",
        "\n",
        "        # 3) Сглаживание (без фазовых сдвигов)\n",
        "        if n > 2:\n",
        "            if smooth_method == \"gauss\":\n",
        "                z_sm = gaussian_filter1d(z_raw, sigma=gauss_sigma, mode=\"nearest\")\n",
        "            elif smooth_method == \"savgol\" and use_savgol and n >= savgol_window:\n",
        "                z_sm = savgol_filter(z_raw, window_length=savgol_window, polyorder=savgol_poly, mode=\"interp\")\n",
        "            elif smooth_method == \"whittaker\":\n",
        "                z_sm = _whittaker_smooth(z_raw, lam=whittaker_lambda)\n",
        "            else:\n",
        "                # запасной вариант, если окно слишком короткое\n",
        "                z_sm = z_raw.copy()\n",
        "        else:\n",
        "            z_sm = z_raw.copy()\n",
        "\n",
        "        # 4) Rearrangement: сохраняем распределение z_raw, но используем порядок z_sm\n",
        "        z_preserved = _rearrange_preserving_marginal(z_raw, z_sm)\n",
        "        #z_preserved = np.where(z_preserved > 0, z_preserved * 1.2, z_preserved)  # Усиливаем положительные пики\n",
        "        #z_preserved = np.clip(z_preserved, -clip_z * 1.5, clip_z * 1.5)\n",
        "\n",
        "        all_indices.append(idx.to_numpy())\n",
        "        all_z_preserved.append(z_preserved)\n",
        "        df.loc[idx, \"batch\"] = batch\n",
        "        batch += 1\n",
        "\n",
        "    # Если событий не нашлось\n",
        "    if len(all_indices) == 0:\n",
        "        df[\"batch\"] = df[\"batch\"].fillna(batch_start).astype(\"int64\", errors=\"ignore\")\n",
        "        df[\"normalized_target\"] = df[\"normalized_target\"].fillna(0.0)\n",
        "        return df\n",
        "\n",
        "    # 5) Глобальная квантильная нормализация: одна общая маргинальная функция\n",
        "    z_pool = np.concatenate(all_z_preserved, axis=0)\n",
        "    z_pool_sorted = np.sort(z_pool)\n",
        "    N = len(z_pool_sorted)\n",
        "    # сетка перцентилей соответствующая отсортированным значениям\n",
        "    p_pool = (np.arange(N) + 0.5) / N\n",
        "\n",
        "    def q_global(p: np.ndarray) -> np.ndarray:\n",
        "        p = np.clip(p, p_pool[0], p_pool[-1])\n",
        "        return np.interp(p, p_pool, z_pool_sorted)\n",
        "\n",
        "    all_z_qn: list[np.ndarray] = []\n",
        "    for z_preserved in all_z_preserved:\n",
        "        n = len(z_preserved)\n",
        "        # перцентиль внутри батча\n",
        "        p_batch = (pd.Series(z_preserved).rank(method=\"first\").to_numpy() - 0.5) / max(n, 1)\n",
        "        z_qn = q_global(p_batch)  # теперь у батча та же маргиналка, что и у пула\n",
        "        all_z_qn.append(z_qn)\n",
        "\n",
        "    # 6) Единая глобальная шкала -> [-1, 1]\n",
        "    g_med = np.median(z_pool)\n",
        "    g_mad = np.median(np.abs(z_pool - g_med)) + 1e-12\n",
        "    scale = 1.4826 * g_mad\n",
        "\n",
        "    pos = 0\n",
        "    for idx, z_qn in zip(all_indices, all_z_qn):\n",
        "        z_g = (z_qn - g_med) / scale\n",
        "        y = np.clip(z_g, -clip_z, clip_z) / clip_z\n",
        "        if tanh_scale:\n",
        "            y = np.tanh(y * tanh_scale) / np.tanh(tanh_scale)\n",
        "\n",
        "        # 7) (опционально) робастная per-batch эквализация до [-1,1]\n",
        "        if per_batch_equalize and len(y) >= 3:\n",
        "            q = per_batch_q\n",
        "            lo, hi = np.quantile(y, [q, 1 - q])\n",
        "            if hi - lo > 1e-12:\n",
        "                y = (y - lo) / (hi - lo)  # [0..1]\n",
        "                y = 2.0 * np.clip(y, 0.0, 1.0) - 1.0  # [-1..1]\n",
        "            y = np.clip(y, -1.0, 1.0)\n",
        "\n",
        "        df.loc[idx, \"normalized_target\"] = y\n",
        "        pos += len(idx)\n",
        "\n",
        "    df[\"batch\"] = df[\"batch\"].astype(\"int64\", errors=\"ignore\")\n",
        "    return df\n",
        "\n",
        "time_last_kline_dt_cache = {}\n",
        "\n",
        "def _to_utc_floor_minute(ts):\n",
        "    return pd.to_datetime(ts, utc=True).floor('T')\n",
        "\n",
        "def _iso_utc(ts):\n",
        "    return pd.Timestamp(ts, tz='UTC').floor('T').isoformat()\n",
        "\n",
        "def _get_dt_scale_for_ticker(ticker):\n",
        "    times_iso = time_last_kline_start.get(ticker, [])\n",
        "    if not times_iso:\n",
        "        return pd.DatetimeIndex([])\n",
        "    if ticker not in time_last_kline_dt_cache or len(time_last_kline_dt_cache[ticker]) != len(times_iso) or (\n",
        "        len(times_iso) and time_last_kline_dt_cache[ticker][-1] != _to_utc_floor_minute(times_iso[-1])\n",
        "    ):\n",
        "        time_last_kline_dt_cache[ticker] = pd.DatetimeIndex(pd.to_datetime(times_iso, utc=True))\n",
        "    return time_last_kline_dt_cache[ticker]\n",
        "\n",
        "\n",
        "def _slice_indices_by_time(ticker, start_time_utc=None, end_time_utc=None):\n",
        "    \"\"\"\n",
        "    Возвращает (start_idx, end_idx) по шкале time_last_kline_start[ticker], границы включительные.\n",
        "    Если start_time_utc/end_time_utc None — граница опущена.\n",
        "    Возвращает None, если шкала пуста или нет пересечения.\n",
        "    \"\"\"\n",
        "    dt_scale = _get_dt_scale_for_ticker(ticker)\n",
        "    if len(dt_scale) == 0:\n",
        "        return None\n",
        "\n",
        "    if start_time_utc is None:\n",
        "        start_idx = 0\n",
        "    else:\n",
        "        start_ts = _to_utc_floor_minute(start_time_utc)\n",
        "        start_idx = int(dt_scale.searchsorted(start_ts, side='left'))\n",
        "        if start_idx >= len(dt_scale):\n",
        "            return None\n",
        "\n",
        "    if end_time_utc is None:\n",
        "        end_idx = len(dt_scale) - 1\n",
        "    else:\n",
        "        end_ts = _to_utc_floor_minute(end_time_utc)\n",
        "        # хотим включительно — берем правую границу и вычитаем 1, но если точное совпадение c началом свечи — ок\n",
        "        end_idx = int(dt_scale.searchsorted(end_ts, side='right') - 1)\n",
        "        if end_idx < 0:\n",
        "            return None\n",
        "\n",
        "    if start_idx > end_idx:\n",
        "        return None\n",
        "    return start_idx, end_idx\n",
        "\n",
        "def _now_monotonic():\n",
        "    return time.monotonic()\n",
        "\n",
        "def _exponential_backoff(attempt: int, base=1.0, cap=15.0, jitter=True):\n",
        "    # attempt: 0,1,2,...\n",
        "    delay = min(cap, base * (2 ** attempt))\n",
        "    if jitter:\n",
        "        # Полуджиттер: равномерный [delay/2, delay]\n",
        "        return random.uniform(delay / 2, delay)\n",
        "    return delay\n",
        "\n",
        "def _is_retryable_grpc_error(e: AioRpcError) -> bool:\n",
        "    code = e.code()\n",
        "    # UNAVAILABLE и CANCELLED — точно перезапускаем\n",
        "    if code in (StatusCode.UNAVAILABLE, StatusCode.CANCELLED, StatusCode.DEADLINE_EXCEEDED):\n",
        "        return True\n",
        "    # INTERNAL иногда тоже имеет смысл ретраить, но осторожно\n",
        "    if code == StatusCode.INTERNAL:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def _is_retryable_generic_error(err: Exception) -> bool:\n",
        "    s = str(err)\n",
        "    needles = [\n",
        "        \"Remote end closed connection without response\",\n",
        "        \"RST_STREAM\",\n",
        "        \"Connection reset by peer\",\n",
        "        \"Server disconnected\",\n",
        "        \"Transport closed\",\n",
        "        \"EOF occurred in violation of protocol\",\n",
        "        \"Stream removed\",\n",
        "        \"recvmsg\",\n",
        "        \"Broken pipe\",\n",
        "        \"Timed out\",\n",
        "    ]\n",
        "    return any(n in s for n in needles)\n",
        "\n",
        "@dataclass\n",
        "class TransformerEntry:\n",
        "    pipe: Pipeline  # preprocessing -> to_dense -> model\n",
        "\n",
        "@dataclass\n",
        "class LGBEntry:\n",
        "    best_method: str\n",
        "    pipe_reg: Optional[Pipeline]\n",
        "    pipe_rank: Optional[Pipeline]\n",
        "    meta: Dict[str, Any]\n",
        "    threshold: float\n",
        "    calib_reg: Dict[str, float]\n",
        "    w_reg: Optional[float]\n",
        "\n",
        "class ModelsRuntimeCache:\n",
        "    def __init__(self):\n",
        "        self.transformers_path: str = \"\"\n",
        "        self.models_path: str = \"\"\n",
        "        self.final_cols: Dict[str, list] = {}\n",
        "        self.final_params: Dict[str, Any] = {}\n",
        "        self.methods: Dict[str, str] = {}\n",
        "        self.scaler_global = None\n",
        "        self.kmeans_global = None\n",
        "        self.transformers: Dict[str, TransformerEntry] = {}\n",
        "        self.lgb_models: Dict[str, LGBEntry] = {}\n",
        "\n",
        "    def init_metadata(self, path_to_save: str):\n",
        "        # Нормализуем пути\n",
        "        self.transformers_path = os.path.join(path_to_save, \"models\", \"neuros\")\n",
        "        self.models_path = os.path.join(path_to_save, \"models\", \"final_models\")\n",
        "\n",
        "        # Метаданные\n",
        "        with open(os.path.join(path_to_save, \"models\", \"final_cols.pkl\"), \"rb\") as f:\n",
        "            self.final_cols = pickle.load(f)\n",
        "        with open(os.path.join(path_to_save, \"models\", \"final_params.pkl\"), \"rb\") as f:\n",
        "            self.final_params = pickle.load(f)\n",
        "        with open(os.path.join(path_to_save, \"models\", \"best_methods.json\"), \"rb\") as f:\n",
        "            self.methods = json.load(f)\n",
        "\n",
        "        # Глобальные объекты\n",
        "        self.scaler_global = joblib.load(os.path.join(path_to_save, \"models\", \"scaler_global.pkl\"))\n",
        "        self.kmeans_global = joblib.load(os.path.join(path_to_save, \"models\", \"kmeans_global.pkl\"))\n",
        "\n",
        "    def _has_transformer_on_disk(self, ticker: str) -> bool:\n",
        "        base = os.path.join(self.transformers_path, ticker)\n",
        "        return os.path.isdir(base)\n",
        "\n",
        "    def _has_lgb_on_disk(self, ticker: str) -> bool:\n",
        "        # Если у вас load_model_for_ticker сам умеет искать файлы — можно опустить эту проверку.\n",
        "        # Оставим мягкую проверку по каталогу тикера.\n",
        "        base = os.path.join(self.models_path, ticker)\n",
        "        return os.path.isdir(base)\n",
        "\n",
        "    def load_transformer_for(self, ticker: str, device: Optional[str] = \"cpu\") -> Optional[Pipeline]:\n",
        "        if ticker in self.transformers:\n",
        "            return self.transformers[ticker].pipe\n",
        "        if not self._has_transformer_on_disk(ticker):\n",
        "            return None\n",
        "        base = os.path.join(self.transformers_path, ticker)\n",
        "        pipe = load_transformer_exact(base, device=device or \"cpu\")\n",
        "        self.transformers[ticker] = TransformerEntry(pipe=pipe)\n",
        "        return pipe\n",
        "\n",
        "    def load_lgb_for(self, ticker: str) -> Optional[LGBEntry]:\n",
        "        if ticker in self.lgb_models:\n",
        "            return self.lgb_models[ticker]\n",
        "        if not self._has_lgb_on_disk(ticker):\n",
        "            return None\n",
        "        data = load_model_for_ticker(ticker, models_dir=self.models_path)\n",
        "        entry = LGBEntry(\n",
        "            best_method=data[\"best_method\"],\n",
        "            pipe_reg=data.get(\"pipe_reg\"),\n",
        "            pipe_rank=data.get(\"pipe_rank\"),\n",
        "            meta=data.get(\"meta\", {}),\n",
        "            threshold=data.get(\"threshold\", 0.0),\n",
        "            calib_reg=data.get(\"calib_reg\", {\"a\": 1.0, \"b\": 0.0}),\n",
        "            w_reg=data.get(\"w_reg\"),\n",
        "        )\n",
        "        self.lgb_models[ticker] = entry\n",
        "        return entry\n",
        "\n",
        "    def preload_all(self, tickers: list, device: str = \"cpu\"):\n",
        "        \"\"\"Аккуратно предзагружает модели только для тех тикеров, которые есть во всех справочниках\n",
        "        и у которых реально есть файлы на диске. Остальные — тихо пропускает.\"\"\"\n",
        "        loaded, skipped = [], []\n",
        "\n",
        "        for t in tickers:\n",
        "            # Проверим наличие описаний в метаданных\n",
        "            has_params = t in self.final_params\n",
        "            has_cols = t in self.final_cols\n",
        "            # Выбираем метод, но отсутствие метода не критично — дефолт 'regressor'\n",
        "            method = self.methods.get(t, \"regressor\")\n",
        "\n",
        "            if not (has_params and has_cols):\n",
        "                skipped.append((t, \"no_meta\"))\n",
        "                continue\n",
        "\n",
        "            # Трансформер\n",
        "            tr_ok = self.load_transformer_for(t, device=device) is not None\n",
        "            # LGB\n",
        "            lgb_ok = self.load_lgb_for(t) is not None\n",
        "\n",
        "            if tr_ok and lgb_ok:\n",
        "                loaded.append(t)\n",
        "            else:\n",
        "                reason = (\"no_transformer\" if not tr_ok else \"no_lgb\")\n",
        "                skipped.append((t, reason))\n",
        "\n",
        "        return {\"loaded\": loaded, \"skipped\": skipped}\n",
        "\n",
        "def to_dense(X):\n",
        "    \"\"\"Преобразует разреженную матрицу в плотную.\"\"\"\n",
        "    if issparse(X):\n",
        "        return X.toarray()\n",
        "    return X\n",
        "\n",
        "class ToDenseTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Преобразует разреженную матрицу в плотную numpy-массив.\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        if issparse(X):\n",
        "            return X.toarray()\n",
        "        return X\n",
        "    def get_feature_names_out(self, input_features: tp.Sequence[str] | None = None):\n",
        "        return np.asarray(input_features) if input_features is not None else np.array([])\n",
        "\n",
        "def deep_elbow(imp: np.ndarray, win: int = 5, eps: float = 0.02) -> int:\n",
        "    \"\"\"\n",
        "    Берём окно длиной win, считаем средний относительный спад.\n",
        "    Первое место, где спад < eps, считаем плато.\n",
        "    \"\"\"\n",
        "    if len(imp) <= win:\n",
        "        return len(imp)\n",
        "    dif = np.abs(np.diff(imp) / (imp[:-1] + 1e-9))\n",
        "    # скользящее среднее\n",
        "    m = np.convolve(dif, np.ones(win) / win, mode=\"valid\")\n",
        "    flat = np.nonzero(m < eps)[0]\n",
        "    return int(flat[0] + win) if flat.size else len(imp)\n",
        "\n",
        "# ───────────────────────────────────────────────────────\n",
        "# 2.  корреляционная чистка (быстрая, исправленная)\n",
        "# ───────────────────────────────────────────────────────\n",
        "def corr_prune(df: pd.DataFrame, feats: list[str], thr=.95) -> list[str]:\n",
        "    if len(feats) < 2 or thr >= 1:\n",
        "        return feats\n",
        "    X  = df[feats].apply(pd.to_numeric, errors='ignore')\n",
        "    C  = X.corr().abs().to_numpy()\n",
        "    keep = []\n",
        "    for i in range(len(feats)):\n",
        "        if not keep or C[i, keep].max() < thr:\n",
        "            keep.append(i)\n",
        "    return [feats[i] for i in keep]\n",
        "\n",
        "# ───────────────────────────────────────────────────────\n",
        "# 3.  универсальный быстрый селектор\n",
        "# ───────────────────────────────────────────────────────\n",
        "def fast_feature_select(\n",
        "        res           : pd.DataFrame,      # feature / importance\n",
        "        df_full       : pd.DataFrame,      # датасет для corr-prune\n",
        "        target_col    : str = \"target\",\n",
        "        *,\n",
        "        method        : str = \"elbow\",     # elbow | deep_elbow | percentile | quantile | top_k\n",
        "        top_k         : int = 150,         # для method=\"top_k\"\n",
        "        perc_limit    : float = .90,       # для method=\"percentile\"\n",
        "        quantile_q    : float = .10,       # для method=\"quantile\"\n",
        "        elbow_eps     : float = .05,       # (> flat %) для (shallow) elbow\n",
        "        deep_win      : int = 5,           # окно для deep_elbow\n",
        "        deep_eps      : float = .02,       # порог для deep_elbow\n",
        "        corr_thr      : float = .95        # корреляционный порог\n",
        ") -> list[str]:\n",
        "\n",
        "    ranked = res.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
        "    feats  = ranked.feature.to_numpy()\n",
        "    imps   = ranked.importance.to_numpy()\n",
        "\n",
        "    # ---------- 1) сколько оставить  ----------\n",
        "    if method == \"elbow\":                 # одношаговое колено\n",
        "        k = np.argmax(np.abs(np.diff(imps) / (imps[:-1] + 1e-9)) < elbow_eps) + 1\n",
        "        if k == 1:        # колено не найдено\n",
        "            k = len(imps)\n",
        "    elif method == \"deep_elbow\":\n",
        "        k = deep_elbow(imps, win=deep_win, eps=deep_eps)\n",
        "    elif method == \"percentile\":          # кумулятивная доля\n",
        "        cum = np.cumsum(imps)\n",
        "        k   = np.searchsorted(cum / cum[-1], perc_limit) + 1\n",
        "    elif method == \"quantile\":\n",
        "        thr = np.quantile(imps, 1 - quantile_q)\n",
        "        k   = int((imps >= thr).sum())\n",
        "    elif method == \"top_k\":\n",
        "        k = min(top_k, len(feats))\n",
        "    else:\n",
        "        raise ValueError(\"unknown method\")\n",
        "\n",
        "    selected = feats[:k].tolist()\n",
        "\n",
        "    # ---------- 2) корреляционная чистка ----------\n",
        "    selected = corr_prune(\n",
        "        df_full.drop(columns=[target_col], errors='ignore'),\n",
        "        selected,\n",
        "        thr=corr_thr\n",
        "    )\n",
        "\n",
        "    return selected\n",
        "\n",
        "def patch_feature_timings(cls):\n",
        "    \"\"\"\n",
        "    Оборачивает все методы cls, начинающиеся на _feat_,\n",
        "    и складывает затраченное время в self._timings[method_name].\n",
        "    Вызывать сразу после объявления класса.\n",
        "    \"\"\"\n",
        "    def timed(func):\n",
        "        def wrapper(self, *args, **kwargs):\n",
        "            t0 = time.perf_counter()\n",
        "            result = func(self, *args, **kwargs)\n",
        "            dt = time.perf_counter() - t0\n",
        "            # заводим словарь при первом же вызове\n",
        "            if not hasattr(self, \"_timings\"):\n",
        "                self._timings = {}\n",
        "            self._timings[func.__name__] = dt\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "    for name, method in inspect.getmembers(cls, inspect.isfunction):\n",
        "        if name.startswith(\"_feat_\"):             # ← только расчётные функции\n",
        "            setattr(cls, name, timed(method))\n",
        "\n",
        "    return cls\n",
        "\n",
        "def _slope(y):\n",
        "        x = np.arange(len(y))\n",
        "        # линейная регрессия «по формуле»\n",
        "        xm, ym = x.mean(), y.mean()\n",
        "        beta = ((x - xm) * (y - ym)).sum() / ((x - xm)**2).sum()\n",
        "        return beta\n",
        "\n",
        "@njit\n",
        "def _rolling_entropy_exact_numba(x, window):\n",
        "    \"\"\" Точная реализация rolling entropy с bins='auto' для каждого окна. \"\"\"\n",
        "    n = len(x)\n",
        "    res = np.empty(n, dtype=np.float32)\n",
        "    res[:] = np.nan\n",
        "    if window < 2:\n",
        "        return res\n",
        "    for end in range(window - 1, n):\n",
        "        win = x[end - window + 1 : end + 1]\n",
        "        a_min = np.min(win)\n",
        "        a_max = np.max(win)\n",
        "        if a_min == a_max:\n",
        "            res[end] = 0.0\n",
        "            continue\n",
        "        sorted_win = np.sort(win)\n",
        "        idx25 = int(0.25 * window)\n",
        "        idx75 = int(0.75 * window)\n",
        "        q25 = sorted_win[idx25]\n",
        "        q75 = sorted_win[idx75]\n",
        "        iqr = q75 - q25\n",
        "        sturges = int(np.ceil(np.log2(window) + 1))\n",
        "        if iqr > 0:\n",
        "            bin_width = 2.0 * iqr / (window ** (1.0 / 3.0))\n",
        "            fd = int(np.ceil((a_max - a_min) / bin_width))\n",
        "        else:\n",
        "            fd = 1\n",
        "        nbins = max(sturges, fd, 1)\n",
        "        edges = np.empty(nbins + 1, dtype=np.float32)\n",
        "        step = (a_max - a_min) / nbins\n",
        "        edges[0] = a_min\n",
        "        for i in range(1, nbins):\n",
        "            edges[i] = a_min + i * step\n",
        "        edges[nbins] = a_max\n",
        "        counts = np.zeros(nbins, dtype=np.int32)  # int32 достаточно для window<=1e9\n",
        "        for val in win:\n",
        "            idx = np.searchsorted(edges, val, side='right') - 1\n",
        "            if 0 <= idx < nbins:\n",
        "                counts[idx] += 1\n",
        "        ent = 0.0\n",
        "        total = float(window)\n",
        "        for c in counts:\n",
        "            if c > 0:\n",
        "                p = c / total\n",
        "                ent -= p * np.log(p + 1e-10)\n",
        "        res[end] = ent\n",
        "    return res\n",
        "\n",
        "@jit(nopython=True)\n",
        "def rolling_autocorr(arr, window):\n",
        "    n = len(arr)\n",
        "    result = np.full(n, 0.0)\n",
        "    for i in range(n):\n",
        "        start = max(0, i - window + 1)\n",
        "        w = i - start + 1\n",
        "        if w <= 1:\n",
        "            continue\n",
        "        s = arr[start: i + 1]\n",
        "        a = s[1:]\n",
        "        b = s[:-1]\n",
        "        n_pts = w - 1\n",
        "        mean_a = np.sum(a) / n_pts\n",
        "        mean_b = np.sum(b) / n_pts\n",
        "        cov = np.dot(a, b) / n_pts - mean_a * mean_b\n",
        "        var_a = np.dot(a, a) / n_pts - mean_a * mean_a\n",
        "        var_b = np.dot(b, b) / n_pts - mean_b * mean_b\n",
        "        if var_a <= 0 or var_b <= 0:\n",
        "            result[i] = np.nan\n",
        "        else:\n",
        "            std_a = np.sqrt(var_a)\n",
        "            std_b = np.sqrt(var_b)\n",
        "            result[i] = cov / (std_a * std_b)\n",
        "    return result\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "@patch_feature_timings\n",
        "class FeatureCalculatorForRegression:\n",
        "    \"\"\"\n",
        "    df  -- исходный OHLCV-DataFrame.\n",
        "    required_features -- список имён колонок, которые нужны модели.\n",
        "    params -- { primitive_name: {... гиперпараметры ...}, 'stat_window': int }.\n",
        "    \"\"\"\n",
        "\n",
        "    _PRIMITIVES = {\n",
        "        \"MEDPRICE\":               \"_feat_base\",\n",
        "        \"MACD\":                   \"_feat_macd\",\n",
        "        \"MACD_Hist\":              \"_feat_macd\",\n",
        "        \"Overbought_Oversold\":    \"_feat_overbought\",\n",
        "        \"Overbought_Oversold_Index_mean\": \"_feat_overbought\",\n",
        "        \"Price_MADist%\":          \"_feat_madist\",\n",
        "        \"Mean_Reversion\":         \"_feat_mean_reversion\",\n",
        "        \"Fear_Greed\":             \"_feat_fear_greed\",\n",
        "        \"perc_var_open_close\":    \"_feat_price_variation\",\n",
        "        \"pmax_norm\":              \"_feat_pmax_ma\",\n",
        "        \"ma_norm\":                \"_feat_pmax_ma\",\n",
        "        \"ma_pmax_norm_rage\":      \"_feat_pmax_ma\",\n",
        "        \"ma_pmax_norm_rage_pct\":  \"_feat_pmax_ma\",\n",
        "        \"slope_trend\":            \"_feat_slope\",\n",
        "        \"ema_trend\":              \"_feat_ema_trend\",\n",
        "        \"hp_trend\":               \"_feat_hp_trend\",\n",
        "        \"trade_bars_counter\":     \"_feat_trade_duration\",\n",
        "        \"ROC\":                    \"_feat_roc\",\n",
        "        \"ATR_norm\":               \"_feat_atr\",\n",
        "        \"BB_Width\":               \"_feat_bb_width\",\n",
        "        \"Asset_Growth\":           \"_feat_asset_growth\",\n",
        "        \"ema_acceleration\":       \"_feat_ema_acceleration\",\n",
        "        \"price_change\":           \"_feat_price_change\",\n",
        "        \"Asset_To_Equity_Ratio\":  \"_feat_asset_to_equity_ratio\",\n",
        "        \"volume_ratio\":           \"_feat_fear_greed_index\",\n",
        "        \"WILLR\":                  \"_feat_willr\",\n",
        "        \"kf_trend\":               \"_feat_kf_trend\",\n",
        "        \"Fractal_Dim\":            \"_feat_fractal_dim\",\n",
        "        \"Peak_Exhaustion_Score\":  \"_feat_peak_exhaustion\",\n",
        "        \"%B_BB\":                  \"_feat_bb_percent\",\n",
        "        \"Kurtosis_roll\":          \"_feat_kurtosis_roll\",\n",
        "        \"OBV_div\":                \"_feat_obv_div\",\n",
        "        \"RSI_slope\":              \"_feat_rsi_slope\",\n",
        "        \"Vol_Decay\":              \"_feat_vol_decay\",\n",
        "        \"Accel_Decay\":            \"_feat_accel_decay\",\n",
        "        \"Entropy_roll\":           \"_feat_entropy_roll\",\n",
        "        \"Wavelet_Var_Ratio\":      \"_feat_wavelet_var\",\n",
        "        \"Autocorr_Lag1\":          \"_feat_autocorr\",\n",
        "        \"Beta_Market\":            \"_feat_beta\",\n",
        "        \"PSC\":                    \"_feat_peak_squeeze_curvature\",\n",
        "        \"PSC_raw\":                \"_feat_peak_squeeze_curvature\",\n",
        "        \"PSC_z\":                  \"_feat_peak_squeeze_curvature\",\n",
        "        \"PSC_sigmoid\":            \"_feat_peak_squeeze_curvature\",\n",
        "    }\n",
        "\n",
        "    # СТАРАЯ: r\"^ago_(\\d+)_\"\n",
        "    # НОВАЯ: умеет и \"ago50_\", и \"ago_50_\"\n",
        "    _LAG_RE  = re.compile(r\"^ago_?(\\d+)_\")\n",
        "    _STAT_RE = re.compile(r\"_(mean|min|max|std|skew|kurt|quantile(\\d{2}))$\")\n",
        "    _LOGSF   = \"_logsf\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, ticker):\n",
        "        self.df = df.copy()\n",
        "        self.ticker = ticker\n",
        "        f64 = self.df.select_dtypes(\"float64\").columns\n",
        "        self.df[f64] = self.df[f64].astype(np.float32)\n",
        "        if \"time\" in self.df:\n",
        "            ts = pd.to_datetime(self.df[\"time\"], utc=True, errors=\"coerce\")\n",
        "            self.df[\"hour\"]        = ts.dt.hour.astype(\"int8\")\n",
        "            self.df[\"day_of_week\"] = ts.dt.day_of_week.astype(\"int8\")\n",
        "\n",
        "    def calculate_features(\n",
        "        self,\n",
        "        required_features: Iterable[str],\n",
        "        params: Mapping[str, Mapping[str, Any]] | None = None\n",
        "    ) -> pd.DataFrame:\n",
        "        saved_cols = ['regime', 'normalized_target', 'batch', 'time', 'open', 'close', 'high', 'low', 'volume', 'buy_signal',\n",
        "                      'sell_signal', 'event_sell_time', 'event_sell_price', 'event_time', 'event_price', 'event_sell_time',\n",
        "                      'event_sell_price', 'target', 'pnl', 'ma', 'pmax']\n",
        "        self._params      = defaultdict(dict, params or {})\n",
        "        self._stat_window = self._params.get(\"stat_window\", 50)\n",
        "        for col in required_features:\n",
        "            self._ensure_column(col)\n",
        "        out = self.df[list(required_features)].copy()\n",
        "        f64 = out.select_dtypes(\"float64\").columns\n",
        "        out[f64] = out[f64].astype(np.float32)\n",
        "\n",
        "        for mandatory_col in saved_cols:\n",
        "            if mandatory_col in self.df.columns:\n",
        "                out[mandatory_col] = self.df[mandatory_col]\n",
        "\n",
        "        return out\n",
        "\n",
        "    def calculate_all_possible_features(self, params: Mapping[str, Mapping[str, Any]] | None = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Вычисляет все возможные фичи, исключая lag-версии для указанных колонок.\n",
        "        Все бесконечные значения (np.inf/-np.inf) заменяются на 0.\n",
        "        Порядок вычислений:\n",
        "        1. Все базовые примитивы\n",
        "        2. Lag-версии фич (кроме исключенных)\n",
        "        3. Статистики для всех фич\n",
        "        \"\"\"\n",
        "        # Инициализация параметров\n",
        "        if not hasattr(self, '_params'):\n",
        "            self._params = defaultdict(dict, params or {})\n",
        "        self._stat_window = self._params.get(\"stat_window\", 50)\n",
        "\n",
        "        # Колонки, для которых не нужно создавать lag-версии\n",
        "        EXCLUDE_FROM_LAGS = {\n",
        "            'time', 'open', 'close', 'high', 'low', 'volume',\n",
        "            'ma', 'pmax', 'buy_signal', 'sell_signal', 'regime',\n",
        "            'event_time', 'event_price', 'event_sell_time',\n",
        "            'event_sell_price', 'pnl', 'target', 'normalized_target',\n",
        "            'batch', 'hour', 'day_of_week', 'trade_bars_counter'\n",
        "        }\n",
        "\n",
        "        # 1. Вычисляем все базовые примитивы\n",
        "        all_primitives = list(self._PRIMITIVES.keys())\n",
        "        for primitive in all_primitives:\n",
        "            method_name = self._PRIMITIVES[primitive]\n",
        "            primitive_params = self._params.get(primitive, {})\n",
        "            try:\n",
        "                getattr(self, method_name)(**primitive_params)\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка при вычислении примитива {primitive}: {str(e)}\")\n",
        "\n",
        "        # 2. Добавляем lag-версии только для разрешенных фич\n",
        "        numeric_cols = [\n",
        "            col for col in self.df.select_dtypes(include=['float32', 'float64', 'int32', 'int64']).columns\n",
        "            if col not in EXCLUDE_FROM_LAGS and  # Исключаем указанные колонки\n",
        "            not self._LAG_RE.match(col) and      # Исключаем уже lag-фичи\n",
        "            not col.endswith(self._LOGSF) and    # Исключаем logsf-фичи\n",
        "            not self._STAT_RE.search(col)        # Исключаем статистики\n",
        "        ]\n",
        "\n",
        "        lag_periods = [1, 2, 3, 5, 10, 20, 50]  # Стандартные лаги\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            for lag in lag_periods:\n",
        "                lag_col = f\"ago_{lag}_{col}\"\n",
        "                if lag_col not in self.df.columns:\n",
        "                    self.df[lag_col] = self.df[col].shift(lag)\n",
        "\n",
        "        # 3. Добавляем статистики для всех фич (кроме исключенных)\n",
        "        all_cols_for_stats = [\n",
        "            col for col in self.df.columns\n",
        "            if col not in EXCLUDE_FROM_LAGS and\n",
        "            not col.endswith(self._LOGSF) and\n",
        "            not self._STAT_RE.search(col)\n",
        "        ]\n",
        "\n",
        "        stats = ['mean', 'std', 'min', 'max', 'skew', 'kurt']\n",
        "\n",
        "        for col in all_cols_for_stats:\n",
        "            for stat in stats:\n",
        "                stat_col = f\"{col}_{stat}\"\n",
        "                if stat_col not in self.df.columns:\n",
        "                    try:\n",
        "                        self._add_stat(col, stat)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Ошибка при вычислении статистики {stat} для {col}: {str(e)}\")\n",
        "\n",
        "        # 4. Добавляем logsf-версии только для разрешенных фич\n",
        "        main_cols_for_logsf = [\n",
        "            col for col in numeric_cols\n",
        "            if not col.startswith('ago_') and\n",
        "            not col.endswith(self._LOGSF) and\n",
        "            col not in EXCLUDE_FROM_LAGS\n",
        "        ]\n",
        "\n",
        "        for col in main_cols_for_logsf:\n",
        "            logsf_col = f\"{col}{self._LOGSF}\"\n",
        "            if logsf_col not in self.df.columns:\n",
        "                try:\n",
        "                    self.df[logsf_col] = norm.logsf(self.df[col])\n",
        "                except Exception as e:\n",
        "                    print(f\"Ошибка при вычислении logsf для {col}: {str(e)}\")\n",
        "\n",
        "        # 5. Заменяем бесконечные значения на 0\n",
        "        numeric_cols_all = self.df.select_dtypes(include=['float32', 'float64', 'int32', 'int64']).columns\n",
        "        self.df[numeric_cols_all] = self.df[numeric_cols_all].replace([np.inf, -np.inf], 0)\n",
        "\n",
        "        # Сохраняем все оригинальные колонки\n",
        "        for col in EXCLUDE_FROM_LAGS:\n",
        "            if col in self.df.columns and col not in self.df:\n",
        "                self.df[col] = self.df[col]\n",
        "\n",
        "        return self.df.copy()\n",
        "\n",
        "    def _ensure_column(self, name: str):\n",
        "        if name in self.df:\n",
        "            return\n",
        "\n",
        "        # 1) lag-префикс \"ago50_\" или \"ago_50_\"\n",
        "        m = self._LAG_RE.match(name)\n",
        "        if m:\n",
        "            lag  = int(m.group(1))\n",
        "            base = name[m.end():]\n",
        "            self._ensure_column(base)\n",
        "            self.df[name] = self.df[base].shift(lag)\n",
        "            return\n",
        "\n",
        "        # 2) _logsf\n",
        "        if name.endswith(self._LOGSF):\n",
        "            base = name[:-len(self._LOGSF)]\n",
        "            self._ensure_column(base)\n",
        "            self.df[name] = norm.logsf(self.df[base])\n",
        "            return\n",
        "\n",
        "        # 3) статистический суффикс\n",
        "        m = self._STAT_RE.search(name)\n",
        "        if m:\n",
        "            stat = m.group(1)\n",
        "            base = name[:m.start()]\n",
        "            self._ensure_column(base)\n",
        "            self._add_stat(base, stat)\n",
        "            return\n",
        "\n",
        "        # 4) примитив\n",
        "        prim = name\n",
        "        if prim.startswith(\"Overbought_Oversold\"):\n",
        "            prim = \"Overbought_Oversold\"\n",
        "        if prim.startswith(\"Fear_Greed\"):\n",
        "            prim = \"Fear_Greed\"\n",
        "        if prim not in self._PRIMITIVES:\n",
        "            raise KeyError(f\"Не знаю, как получить примитив «{prim}» для «{name}»\")\n",
        "        getattr(self, self._PRIMITIVES[prim])(**self._params.get(prim, {}))\n",
        "        if name not in self.df:\n",
        "            raise RuntimeError(f\"После _feat_{prim}() нет колонки «{name}»\")\n",
        "\n",
        "    def _add_stat(self, base: str, stat: str):\n",
        "        col = f\"{base}_{stat}\"\n",
        "        if col in self.df:\n",
        "            return\n",
        "        s = self.df[base]; w = self._stat_window\n",
        "        if stat == \"mean\":\n",
        "            self.df[col] = s.rolling(w).mean()\n",
        "        elif stat == \"std\":\n",
        "            self.df[col] = s.rolling(w).std()\n",
        "        elif stat == \"min\":\n",
        "            self.df[col] = s.rolling(w).min()\n",
        "        elif stat == \"max\":\n",
        "            self.df[col] = s.rolling(w).max()\n",
        "        elif stat == \"skew\":\n",
        "            self.df[col] = s.rolling(w).skew()\n",
        "        elif stat == \"kurt\":\n",
        "            self.df[col] = s.rolling(w).kurt()\n",
        "        elif stat.startswith(\"quantile\"):\n",
        "            q = int(stat[-2:]) / 100\n",
        "            self.df[col] = s.rolling(w).quantile(q)\n",
        "        else:\n",
        "            raise ValueError(f\"Неизвестная stat «{stat}»\")\n",
        "\n",
        "    # ---------------------- ПРИМИТИВЫ ----------------------\n",
        "\n",
        "    def _feat_base(self, medprice: int = 50):\n",
        "        if \"MEDPRICE\" in self.df:\n",
        "            return\n",
        "        self.df[\"MEDPRICE\"]      = (self.df[\"high\"] + self.df[\"low\"]) / 2\n",
        "        self.df[\"MEDPRICE_std\"] = self.df[\"MEDPRICE\"].rolling(medprice).std()\n",
        "\n",
        "    def _feat_macd(self, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "        \"\"\"\n",
        "        Быстрый расчет нормализованного MACD с использованием векторизованных операций\n",
        "        \"\"\"\n",
        "        if {\"MACD\",\"MACD_Hist\"}.issubset(self.df.columns):\n",
        "            return\n",
        "\n",
        "        close = self.df['close']\n",
        "        # Создаем множества для уникальных периодов\n",
        "        ema_cache_fp = close.ewm(span=fast, adjust=False).mean()\n",
        "\n",
        "        ema_cache_sp = close.ewm(span=slow, adjust=False).mean()\n",
        "        rolling_cache = close.rolling(window=slow).mean()\n",
        "\n",
        "        # Основной цикл вычислений\n",
        "        ema_fast = ema_cache_fp\n",
        "        ema_slow = ema_cache_sp\n",
        "        rolling_mean = rolling_cache\n",
        "        macd = ema_fast - ema_slow\n",
        "        macd_norm = macd / rolling_mean\n",
        "        self.df[f'MACD'] = macd_norm\n",
        "        signal = macd.ewm(span=signal, adjust=False).mean()\n",
        "        signal_norm = signal / rolling_mean\n",
        "\n",
        "        # Сохраняем результаты\n",
        "        self.df[f'MACD_Hist'] = macd_norm - signal_norm\n",
        "\n",
        "    def _feat_overbought(self, rsi_p: int = 14, stoch_p: int = 14):\n",
        "        name = \"Overbought_Oversold_Index\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        c   = self.df[\"close\"]; d = c.diff()\n",
        "        g   = d.clip(lower=0); l = (-d).clip(lower=0)\n",
        "        rs  = g.rolling(rsi_p).mean() / (l.rolling(rsi_p).mean().add(1e-10))\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        lo  = self.df[\"low\"].rolling(stoch_p).min()\n",
        "        hi  = self.df[\"high\"].rolling(stoch_p).max()\n",
        "        st  = 100*(c - lo)/(hi - lo + 1e-10)\n",
        "        self.df[name] = (rsi + st)/2\n",
        "\n",
        "    def _feat_madist(self, span_lenght: int = 200):\n",
        "        name = \"Price_MADist%\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ema = self.df[\"close\"].ewm(span=span_lenght, adjust=False).mean()\n",
        "        self.df[name] = (self.df[\"close\"]/ema - 1)*100\n",
        "\n",
        "    def _feat_mean_reversion(self, window: int = 20):\n",
        "        name = \"Mean_Reversion\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ma = self.df[\"close\"].rolling(window).mean()\n",
        "        self.df[name] = self.df[\"close\"] - ma\n",
        "\n",
        "    def _feat_fear_greed(self, window: int = 14):\n",
        "        name = \"Fear_Greed_Index\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        v  = self.df[\"close\"].pct_change().rolling(window).std()\n",
        "        vc = self.df[\"volume\"].pct_change().rolling(window).mean()\n",
        "        tr = self.df[\"close\"]/self.df[\"close\"].rolling(window).mean()\n",
        "        self.df[name] = (v + vc + tr)/3*100\n",
        "\n",
        "    def _feat_price_variation(self):\n",
        "        name = \"perc_var_open_close\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        eps = 1e-10\n",
        "        self.df[name] = (self.df[\"close\"]-self.df[\"open\"])/(self.df[\"open\"]+eps)*100\n",
        "\n",
        "    def _feat_pmax_ma(self,\n",
        "        pmax_ma_length: int = 10,\n",
        "        pmax_ma_length_roll: int = 50,\n",
        "        pct_window: int = 5\n",
        "    ):\n",
        "        need = {\n",
        "            \"pmax_norm\", \"ma_norm\",\n",
        "            \"ma_pmax_norm_rage\", \"ma_pmax_norm_rage_pct\"\n",
        "        }\n",
        "        if need.issubset(self.df.columns):\n",
        "            return\n",
        "        if {\"pmax\",\"ma\"}.difference(self.df.columns):\n",
        "            raise ValueError(\"Нужны 'pmax' и 'ma'\")\n",
        "        c = self.df[\"close\"]\n",
        "        self.df[\"pmax_norm\"]             = (c-self.df[\"pmax\"])/self.df[\"pmax\"]\n",
        "        self.df[\"ma_norm\"]               = (c-self.df[\"ma\"])/self.df[\"ma\"]\n",
        "        self.df[\"ma_pmax_norm_rage\"]     = self.df[\"ma_norm\"] - self.df[\"pmax_norm\"]\n",
        "        # новый примитив — pct-динамика\n",
        "        self.df[\"ma_pmax_norm_rage_pct\"] = \\\n",
        "          self.df[\"ma_pmax_norm_rage\"].pct_change(pct_window).fillna(0)\n",
        "\n",
        "    def _feat_slope(self, slope_lag: int = 300, pct_window: int = 6):\n",
        "        name = \"slope_trend\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        r = self.df[\"close\"].pct_change(pct_window).fillna(0)\n",
        "        self.df[name] = r.rolling(slope_lag, min_periods=slope_lag)\\\n",
        "                         .apply(_slope, raw=True)\n",
        "\n",
        "    def _feat_ema_trend(self, span: int = 300, pct_window: int = 6):\n",
        "        name = \"ema_trend\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        r = self.df[\"close\"].pct_change(pct_window).fillna(0)\n",
        "        e = r.ewm(span=span, adjust=False).mean()\n",
        "        self.df[name] = e.diff().fillna(0)\n",
        "\n",
        "    def _feat_asset_to_equity_ratio(self):\n",
        "        \"\"\"\n",
        "        Вычисление коэффициента соотношения активов и собственного капитала.\n",
        "        \"\"\"\n",
        "        name = \"Asset_To_Equity_Ratio\"\n",
        "        asset = self.df['close']\n",
        "        equity = self.df['low']\n",
        "        # Добавляем в DataFrame\n",
        "        self.df[name] = asset / (equity + 1e-10)\n",
        "\n",
        "    def _feat_hp_trend(self, lamb: float = 1600):\n",
        "        name = \"hp_trend\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        y    = np.log(self.df[\"close\"]).fillna(method=\"ffill\")\n",
        "        coef = lamb/(1+lamb)\n",
        "        tr   = np.empty(len(y), dtype=float)\n",
        "        tr[0] = y.iloc[0]\n",
        "        for i in range(1, len(y)):\n",
        "            tr[i] = coef*y.iloc[i] + (1-coef)*tr[i-1]\n",
        "        self.df[name] = np.append([0], np.diff(tr))\n",
        "\n",
        "    def _feat_kf_trend(self,\n",
        "        pct_window: int = 6,\n",
        "        obs_var: float = 1e-4, # σ² ε_t (шум наблюдения)\n",
        "        level_var: float = 1e-5 # σ² η_t (шум уровня)\n",
        "        ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Добавляет к DataFrame колонки:\n",
        "        kf_trend — one-sided Калман-оценка тренда доходностей\n",
        "        kf_trend_logsf — лог-survival-function (z-score) тренда\n",
        "        Полностью каузально, обновляется тик-за-тиком.\n",
        "        \"\"\"\n",
        "\n",
        "        name = 'kf_trend'\n",
        "        # 1. Доходности\n",
        "        r = self.df['close'].pct_change(pct_window).fillna(0)\n",
        "        # 2. Local-level модель: y_t = μ_t + ε_t ;  μ_t = μ_{t-1} + η_t\n",
        "        mod = sm.tsa.UnobservedComponents(r, level='llevel')\n",
        "\n",
        "        # 3. Параметры модели в log-шкале (требование statsmodels)\n",
        "        params = np.log([obs_var, level_var])\n",
        "\n",
        "        # 4. Только forward-filter → нет look-ahead bias\n",
        "        res = mod.filter(params)                       # <— односторонний Калман\n",
        "        trend = pd.Series(res.filtered_state[0], index=self.df.index)\n",
        "\n",
        "        # 5. Запись результата\n",
        "        self.df['kf_trend'] = trend\n",
        "\n",
        "    def _feat_willr(self, window=14):\n",
        "        \"\"\"\n",
        "        Вычисление %R по методу Уильямса (WILLR).\n",
        "        \"\"\"\n",
        "        name = 'WILLR'\n",
        "        high = self.df['high']\n",
        "        low = self.df['low']\n",
        "        close = self.df['close']\n",
        "\n",
        "        highest_high = high.rolling(window).max()\n",
        "        lowest_low = low.rolling(window).min()\n",
        "\n",
        "        willr = ((highest_high - close) / (highest_high - lowest_low)) * -100\n",
        "\n",
        "        # Добавляем в DataFrame\n",
        "        self.df[name] = willr\n",
        "\n",
        "    def _feat_fear_greed_index(self, window: int = 14):\n",
        "        \"\"\"\n",
        "        Расчет объема как отношение последнего объема к скользящему среднему.\n",
        "        \"\"\"\n",
        "        name = \"volume_ratio\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        s = self.df[\"volume\"]\n",
        "        self.df[name] = s / s.rolling(window).mean()\n",
        "\n",
        "    def _feat_trade_duration(self):\n",
        "        name = \"trade_bars_counter\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = np.nan\n",
        "        entries = self.df.index[self.df[\"event_time\"].notna()]\n",
        "        last    = self.df.index[-1]\n",
        "        for st in entries:\n",
        "            sell = self.df.at[st, \"event_sell_time\"]\n",
        "            ends = self.df.index[self.df[\"time\"] == sell]\n",
        "            end  = ends[0] if len(ends) else last\n",
        "            s,e  = self.df.index.get_loc(st), self.df.index.get_loc(end)\n",
        "            self.df.loc[self.df.index[s:e+1], name] = np.arange(e-s+1, dtype=np.float32)\n",
        "\n",
        "    def _feat_roc(self, window: int = 5):\n",
        "        name = \"ROC\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = self.df[\"close\"].pct_change(window)\n",
        "\n",
        "    def _feat_atr(self, atr_window: int = 14):\n",
        "        name = \"ATR_norm\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        h,l,c = self.df[\"high\"], self.df[\"low\"], self.df[\"close\"]\n",
        "        tr1 = h-l\n",
        "        tr2 = (h-c.shift()).abs()\n",
        "        tr3 = (l-c.shift()).abs()\n",
        "        tr  = pd.concat([tr1,tr2,tr3], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_window).mean()\n",
        "        self.df[name] = atr/c\n",
        "\n",
        "    def _feat_bb_width(self, bb_window: int = 20):\n",
        "        name = \"BB_Width\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        c   = self.df[\"close\"]\n",
        "        ma  = c.rolling(bb_window).mean()\n",
        "        std = c.rolling(bb_window).std()\n",
        "        self.df[name] = 2*std/ma\n",
        "\n",
        "    def _feat_asset_growth(self, window: int = 3):\n",
        "        name = \"Asset_Growth\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = self.df[\"close\"].pct_change(window).fillna(0)*100\n",
        "\n",
        "    def _feat_ema_acceleration(self, pct_window: int = 3, ema_window: int = 300):\n",
        "        name = \"ema_acceleration\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        r = self.df[\"close\"].pct_change(pct_window).fillna(0)\n",
        "        e = r.ewm(span=ema_window).mean()\n",
        "        self.df[name] = e.diff(4)\n",
        "\n",
        "    def _feat_price_change(self, window: int = 1):\n",
        "        name = \"price_change\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        self.df[name] = self.df[\"close\"].pct_change(window).fillna(0)\n",
        "\n",
        "    def _feat_peak_exhaustion(\n",
        "        self,\n",
        "        price_win: int = 60,    # окно \"локального максимума\"\n",
        "        mom_win:   int = 10,    # окно для momentum\n",
        "        vol_win:   int = 20,\n",
        "        atr_win:   int = 14,\n",
        "        z_win:     int = 100    # z-score нормализация\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Peak-Exhaustion Score  ~ 0…1\n",
        "        1 → почти наверху, импульс затух, объём падает, ATR высок.\n",
        "        \"\"\"\n",
        "        name = \"Peak_Exhaustion_Score\"\n",
        "        c = self.df[\"close\"]\n",
        "\n",
        "        # 1) расстояние до локального max\n",
        "        roll_max = c.rolling(price_win).max()\n",
        "        dist_max = (roll_max - c) / roll_max          # 0 — на max, >0 — ниже\n",
        "\n",
        "        # 2) ослабевающий импульс\n",
        "        roc_now  = c.pct_change(mom_win)\n",
        "        roc_hist = roc_now.rolling(price_win).max()   # max импульса в окне\n",
        "        momentum_div = 1 - (roc_now / (roc_hist + 1e-12))   # 0 → свежий high\n",
        "\n",
        "        # 3) сушащийся объём\n",
        "        vol_ratio = self.df[\"volume\"] / \\\n",
        "            self.df[\"volume\"].rolling(vol_win).mean()\n",
        "\n",
        "        # 4) расширенный спред (ATR/price)\n",
        "        tr  = pd.concat([\n",
        "                self.df[\"high\"]  - self.df[\"low\"],\n",
        "                (self.df[\"high\"] - c.shift()).abs(),\n",
        "                (self.df[\"low\"]  - c.shift()).abs()\n",
        "            ], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_win).mean()\n",
        "        atr_norm = atr / c\n",
        "\n",
        "        # 5) агрегируем, переводим в z-score, squash σ → 0…1\n",
        "        raw = (dist_max + momentum_div + (1/vol_ratio) + atr_norm) / 4\n",
        "        z   = (raw - raw.rolling(z_win).mean()) / (raw.rolling(z_win).std() + 1e-9)\n",
        "        self.df[name] = 1 / (1 + np.exp(-z))   # σ(z)\n",
        "\n",
        "    def _feat_fractal_dim(self, short_win=20, long_win=40):\n",
        "        \"\"\"Вычисляет фрактальную размерность на основе отношения ATR разных периодов\"\"\"\n",
        "        name = \"Fractal_Dim\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "\n",
        "        # Вычисляем ATR для короткого периода\n",
        "        h, l, c = self.df['high'], self.df['low'], self.df['close']\n",
        "        tr1 = h - l\n",
        "        tr2 = (h - c.shift()).abs()\n",
        "        tr3 = (l - c.shift()).abs()\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        atr_short = tr.rolling(short_win).mean()\n",
        "\n",
        "        # Вычисляем ATR для длинного периода\n",
        "        atr_long = tr.rolling(long_win).mean()\n",
        "\n",
        "        # Вычисляем фрактальную размерность\n",
        "        ratio = atr_long / (atr_short + 1e-10)  # Добавляем небольшое значение для избежания деления на 0\n",
        "        self.df[name] = np.log(ratio) / np.log(2)\n",
        "\n",
        "    def _feat_bb_percent(self, window=20, std_mult=2):\n",
        "        name = \"%B_BB\"\n",
        "        if name in self.df: return\n",
        "        ma = self.df[\"close\"].rolling(window).mean()\n",
        "        std = self.df[\"close\"].rolling(window).std()\n",
        "        self.df[name] = (self.df[\"close\"] - (ma - std_mult * std)) / (4 * std)\n",
        "\n",
        "    def _feat_kurtosis_roll(self, window=50):\n",
        "        name = \"Kurtosis_roll\"\n",
        "        if name in self.df: return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0)\n",
        "        self.df[name] = ret.rolling(window).kurt()\n",
        "\n",
        "    def _feat_obv_div(self, window=10):\n",
        "        name = \"OBV_div\"\n",
        "        if name in self.df: return\n",
        "        sign = np.sign(self.df[\"close\"].diff())\n",
        "        obv = (sign * self.df[\"volume\"]).cumsum()\n",
        "        price_chg = self.df[\"close\"].pct_change(window)\n",
        "        obv_chg = obv.pct_change(window)\n",
        "        self.df[name] = price_chg - obv_chg\n",
        "\n",
        "    def _feat_rsi_slope(self, rsi_p=14, diff_win=5):\n",
        "        name = \"RSI_slope\"\n",
        "        if name in self.df: return\n",
        "        delta = self.df[\"close\"].diff()\n",
        "        gain = delta.clip(lower=0).rolling(rsi_p).mean()\n",
        "        loss = -delta.clip(lower=0).rolling(rsi_p).mean()\n",
        "        rsi = 100 - 100 / (1 + gain / (loss + 1e-10))\n",
        "        self.df[name] = rsi.diff(diff_win)\n",
        "\n",
        "    def _feat_vol_decay(self, window=20):\n",
        "        name = \"Vol_Decay\"\n",
        "        if name in self.df: return\n",
        "        vol_ema = self.df[\"volume\"].ewm(span=window).mean()\n",
        "        self.df[name] = self.df[\"volume\"] / vol_ema - 1\n",
        "\n",
        "    def _feat_accel_decay(self, window=10):\n",
        "        name = \"Accel_Decay\"\n",
        "        if name in self.df: return\n",
        "        vel = self.df[\"close\"].diff(window)\n",
        "        accel = vel.diff(window)\n",
        "        self.df[name] = accel / (vel.abs() + 1e-10)\n",
        "\n",
        "    def _feat_entropy_roll(self, window: int = 50):\n",
        "        name = \"Entropy_roll\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0.0).to_numpy(dtype=np.float32)\n",
        "        ent = _rolling_entropy_exact_numba(ret, window)\n",
        "        self.df[name] = ent\n",
        "\n",
        "    def _feat_wavelet_var(self, short_win=10, long_win=50):\n",
        "        name = \"Wavelet_Var_Ratio\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0)\n",
        "        var_short = ret.rolling(short_win).var()\n",
        "        var_long = ret.rolling(long_win).var()\n",
        "        self.df[name] = var_short / (var_long + 1e-10)\n",
        "\n",
        "    def _feat_autocorr(self, window=50):\n",
        "        name = \"Autocorr_Lag1\"\n",
        "        if name in self.df:\n",
        "            return\n",
        "        ret = self.df[\"close\"].pct_change().fillna(0)\n",
        "        arr = ret.to_numpy()  # Use to_numpy() for compatibility\n",
        "        autocorrs = rolling_autocorr(arr, window)\n",
        "        self.df[name] = autocorrs\n",
        "\n",
        "    def _feat_beta(self, window=50):\n",
        "        name = \"Beta_Market\"\n",
        "        if name in self.df or \"market_close\" not in self.df:\n",
        "            return\n",
        "        ret_stock = self.df[\"close\"].pct_change().fillna(0)\n",
        "        ret_market = self.df[\"market_close\"].pct_change().fillna(0)\n",
        "        cov = ret_stock.rolling(window).cov(ret_market)\n",
        "        var_market = ret_market.rolling(window).var()\n",
        "        self.df[name] = cov / (var_market + 1e-10)\n",
        "\n",
        "    def _feat_peak_squeeze_curvature(self,\n",
        "                                vel_win: int = 5,\n",
        "                                acc_win: int = 5,\n",
        "                                vol_win: int = 20,\n",
        "                                atr_win: int = 14,\n",
        "                                z_win : int = 60):\n",
        "        \"\"\"\n",
        "        Возвращает 3 колонки:\n",
        "        PSC_raw, PSC_z, PSC_sigmoid ∈ [0,1]\n",
        "        \"\"\"\n",
        "        name = \"PSC\"\n",
        "        cols_need = {\"PSC_raw\",\"PSC_z\",\"PSC_sigmoid\"}\n",
        "        if cols_need.issubset(self.df.columns): return\n",
        "        c = self.df['close']\n",
        "\n",
        "        # 1) speed & accel\n",
        "        speed  = c.pct_change(vel_win).fillna(0)\n",
        "        accel  = speed.diff(acc_win).fillna(0)\n",
        "        curvature = accel / (speed.abs() + 1e-10)\n",
        "\n",
        "        # 2) squeeze = ATR_norm ↘ & HV_norm ↘\n",
        "        h,l = self.df['high'], self.df['low']\n",
        "        tr = pd.concat([h-l, (h-c.shift()).abs(), (l-c.shift()).abs()], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_win).mean()\n",
        "        hv  = c.pct_change().rolling(vol_win).std()\n",
        "        squeeze = - (atr / (c+1e-10)).diff().clip(upper=0)   # падение ATR\n",
        "        squeeze += - hv.diff().clip(upper=0)                 # падение HV\n",
        "        squeeze /= 2\n",
        "\n",
        "        # 3) агрегируем\n",
        "        raw = 0.6*curvature + 0.4*squeeze\n",
        "\n",
        "        # 4) z-score + σ(z)\n",
        "        mu  = raw.rolling(z_win).mean()\n",
        "        std = raw.rolling(z_win).std()\n",
        "        z = (raw - mu)/(std + 1e-9)\n",
        "        sigm = 1/(1+np.exp(-z))\n",
        "\n",
        "        self.df[f'{name}_raw']     = raw\n",
        "        self.df[f'{name}_z']       = z.clip(-5, 5)\n",
        "        self.df[f'{name}_sigmoid'] = sigm\n",
        "\n",
        "\n",
        "def calculate_metrics(test_data, y_test, y_pred, target_column='normalized_target'):\n",
        "    \"\"\"\n",
        "    Функция для расчета метрик по данным теста и предсказаниям модели.\n",
        "\n",
        "    Параметры:\n",
        "    - test_data: pd.DataFrame — тестовые данные с колонками batch, high, close и другими.\n",
        "    - y_test: pd.Series или np.array — фактические значения целевой переменной.\n",
        "    - y_pred: pd.Series или np.array — предсказанные моделью значения.\n",
        "    - target_column: str — название колонки целевой переменной в test_data.\n",
        "\n",
        "    Возвращает:\n",
        "    - avg_mse: float — среднеквадратическая ошибка.\n",
        "    - avg_r2: float — средняя R².\n",
        "    - std_r2: float — стандартное отклонение R².\n",
        "    - corr_mean: float — средняя корреляция.\n",
        "    - corr_std: float — стандартное отклонение корреляции.\n",
        "    - avg_missed: float — средний процент упущенной прибыли.\n",
        "    \"\"\"\n",
        "    # Инициализация метрик\n",
        "    mse_scores, r2_scores, corr_scores, missed_pnl = [], [], [], []\n",
        "\n",
        "    # Расчет корреляции целевой переменной и предсказаний\n",
        "    y_pred_series = pd.Series(y_pred, index=y_test.index)\n",
        "    corr_score = test_data[target_column].corr(y_pred_series)\n",
        "    corr_scores.append(corr_score)\n",
        "\n",
        "    # MSE и R2\n",
        "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
        "    r2_scores.append(r2_score(y_test, y_pred))\n",
        "\n",
        "    # Расчет missed_pnl для каждого batch\n",
        "    \"\"\"for batch in test_data['batch'].unique():\n",
        "        mask = test_data['batch'] == batch\n",
        "        max_high = test_data.loc[mask, 'high'].max()\n",
        "        pred = y_pred[mask]  # предполагается, что y_pred соответствует normalized_target\n",
        "        sell_idx = np.argmin(pred)  # продажа на минимальном предсказанном значении\n",
        "        sell_price = test_data.loc[mask].iloc[sell_idx]['close']\n",
        "        missed = (max_high - sell_price) / (max_high - test_data.loc[mask].iloc[0]['close'])  # % упущенной прибыли\n",
        "        missed_pnl.append(missed)\"\"\"\n",
        "\n",
        "    # Усреднение метрик\n",
        "    avg_mse = float(np.mean(mse_scores))\n",
        "    avg_r2 = float(np.mean(r2_scores))\n",
        "    std_r2 = float(np.std(r2_scores))\n",
        "    corr_mean = float(np.mean(corr_scores))\n",
        "    corr_std = float(np.std(corr_scores))\n",
        "    #avg_missed = float(np.mean(missed_pnl))\n",
        "\n",
        "    # Проверка на корректность результатов\n",
        "    if np.isfinite([avg_mse, avg_r2, std_r2, corr_mean, corr_std]).all(): #avg_missed\n",
        "        return avg_mse, avg_r2, std_r2, corr_mean, corr_std, #avg_missed\n",
        "    else:\n",
        "        return float('inf'), float('inf'), float('inf'), float('inf'), float('inf'), float('inf')\n",
        "\n",
        "def prepare_data(df, target_col):\n",
        "    \"\"\"\n",
        "    Подготавливает данные: разделяет на числовые и категориальные признаки, создает конвейер преобразования.\n",
        "    \"\"\"\n",
        "    if type(target_col) == str:\n",
        "        df.dropna(inplace=True)\n",
        "        X = df.drop([target_col, 'batch'], axis=1)\n",
        "        y = df[target_col]\n",
        "    elif type(target_col) == list:\n",
        "        df.dropna(inplace=True)\n",
        "        X = df.drop(target_col+['batch'], axis=1)\n",
        "        y = df[target_col]\n",
        "\n",
        "    # Разделение на числовые и категориальные признаки\n",
        "    numeric_features = X.select_dtypes(include=['int64', 'float64', 'float32', 'int32']).columns\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Создание конвейера преобразования\n",
        "    preprocessing = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', Pipeline([\n",
        "                ('scaler', RobustScaler()),\n",
        "                ('normalize', PowerTransformer(method='yeo-johnson')),\n",
        "            ]), numeric_features),\n",
        "            ('cat', Pipeline([\n",
        "                ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "            ]), categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return X, y, preprocessing\n",
        "\n",
        "\n",
        "def calculate_indicators_pred(df, features, params=None, ticker=None, mode=None, multy=False):\n",
        "\n",
        "    fc = FeatureCalculatorForRegression(df, ticker)\n",
        "    if mode==None:\n",
        "        df1 = fc.calculate_features(params=params, required_features=features)\n",
        "    else:\n",
        "        df1 = fc.calculate_all_possible_features()\n",
        "    features = ['open', 'close', 'high', 'low', 'volume', 'ma', 'pmax'] #time\n",
        "    df1['regime'] = df1['regime'].astype('object')\n",
        "    df1 = df1[df1['trade_bars_counter']>=0]\n",
        "    df1['trade_bars_counter'] = df1['trade_bars_counter'].astype('int')\n",
        "    df1 = df1.drop(features, axis=1)\n",
        "    #df1 = df1.dropna()\n",
        "    return df1, fc._timings\n",
        "\n",
        "def sample_feature_params(params) -> dict:\n",
        "        \"\"\"\n",
        "        Draws *one* sample of the whole feature-engineering hyper-parameter set.\n",
        "        Rule of thumb for ranges:\n",
        "          • lower bound = ‘sane minimum‘ from domain knowledge\n",
        "          • upper bound = ‘sane maximum’\n",
        "        Adjust them if you feel the search space is too wide or too narrow.\n",
        "        \"\"\"\n",
        "        # ---- helpers for monotone constraints ----------------------------------\n",
        "        fast  = params['macd_fast']\n",
        "        slow  = params['macd_slow']\n",
        "\n",
        "        slope_lag_min = params['slope_lag_min']\n",
        "        slope_lag     = params['slope_lag']\n",
        "\n",
        "        # ---- finally compose the nested dict -----------------------------------\n",
        "        return {\n",
        "            'base': {\n",
        "                'medprice': params['medprice']\n",
        "            },\n",
        "            'macd': {\n",
        "                'fast'      : fast,\n",
        "                'slow'      : slow,\n",
        "                'signal'    : params['macd_signal'],\n",
        "                'macd_roll' : params['macd_roll']\n",
        "            },\n",
        "            'overbought': {\n",
        "                'rsi_p'         : params['rsi_p'],\n",
        "                'stoch_p'       : params['stoch_p'],\n",
        "                'oversold_roll' : params['oversold_roll']\n",
        "            },\n",
        "            'madist': {\n",
        "                'span_lenght'   : params['madist_span'],\n",
        "                'madist_lenght' : params['madist_len']\n",
        "            },\n",
        "            'mean_reversion': {\n",
        "                'window' : params['mr_window']\n",
        "            },\n",
        "            'fear_greed': {\n",
        "                'greed_pct'    : params['fg_greed_pct'],\n",
        "                'volume_ratio_scr' : params['fg_vol_ratio'],\n",
        "                'window'       : params['fg_window'],\n",
        "                'greed_roll'   : params['fg_roll']\n",
        "            },\n",
        "            'price_variation': {\n",
        "                'variation_lenght': params['pv_len']\n",
        "            },\n",
        "            'pmax_ma': {\n",
        "                'pmax_ma_lenght'      : params['pmax_len'],\n",
        "                'pmax_ma_lenght_roll' : params['pmax_roll']\n",
        "            },\n",
        "            'slope': {\n",
        "                'slope_lag'     : slope_lag,\n",
        "                'slope_lag_min' : slope_lag_min,\n",
        "                'sloap_pct'     : params['slope_pct'],\n",
        "                'sloap_roll'    : params['slope_roll']\n",
        "            },\n",
        "            # _trade_duration_features – no params\n",
        "        }\n",
        "\n",
        "def build_feature_params(\n",
        "    flat_params: Dict[str, Any],\n",
        "    extra_alias: Optional[Dict[str, Tuple[str, str | None]]] = None\n",
        ") -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Преобразует «плоский» словарь от Optuna в структуру,\n",
        "    которую понимает FeatureCalculatorForRegression.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Базовая явная таблица соответствий\n",
        "    alias: Dict[str, Tuple[str, str | None]] = {\n",
        "        'hp_lamb'          : ('hp_trend'           , 'lamb'),\n",
        "        'ea_pct'           : ('ema_acceleration'   , 'pct_window'),\n",
        "        'ea_ema'           : ('ema_acceleration'   , 'ema_window'),\n",
        "        'mr_window'        : ('Mean_Reversion'     , 'window'),\n",
        "        'ag_window'        : ('Asset_Growth'       , 'window'),\n",
        "        'medprice'         : ('MEDPRICE'           , 'medprice'),\n",
        "        'bb_window'        : ('BB_Width'           , 'bb_window'),\n",
        "        'macd_fast'        : ('MACD'               , 'fast'),\n",
        "        'macd_slow'        : ('MACD'               , 'slow'),\n",
        "        'macd_signal'      : ('MACD'               , 'signal'),\n",
        "        'fg_window'        : ('Fear_Greed'         , 'window'),\n",
        "        'atr_window'       : ('ATR_norm'           , 'atr_window'),\n",
        "        'vr_window'        : ('volume_ratio'       , 'window'),\n",
        "        'madist_span'      : ('Price_MADist%'      , 'span_lenght'),\n",
        "        'slope_lag'        : ('slope_trend'        , 'slope_lag'),\n",
        "        'slope_lag_min'    : ('slope_trend'        , 'slope_lag'),\n",
        "        'rsi_p'            : ('Overbought_Oversold', 'rsi_p'),\n",
        "        'stoch_p'          : ('Overbought_Oversold', 'stoch_p'),\n",
        "        'pmax_len'         : ('pmax_norm'          , 'pmax_ma_length'),\n",
        "        'pmax_roll'        : ('pmax_norm'          , 'pmax_ma_length_roll'),\n",
        "        'pc_window'        : ('pmax_norm'          , 'pct_window'),\n",
        "        'ema_trend_span'   : ('ema_trend'          , 'span'),\n",
        "        'ema_trend_pct'    : ('ema_trend'          , 'pct_window'),\n",
        "        'stat_window'      : ('stat_window', None),\n",
        "        # --- новые алиасы ---\n",
        "        'roc_window'        : ('ROC'          , 'window'),\n",
        "        'willr_window'      : ('WILLR'          , 'window'),\n",
        "        'fractal_short_win' : ('Fractal_Dim', 'short_win'),\n",
        "        'fractal_long_win'  : ('Fractal_Dim', 'long_win'),\n",
        "        'peak_price_win'    : ('Peak_Exhaustion_Score', 'price_win'),\n",
        "        'peak_mom_win'      : ('Peak_Exhaustion_Score', 'mom_win'),\n",
        "        'peak_vol_win'      : ('Peak_Exhaustion_Score', 'vol_win'),\n",
        "        'peak_atr_win'      : ('Peak_Exhaustion_Score', 'atr_win'),\n",
        "        'peak_z_win'        : ('Peak_Exhaustion_Score', 'z_win'),\n",
        "        'bb_window'         : ('%B_BB', 'window'),\n",
        "        'bb_std_mult'       : ('%B_BB', 'std_mult'),\n",
        "        'kurt_window'       : ('Kurtosis_roll', 'window'),\n",
        "        'obv_window'        : ('OBV_div', 'window'),\n",
        "        'rsi_slope_rsi_p'   : ('RSI_slope', 'rsi_p'),\n",
        "        'rsi_diff_win'      : ('RSI_slope', 'diff_win'),\n",
        "        'voldec_window'     : ('Vol_Decay', 'window'),\n",
        "        'acceldec_window'   : ('Accel_Decay', 'window'),\n",
        "        'ent_window'        : ('Entropy_roll', 'window'),\n",
        "        'wlt_short_win'     : ('Wavelet_Var_Ratio', 'short_win'),\n",
        "        'wlt_long_win'      : ('Wavelet_Var_Ratio', 'long_win'),\n",
        "        'acorr_window'      : ('Autocorr_Lag1', 'window'),\n",
        "        'beta_window'       : ('Beta_Market', 'window'),\n",
        "        'psc_vel_win'       : ('PSC', 'vel_win'),\n",
        "        'psc_acc_win'       : ('PSC', 'acc_win'),\n",
        "        'psc_vol_win'       : ('PSC', 'vol_win'),\n",
        "        'psc_atr_win'       : ('PSC', 'atr_win'),\n",
        "        'psc_z_win'         : ('PSC', 'z_win'),\n",
        "    }\n",
        "\n",
        "    # 2. Пользовательские переопределения\n",
        "    if extra_alias:\n",
        "        alias.update(extra_alias)\n",
        "\n",
        "    # 3. Автоматический разбор префиксов (fallback)\n",
        "    prefix_map: Dict[str, str] = {\n",
        "        'macd'        : 'MACD',\n",
        "        'hp'          : 'hp_trend',\n",
        "        'ea'          : 'ema_acceleration',\n",
        "        'mr'          : 'Mean_Reversion',\n",
        "        'ag'          : 'Asset_Growth',\n",
        "        'bb'          : 'BB_Width',\n",
        "        'fg'          : 'Fear_Greed',\n",
        "        'atr'         : 'ATR_norm',\n",
        "        'vr'          : 'volume_ratio',\n",
        "        'madist'      : 'Price_MADist%',\n",
        "        'slope'       : 'slope_trend',\n",
        "        'pmax'        : 'pmax_norm',\n",
        "        'ema_trend'   : 'ema_trend',\n",
        "        'rsi'         : 'Overbought_Oversold',\n",
        "        'stoch'       : 'Overbought_Oversold',\n",
        "        'fractal'     : 'Fractal_Dim',\n",
        "        'peak'        : 'Peak_Exhaustion_Score',\n",
        "        'bb'          : '%B_BB',\n",
        "        'kurt'        : 'Kurtosis_roll',\n",
        "        'obv'         : 'OBV_div',\n",
        "        'rsi_slope'   : 'RSI_slope',\n",
        "        'voldec'      : 'Vol_Decay',\n",
        "        'acceldec'    : 'Accel_Decay',\n",
        "        'entropy'     : 'Entropy_roll',\n",
        "        'wavelet'     : 'Wavelet_Var_Ratio',\n",
        "        'acorr'       : 'Autocorr_Lag1',\n",
        "        'beta'        : 'Beta_Market',\n",
        "        'psc'         : 'PSC',\n",
        "    }\n",
        "\n",
        "    nested: Dict[str, Dict[str, Any]] = defaultdict(dict)\n",
        "\n",
        "    for key, val in flat_params.items():\n",
        "\n",
        "        # 3.1 Явное соответствие\n",
        "        if key in alias:\n",
        "            prim, arg = alias[key]\n",
        "            if prim == 'stat_window' or arg is None:\n",
        "                nested['stat_window'] = val\n",
        "            else:\n",
        "                nested[prim][arg] = val\n",
        "            continue\n",
        "\n",
        "        # 3.2 Игнорируем вспомогательные ключи вида *_min, *_max, если\n",
        "        #     они не нужны никакому примитиву.\n",
        "        if key.endswith('_min') or key.endswith('_max'):\n",
        "            continue\n",
        "\n",
        "        # 3.3 Fallback-разбор _\n",
        "        if '_' in key:\n",
        "            prefix, arg = key.split('_', 1)\n",
        "            if prefix in prefix_map:\n",
        "                nested[prefix_map[prefix]][arg] = val\n",
        "                continue\n",
        "\n",
        "        # 3.4 Неизвестный ключ — игнорируем или логируем\n",
        "        # print(f'Warning: parameter \"{key}\" was not mapped')\n",
        "\n",
        "    return {p: d for p, d in nested.items()}\n",
        "\n",
        "_ORIG_INTERP = F.interpolate\n",
        "\n",
        "\n",
        "def _collapse_pred_to_bt(y_pred: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Приводим предсказание к виду (B, T), считая последнюю ось временем (горизонтом).\n",
        "    Все промежуточные оси (кроме batch=ось 0 и time=последняя ось) усредняем.\n",
        "    Пример: (B, 1, 4, 10) -> mean по осям (1,2) -> (B,10)\n",
        "    (B, 10) -> ок\n",
        "    (B, 1, 10) -> squeeze -> (B,10)\n",
        "    \"\"\"\n",
        "    if not isinstance(y_pred, torch.Tensor):\n",
        "        raise TypeError(f\"y_pred must be a tensor, got {type(y_pred)}\")\n",
        "\n",
        "    # Сначала уберём все единичные оси\n",
        "    if any(s == 1 for s in y_pred.shape[1:-1]):\n",
        "        # squeeze не трогает последнюю ось, если она не равна 1\n",
        "        y_pred = y_pred.squeeze()\n",
        "        # Если squeeze убрал не только единичные, но и привёл к (B, T) — хорошо.\n",
        "\n",
        "    if y_pred.dim() == 1:\n",
        "        # (B,) — интерпретируем как T=1, сделаем (B,1)\n",
        "        y_pred = y_pred.unsqueeze(-1)\n",
        "        return y_pred\n",
        "\n",
        "    if y_pred.dim() == 2:\n",
        "        # (B, T) — уже как надо\n",
        "        return y_pred\n",
        "\n",
        "    # Если размерностей больше 2: считаем last dim = time, batch = 0\n",
        "    # Все промежуточные оси схлопываем усреднением\n",
        "    reduce_dims = tuple(range(1, y_pred.dim() - 1))\n",
        "    if len(reduce_dims) > 0:\n",
        "        y_pred = y_pred.mean(dim=reduce_dims)\n",
        "    # На выходе (B, T)\n",
        "    if y_pred.dim() != 2:\n",
        "        # На всякий случай добьёмся (B, T)\n",
        "        y_pred = y_pred.view(y_pred.size(0), -1)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def _install_safe_interpolate_patch():\n",
        "    \"\"\"\n",
        "    Патч делает F.interpolate детерминированным при включённом torch.use_deterministic_algorithms(True)\n",
        "    для CUDA и режимов linear/bilinear/bicubic, прогоняя вычисление на CPU.\n",
        "    Идемпотентен и не меняет сигнатуру.\n",
        "    \"\"\"\n",
        "    if getattr(F.interpolate, \"_is_deterministic_wrapper\", False):\n",
        "        return\n",
        "\n",
        "    _orig_interpolate = F.interpolate\n",
        "\n",
        "    # Какие режимы считаем потенциально недетерминируемыми на CUDA\n",
        "    _CUDA_UNSAFE_MODES = {\"linear\", \"bilinear\", \"bicubic\"}  # 1d/2d/2d\n",
        "\n",
        "    def _needs_cpu_fallback(input, mode):\n",
        "        if not torch.is_tensor(input):\n",
        "            return False\n",
        "        if input.is_cuda and mode in _CUDA_UNSAFE_MODES:\n",
        "            # upsample_linear1d_backward_out_cuda и др. — недетерминируемы\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    @functools.wraps(_orig_interpolate)\n",
        "    def _deterministic_interpolate(\n",
        "        input: torch.Tensor,\n",
        "        size=None,\n",
        "        scale_factor=None,\n",
        "        mode=\"nearest\",\n",
        "        align_corners=None,\n",
        "        recompute_scale_factor=None,\n",
        "        antialias=False,\n",
        "    ):\n",
        "        # Если не нужно, просто вызовем оригинал\n",
        "        if not _needs_cpu_fallback(input, mode):\n",
        "            return _orig_interpolate(\n",
        "                input,\n",
        "                size=size,\n",
        "                scale_factor=scale_factor,\n",
        "                mode=mode,\n",
        "                align_corners=align_corners,\n",
        "                recompute_scale_factor=recompute_scale_factor,\n",
        "                antialias=antialias,\n",
        "            )\n",
        "\n",
        "        # CUDA + linear/bilinear/bicubic → CPU fallback\n",
        "        x = input\n",
        "        dev = x.device\n",
        "        orig_dtype = x.dtype\n",
        "\n",
        "        # Для стабильности переводим в float32 на CPU\n",
        "        x_cpu = x.detach().to(\"cpu\", dtype=torch.float32).requires_grad_(x.requires_grad)\n",
        "\n",
        "        y_cpu = _orig_interpolate(\n",
        "            x_cpu,\n",
        "            size=size,\n",
        "            scale_factor=scale_factor,\n",
        "            mode=mode,\n",
        "            align_corners=align_corners,\n",
        "            recompute_scale_factor=recompute_scale_factor,\n",
        "            antialias=antialias,\n",
        "        )\n",
        "\n",
        "        # Возвращаем на исходное устройство и тип\n",
        "        y = y_cpu.to(dev, dtype=orig_dtype)\n",
        "\n",
        "        return y\n",
        "\n",
        "    _deterministic_interpolate._is_deterministic_wrapper = True  # type: ignore[attr-defined]\n",
        "    F.interpolate = _deterministic_interpolate\n",
        "\n",
        "\n",
        "_install_safe_interpolate_patch()\n",
        "\n",
        "\n",
        "def _unpack_pf_batch(batch):\n",
        "    \"\"\"\n",
        "    Унифицированная распаковка батча из TimeSeriesDataSet.to_dataloader(...)\n",
        "    Возвращает: x (dict), y (Tensor|None), weight (Tensor|None)\n",
        "    \"\"\"\n",
        "    if isinstance(batch, (list, tuple)):\n",
        "        if len(batch) == 3:\n",
        "            x, y, weight = batch\n",
        "        elif len(batch) == 2:\n",
        "            x, y = batch\n",
        "            weight = None\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected batch tuple length: {len(batch)}\")\n",
        "    elif isinstance(batch, dict):\n",
        "        # На всякий случай поддержим dict → возьмём таргет из decoder_target, если есть\n",
        "        x = batch\n",
        "        y = batch.get(\"decoder_target\", None)\n",
        "        weight = None\n",
        "    else:\n",
        "        raise TypeError(f\"Unexpected batch type: {type(batch)}\")\n",
        "    return x, y, weight\n",
        "\n",
        "\n",
        "# F.interpolate = _deterministic_interpolate\n",
        "\n",
        "\n",
        "def _extract_pred_tensor(y_pred):\n",
        "    # извлекаем тензор предикта из любых обёрток\n",
        "    if isinstance(y_pred, dict):\n",
        "        for key in (\"prediction\", \"output\", \"decoder_output\"):\n",
        "            if key in y_pred and torch.is_tensor(y_pred[key]):\n",
        "                return y_pred[key]\n",
        "        # если не нашли — попробуем fallback: первый тензор в dict\n",
        "        for v in y_pred.values():\n",
        "            if torch.is_tensor(v):\n",
        "                return v\n",
        "        raise ValueError(\"Could not extract prediction tensor from dict y_pred.\")\n",
        "\n",
        "    if isinstance(y_pred, (list, tuple)):\n",
        "        # обычно y_pred[0] — предсказание\n",
        "        return y_pred[0]\n",
        "\n",
        "    if torch.is_tensor(y_pred):\n",
        "        return y_pred\n",
        "\n",
        "    raise TypeError(f\"Unsupported y_pred type: {type(y_pred)}\")\n",
        "\n",
        "\n",
        "class EventTimeSeriesSplit(BaseCrossValidator):\n",
        "    \"\"\"\n",
        "    Кросс-валидация по событиям (batch), хронологическая, с эмбарго.\n",
        "    groups: массив той же длины, что и df, со значениями batch\n",
        "    times:  массив pd.Timestamp (или sortable), та же длина, что и df\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_splits: int = 5, embargo_events: int = 1, min_train_events: int = 5):\n",
        "        self.n_splits = n_splits\n",
        "        self.embargo_events = embargo_events\n",
        "        self.min_train_events = min_train_events\n",
        "\n",
        "    def get_n_splits(self, X=None, y=None, groups=None):\n",
        "        return self.n_splits\n",
        "\n",
        "    def split(self, X, y=None, groups=None, times: Optional[pd.Series] = None) -> Iterator[\n",
        "        Tuple[np.ndarray, np.ndarray]]:\n",
        "        if groups is None or times is None:\n",
        "            raise ValueError(\"Pass groups=batch and times=time columns\")\n",
        "\n",
        "        groups = np.asarray(groups)\n",
        "        times = pd.to_datetime(times)\n",
        "\n",
        "        # порядок событий по старт-времени\n",
        "        df_tmp = pd.DataFrame({\"group\": groups, \"time\": times}).reset_index(names=\"row_idx\")\n",
        "        first_time = df_tmp.groupby(\"group\")[\"time\"].min().sort_values()\n",
        "        uniq_groups = first_time.index.to_numpy()\n",
        "\n",
        "        n_events = len(uniq_groups)\n",
        "        if n_events < (self.n_splits + self.min_train_events):\n",
        "            # уменьшаем число сплитов, если событий мало\n",
        "            eff_splits = max(1, n_events - self.min_train_events)\n",
        "        else:\n",
        "            eff_splits = self.n_splits\n",
        "\n",
        "        # на каждой итерации расширяем train вправо\n",
        "        for split_idx in range(1, eff_splits + 1):\n",
        "            # доля событий для валидации\n",
        "            val_events = max(1, n_events // (eff_splits + 1))\n",
        "            train_end = n_events - (eff_splits - split_idx + 1) * val_events\n",
        "\n",
        "            if train_end < self.min_train_events:\n",
        "                continue\n",
        "\n",
        "            # эмбарго\n",
        "            embargoed_end = max(0, train_end - self.embargo_events)\n",
        "\n",
        "            train_groups = uniq_groups[:embargoed_end]\n",
        "            val_groups = uniq_groups[train_end: train_end + val_events]\n",
        "\n",
        "            train_idx = df_tmp.index[df_tmp[\"group\"].isin(train_groups)].to_numpy()\n",
        "            val_idx = df_tmp.index[df_tmp[\"group\"].isin(val_groups)].to_numpy()\n",
        "\n",
        "            # индексы исходной X (если это DataFrame — у вас совпадают позиции с row_idx)\n",
        "            yield (train_idx, val_idx)\n",
        "\n",
        "\n",
        "class MinimalRichProgressBar(RichProgressBar):\n",
        "    def on_validation_start(self, trainer, pl_module):\n",
        "        pass\n",
        "\n",
        "    def on_validation_batch_start(self, trainer, pl_module, batch, batch_idx):\n",
        "        pass\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        pass\n",
        "\n",
        "\n",
        "class NoValidationBar(TQDMProgressBar):\n",
        "    def init_validation_tqdm(self):\n",
        "        # возвращаем полностью отключённый tqdm для валидации\n",
        "        return tqdm_class(disable=True)\n",
        "\n",
        "class CustomTFT(TemporalFusionTransformer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.mask_prob = kwargs.pop(\"mask_prob\", 0.05)\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self._val_preds = []\n",
        "        self._val_trues = []\n",
        "        self._val_gids = []\n",
        "        self.scheduled_prob = 0.0\n",
        "\n",
        "        safe_val = torch.tensor(\n",
        "            torch.finfo(torch.float16).min,\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        m = self.multihead_attn.attention\n",
        "        if hasattr(m, \"mask_bias\") and not isinstance(m.mask_bias, torch.Tensor):\n",
        "            delattr(m, \"mask_bias\")\n",
        "        m.register_buffer(\"mask_bias\", safe_val)\n",
        "\n",
        "    def on_epoch_start(self, trainer, pl_module):\n",
        "        if trainer.max_epochs > 0:\n",
        "            self.scheduled_prob = min(1.0, trainer.current_epoch / (trainer.max_epochs * 0.8))\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, weight = _unpack_pf_batch(batch)\n",
        "\n",
        "        if torch.rand(1).item() < self.mask_prob and \"encoder_target\" in x:\n",
        "            enc = x[\"encoder_target\"]\n",
        "            noise = torch.normal(0, 0.15, size=enc.shape, device=enc.device)\n",
        "            x = {**x, \"encoder_target\": noise}\n",
        "            del enc, noise\n",
        "\n",
        "        if torch.rand(1).item() < self.scheduled_prob and y is not None:\n",
        "            with torch.no_grad():\n",
        "                out = self(x)\n",
        "                y_pred = self.loss.to_prediction(out)\n",
        "                y_bt = _collapse_pred_to_bt(y_pred)\n",
        "                dec_tgt = y_bt if y_bt.dim() == 2 else y_bt.unsqueeze(-1)\n",
        "                x['decoder_target'] = dec_tgt.detach()\n",
        "                del out, y_pred, y_bt, dec_tgt\n",
        "\n",
        "        batch = (x, y, weight) if weight is not None else (x, y)\n",
        "        result = super().training_step(batch, batch_idx)\n",
        "\n",
        "        if batch_idx % 50 == 0:  # Rare for speed\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, weight = _unpack_pf_batch(batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out_temp = self(x)\n",
        "            y_pred_temp = self.loss.to_prediction(out_temp)\n",
        "            y_bt_temp = _collapse_pred_to_bt(y_pred_temp)\n",
        "            del out_temp, y_pred_temp\n",
        "\n",
        "        if \"decoder_target\" in x:\n",
        "            enc_tgt = x.get(\"encoder_target\")\n",
        "            if enc_tgt is not None:\n",
        "                batch_mean = enc_tgt.mean(dim=-1, keepdim=True)\n",
        "                batch_std = enc_tgt.std(dim=-1, keepdim=True) + 1e-8\n",
        "                mean_tensor = batch_mean.expand_as(x[\"decoder_target\"])\n",
        "                std_tensor = (0.1 * batch_std).expand_as(x[\"decoder_target\"])\n",
        "                noise_fill = torch.normal(mean_tensor, std_tensor)\n",
        "                del batch_mean, std_tensor, mean_tensor\n",
        "            else:\n",
        "                dec_tgt = x[\"decoder_target\"]\n",
        "                device = dec_tgt.device\n",
        "                noise_fill = torch.full_like(dec_tgt, self.global_target_mean)\n",
        "                batch_size = dec_tgt.size(0)\n",
        "                batch_std = torch.full((batch_size,), self.global_target_std, device=device).unsqueeze(-1)\n",
        "\n",
        "            if torch.rand(1).item() < self.scheduled_prob:\n",
        "                decoder_fill = y_bt_temp\n",
        "            else:\n",
        "                jitter_size = noise_fill.shape\n",
        "                additional_jitter = torch.randn(jitter_size, device=noise_fill.device) * (0.05 * batch_std.expand_as(noise_fill))\n",
        "                decoder_fill = noise_fill + additional_jitter\n",
        "                del additional_jitter, noise_fill\n",
        "\n",
        "            decoder_fill = torch.clamp(decoder_fill, -1.0, 1.0)\n",
        "            x[\"decoder_target\"] = decoder_fill\n",
        "            del y_bt_temp, batch_std\n",
        "\n",
        "        out = self(x)\n",
        "        y_pred_raw = self.loss.to_prediction(out)\n",
        "        del out\n",
        "\n",
        "        y_pred_metrics = torch.clamp(y_pred_raw, -1.0, 1.0)\n",
        "        del y_pred_raw\n",
        "\n",
        "        y_actual = y if y is not None else x.get(\"decoder_target\")\n",
        "        if y_actual is None:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            y_pred_aligned, y_actual_aligned = _align_pred_target(y_pred_metrics, y_actual)\n",
        "            del y_pred_metrics, y_actual\n",
        "        except Exception:\n",
        "            return\n",
        "\n",
        "        self._val_preds.append(y_pred_aligned.detach())\n",
        "        self._val_trues.append(y_actual_aligned.detach())\n",
        "        del y_pred_aligned, y_actual_aligned\n",
        "\n",
        "        gid = x.get(\"group_ids\")\n",
        "        if gid is not None and isinstance(gid, torch.Tensor):\n",
        "            self._val_gids.append(gid.detach())\n",
        "        else:\n",
        "            self._val_gids.append(None)\n",
        "\n",
        "        if batch_idx % 50 == 0:  # Rare for speed\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if len(self._val_preds) == 0:\n",
        "            return\n",
        "\n",
        "        yp = torch.cat(self._val_preds, dim=0)\n",
        "        yt = torch.cat(self._val_trues, dim=0)\n",
        "\n",
        "        self._val_preds.clear()\n",
        "        self._val_trues.clear()\n",
        "\n",
        "        se = (yp - yt) ** 2\n",
        "        val_mse = float(se.mean().item())\n",
        "        val_mse_std = float(se.std(unbiased=False).item())\n",
        "        del yp, yt\n",
        "\n",
        "        self.log(\"val_mse\", val_mse, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_mse_std\", val_mse_std, prog_bar=False, on_step=False, on_epoch=True)\n",
        "\n",
        "        has_any_gid = any(g is not None for g in self._val_gids)\n",
        "        if has_any_gid:\n",
        "            gid_list = []\n",
        "            valid = True\n",
        "            for g in self._val_gids:\n",
        "                if g is None:\n",
        "                    valid = False\n",
        "                    break\n",
        "                gid_list.append(g)\n",
        "\n",
        "            if valid and len(gid_list) > 0:\n",
        "                gid_all = torch.cat(gid_list, dim=0).numpy().ravel()\n",
        "                se_np = se.numpy().ravel()\n",
        "                del se\n",
        "\n",
        "                if gid_all.shape[0] == se_np.shape[0]:\n",
        "                    uniq = np.unique(gid_all)\n",
        "                    g_mse = [se_np[gid_all == u].mean() for u in uniq if (gid_all == u).any()]\n",
        "                    if len(g_mse) > 0:\n",
        "                        g_mse = np.asarray(g_mse, dtype=float)\n",
        "                        val_mse_group_mean = float(g_mse.mean())\n",
        "                        val_mse_group_std = float(g_mse.std(ddof=0))\n",
        "                        self.log(\"val_mse_group_mean\", val_mse_group_mean, prog_bar=False, on_step=False, on_epoch=True)\n",
        "                        self.log(\"val_mse_group_std\", val_mse_group_std, prog_bar=True, on_step=False, on_epoch=True)\n",
        "                    del g_mse, uniq\n",
        "\n",
        "                del gid_all, se_np\n",
        "\n",
        "        self._val_gids.clear()\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    def log(self, name, value, *args, **kwargs):\n",
        "        if value is None:\n",
        "            return\n",
        "        super().log(name, value, *args, **kwargs)\n",
        "\n",
        "\n",
        "def _worker_init_fn(worker_id: int, seed: int):\n",
        "    \"\"\"\n",
        "    Глобальная функция для инициализации worker-а DataLoader-а.\n",
        "    pickle её «видит» и может передать в подпроцессы.\n",
        "    \"\"\"\n",
        "    set_seeds(seed + worker_id)\n",
        "\n",
        "\n",
        "def _extract_tensor(x, role=\"pred\"):\n",
        "    \"\"\"\n",
        "    Извлекает torch.Tensor из различных контейнеров/структур.\n",
        "    - dict: сперва пробуем ключи, характерные для предсказаний/таргета\n",
        "    - tuple/list: берём первый тензор или первый элемент, приводимый к тензору\n",
        "    - tensor: возвращаем как есть\n",
        "    \"\"\"\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x\n",
        "\n",
        "    if isinstance(x, dict):\n",
        "        # Наиболее типичные ключи в pytorch-forecasting / lightning шагах\n",
        "        preferred_keys = [\n",
        "            \"prediction\", \"pred\", \"output\", \"y_pred\", \"yhat\", \"y\", \"target\"\n",
        "        ]\n",
        "        for k in preferred_keys:\n",
        "            if k in x and isinstance(x[k], torch.Tensor):\n",
        "                return x[k]\n",
        "        # Если значения-словари/кортежи — попробуем рекурсивно\n",
        "        for v in x.values():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                return v\n",
        "            if isinstance(v, (list, tuple, dict)):\n",
        "                try:\n",
        "                    t = _extract_tensor(v, role=role)\n",
        "                    if isinstance(t, torch.Tensor):\n",
        "                        return t\n",
        "                except Exception:\n",
        "                    pass\n",
        "        raise TypeError(f\"Cannot extract tensor from dict for role={role}. Keys={list(x.keys())}\")\n",
        "\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        for item in x:\n",
        "            if isinstance(item, torch.Tensor):\n",
        "                return item\n",
        "        # если нет прямого тензора — попробуем рекурсивно\n",
        "        for item in x:\n",
        "            if isinstance(item, (list, tuple, dict)):\n",
        "                try:\n",
        "                    t = _extract_tensor(item, role=role)\n",
        "                    if isinstance(t, torch.Tensor):\n",
        "                        return t\n",
        "                except Exception:\n",
        "                    pass\n",
        "        raise TypeError(f\"Cannot extract tensor from {type(x)} for role={role}\")\n",
        "\n",
        "    # Последняя попытка — у объектов некоторых библиотек есть .values или .tensor\n",
        "    for attr in (\"values\", \"tensor\", \"data\"):\n",
        "        if hasattr(x, attr):\n",
        "            v = getattr(x, attr)\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                return v\n",
        "\n",
        "    raise TypeError(f\"Unsupported type for tensor extraction (role={role}): {type(x)}\")\n",
        "\n",
        "\n",
        "def _maybe_squeeze_last(x):\n",
        "    \"\"\"\n",
        "    Безопасно убираем последнюю размерность, если она равна 1.\n",
        "    Если x не тензор — возвращаем как есть.\n",
        "    \"\"\"\n",
        "    if not isinstance(x, torch.Tensor):\n",
        "        return x\n",
        "    if x.dim() > 0 and x.size(-1) == 1:\n",
        "        return x.squeeze(-1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _align_pred_target(y_pred, y_actual):\n",
        "    \"\"\"\n",
        "    Приводим предсказания и таргет к совместимым формам для MSE:\n",
        "    - Извлекаем тензоры из возможных контейнеров.\n",
        "    - Сводим предсказание к (B, T_pred) с последней осью как временем.\n",
        "    - Таргет сводим к (B,) или (B, T_act).\n",
        "    - Если таргет (B,) — берём последний горизонт из предсказаний.\n",
        "    - Если таргет (B, T_act) — подгоняем по времени (обрезаем/проверяем равенство).\n",
        "    \"\"\"\n",
        "    # 1) Достаём тензоры\n",
        "    y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "    y_actual = _extract_tensor(y_actual, role=\"target\")\n",
        "\n",
        "    # 2) Сжимаем последнюю единичную ось\n",
        "    y_pred = _maybe_squeeze_last(y_pred)\n",
        "    y_actual = _maybe_squeeze_last(y_actual)\n",
        "\n",
        "    # Быстрый путь: формы совпали\n",
        "    if isinstance(y_pred, torch.Tensor) and isinstance(y_actual, torch.Tensor):\n",
        "        if y_pred.shape == y_actual.shape:\n",
        "            return y_pred, y_actual\n",
        "\n",
        "    # 3) Приводим предсказание к (B, T_pred)\n",
        "    y_pred_bt = _collapse_pred_to_bt(y_pred)  # (B, T_pred)\n",
        "\n",
        "    # 4) Приведём таргет к (B,) или (B, T_act)\n",
        "    if y_actual.dim() == 1:\n",
        "        # (B,) — ожидаем 1 шаг на таргет → берём последний горизонт из предсказаний\n",
        "        if y_pred_bt.dim() != 2 or y_pred_bt.size(0) != y_actual.size(0):\n",
        "            raise ValueError(f\"Batch mismatch: pred={tuple(y_pred_bt.shape)} vs target={tuple(y_actual.shape)}\")\n",
        "        y_pred_aligned = y_pred_bt[:, -1]  # последний шаг горизонта\n",
        "        return y_pred_aligned, y_actual\n",
        "\n",
        "    if y_actual.dim() == 2:\n",
        "        # (B, T_act)\n",
        "        if y_pred_bt.size(0) != y_actual.size(0):\n",
        "            raise ValueError(f\"Batch mismatch: pred={tuple(y_pred_bt.shape)} vs target={tuple(y_actual.shape)}\")\n",
        "        T_pred = y_pred_bt.size(1)\n",
        "        T_act = y_actual.size(1)\n",
        "        if T_pred == T_act:\n",
        "            return y_pred_bt, y_actual\n",
        "        if T_pred > T_act:\n",
        "            # Обрежем последние T_act шагов, чтобы соответствовать таргету\n",
        "            y_pred_bt = y_pred_bt[:, -T_act:]\n",
        "            return y_pred_bt, y_actual\n",
        "        # Если предсказаний по времени меньше, чем в таргете — это логическая ошибка настройки\n",
        "        raise ValueError(\n",
        "            f\"Prediction horizon shorter than target: pred T={T_pred}, target T={T_act} \"\n",
        "            f\"(pred shape={tuple(y_pred_bt.shape)}, target shape={tuple(y_actual.shape)})\"\n",
        "        )\n",
        "\n",
        "    # Случай редкий: если таргет внезапно >2D — пробуем схлопнуть по всем, кроме батча\n",
        "    if y_actual.dim() > 2:\n",
        "        # Схлопнём таргет к (B, T_act) по последней оси\n",
        "        reduce_dims = tuple(range(1, y_actual.dim() - 1))\n",
        "        if len(reduce_dims) > 0:\n",
        "            y_actual_bt = y_actual.mean(dim=reduce_dims)\n",
        "        else:\n",
        "            y_actual_bt = y_actual\n",
        "        # Рекурсивно выровняем теперь как (B, ?)\n",
        "        return _align_pred_target(y_pred_bt, y_actual_bt)\n",
        "\n",
        "    # Если таргет скалярный (редко, но вдруг), расширим до (B,) повтором\n",
        "    if y_actual.dim() == 0:\n",
        "        y_actual = y_actual.expand(y_pred_bt.size(0))\n",
        "        y_pred_aligned = y_pred_bt[:, -1]\n",
        "        return y_pred_aligned, y_actual\n",
        "\n",
        "    # Если сюда дошли — что-то совсем нетипичное\n",
        "    raise ValueError(\n",
        "        f\"Shapes still mismatch after alignment: pred={tuple(y_pred.shape)} vs target={tuple(y_actual.shape)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Фиксируем seeds для воспроизводимости и стабильности\n",
        "def set_seeds(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    pl.seed_everything(seed, verbose=False)\n",
        "\n",
        "\n",
        "class PeakFriendlyHuber(Metric):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        delta: float = 0.5,\n",
        "        peak_thr: float = 0.85,\n",
        "        peak_weight: float = 1.6,  # Увеличено до 1.6 для stronger поощрения пиков\n",
        "        contrast_weight: float = 0.02,\n",
        "        center_band: float = 0.3,\n",
        "        clip_scale: float = 1.5,  # Новый: scale для soft-clip (tanh * scale, чтобы не сжимать середину сильно)\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.delta = float(delta)\n",
        "        self.peak_thr = float(peak_thr)\n",
        "        self.peak_weight = float(peak_weight)\n",
        "        self.contrast_weight = float(contrast_weight)\n",
        "        self.center_band = float(center_band)\n",
        "        self.clip_scale = float(clip_scale)  # Новый параметр\n",
        "        self.mse = MeanSquaredError()\n",
        "\n",
        "    @staticmethod\n",
        "    def _smooth_l1(diff, delta):\n",
        "        absd = diff.abs()\n",
        "        return torch.where(absd < delta, 0.5 * (diff ** 2) / delta, absd - 0.5 * delta)\n",
        "\n",
        "    def to_prediction(self, y_pred):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        return super().to_prediction(y_pred)\n",
        "\n",
        "    def to_quantiles(self, y_pred, quantiles=None, **kwargs):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        return super().to_quantiles(y_pred, quantiles=quantiles, **kwargs)\n",
        "\n",
        "    def loss(self, y_pred, y_actual, **kwargs):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        y_actual = _extract_tensor(y_actual, role=\"target\")\n",
        "        y_pred, y_actual = _align_pred_target(y_pred, y_actual)\n",
        "\n",
        "        # Soft-clip (без изменений)\n",
        "        y_pred = torch.tanh(y_pred * self.clip_scale) / self.clip_scale\n",
        "\n",
        "        diff = y_pred - y_actual\n",
        "        base = self._smooth_l1(diff, self.delta)\n",
        "\n",
        "        # Адаптивный peak_weight: средний по батчу, scale от доли пиков\n",
        "        if self.peak_weight > 1.0:\n",
        "            with torch.no_grad():\n",
        "                peak_mag = torch.relu(y_actual.abs() - self.peak_thr)\n",
        "                peak_frac = (peak_mag > 0).float().mean()  # Доля пиков в батче\n",
        "                adaptive_weight = 1.0 + (self.peak_weight - 1.0) * peak_frac  # Больше веса, если много пиков\n",
        "                w = adaptive_weight * torch.clamp(peak_mag / (1.0 - self.peak_thr + 1e-8), 0.0, 1.0) + 1.0\n",
        "            huber_term = (base * w).mean()\n",
        "        else:\n",
        "            huber_term = base.mean()\n",
        "\n",
        "        # Лёгкий «anti-flatness» у центра: штрафим чрезмерно малую амплитуду,\n",
        "        # но только там, где таргет далеко от 0.\n",
        "        if self.contrast_weight > 0.0:\n",
        "            with torch.no_grad():\n",
        "                far_mask = (y_actual.abs() >= self.center_band).float()\n",
        "                near_mask = (y_actual.abs() < self.center_band).float()\n",
        "\n",
        "            # Прямая амплитуда предсказания\n",
        "            far_amp = (y_pred.abs() * far_mask).sum() / (far_mask.sum() + 1e-8)\n",
        "            near_amp = (y_pred.abs() * near_mask).sum() / (near_mask.sum() + 1e-8)\n",
        "\n",
        "            # Хотим far_amp >= near_amp + margin; введём небольшой margin\n",
        "            margin = 0.05\n",
        "            contrast = torch.relu((near_amp + margin) - far_amp)\n",
        "            loss = huber_term + self.contrast_weight * contrast\n",
        "        else:\n",
        "            loss = huber_term\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def __call__(self, y_pred, y_actual, **kwargs):\n",
        "        return self.loss(y_pred, y_actual, **kwargs)\n",
        "\n",
        "    def update(self, y_pred, y_actual, **kwargs):\n",
        "        y_pred = _extract_tensor(y_pred, role=\"pred\")\n",
        "        y_actual = _extract_tensor(y_actual, role=\"target\")\n",
        "        y_pred, y_actual = _align_pred_target(y_pred, y_actual)\n",
        "        self.mse.update(y_pred, y_actual)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.mse.compute()\n",
        "\n",
        "    def reset(self):\n",
        "        self.mse.reset()\n",
        "\n",
        "    def name(self):\n",
        "        return \"PeakFriendlyHuber\"\n",
        "\n",
        "class TFTAdapter(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Обёртка над TemporalFusionTransformer,\n",
        "    чтобы Trainer воспринимал модель нужного типа\n",
        "    и наш tft.training_step видел непустой self.trainer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tft: TemporalFusionTransformer):\n",
        "        super().__init__()\n",
        "        self.tft = tft\n",
        "\n",
        "    def on_fit_start(self) -> None:\n",
        "        # вызовется перед стартом Trainer.fit\n",
        "        # прикрепляем Trainer к внутреннему tft\n",
        "        self.tft.trainer = self.trainer\n",
        "        # и логгеры\n",
        "        self.tft.log = self.log\n",
        "        self.tft.log_dict = self.log_dict\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        return self.tft(*args, **kwargs)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.tft.trainer = self.trainer\n",
        "        result = self.tft.training_step(batch, batch_idx)\n",
        "        if isinstance(result, dict):\n",
        "            return result.get(\"loss\")\n",
        "        elif isinstance(result, tuple) and len(result) >= 2:\n",
        "            log_dict, out = result[:2]  # Берем первые два элемента\n",
        "            if isinstance(log_dict, dict):\n",
        "                return log_dict.get(\"loss\")\n",
        "        # Если ни один вариант не подошел\n",
        "        raise ValueError(f\"Unexpected return type from tft.training_step: {type(result)}\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # обеспечим корректную ссылку на тренер внутри tft (если нужно)\n",
        "        self.tft.trainer = self.trainer\n",
        "        self.tft.validation_step(batch, batch_idx)\n",
        "        return\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        # Просто передаём вызов внутреннему TFT, без dataloader_idx (не нужен для TFT)\n",
        "        return self.tft.predict_step(batch, batch_idx)\n",
        "\n",
        "    def predict(self, *args, **kwargs):\n",
        "        return self.tft.predict(*args, **kwargs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.tft.configure_optimizers()\n",
        "\n",
        "\n",
        "def to_dense(X):\n",
        "    \"\"\"Преобразование sparse matrix в dense numpy array\"\"\"\n",
        "    if hasattr(X, 'toarray'):\n",
        "        return X.toarray()\n",
        "    return np.asarray(X)\n",
        "\n",
        "def prepare_data_transformer(df, target_col):\n",
        "    df = df.dropna(subset=[target_col])\n",
        "    if 'time' in df.columns and 'time_idx' not in df.columns:\n",
        "        df = df.rename(columns={'time': 'time_idx'})\n",
        "    X = df.drop(columns=target_col)\n",
        "    y = df[target_col].copy()\n",
        "\n",
        "    exclude = ['time_idx', 'batch']\n",
        "    numeric_features = [\n",
        "        c for c in X.select_dtypes(include=['int64', 'float64', 'float32', 'int32']).columns\n",
        "        if c not in exclude\n",
        "    ]\n",
        "    categorical_features = [\n",
        "        c for c in X.select_dtypes(include=['object', 'category']).columns\n",
        "        if c not in exclude\n",
        "    ]\n",
        "\n",
        "    preprocessing = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', Pipeline([\n",
        "                ('scaler', RobustScaler()),\n",
        "                ('yeo', PowerTransformer(method='yeo-johnson'))\n",
        "            ]), numeric_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ],\n",
        "        remainder='passthrough'  # passthrough → тут окажутся сначала все num→cat, а потом time_idx и batch\n",
        "    )\n",
        "    # Возвращаем дополнительные списки для передачи в модель\n",
        "    return X, y, preprocessing, numeric_features, categorical_features\n",
        "\n",
        "def split_features_batch_time(X_array, n_transformed):\n",
        "    \"\"\"\n",
        "    X_array: np.ndarray после преобразований shape=(N, n_transformed + 2)\n",
        "    n_transformed: сколько колонок ушло на num+cat\n",
        "    возвращает (features, time_raw, batch_raw)\n",
        "    \"\"\"\n",
        "    features = X_array[:, :n_transformed]\n",
        "    batch_raw = X_array[:, n_transformed].ravel()\n",
        "    time_raw = X_array[:, n_transformed + 1].ravel()\n",
        "    return features, batch_raw, time_raw\n",
        "\n",
        "\n",
        "def tft_output_transformer(x):\n",
        "    # Больше НЕ клипуем внутри графа. Пусть модель учится выходить за [-1,1],\n",
        "    # а мы ограничим при расчёте метрик и при возврате пользователю.\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_early_stopping_callback(patience=10, min_delta=0.001):\n",
        "    return EarlyStopping(\n",
        "        monitor=\"train_loss\",\n",
        "        patience=patience,\n",
        "        min_delta=min_delta,\n",
        "        mode=\"min\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "\n",
        "class SequenceTransformerRegressor(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"\n",
        "    Temporal Fusion Transformer для последовательностей.\n",
        "    Интегрируется в Pipeline аналогично LSTM.\n",
        "    Адаптировано для стабильного обучения и алготрейдинга (реального времени).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq_len: int = 10,\n",
        "                 pred_len: int = 1,\n",
        "                 hidden_size: int = 64,  # Увеличено для лучшей емкости\n",
        "                 hidden_continuous_size: int = 24,\n",
        "                 epochs: int = 100,  # Увеличено для более долгого обучения\n",
        "                 batch_size: int = 128,  # Увеличено для стабильности\n",
        "                 learning_rate: float = 1e-3,  # Увеличено для более быстрого старта\n",
        "                 patience: int = 15,  # Увеличено для терпимости\n",
        "                 seed: int = 42,\n",
        "                 dropout: float = 0.25,  # Уменьшено для меньшей регуляризации\n",
        "                 weight_decay: float = 1e-4,  # Новый: для регуляризации\n",
        "                 verbose: int = 2,\n",
        "                 mask_prob: float = 0.1,  # Уменьшено, чтобы меньше шумить\n",
        "                 infer_stride: int = 2,\n",
        "                 ckpt_path=None,\n",
        "                 preprocessing=None,\n",
        "                 numeric_features=None,\n",
        "                 categorical_features=None,\n",
        "                 remainder_columns=None,\n",
        "                 min_encoder_length: int = 1):  # Больше логов\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_continuous_size = hidden_continuous_size\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.patience = patience\n",
        "        self.seed = seed\n",
        "        self.verbose = verbose\n",
        "        self._model = None\n",
        "        self._trainer = None\n",
        "        self._n_transformed = None\n",
        "        self._n_feat = None\n",
        "        self._train_dataset = None\n",
        "        self._feature_columns = None\n",
        "        self._dropout = dropout\n",
        "        self.norm_eps = 1e-6\n",
        "        self.norm_window = max(10, self.seq_len // 2)\n",
        "        self.ckpt_path = ckpt_path\n",
        "        self.weight_decay = weight_decay  # Новый\n",
        "        self.mask_prob = mask_prob\n",
        "        self.infer_stride = infer_stride\n",
        "        self.global_target_mean = 0.0  # Будем вычислять в fit\n",
        "        self.global_target_std = 1.0  # Fallback global scale\n",
        "        self.global_target_min = None\n",
        "        self.global_target_max = None\n",
        "        self.global_range = None\n",
        "        self.soft_clip_scale =  None\n",
        "        self.preprocessing = preprocessing\n",
        "        self.numeric_features = numeric_features or []\n",
        "        self.categorical_features = categorical_features or []\n",
        "        self.remainder_columns = remainder_columns or ['batch', 'time']\n",
        "        self.use_tanh_post = False\n",
        "        self.train_q_lo = None\n",
        "        self.train_q_hi = None\n",
        "        self.clip_scale = 1.5\n",
        "        self.future_fill_mode = \"repeat\"\n",
        "        self.smooth_window = max(5, self.seq_len // 5)  # For savgol\n",
        "        self.smooth_poly = 2\n",
        "        self.ema_alpha = 0.1\n",
        "        self.infer_batch_size = 512  # Новый: большой батч для inference\n",
        "        self.infer_stride = infer_stride if infer_stride is not None else 4\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'# Добавьте это, если нужно tanh в предикте\n",
        "        self.min_encoder_length = max(1, min_encoder_length)  # Не меньше 1\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        set_seeds(self.seed)\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        if self._n_transformed is None:\n",
        "            self._n_transformed = X.shape[1] - 2\n",
        "            self._n_feat = X.shape[1]\n",
        "\n",
        "        feat, batch_raw, time_raw = split_features_batch_time(X, self._n_transformed)\n",
        "\n",
        "        df = pd.DataFrame(feat, columns=[f\"f{i}\" for i in range(feat.shape[1])])\n",
        "        self._feature_columns = df.columns.tolist()\n",
        "\n",
        "        df[\"batch\"] = pd.Series(batch_raw).astype(\"int64\")\n",
        "        df[\"time_raw\"] = pd.to_datetime(time_raw, utc=True, errors=\"coerce\")\n",
        "\n",
        "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
        "            y = y.reset_index(drop=True)\n",
        "        df[\"target\"] = pd.Series(y, index=df.index).astype(float)\n",
        "\n",
        "        before = len(df)\n",
        "        df = df.dropna(subset=[\"time_raw\", \"target\"]).reset_index(drop=True)\n",
        "        if self.verbose and len(df) < before:\n",
        "            print(f\"Dropped {before - len(df)} rows with invalid time/target\")\n",
        "\n",
        "        df = df.sort_values([\"batch\", \"time_raw\"]).reset_index(drop=True)\n",
        "        df[\"time_idx\"] = df.groupby(\"batch\").cumcount()\n",
        "\n",
        "        min_len = max(1, int(self.pred_len))  # Изменено: позволяем короткие батчи (encoder может быть < seq_len)\n",
        "        gsize = df.groupby(\"batch\").size()\n",
        "        valid_batches = gsize[gsize >= min_len].index\n",
        "        if len(valid_batches) == 0:\n",
        "            raise ValueError(f\"No batches with length >= {min_len}. Reduce pred_len.\")\n",
        "        if self.verbose and len(valid_batches) < gsize.index.nunique():\n",
        "            dropped = sorted(list(set(gsize.index) - set(valid_batches)))\n",
        "            print(f\"Warning: dropped {len(dropped)} short batches: {dropped[:8]}{' ...' if len(dropped) > 8 else ''}\")\n",
        "        df = df[df[\"batch\"].isin(valid_batches)].reset_index(drop=True)\n",
        "\n",
        "        batch_starts = df.groupby(\"batch\")[\"time_raw\"].min().sort_values()\n",
        "        uniq_batches = batch_starts.index.to_numpy()\n",
        "        n_total = len(uniq_batches)\n",
        "        val_frac = 0.3 if n_total >= 10 else 0.1  # Увеличено для лучшего обобщения\n",
        "        n_val = max(1, int(round(n_total * val_frac)))\n",
        "\n",
        "        embargo = 1 if n_total >= 8 else 0\n",
        "\n",
        "        train_end = max(0, n_total - n_val - embargo)\n",
        "        train_batches = uniq_batches[:train_end]\n",
        "        val_batches = uniq_batches[-n_val:]\n",
        "\n",
        "        if len(train_batches) == 0 and n_total > 1:\n",
        "            train_batches = uniq_batches[:-1]\n",
        "            val_batches = uniq_batches[-1:]\n",
        "\n",
        "        train_df = df[df[\"batch\"].isin(train_batches)].copy()\n",
        "        val_df = df[df[\"batch\"].isin(val_batches)].copy()\n",
        "\n",
        "        self.global_target_mean = train_df[\"target\"].mean()\n",
        "        self.global_target_std = train_df[\"target\"].std() + 1e-8\n",
        "        self.global_target_min = train_df[\"target\"].min()\n",
        "        self.global_target_max = train_df[\"target\"].max()\n",
        "        self.global_range = self.global_target_max - self.global_target_min + 1e-8\n",
        "        self.soft_clip_scale = max(1.0, self.global_target_std * 1.5)  # Adaptive soft clip for stable [-1,1] without compression\n",
        "\n",
        "        #self.clip_scale = max(1.0, self.global_target_std * 1.2)   # Adaptive to train variance\n",
        "\n",
        "        train_targets = train_df[\"target\"].values\n",
        "        #if len(train_targets) > 0:\n",
        "        #   self.train_q_lo, self.train_q_hi = np.quantile(train_targets, [0.01, 0.99])\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Train batches: {len(np.unique(train_batches))}\")\n",
        "            print(f\"Val batches: {len(np.unique(val_batches))}\")\n",
        "            print(f\"Train rows: {len(train_df)}, Val rows: {len(val_df)}\")\n",
        "\n",
        "        full_dataset = TimeSeriesDataSet(\n",
        "            df,\n",
        "            time_idx=\"time_idx\",\n",
        "            target=\"target\",\n",
        "            group_ids=[\"batch\"],\n",
        "            max_encoder_length=int(self.seq_len),\n",
        "            min_encoder_length=0,#int(self.min_encoder_length),  # Новый: позволяем короткие encoder\n",
        "            max_prediction_length=int(self.pred_len),\n",
        "            time_varying_unknown_reals=self._feature_columns,\n",
        "            target_normalizer=None,\n",
        "            allow_missing_timesteps=True,\n",
        "            add_relative_time_idx=True,\n",
        "            add_target_scales=False,\n",
        "            add_encoder_length=True,\n",
        "            min_prediction_length=1,\n",
        "        )\n",
        "\n",
        "        train_dataset = TimeSeriesDataSet.from_dataset(\n",
        "            full_dataset, train_df, predict=False, stop_randomization=True\n",
        "        )\n",
        "        val_dataset = TimeSeriesDataSet.from_dataset(\n",
        "            full_dataset, val_df, predict=False, stop_randomization=True\n",
        "        ) if len(val_df) > 0 else None\n",
        "\n",
        "        train_dl = train_dataset.to_dataloader(\n",
        "            train=True,\n",
        "            batch_size=int(self.batch_size),\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            worker_init_fn=None,\n",
        "            drop_last=False,\n",
        "            persistent_workers=False,\n",
        "        )\n",
        "        val_dl = None\n",
        "        if val_dataset is not None and len(val_dataset) > 0:\n",
        "            val_dl = val_dataset.to_dataloader(\n",
        "                train=False,\n",
        "                batch_size=int(self.batch_size),\n",
        "                shuffle=False,\n",
        "                num_workers=0,\n",
        "                worker_init_fn=None,\n",
        "                drop_last=False,\n",
        "                persistent_workers=False,\n",
        "            )\n",
        "\n",
        "        tft = CustomTFT.from_dataset(\n",
        "            train_dataset,\n",
        "            hidden_size=int(self.hidden_size),\n",
        "            output_size=1,\n",
        "            loss=PeakFriendlyHuber(\n",
        "                delta=0.5,\n",
        "                peak_thr=0.85,  # можно затем подвинуть 0.8..0.9\n",
        "                peak_weight=1.3,  # аккуратно: 1.3..1.6\n",
        "                contrast_weight=0.03,  # очень маленькая добавка\n",
        "                center_band=0.3,  # что считать «центром»\n",
        "                clip_scale=1.5\n",
        "            ),\n",
        "            optimizer=\"adam\",\n",
        "            learning_rate=float(self.learning_rate),  # оставьте тот, на котором MSE был лучше (у вас 1e-4 давал ~0.186)\n",
        "            lstm_layers=3,\n",
        "            hidden_continuous_size=self.hidden_continuous_size,\n",
        "            attention_head_size=4,\n",
        "            dropout=float(self._dropout),\n",
        "            reduce_on_plateau_patience=5,\n",
        "            reduce_on_plateau_min_lr=1e-6,\n",
        "            weight_decay=float(self.weight_decay),\n",
        "            mask_prob=float(self.mask_prob),\n",
        "            output_transformer=tft_output_transformer,\n",
        "        )\n",
        "\n",
        "        class GCCallback(pl.Callback):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.last_mem = psutil.Process().memory_info().rss / 1e6\n",
        "\n",
        "            def _check_gc(self):\n",
        "                current_mem = psutil.Process().memory_info().rss / 1e6\n",
        "                if current_mem - self.last_mem > 50:\n",
        "                    gc.collect()\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                self.last_mem = current_mem\n",
        "\n",
        "            def on_train_epoch_end(self, trainer, pl_module):\n",
        "                self._check_gc()\n",
        "\n",
        "            def on_validation_epoch_end(self, trainer, pl_module):\n",
        "                self._check_gc()\n",
        "\n",
        "            def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "                if batch_idx % 10 == 0:\n",
        "                    self._check_gc()\n",
        "\n",
        "            def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "                if batch_idx % 10 == 0:\n",
        "                    self._check_gc()\n",
        "\n",
        "        callbacks = []\n",
        "        if val_dl is not None:\n",
        "            callbacks.append(\n",
        "                get_early_stopping_callback(patience=self.patience, min_delta=1e-3))  # Новый: больше patience\n",
        "            checkpoint_callback = ModelCheckpoint(monitor=\"train_loss\", mode=\"min\", save_top_k=1, verbose=True)\n",
        "            callbacks.append(checkpoint_callback)\n",
        "        else:\n",
        "            checkpoint_callback = None\n",
        "\n",
        "        logger = TensorBoardLogger(save_dir=\"lightning_logs/\", name=\"my_model\") if self.verbose > 0 else False\n",
        "        if self.verbose > 0:\n",
        "            callbacks.append(LearningRateMonitor(logging_interval=\"step\"))\n",
        "            callbacks.append(NoValidationBar(refresh_rate=20))\n",
        "        callbacks.append(GCCallback())\n",
        "\n",
        "        self._model = TFTAdapter(tft)\n",
        "        self._trainer = pl.Trainer(\n",
        "            max_epochs=int(self.epochs),\n",
        "            enable_checkpointing=(checkpoint_callback is not None),\n",
        "            callbacks=callbacks,\n",
        "            logger=logger,\n",
        "            enable_model_summary=True,\n",
        "            gradient_clip_val=1.0,\n",
        "            gradient_clip_algorithm=\"norm\",\n",
        "            deterministic=True,\n",
        "            benchmark=False,\n",
        "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "            precision=32,\n",
        "            limit_val_batches=1.0 if val_dl is not None else 0.0,\n",
        "            enable_progress_bar=self.verbose > 0,\n",
        "            log_every_n_steps=50,\n",
        "            num_sanity_val_steps=0,\n",
        "        )\n",
        "\n",
        "        self._trainer.fit(\n",
        "            self._model,\n",
        "            train_dataloaders=train_dl,\n",
        "            val_dataloaders=val_dl if val_dl is not None else None,\n",
        "            ckpt_path=self.ckpt_path if self.ckpt_path and self.epochs > 0 else None,\n",
        "        )\n",
        "\n",
        "        if checkpoint_callback is not None and checkpoint_callback.best_model_path:\n",
        "            best_path = checkpoint_callback.best_model_path\n",
        "            if self.verbose:\n",
        "                print(f\"Loaded best model from {best_path} with val_loss={checkpoint_callback.best_model_score}\")\n",
        "            self._model = TFTAdapter.load_from_checkpoint(best_path, tft=tft)\n",
        "\n",
        "        self._train_dataset = full_dataset\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        #return self\n",
        "        try:\n",
        "            y_train = train_df[\"target\"].to_numpy(dtype=float)\n",
        "            # robust percentiles — перестрахуемся от выносов: 1% и 99%\n",
        "            self._cal_p_low = float(np.nanpercentile(y_train, 1))\n",
        "            self._cal_p_high = float(np.nanpercentile(y_train, 99))\n",
        "            # амплитуды «типичных пиков»\n",
        "            top_mask = y_train >= self._cal_p_high\n",
        "            bot_mask = y_train <= self._cal_p_low\n",
        "            self._cal_mean_top = float(np.nanmean(y_train[top_mask])) if np.any(top_mask) else float(self.global_target_max)\n",
        "            self._cal_mean_bot = float(np.nanmean(y_train[bot_mask])) if np.any(bot_mask) else float(self.global_target_min)\n",
        "            # защита от вырождения\n",
        "            if not np.isfinite(self._cal_mean_top): self._cal_mean_top = float(self.global_target_max)\n",
        "            if not np.isfinite(self._cal_mean_bot): self._cal_mean_bot = float(self.global_target_min)\n",
        "        except Exception:\n",
        "            # безопасные фолбэки\n",
        "            self._cal_p_low, self._cal_p_high = self.global_target_min, self.global_target_max\n",
        "            self._cal_mean_top, self._cal_mean_bot = self.global_target_max, self.global_target_min\n",
        "        # ----------------------------------------------\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self._train_dataset is None or self._model is None:\n",
        "            raise RuntimeError(\"Model is not fitted yet\")\n",
        "\n",
        "        # Full suppress context (no logs/output, including PL/Torch/PF/Seed/GPU/TPU/HPU messages)\n",
        "        @contextlib.contextmanager\n",
        "        def suppress_all():\n",
        "            with open(os.devnull, \"w\") as devnull, contextlib.redirect_stdout(devnull), contextlib.redirect_stderr(devnull):\n",
        "                # Подавление всех возможных логгеров\n",
        "                root_logger = logging.getLogger()\n",
        "                old_level = root_logger.level\n",
        "                root_logger.setLevel(logging.CRITICAL + 1)  # Выше CRITICAL, чтобы ничего не логировалось\n",
        "\n",
        "                # Специфические логгеры (расширенный список)\n",
        "                for logger_name in [\n",
        "                    \"pytorch_lightning\", \"lightning.pytorch\", \"lightning\",\n",
        "                    \"torch\", \"pytorch_forecasting\", \"optuna\",\n",
        "                    \"sklearn\", \"joblib\", \"numpy\", \"pandas\",\n",
        "                    \"scipy\", \"matplotlib\", \"seaborn\", \"plotly\",\n",
        "                    \"shap\", \"statsmodels\", \"torchmetrics\",\n",
        "                    \"lightning.pytorch.utilities.migration.utils\",  # Для Attribute 'loss' warnings\n",
        "                    \"lightning.pytorch.utilities.migration\",\n",
        "                    \"lightning.pytorch.utilities\",\n",
        "                    \"lightning.pytorch\"\n",
        "                ]:\n",
        "                    logging.getLogger(logger_name).setLevel(logging.CRITICAL + 1)\n",
        "\n",
        "                # Подавление всех предупреждений (расширенный список)\n",
        "                warnings.filterwarnings(\"ignore\")\n",
        "                warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "                warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "                warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*Attribute 'loss' is an instance of nn.Module.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*Attribute 'logging_metrics' is an instance of nn.Module.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*GPU available.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*TPU available.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*HPU available.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*This Pipeline instance is not fitted yet.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*Using an existing study with name.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*A value is trying to be set on a copy of a slice.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*The behavior of DataFrame concatenation.*\")\n",
        "                warnings.filterwarnings(\"ignore\", message=\".*torch.utils.checkpoint: the use_reentrant parameter.*\")\n",
        "\n",
        "                # Окружение (расширенное)\n",
        "                os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "                os.environ['LITMODELS_DISABLE_TIP'] = '1'\n",
        "                os.environ['HYDRA_FULL_ERROR'] = '1'\n",
        "                os.environ['TQDM_DISABLE'] = '0'  # Не подавлять tqdm (если вызван снаружи)\n",
        "                os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Для синхронизации CUDA, но без логов\n",
        "                os.environ['TORCH_USE_DETERMINISTIC_ALGORITHMS'] = '1'  # Без логов\n",
        "\n",
        "                try:\n",
        "                    yield\n",
        "                finally:\n",
        "                    root_logger.setLevel(old_level)\n",
        "                    warnings.resetwarnings()\n",
        "\n",
        "        with suppress_all():\n",
        "            set_seeds(self.seed)\n",
        "            pl.seed_everything(self.seed, verbose=False, workers=True)\n",
        "\n",
        "            if self.preprocessing is not None and not isinstance(X, np.ndarray):\n",
        "                X = self.preprocessing.transform(X)\n",
        "\n",
        "            X = np.asarray(X)\n",
        "            N = X.shape[0]\n",
        "            if N < self.min_encoder_length:\n",
        "                return [float(np.nan)] * N\n",
        "\n",
        "            feat, _, time_raw = split_features_batch_time(X, self._n_transformed)\n",
        "            df = pd.DataFrame(feat, columns=self._feature_columns)\n",
        "            df[\"__row_id\"] = np.arange(N)\n",
        "            df[\"time_raw\"] = pd.to_datetime(time_raw, utc=True, errors=\"coerce\")\n",
        "            df[\"batch\"] = np.int64(0)\n",
        "            df[\"target\"] = self.global_target_mean\n",
        "\n",
        "            df = df.dropna(subset=[\"time_raw\"]).reset_index(drop=True)\n",
        "            df_sorted = df.sort_values(\"time_raw\").reset_index(drop=True)\n",
        "            df_sorted[\"time_idx\"] = np.arange(len(df_sorted), dtype=np.int64)\n",
        "\n",
        "            eff_N = len(df_sorted)\n",
        "            if eff_N < self.min_encoder_length:\n",
        "                out = np.full(N, np.nan, dtype=float)\n",
        "                return out.tolist()\n",
        "\n",
        "            step_ns = int(60 * 1e9)\n",
        "            if eff_N >= 2:\n",
        "                diffs = df_sorted[\"time_raw\"].view(\"int64\").astype(\"int64\").to_numpy()\n",
        "                diffs = np.diff(diffs)\n",
        "                step_ns = int(np.nan_to_num(np.median(diffs), nan=step_ns))\n",
        "                if step_ns <= 0:\n",
        "                    step_ns = int(60 * 1e9)\n",
        "\n",
        "            out_raw = np.full(eff_N, np.nan, dtype=float)\n",
        "\n",
        "            tft = self._model.tft\n",
        "            orig_log = tft.log\n",
        "            tft.log = lambda *args, **kwargs: None\n",
        "\n",
        "            try:\n",
        "                eff_encoder_len = min(self.seq_len, eff_N)\n",
        "                M = max(0, eff_N - eff_encoder_len + 1)\n",
        "                stride = self.pred_len  # Keep original stride to preserve logic\n",
        "                window_starts = np.arange(0, M, stride)\n",
        "                K = len(window_starts)\n",
        "\n",
        "                if K == 0:\n",
        "                    K = 1\n",
        "                    window_starts = np.array([0])\n",
        "                    eff_encoder_len = eff_N\n",
        "\n",
        "                num_feat_cols = len(self._feature_columns)\n",
        "\n",
        "                # Vectorized construction of all_feats\n",
        "                enc_indices = window_starts[:, np.newaxis] + np.arange(eff_encoder_len)\n",
        "                all_enc_feats = feat[enc_indices]  # (K, eff_encoder_len, num_feat_cols)\n",
        "                last_enc_feats = all_enc_feats[:, -1, :]\n",
        "                all_fut_feats = np.repeat(last_enc_feats[:, np.newaxis, :], self.pred_len, axis=1)  # (K, pred_len, num_feat_cols)\n",
        "                all_feats = np.concatenate([all_enc_feats, all_fut_feats], axis=1).reshape(-1, num_feat_cols)\n",
        "\n",
        "                # Vectorized all_time_idx\n",
        "                orig_time_idx = df_sorted[\"time_idx\"].values\n",
        "                all_enc_time_idx = orig_time_idx[enc_indices]  # (K, eff_encoder_len)\n",
        "                last_time_idx = all_enc_time_idx[:, -1]\n",
        "                fut_offsets = np.arange(1, self.pred_len + 1)\n",
        "                all_fut_time_idx = last_time_idx[:, np.newaxis] + fut_offsets  # (K, pred_len)\n",
        "                all_time_idx = np.concatenate([all_enc_time_idx, all_fut_time_idx], axis=1).reshape(-1)\n",
        "\n",
        "                # Vectorized all_batch\n",
        "                batch_per_window = np.arange(K)[:, np.newaxis]\n",
        "                all_enc_batch = np.repeat(batch_per_window, eff_encoder_len, axis=1)  # (K, eff_encoder_len)\n",
        "                all_fut_batch = np.repeat(batch_per_window, self.pred_len, axis=1)  # (K, pred_len)\n",
        "                all_batch = np.concatenate([all_enc_batch, all_fut_batch], axis=1).reshape(-1)\n",
        "\n",
        "                # all_target (constant)\n",
        "                all_target = np.full(K * (eff_encoder_len + self.pred_len), self.global_target_mean, dtype=np.float32)\n",
        "\n",
        "                # Vectorized all_time_raw using int64 ns\n",
        "                orig_time_raw_int = df_sorted[\"time_raw\"].view(\"int64\").values\n",
        "                all_enc_time_int = orig_time_raw_int[enc_indices]  # (K, eff_encoder_len)\n",
        "                last_time_int = all_enc_time_int[:, -1]\n",
        "                fut_offsets_ns = fut_offsets * step_ns\n",
        "                all_fut_time_int = last_time_int[:, np.newaxis] + fut_offsets_ns  # (K, pred_len)\n",
        "                all_time_int_flat = np.concatenate([all_enc_time_int.reshape(-1), all_fut_time_int.reshape(-1)])\n",
        "                all_time_raw = pd.to_datetime(all_time_int_flat, unit='ns', utc=True).values  # object array of Timestamp\n",
        "\n",
        "                pred_df = pd.DataFrame(all_feats, columns=self._feature_columns)\n",
        "                pred_df[\"time_idx\"] = all_time_idx\n",
        "                pred_df[\"batch\"] = all_batch\n",
        "                pred_df[\"target\"] = all_target\n",
        "                pred_df[\"time_raw\"] = all_time_raw\n",
        "\n",
        "                pred_df[\"batch\"] = pred_df[\"batch\"].astype(\"int64\")\n",
        "                pred_df[\"time_idx\"] = pred_df[\"time_idx\"].astype(\"int64\")\n",
        "                pred_df[\"target\"] = pred_df[\"target\"].astype(\"float32\")\n",
        "\n",
        "                sliding_dataset = TimeSeriesDataSet.from_dataset(\n",
        "                    self._train_dataset,\n",
        "                    pred_df,\n",
        "                    predict=True,\n",
        "                    stop_randomization=True,\n",
        "                    min_prediction_length=self.pred_len,\n",
        "                    max_prediction_length=self.pred_len,\n",
        "                )\n",
        "\n",
        "                test_dl = sliding_dataset.to_dataloader(\n",
        "                    train=False,\n",
        "                    batch_size=K,  # Full batch for max speed (K small due to stride=pred_len)\n",
        "                    num_workers=0,\n",
        "                    persistent_workers=False,\n",
        "                    pin_memory=False,\n",
        "                )\n",
        "\n",
        "                preds = tft.predict(\n",
        "                    test_dl,\n",
        "                    mode=\"prediction\",\n",
        "                    return_x=False,\n",
        "                    trainer_kwargs={\n",
        "                        \"logger\": False,\n",
        "                        \"enable_progress_bar\": False,\n",
        "                        \"enable_model_summary\": False,\n",
        "                        \"enable_checkpointing\": False,\n",
        "                        \"accelerator\": \"gpu\" if self.device == \"cuda\" else \"cpu\"\n",
        "                    },\n",
        "                )\n",
        "\n",
        "                if isinstance(preds, torch.Tensor):\n",
        "                    preds = preds.detach().cpu()\n",
        "                    if preds.dim() == 3 and preds.size(-1) == 1:\n",
        "                        preds = preds.squeeze(-1)\n",
        "                    if preds.dim() == 2:\n",
        "                        yhat_stride = preds[:, 0].numpy()  # First step per window\n",
        "                    elif preds.dim() == 1:\n",
        "                        yhat_stride = preds.numpy()\n",
        "                    elif preds.dim() == 0:\n",
        "                        yhat_stride = np.array([preds.item()])\n",
        "                    else:\n",
        "                        yhat_stride = np.full(K, self.global_target_mean)\n",
        "                else:\n",
        "                    yhat_stride = np.full(K, self.global_target_mean)\n",
        "\n",
        "                # Fill out_raw at window ends\n",
        "                for j, i in enumerate(window_starts):\n",
        "                    out_raw[i + eff_encoder_len - 1] = yhat_stride[j]\n",
        "\n",
        "                # Causal interpolation for missed points (linear from past, no future look)\n",
        "                s = pd.Series(out_raw)\n",
        "                s = s.interpolate(method='linear', limit_direction='forward')  # Only forward for causality\n",
        "                s = s.ffill()  # Fill initial with first pred\n",
        "                out_raw = s.values\n",
        "\n",
        "                # Global map to [-1,1] (consistent scale, preserves relative peaks)\n",
        "                out = (out_raw - self.global_target_min) / self.global_range * 2 - 1\n",
        "                out = np.tanh(out * self.soft_clip_scale) / np.tanh(self.soft_clip_scale)\n",
        "                out = np.clip(out, -1.0, 1.0)\n",
        "\n",
        "                # Fill any remaining nans (unlikely) with mapped mean\n",
        "                nan_mask = np.isnan(out)\n",
        "                mapped_mean = (self.global_target_mean - self.global_target_min) / self.global_range * 2 - 1\n",
        "                out[nan_mask] = mapped_mean\n",
        "\n",
        "            finally:\n",
        "                tft.log = orig_log\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            original_pos = df_sorted[\"__row_id\"].to_numpy()\n",
        "            out_final = np.full(N, np.nan, dtype=float)\n",
        "            out_final[original_pos] = out\n",
        "\n",
        "            return out_final.tolist()\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        # Чтобы sklearn корректно передавал параметры в Pipeline\n",
        "        return {\n",
        "            \"seq_len\": self.seq_len,\n",
        "            \"pred_len\": self.pred_len,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"epochs\": self.epochs,\n",
        "            \"batch_size\": self.batch_size,\n",
        "            \"learning_rate\": self.learning_rate,\n",
        "            \"patience\": self.patience,\n",
        "            \"seed\": self.seed,\n",
        "            \"dropout\": self._dropout,\n",
        "            \"weight_decay\": self.weight_decay,\n",
        "            \"verbose\": self.verbose,\n",
        "            \"ckpt_path\": self.ckpt_path\n",
        "        }\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self\n",
        "\n",
        "def _tensor_state_dict_to(dtype: torch.dtype, state: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "    out = {}\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            # важно: сохраняем в CPU и ровно в dtype (float32 для идентичности)\n",
        "            out[k] = v.detach().to('cpu', dtype=dtype)\n",
        "        else:\n",
        "            out[k] = v\n",
        "    return out\n",
        "\n",
        "\n",
        "def _save_bytes_compressed_zip(file_path: str, bytes_map: Dict[str, bytes], compression=zipfile.ZIP_DEFLATED, compresslevel=9):\n",
        "    with zipfile.ZipFile(file_path, mode='w', compression=compression, compresslevel=compresslevel) as zf:\n",
        "        for name, b in bytes_map.items():\n",
        "            zf.writestr(name, b)\n",
        "\n",
        "\n",
        "def _load_bytes_from_zip(file_path: str) -> Dict[str, bytes]:\n",
        "    out = {}\n",
        "    with zipfile.ZipFile(file_path, mode='r') as zf:\n",
        "        for name in zf.namelist():\n",
        "            out[name] = zf.read(name)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _safe_json_dump(obj: Dict[str, Any]) -> bytes:\n",
        "    def to_builtin(x):\n",
        "        import numpy as _np\n",
        "        import pandas as _pd\n",
        "        if isinstance(x, (_np.integer,)):\n",
        "            return int(x)\n",
        "        if isinstance(x, (_np.floating,)):\n",
        "            return float(x)\n",
        "        if isinstance(x, (_np.ndarray,)):\n",
        "            return x.tolist()\n",
        "        if isinstance(x, (_pd.Timestamp,)):\n",
        "            return x.isoformat()\n",
        "        return x\n",
        "\n",
        "    def convert(v):\n",
        "        if isinstance(v, dict):\n",
        "            return {k: convert(val) for k, val in v.items()}\n",
        "        if isinstance(v, (list, tuple)):\n",
        "            return [convert(i) for i in v]\n",
        "        return to_builtin(v)\n",
        "\n",
        "    return json.dumps(convert(obj), ensure_ascii=False, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "\n",
        "\n",
        "def _safe_json_load(b: bytes) -> Dict[str, Any]:\n",
        "    return json.loads(b.decode(\"utf-8\"))\n",
        "\n",
        "\n",
        "def _extract_tsd_feature_lists(tds) -> Dict[str, Any]:\n",
        "    def g(name, default=None):\n",
        "        return getattr(tds, name, default)\n",
        "\n",
        "    lists = {}\n",
        "    for name in [\n",
        "        \"time_varying_known_reals\",\n",
        "        \"time_varying_unknown_reals\",\n",
        "        \"static_reals\",\n",
        "        \"time_varying_known_categoricals\",\n",
        "        \"time_varying_unknown_categoricals\",\n",
        "        \"static_categoricals\",\n",
        "        \"target_categoricals\",\n",
        "        \"known_reals\",\n",
        "        \"unknown_reals\",\n",
        "        \"known_categoricals\",\n",
        "        \"unknown_categoricals\",\n",
        "        \"reals\",\n",
        "        \"categoricals\",\n",
        "    ]:\n",
        "        val = g(name, None)\n",
        "        if val is not None:\n",
        "            try:\n",
        "                lists[name] = list(val)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return lists\n",
        "\n",
        "\n",
        "def save_transformer(\n",
        "    pipeline: Pipeline,\n",
        "    path: str,\n",
        "    *,\n",
        "    # ЖЁСТКО: float32 по умолчанию для идентичности. Не выставляйте True, пока не сравните предикты.\n",
        "    float16_weights: bool = False,\n",
        "    preprocessing_filename: str = \"preprocessing.joblib.lzma\",\n",
        "    model_zip_filename: str = \"model_weights.zip\",\n",
        "    meta_json_filename: str = \"meta.json\"\n",
        "):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    if not isinstance(pipeline, Pipeline):\n",
        "        raise TypeError(\"Expected sklearn Pipeline\")\n",
        "\n",
        "    steps_dict = dict(pipeline.named_steps)\n",
        "    if \"preprocessing\" not in steps_dict or \"model\" not in steps_dict:\n",
        "        raise ValueError(\"Pipeline must have 'preprocessing' and 'model' steps\")\n",
        "\n",
        "    preprocessing = steps_dict[\"preprocessing\"]\n",
        "    model: SequenceTransformerRegressor = steps_dict[\"model\"]\n",
        "\n",
        "    if model._model is None or model._train_dataset is None:\n",
        "        raise RuntimeError(\"Model must be fitted before saving\")\n",
        "\n",
        "    # 1) preprocessing\n",
        "    prep_path = os.path.join(path, preprocessing_filename)\n",
        "    with lzma.open(prep_path, \"wb\", preset=9) as f:\n",
        "        joblib.dump(preprocessing, f)\n",
        "\n",
        "    # 2) параметры TDS\n",
        "    tds = model._train_dataset\n",
        "    def g(name, default=None):\n",
        "        return getattr(tds, name, default)\n",
        "\n",
        "    train_dataset_params = {\n",
        "        \"time_idx\": g(\"time_idx\", \"time_idx\"),\n",
        "        \"target\": g(\"target\", \"target\"),\n",
        "        \"group_ids\": list(g(\"group_ids\", [\"batch\"])),\n",
        "        \"max_encoder_length\": int(g(\"max_encoder_length\", model.seq_len)),\n",
        "        \"max_prediction_length\": int(g(\"max_prediction_length\", model.pred_len)),\n",
        "        \"target_normalizer\": None,\n",
        "        \"allow_missing_timesteps\": bool(g(\"allow_missing_timesteps\", True)),\n",
        "        \"add_relative_time_idx\": bool(g(\"add_relative_time_idx\", True)),\n",
        "        \"add_target_scales\": bool(g(\"add_target_scales\", False)),\n",
        "        \"add_encoder_length\": bool(g(\"add_encoder_length\", True)),\n",
        "        \"min_prediction_length\": int(g(\"min_prediction_length\", 1)),\n",
        "        \"min_encoder_length\": int(g(\"min_encoder_length\", 0)),\n",
        "    }\n",
        "    feature_lists = _extract_tsd_feature_lists(tds)\n",
        "\n",
        "    # 3) веса TFT — строго в float32 (если float16_weights=False)\n",
        "    tft = model._model.tft\n",
        "    state = tft.state_dict()\n",
        "    dtype = torch.float16 if float16_weights else torch.float32\n",
        "    state = _tensor_state_dict_to(dtype, state)\n",
        "    buf = io.BytesIO()\n",
        "    torch.save(state, buf, _use_new_zipfile_serialization=True)\n",
        "    buf.seek(0)\n",
        "    weights_zip_path = os.path.join(path, model_zip_filename)\n",
        "    _save_bytes_compressed_zip(weights_zip_path, {\"tft_state_dict.pt\": buf.getvalue()})\n",
        "\n",
        "    # 4) метаданные\n",
        "    meta = {\n",
        "        \"class\": \"SequenceTransformerRegressor\",\n",
        "        \"params\": {\n",
        "            \"seq_len\": model.seq_len,\n",
        "            \"pred_len\": model.pred_len,\n",
        "            \"hidden_size\": model.hidden_size,\n",
        "            \"hidden_continuous_size\": model.hidden_continuous_size,\n",
        "            \"epochs\": model.epochs,\n",
        "            \"batch_size\": model.batch_size,\n",
        "            \"learning_rate\": model.learning_rate,\n",
        "            \"patience\": model.patience,\n",
        "            \"seed\": model.seed,\n",
        "            \"dropout\": model._dropout,\n",
        "            \"weight_decay\": model.weight_decay,\n",
        "            \"verbose\": model.verbose,\n",
        "            \"mask_prob\": model.mask_prob,\n",
        "            \"infer_stride\": model.infer_stride,\n",
        "            \"ckpt_path\": None,\n",
        "            \"min_encoder_length\": model.min_encoder_length,\n",
        "            \"lstm_layers\": 3,\n",
        "            \"attention_head_size\": 4,\n",
        "            \"output_size\": 1,\n",
        "        },\n",
        "        \"feature_columns\": model._feature_columns,\n",
        "        \"n_transformed\": model._n_transformed,\n",
        "        \"n_feat\": model._n_feat,\n",
        "        \"global_stats\": {\n",
        "            \"global_target_mean\": model.global_target_mean,\n",
        "            \"global_target_std\": model.global_target_std,\n",
        "            \"global_target_min\": model.global_target_min,\n",
        "            \"global_target_max\": model.global_target_max,\n",
        "            \"global_range\": model.global_range,\n",
        "            \"soft_clip_scale\": model.soft_clip_scale,\n",
        "            \"clip_scale\": model.clip_scale,\n",
        "        },\n",
        "        \"train_dataset_params\": train_dataset_params,\n",
        "        \"feature_lists\": feature_lists,\n",
        "        \"torch_dtype\": \"float16\" if float16_weights else \"float32\",\n",
        "        \"preproc_feature_names_out\": list(getattr(preprocessing, \"get_feature_names_out\", lambda: [])()),\n",
        "    }\n",
        "\n",
        "    meta_path = os.path.join(path, meta_json_filename)\n",
        "    with open(meta_path, \"wb\") as f:\n",
        "        f.write(_safe_json_dump(meta))\n",
        "\n",
        "    weights_size_mb = os.path.getsize(weights_zip_path) / (1024 * 1024)\n",
        "    prep_size_mb = os.path.getsize(prep_path) / (1024 * 1024)\n",
        "    meta_size_kb = os.path.getsize(meta_path) / 1024.0\n",
        "    print(f\"Saved: weights={weights_size_mb:.2f} MB, preprocessing={prep_size_mb:.2f} MB, meta={meta_size_kb:.1f} KB → dir={path}\")\n",
        "\n",
        "# Требуется наличие в окружении:\n",
        "# - SequenceTransformerRegressor\n",
        "# - TimeSeriesDataSet\n",
        "# - CustomTFT, TFTAdapter\n",
        "# - tft_output_transformer\n",
        "# - PeakFriendlyHuber\n",
        "# - to_dense\n",
        "# - вспомогательные функции _load_bytes_from_zip, _safe_json_load из предыдущей версии\n",
        "\n",
        "\n",
        "def load_transformer_exact(\n",
        "    path: str,\n",
        "    *,\n",
        "    preprocessing_filename: str = \"preprocessing.joblib.lzma\",\n",
        "    model_zip_filename: str = \"model_weights.zip\",\n",
        "    meta_json_filename: str = \"meta.json\",\n",
        "    device: Optional[str] = None,\n",
        ") -> Pipeline:\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\", message=\".*Attribute 'loss' is an instance of `nn.Module`.*\")\n",
        "    warnings.filterwarnings(\"ignore\", message=\".*Attribute 'logging_metrics' is an instance of `nn.Module`.*\")\n",
        "\n",
        "    # 1) preprocessing\n",
        "    prep_path = os.path.join(path, preprocessing_filename)\n",
        "    with lzma.open(prep_path, \"rb\") as f:\n",
        "        preprocessing = joblib.load(f)\n",
        "\n",
        "    # 2) meta\n",
        "    meta_path = os.path.join(path, meta_json_filename)\n",
        "    if not os.path.isfile(meta_path):\n",
        "        raise FileNotFoundError(meta_path)\n",
        "    with open(meta_path, \"rb\") as f:\n",
        "        meta = json.loads(f.read().decode(\"utf-8\"))\n",
        "\n",
        "    params = meta[\"params\"]\n",
        "    feature_columns = meta[\"feature_columns\"]\n",
        "    n_transformed = meta[\"n_transformed\"]\n",
        "    n_feat = meta[\"n_feat\"]\n",
        "    global_stats = meta[\"global_stats\"]\n",
        "    tds_params = meta[\"train_dataset_params\"]\n",
        "    feature_lists = meta.get(\"feature_lists\", {})\n",
        "    saved_torch_dtype = meta.get(\"torch_dtype\", \"float32\")\n",
        "\n",
        "    # 3) регрессор\n",
        "    model = SequenceTransformerRegressor(\n",
        "        seq_len=params[\"seq_len\"],\n",
        "        pred_len=params[\"pred_len\"],\n",
        "        hidden_size=params[\"hidden_size\"],\n",
        "        hidden_continuous_size=params[\"hidden_continuous_size\"],\n",
        "        epochs=params[\"epochs\"],\n",
        "        batch_size=params[\"batch_size\"],\n",
        "        learning_rate=params[\"learning_rate\"],\n",
        "        patience=params[\"patience\"],\n",
        "        seed=params[\"seed\"],\n",
        "        dropout=params[\"dropout\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        verbose=params[\"verbose\"],\n",
        "        mask_prob=params[\"mask_prob\"],\n",
        "        infer_stride=params[\"infer_stride\"],\n",
        "        ckpt_path=None,\n",
        "        preprocessing=preprocessing,\n",
        "        min_encoder_length=params.get(\"min_encoder_length\", 1),\n",
        "    )\n",
        "\n",
        "    model._feature_columns = feature_columns\n",
        "    model._n_transformed = n_transformed\n",
        "    model._n_feat = n_feat\n",
        "    model.global_target_mean = float(global_stats[\"global_target_mean\"])\n",
        "    model.global_target_std = float(global_stats[\"global_target_std\"])\n",
        "    model.global_target_min = float(global_stats[\"global_target_min\"])\n",
        "    model.global_target_max = float(global_stats[\"global_target_max\"])\n",
        "    model.global_range = float(global_stats[\"global_range\"])\n",
        "    model.soft_clip_scale = float(global_stats[\"soft_clip_scale\"])\n",
        "    model.clip_scale = float(global_stats.get(\"clip_scale\", 1.5))\n",
        "    model.device = device\n",
        "\n",
        "    # 4) синтетический df\n",
        "    max_enc = int(tds_params[\"max_encoder_length\"])\n",
        "    max_pred = int(tds_params[\"max_prediction_length\"])\n",
        "    num_feat_cols = len(feature_columns)\n",
        "    rows = max_enc + max_pred\n",
        "\n",
        "    synth_df_base = pd.DataFrame(\n",
        "        np.zeros((rows, num_feat_cols), dtype=np.float32),\n",
        "        columns=feature_columns,\n",
        "    )\n",
        "    synth_df_base[\"time_idx\"] = np.arange(rows, dtype=np.int64)\n",
        "    synth_df_base[\"target\"] = np.zeros(rows, dtype=np.float32)\n",
        "    synth_df_base[\"batch\"] = 0\n",
        "\n",
        "    # Попытка №1: «обычная» конструкция TDS как при обучении\n",
        "    tds_kwargs = dict(\n",
        "        time_idx=tds_params[\"time_idx\"],\n",
        "        target=tds_params[\"target\"],\n",
        "        group_ids=tds_params[\"group_ids\"],\n",
        "        max_encoder_length=tds_params[\"max_encoder_length\"],\n",
        "        max_prediction_length=tds_params[\"max_prediction_length\"],\n",
        "        target_normalizer=None,\n",
        "        allow_missing_timesteps=tds_params[\"allow_missing_timesteps\"],\n",
        "        add_relative_time_idx=tds_params[\"add_relative_time_idx\"],\n",
        "        add_target_scales=tds_params[\"add_target_scales\"],\n",
        "        add_encoder_length=tds_params[\"add_encoder_length\"],\n",
        "        min_prediction_length=tds_params[\"min_prediction_length\"],\n",
        "        min_encoder_length=tds_params.get(\"min_encoder_length\", 0),\n",
        "    )\n",
        "\n",
        "    if \"time_varying_unknown_reals\" in feature_lists:\n",
        "        tds_kwargs[\"time_varying_unknown_reals\"] = list(feature_lists[\"time_varying_unknown_reals\"])\n",
        "    else:\n",
        "        tds_kwargs[\"time_varying_unknown_reals\"] = list(feature_columns)\n",
        "\n",
        "    for key in [\n",
        "        \"time_varying_known_reals\",\n",
        "        \"static_reals\",\n",
        "        \"time_varying_known_categoricals\",\n",
        "        \"time_varying_unknown_categoricals\",\n",
        "        \"static_categoricals\",\n",
        "        \"known_reals\",\n",
        "        \"unknown_reals\",\n",
        "        \"known_categoricals\",\n",
        "        \"unknown_categoricals\",\n",
        "    ]:\n",
        "        if key in feature_lists:\n",
        "            tds_kwargs[key] = list(feature_lists[key])\n",
        "\n",
        "    dataset = TimeSeriesDataSet(synth_df_base.copy(), **tds_kwargs)\n",
        "\n",
        "    # Проверяем порядок reals\n",
        "    saved_reals = feature_lists.get(\"reals\")\n",
        "    rebuild_forced = False\n",
        "    if saved_reals is not None:\n",
        "        # В PF список dataset.reals может быть кортежами/объектами -- приводим к строкам\n",
        "        ds_reals = list(getattr(dataset, \"reals\", []))\n",
        "        ds_reals = [str(x) for x in ds_reals]\n",
        "        saved_reals_str = [str(x) for x in saved_reals]\n",
        "        if ds_reals != saved_reals_str:\n",
        "            rebuild_forced = True\n",
        "\n",
        "    if rebuild_forced:\n",
        "        # Попытка №2: Форсируем порядок каналов reals.\n",
        "        # Для этого отключим автоматические добавления и сами сгенерируем служебные колонки\n",
        "        # encoder_length и relative_time_idx в synth_df.\n",
        "        synth_df = synth_df_base.copy()\n",
        "        # relative_time_idx: от 0 до rows-1\n",
        "        synth_df[\"relative_time_idx\"] = np.arange(rows, dtype=np.int64)\n",
        "        # encoder_length: длина encoder для каждой позиции; для синтетики можно установить константу max_enc\n",
        "        # PF ожидает целочисленную encoder_length, соответствующую длине энкодера на каждом шаге.\n",
        "        # Для инициализации архитектуры достаточно положить валидные числа.\n",
        "        enc_len = np.zeros(rows, dtype=np.int64)\n",
        "        enc_len[:max_enc] = np.arange(1, max_enc + 1, dtype=np.int64)\n",
        "        enc_len[max_enc:] = max_enc\n",
        "        synth_df[\"encoder_length\"] = enc_len\n",
        "\n",
        "        # Теперь задаём TDS без add_* фичей, и передаём time_varying_unknown_reals в порядке saved_reals.\n",
        "        # saved_reals начинается с [\"encoder_length\",\"relative_time_idx\", ... f0..fN]\n",
        "        tds_kwargs_forced = dict(\n",
        "            time_idx=tds_params[\"time_idx\"],\n",
        "            target=tds_params[\"target\"],\n",
        "            group_ids=tds_params[\"group_ids\"],\n",
        "            max_encoder_length=tds_params[\"max_encoder_length\"],\n",
        "            max_prediction_length=tds_params[\"max_prediction_length\"],\n",
        "            target_normalizer=None,\n",
        "            allow_missing_timesteps=tds_params[\"allow_missing_timesteps\"],\n",
        "            add_relative_time_idx=False,\n",
        "            add_target_scales=tds_params[\"add_target_scales\"],\n",
        "            add_encoder_length=False,\n",
        "            min_prediction_length=tds_params[\"min_prediction_length\"],\n",
        "            min_encoder_length=tds_params.get(\"min_encoder_length\", 0),\n",
        "            time_varying_unknown_reals=list(saved_reals),  # порядок каналов фиксируем здесь\n",
        "            # Не задаём known/unknown cats/reals дополнительно, чтобы не нарушить порядок\n",
        "        )\n",
        "        dataset = TimeSeriesDataSet(synth_df, **tds_kwargs_forced)\n",
        "\n",
        "        # Контроль: проверим снова порядок\n",
        "        ds_reals2 = [str(x) for x in list(getattr(dataset, \"reals\", []))]\n",
        "        if ds_reals2 != [str(x) for x in saved_reals]:\n",
        "            raise RuntimeError(\n",
        "                f\"Failed to force reals order. Got {ds_reals2[:8]}..., expected {list(saved_reals)[:8]}...\"\n",
        "            )\n",
        "\n",
        "    # 5) TFT 1-в-1\n",
        "    tft = CustomTFT.from_dataset(\n",
        "        dataset,\n",
        "        hidden_size=int(model.hidden_size),\n",
        "        output_size=int(params.get(\"output_size\", 1)),\n",
        "        loss=PeakFriendlyHuber(\n",
        "            delta=0.5,\n",
        "            peak_thr=0.85,\n",
        "            peak_weight=1.3,\n",
        "            contrast_weight=0.03,\n",
        "            center_band=0.3,\n",
        "            clip_scale=1.5,\n",
        "        ),\n",
        "        optimizer=\"adam\",\n",
        "        learning_rate=float(model.learning_rate),\n",
        "        lstm_layers=int(params.get(\"lstm_layers\", 3)),\n",
        "        hidden_continuous_size=int(model.hidden_continuous_size),\n",
        "        attention_head_size=int(params.get(\"attention_head_size\", 4)),\n",
        "        dropout=float(model._dropout),\n",
        "        reduce_on_plateau_patience=5,\n",
        "        reduce_on_plateau_min_lr=1e-6,\n",
        "        weight_decay=float(model.weight_decay),\n",
        "        mask_prob=float(model.mask_prob),\n",
        "        output_transformer=tft_output_transformer,\n",
        "    )\n",
        "\n",
        "    model._model = TFTAdapter(tft)\n",
        "    model._train_dataset = dataset\n",
        "\n",
        "    # 6) загрузка весов\n",
        "    weights_zip_path = os.path.join(path, model_zip_filename)\n",
        "    with zipfile.ZipFile(weights_zip_path, mode='r') as zf:\n",
        "        if \"tft_state_dict.pt\" not in zf.namelist():\n",
        "            raise RuntimeError(\"tft_state_dict.pt not found in weights zip\")\n",
        "        state = torch.load(io.BytesIO(zf.read(\"tft_state_dict.pt\")), map_location=\"cpu\")\n",
        "\n",
        "    missing, unexpected = tft.load_state_dict(state, strict=False)\n",
        "    if missing or unexpected:\n",
        "        warnings.warn(f\"load_state_dict: missing={missing}, unexpected={unexpected}\")\n",
        "\n",
        "    # 7) eval + dropout off\n",
        "    tft.eval()\n",
        "    for m in tft.modules():\n",
        "        if isinstance(m, torch.nn.Dropout):\n",
        "            m.p = 0.0\n",
        "\n",
        "    model._model.to(device)\n",
        "\n",
        "    restored = Pipeline([\n",
        "        (\"preprocessing\", preprocessing),\n",
        "        (\"to_dense\", FunctionTransformer(to_dense)),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "    return restored\n",
        "\n",
        "def apply_linear_calibration(y_pred: np.ndarray, calib: dict) -> np.ndarray:\n",
        "    a, b = calib.get('a', 1.0), calib.get('b', 0.0)\n",
        "    return a * np.ravel(y_pred) + b\n",
        "\n",
        "def ranker_postprocess_minus1_1(y_pred_ranker: np.ndarray) -> np.ndarray:\n",
        "    yp = np.ravel(y_pred_ranker)\n",
        "    return 2.0 * ((yp + 15.0) / (5.0 + 15.0)) - 1.0\n",
        "\n",
        "def load_optimized_pipeline(out_dir, model_type='regressor'):\n",
        "    \"\"\"\n",
        "    Загружает оптимизированный pipeline.\n",
        "    Возвращает полный pipe.\n",
        "    \"\"\"\n",
        "    # Загружаем preproc\n",
        "    preproc_file = f'preproc_{model_type}.pkl' if model_type == 'ranker' else 'preproc.pkl'\n",
        "    preproc = joblib.load(os.path.join(out_dir, preproc_file))\n",
        "\n",
        "    # Booster из gz\n",
        "    gz_file = os.path.join(out_dir, f'{model_type}.txt.gz')\n",
        "    temp_file = os.path.join(out_dir, f'temp_{model_type}.txt')\n",
        "    with gzip.open(gz_file, 'rb') as f_in:\n",
        "        with open(temp_file, 'wb') as f_out:\n",
        "            f_out.write(f_in.read())\n",
        "    booster = lgb.Booster(model_file=temp_file)\n",
        "    os.remove(temp_file)\n",
        "\n",
        "    # Реконструируем модель (LGBM wrapper)\n",
        "    step_name = 'model' if model_type == 'regressor' else 'ranker'\n",
        "    if model_type == 'regressor':\n",
        "        model = lgb.LGBMRegressor()\n",
        "    elif model_type == 'ranker':\n",
        "        model = lgb.LGBMRanker()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model_type\")\n",
        "\n",
        "    model._Booster = booster\n",
        "    model.fitted_ = True  # Отметить как обученную\n",
        "    # Устанавливаем n_features_in_ из booster\n",
        "    model.n_features_in_ = booster.num_feature()\n",
        "\n",
        "    # Полный pipe\n",
        "    pipe = Pipeline([\n",
        "        ('preprocessing', preproc),\n",
        "        ('to_dense', FunctionTransformer(to_dense, feature_names_out=\"one-to-one\")),\n",
        "        (step_name, model),\n",
        "    ])\n",
        "\n",
        "    return pipe\n",
        "\n",
        "def load_model_for_ticker(ticker, models_dir=r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\models'):\n",
        "    \"\"\"\n",
        "    Загружает модель(и) для тикера из директории models//.\n",
        "    Возвращает dict с: pipe_reg, pipe_rank (если combined), meta, threshold.\n",
        "    \"\"\"\n",
        "    out_dir = os.path.join(models_dir, ticker)\n",
        "    if not os.path.exists(out_dir):\n",
        "        raise FileNotFoundError(f\"Directory for {ticker} not found: {out_dir}\")\n",
        "\n",
        "    # Загружаем meta\n",
        "    with open(os.path.join(out_dir, 'meta.json'), 'r') as f:\n",
        "        meta = json.load(f)\n",
        "\n",
        "    best_method = meta['best_method']\n",
        "    thresh = meta.get('sell_threshold', 0.0)  # Fallback\n",
        "\n",
        "    pipe_reg = None\n",
        "    pipe_rank = None\n",
        "\n",
        "    if best_method == 'regressor':\n",
        "        pipe_reg = load_optimized_pipeline(out_dir, 'regressor')\n",
        "\n",
        "    elif best_method == 'ranker':\n",
        "        pipe_rank = load_optimized_pipeline(out_dir, 'ranker')\n",
        "\n",
        "    elif best_method == 'combined':\n",
        "        pipe_reg = load_optimized_pipeline(out_dir, 'regressor')\n",
        "        pipe_rank = load_optimized_pipeline(out_dir, 'ranker')\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown best_method: {best_method}\")\n",
        "\n",
        "    return {\n",
        "        'best_method': best_method,\n",
        "        'pipe_reg': pipe_reg,\n",
        "        'pipe_rank': pipe_rank,\n",
        "        'meta': meta,\n",
        "        'threshold': thresh,\n",
        "        'calib_reg': meta.get('reg_calibration', {'a': 1.0, 'b': 0.0}),\n",
        "        'w_reg': meta.get('best_w_reg', 0.5) if best_method == 'combined' else None\n",
        "    }\n",
        "\n",
        "def extract_features(df: pd.DataFrame, window: int = 126):\n",
        "    \"\"\"\n",
        "    Вычисляет устойчивые признаки для кластеризации рыночных режимов.\n",
        "    \"\"\"\n",
        "\n",
        "    def calculate_macd(df, macd_fast_periods=[12], macd_slow_periods=[26], macd_signal_periods=[9]):\n",
        "        \"\"\"\n",
        "        Быстрый расчет нормализованного MACD с использованием векторизованных операций\n",
        "        \"\"\"\n",
        "        close = df['close']\n",
        "\n",
        "        # Создаем множества для уникальных периодов\n",
        "        unique_fast = set(macd_fast_periods)\n",
        "        unique_slow = set(macd_slow_periods)\n",
        "\n",
        "\n",
        "        # Предварительно вычисляем все необходимые EMA и скользящие средние\n",
        "        ema_cache = {}\n",
        "        rolling_cache = {}\n",
        "\n",
        "        # Кешируем быстрые EMA\n",
        "        for fp in unique_fast:\n",
        "            ema_cache[f'ema_{fp}'] = close.ewm(span=fp, adjust=False).mean()\n",
        "\n",
        "        # Кешируем медленные EMA и скользящие средние\n",
        "        for sp in unique_slow:\n",
        "            ema_cache[f'ema_{sp}'] = close.ewm(span=sp, adjust=False).mean()\n",
        "            rolling_cache[f'rolling_{sp}'] = close.rolling(window=sp).mean()\n",
        "\n",
        "        # Основной цикл вычислений\n",
        "        for fp in macd_fast_periods:\n",
        "            ema_fast = ema_cache[f'ema_{fp}']\n",
        "            for sp in macd_slow_periods:\n",
        "                ema_slow = ema_cache[f'ema_{sp}']\n",
        "                rolling_mean = rolling_cache[f'rolling_{sp}']\n",
        "\n",
        "                # Вычисляем MACD и нормализацию\n",
        "                macd = ema_fast - ema_slow\n",
        "                macd_norm = macd / rolling_mean\n",
        "\n",
        "                # Сохраняем MACD только один раз для комбинации fp/sp\n",
        "\n",
        "                # Обрабатываем сигнальные периоды\n",
        "                for sig in macd_signal_periods:\n",
        "                    # Вычисляем сигнальную линию\n",
        "                    signal = macd.ewm(span=sig, adjust=False).mean()\n",
        "                    signal_norm = signal / rolling_mean\n",
        "\n",
        "        return pd.DataFrame([macd_norm, signal_norm, macd_norm - signal_norm]).T.fillna(0)\n",
        "\n",
        "    def calculate_atr(df, atr_window=14):\n",
        "        \"\"\"\n",
        "        Расчет ATR и его сдвигов.\n",
        "        \"\"\"\n",
        "        high = df['high']\n",
        "        low = df['low']\n",
        "        close = df['close']\n",
        "\n",
        "        tr1 = high - low\n",
        "        tr2 = np.abs(high - close.shift(1))\n",
        "        tr3 = np.abs(low - close.shift(1))\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        atr = tr.rolling(atr_window).mean()\n",
        "\n",
        "        return pd.Series(atr).fillna(0)\n",
        "\n",
        "    def calculate_rsi(df, rsi_period=14):\n",
        "        \"\"\"\n",
        "        Расчет RSI и его сдвиги.\n",
        "        \"\"\"\n",
        "        close = df['close']\n",
        "        delta = close.diff()\n",
        "        gain = delta.where(delta > 0, 0)\n",
        "        loss = -delta.where(delta < 0, 0)\n",
        "        avg_gain = gain.rolling(rsi_period).mean()\n",
        "        avg_loss = loss.rolling(rsi_period).mean()\n",
        "        rs = avg_gain / (avg_loss + 1e-10)\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "        return pd.Series(rsi).fillna(0)\n",
        "\n",
        "    def calculate_bollinger_bands(df, bollinger_window=20):\n",
        "        \"\"\"\n",
        "        Расчет Bollinger Bands (ширины полос) и сдвигов.\n",
        "        \"\"\"\n",
        "        close = df['close']\n",
        "        ma = close.rolling(bollinger_window).mean()\n",
        "        std = close.rolling(bollinger_window).std()\n",
        "        bb_width = (2 * std) / ma\n",
        "\n",
        "        return pd.Series(bb_width).fillna(0)\n",
        "\n",
        "    macd_trend = calculate_macd(df, macd_slow_periods=[window], macd_fast_periods=[window//3],\n",
        "                                 macd_signal_periods=[window//6])\n",
        "    atr = calculate_atr(df, atr_window=window)\n",
        "    rel_volatility = atr / df[\"close\"]\n",
        "    rsi_ind = calculate_rsi(df, rsi_period=window//2)\n",
        "    volume_ratio = df['volume'].rolling(window).apply(\n",
        "        lambda x: x[-1]/x.mean(), raw=True\n",
        "    ).fillna(1).values\n",
        "\n",
        "    features = np.column_stack([\n",
        "        macd_trend,\n",
        "        rel_volatility,\n",
        "        rsi_ind,\n",
        "        volume_ratio\n",
        "    ])\n",
        "\n",
        "    return features\n",
        "\n",
        "def prepare_regime_params(optuna_params):\n",
        "    \"\"\"\n",
        "    Преобразует параметры из формата Optuna в два словаря: базовые параметры режимов и параметры расчета.\n",
        "\n",
        "    Args:\n",
        "        optuna_params (dict): Словарь с параметрами из Optuna\n",
        "\n",
        "    Returns:\n",
        "        dict: Словарь с двумя ключами: 'base_params' (параметры режимов) и 'calc_params' (остальные параметры)\n",
        "    \"\"\"\n",
        "    # Инициализируем словари для базовых параметров и параметров расчета\n",
        "    start_params = {}\n",
        "    base_params = {}\n",
        "    calc_params = {}\n",
        "\n",
        "    # Сначала обрабатываем параметры режимов (0-4)\n",
        "\n",
        "    start_params['moving_average_length'] = optuna_params.get('moving_average_length', 14)\n",
        "    start_params['atr_period'] = optuna_params.get('atr_period', 10)\n",
        "    for regime in range(5):\n",
        "        regime_key = f'regime_{regime}_'\n",
        "        regime_params = {}\n",
        "\n",
        "        # Основные параметры режима\n",
        "        regime_params['average_type'] = optuna_params.get(f'{regime_key}average_type', 'SMA')\n",
        "        regime_params['moving_average_length'] = optuna_params.get(f'{regime_key}ma_length', 50)\n",
        "        regime_params['atr_period'] = optuna_params.get(f'{regime_key}atr_period', 14)\n",
        "        regime_params['atr_multiplier'] = optuna_params.get(f'{regime_key}atr_multiplier', 3.0)\n",
        "\n",
        "        # Параметры AMA, если они есть\n",
        "        ama_atr_period = optuna_params.get(f'{regime_key}ama_atr_period')\n",
        "        ama_min_period = optuna_params.get(f'{regime_key}ama_min_period')\n",
        "        ama_max_period = optuna_params.get(f'{regime_key}ama_max_period')\n",
        "\n",
        "        if regime_params['average_type'] == 'AMA' and all(p is not None for p in [ama_atr_period, ama_min_period, ama_max_period]):\n",
        "            regime_params['ama_params'] = {\n",
        "                'atr_period': int(ama_atr_period),\n",
        "                'min_period': int(ama_min_period),\n",
        "                'max_period': int(ama_max_period)\n",
        "            }\n",
        "\n",
        "        base_params[regime] = regime_params\n",
        "\n",
        "    # Теперь собираем все остальные параметры в calc_params\n",
        "    other_params = [\n",
        "        'rsi_length', 'use_smoothing', 'smoothing_length', 'smoothing_type',\n",
        "        'alma_sigma', 'rsi_overbought', 'rsi_oversold', 'use_knn',\n",
        "        'knn_neighbors', 'knn_lookback', 'knn_weight', 'feature_count',\n",
        "        'use_filter', 'filter_method', 'filter_strength', 'sma_length',\n",
        "        'ema_length', 'rsi_helbuth'\n",
        "    ]\n",
        "\n",
        "    for param in other_params:\n",
        "        if param in optuna_params:\n",
        "            calc_params[param] = optuna_params[param]\n",
        "\n",
        "    return {\n",
        "        'start_params': start_params,\n",
        "        'base_params': base_params,\n",
        "        'calc_params': calc_params\n",
        "    }\n",
        "\n",
        "class FastRollingMode:\n",
        "    def __init__(self, window_size):\n",
        "        self.window = deque(maxlen=window_size)\n",
        "        self.counts = {}\n",
        "\n",
        "    def update(self, new_val):\n",
        "        if len(self.window) == self.window.maxlen:\n",
        "            old_val = self.window.popleft()\n",
        "            self.counts[old_val] -= 1\n",
        "            if self.counts[old_val] == 0:\n",
        "                del self.counts[old_val]\n",
        "\n",
        "        self.window.append(new_val)\n",
        "        self.counts[new_val] = self.counts.get(new_val, 0) + 1\n",
        "        return max(self.counts.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "MODELS_CACHE = ModelsRuntimeCache()\n",
        "\n",
        "class TradingBot:\n",
        "    def __init__(self, token, tickers, data_path, interval, timeframe_minutes, data_points):\n",
        "        self.token = token\n",
        "        self.tickers = tickers\n",
        "        self.data_path = data_path\n",
        "        self.interval = interval\n",
        "        self.timeframe_minutes = timeframe_minutes\n",
        "        self.data_points = data_points\n",
        "\n",
        "        # Маппинг тикеров и FIGI\n",
        "        self.ticker_to_figi = {}\n",
        "        self.figi_to_ticker = {}\n",
        "\n",
        "        # Исторические данные\n",
        "        self.open_price = open_price\n",
        "        self.close_price = close_price\n",
        "        self.high_price = high_price\n",
        "        self.low_price = low_price\n",
        "        self.volume = volume\n",
        "        self.time_last_kline_start = time_last_kline_start\n",
        "        self.time_last_kline_end = time_last_kline_end\n",
        "        self.ma = ma\n",
        "        self.pmax = pmax\n",
        "        self.signals = signals\n",
        "        self.close_preds = close_preds\n",
        "\n",
        "        self.active_tickers = {}\n",
        "\n",
        "        self._smoothers       = {}    # ticker → FastRollingMode\n",
        "        self._regime_history  = {}    # ticker → deque[int]\n",
        "        self._adaptive_params = {}\n",
        "        self._regime_hist    = {}\n",
        "\n",
        "\n",
        "        self.api_limits = {\n",
        "            'remaining': 600,\n",
        "            'reset_time': None,\n",
        "            'last_request': None\n",
        "        }\n",
        "\n",
        "        # Создать папку для сохранения данных, если её нет\n",
        "        if not os.path.exists(self.data_path):\n",
        "            os.makedirs(self.data_path)\n",
        "\n",
        "    async def calculate_indicators_and_signals(self, df, ticker):\n",
        "        # 0) Читаем цену\n",
        "        high_arr = df['high'].copy()\n",
        "        low_arr = df['low'].copy()\n",
        "        close_arr = df['close'].copy()\n",
        "        vol_arr = df['volume'].copy()\n",
        "\n",
        "        logging.debug(f\"high_data: {high_arr}\")\n",
        "        logging.debug(f\"low_data: {low_arr}\")\n",
        "        logging.debug(f\"close_data: {close_arr}\")\n",
        "\n",
        "        if len(high_arr) < 2 or len(low_arr) < 2 or len(close_arr) < 2:\n",
        "            return\n",
        "\n",
        "        n = high_arr.shape[0]\n",
        "\n",
        "        # 1) Режимная часть: кластерим + сглаживаем\n",
        "        params       = phase_ticker_params[ticker]['params']\n",
        "        # размер окна для признаков\n",
        "        window_feat  = int(params['moving_average_length'] * 9.5)\n",
        "        # формируем DataFrame-мини-окно для extract_features\n",
        "        import pandas as pd\n",
        "        hist_df = pd.DataFrame({\n",
        "            'high':   high_arr,\n",
        "            'low':    low_arr,\n",
        "            'close':  close_arr,\n",
        "            'volume': vol_arr\n",
        "        })\n",
        "        features = extract_features(hist_df, window=window_feat)  # ваша функция\n",
        "        # scale + predict\n",
        "        scaled = scaler_global.transform(features)\n",
        "        labels = kmeans_global.predict(scaled)\n",
        "\n",
        "        # сглаживаем\n",
        "        window_smooth = int(params['atr_period'] * 5.5)\n",
        "        smoother = FastRollingMode(window_size=window_smooth)\n",
        "        regimes = np.array([smoother.update(l) for l in labels], dtype=int)\n",
        "\n",
        "        # 2) Готовим базовые параметры по режиму\n",
        "        regime_params = prepare_regime_params(params)['base_params']\n",
        "\n",
        "        # 3) PRE-COMPUTE MA & ATR для каждого режима\n",
        "        ma_cache  = {}\n",
        "        atr_cache = {}\n",
        "        for regime, p in regime_params.items():\n",
        "            atype = p['average_type']\n",
        "            L     = p['moving_average_length']\n",
        "            P     = p['atr_period']\n",
        "\n",
        "            if atype == 'SMA':\n",
        "                ma = self.generateSma(high_arr, low_arr, window=L)\n",
        "            elif atype == 'VAR':\n",
        "                ma = self.generateVar(high_arr, low_arr, moving_average_length=L)\n",
        "            elif atype == 'EMA':\n",
        "                ma = self.generateEma(high_arr, low_arr, moving_average_length=L)\n",
        "            elif atype == 'AMA':\n",
        "                ama_p = p.get('ama_params', {'atr_period':14,'min_period':5,'max_period':50})\n",
        "                ma = self.generateAma(\n",
        "                    high_arr, low_arr, close_arr,\n",
        "                    atr_period=ama_p['atr_period'],\n",
        "                    min_period=ama_p['min_period'],\n",
        "                    max_period=ama_p['max_period']\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown MA type {atype!r}\")\n",
        "\n",
        "            ma_cache[regime]  = ma\n",
        "            atr_cache[regime] = self.generateAtr(high_arr, low_arr, close_arr, length=P)\n",
        "\n",
        "        # 4) MERGE по маске режимов\n",
        "        var_all = np.empty(n, dtype=float)\n",
        "        atr_all = np.empty(n, dtype=float)\n",
        "        mul_all = np.empty(n, dtype=float)\n",
        "\n",
        "        for regime, p in regime_params.items():\n",
        "            mask = (regimes == regime)\n",
        "            var_all[mask] = ma_cache[regime][mask]\n",
        "            atr_all[mask] = atr_cache[regime][mask]\n",
        "            mul_all[mask] = p['atr_multiplier']\n",
        "\n",
        "        # Заполняем NAN в начале var_all\n",
        "        if np.isnan(var_all[0]):\n",
        "            first = var_all[~np.isnan(var_all)][0]\n",
        "            var_all[np.isnan(var_all)] = first\n",
        "\n",
        "        # 5) PMax state machine\n",
        "        atr_all = np.nan_to_num(atr_all, nan=0.0)\n",
        "        first_var = var_all[~np.isnan(var_all)][0]\n",
        "        var_all = np.nan_to_num(var_all, nan=first_var)\n",
        "        pmax_all = np.empty(n, dtype=float)\n",
        "        prev_v   = var_all[0]\n",
        "        prev_a   = atr_all[0]\n",
        "        prev_m   = mul_all[0]\n",
        "        prev_fu  = prev_v + prev_m * prev_a\n",
        "        prev_fl  = prev_v - prev_m * prev_a\n",
        "        prev_p   = prev_fl\n",
        "        pmax_all[0] = prev_p\n",
        "\n",
        "        for i in range(1, n):\n",
        "            v = var_all[i]; a = atr_all[i]; m = mul_all[i]\n",
        "            bu = v + m * a\n",
        "            bl = v - m * a\n",
        "\n",
        "            fu = bu if (bu < prev_fu or prev_v > prev_fu) else prev_fu\n",
        "            fl = bl if (bl > prev_fl or prev_v < prev_fl) else prev_fl\n",
        "\n",
        "            if prev_p == prev_fu:\n",
        "                p = fu if v <= fu else fl\n",
        "            else:\n",
        "                p = fl if v >= fl else fu\n",
        "\n",
        "            pmax_all[i] = p\n",
        "            prev_v, prev_fu, prev_fl, prev_p = v, fu, fl, p\n",
        "\n",
        "        # 7. Сигналы\n",
        "        v_prev = np.concatenate(([var_all[0]], var_all[:-1]))\n",
        "        p_prev = np.concatenate(([pmax_all[0]], pmax_all[:-1]))\n",
        "        buy = (v_prev < p_prev) & (var_all > pmax_all)\n",
        "        sell = (v_prev > p_prev) & (var_all < pmax_all)\n",
        "\n",
        "\n",
        "        self.ma[ticker] = var_all\n",
        "        self.pmax[ticker] = pmax_all\n",
        "\n",
        "\n",
        "        try:\n",
        "            signal = self.generate_signal(var_all[-2:], pmax_all[-2:])\n",
        "            logging.debug(f\"Сигнал для {ticker}: {signal}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при генерации сигнала для тикера {ticker}: {e}\")\n",
        "            return\n",
        "\n",
        "        # Сохраняем сигнал\n",
        "        self.signals[ticker] = signal\n",
        "        logging.debug(f\"Сигнал сохранен для {ticker}: {signal}\")\n",
        "\n",
        "    async def calculate_indicators_and_signals1(self, df, ticker):\n",
        "        \"\"\"\n",
        "        Вычисление индикаторов и сигналов для каждого тикера.\n",
        "\n",
        "        \"\"\"\n",
        "        # Получаем последние данные для тикера\n",
        "\n",
        "        #Paramsticker_params\n",
        "        params = ticker_params[ticker]['params']\n",
        "        MOVING_AVERAGE_LENGHT = params['moving_average_length']\n",
        "        ATR_PERIOD = params['atr_period']\n",
        "        ATR_MULTIPLIER = params['atr_multiplier']\n",
        "        average_type = params['average_type']\n",
        "        if average_type == 'AMA':\n",
        "          ama_params = {\n",
        "          'atr_period': int(params['ama_atr_period']),\n",
        "          'min_period': int(params['ama_min_period']),\n",
        "          'max_period': int(params['ama_max_period'])\n",
        "          }\n",
        "\n",
        "\n",
        "        high_data = df['high'].copy()\n",
        "        low_data = df['low'].copy()\n",
        "        close_data = df['close'].copy()\n",
        "\n",
        "        logging.debug(f\"high_data: {high_data}\")\n",
        "        logging.debug(f\"low_data: {low_data}\")\n",
        "        logging.debug(f\"close_data: {close_data}\")\n",
        "\n",
        "        # Проверяем, есть ли данные\n",
        "        if high_data.empty or low_data.empty or close_data.empty:\n",
        "            logging.warning(f\"Пустые данные для тикера {ticker}\")\n",
        "            return\n",
        "\n",
        "        # Генерация индикаторов\n",
        "\n",
        "        try:\n",
        "          if average_type == 'SMA':\n",
        "              ma_data = self.generateSma(high_data, low_data, MOVING_AVERAGE_LENGHT)\n",
        "          elif average_type == 'VAR':\n",
        "              ma_data = self.generateVar(high_data, low_data, MOVING_AVERAGE_LENGHT)\n",
        "          elif average_type == 'AMA':\n",
        "              if ama_params is None:\n",
        "                  raise ValueError(\"Для AMA необходимо указать параметры ama_params.\")\n",
        "              ma_data = self.generateAma(high_data, low_data, close_data, **ama_params)\n",
        "          else:\n",
        "              raise ValueError(\"Неподдерживаемый тип скользящего среднего.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при вычислении линий средних для тикера {ticker}: {e}\")\n",
        "            return\n",
        "        try:\n",
        "            logging.debug(f\"ma_data: {ma_data}\")\n",
        "\n",
        "            pmax_data = self.generatePMax(ma_data, close_data, high_data, low_data, atr_period=ATR_PERIOD,\n",
        "                                          atr_multiplier=ATR_MULTIPLIER)\n",
        "            logging.debug(f\"pmax_data: {pmax_data}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при вычислении индикаторов для тикера {ticker}: {e}\")\n",
        "            return\n",
        "\n",
        "        # Обновляем словари с индикаторами\n",
        "        self.ma[ticker] = ma_data\n",
        "        self.pmax[ticker] = pmax_data\n",
        "\n",
        "        # Вычисляем сигналы\n",
        "        try:\n",
        "            signal = self.generate_signal(ma_data[-2:], pmax_data[-2:])\n",
        "            logging.debug(f\"Сигнал для {ticker}: {signal}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Ошибка при генерации сигнала для тикера {ticker}: {e}\")\n",
        "            return\n",
        "\n",
        "        # Сохраняем сигнал\n",
        "        self.signals[ticker] = signal\n",
        "        logging.debug(f\"Сигнал сохранен для {ticker}: {signal}\")\n",
        "\n",
        "        '''# Отправляем сигнал в Telegram если необходимо\n",
        "        if signal == 'buy':\n",
        "            send_buy_signal_to_telegram(ticker, close_data[-1])\n",
        "        elif signal == 'sell':\n",
        "            send_sell_signal_to_telegram(ticker, close_data[-1])'''\n",
        "\n",
        "    def generateVar(self, high_array, low_array, moving_average_length=14):\n",
        "        \"\"\"\n",
        "        Генерация VAR (Volatility Adjusted Ratio).\n",
        "\n",
        "        :param high_array: Массив значений high.\n",
        "        :param low_array: Массив значений low.\n",
        "        :param moving_average_length: Период для расчета VAR.\n",
        "        :return: Массив значений VAR.\n",
        "        \"\"\"\n",
        "        # Константа alpha\n",
        "        valpha = 2 / (moving_average_length + 1)\n",
        "\n",
        "        # Вычисляем среднее значение между high и low\n",
        "        hl2 = (high_array + low_array) / 2\n",
        "\n",
        "        # Вычисляем разницы для vud1 и vdd1\n",
        "        diff = np.diff(hl2, prepend=hl2[0])\n",
        "        vud1 = np.where(diff > 0, diff, 0)\n",
        "        vdd1 = np.where(diff < 0, -diff, 0)\n",
        "\n",
        "        # Функция для расчета скользящих сумм\n",
        "        def calculate_window_sums(arr, window_size=9):\n",
        "            cumsum = np.cumsum(arr)\n",
        "            return cumsum - np.concatenate((np.zeros(window_size), cumsum[:-window_size]))\n",
        "\n",
        "        # Вычисляем vUD и vDD\n",
        "        vUD = calculate_window_sums(vud1, 9)\n",
        "        vDD = calculate_window_sums(vdd1, 9)\n",
        "\n",
        "        # Вычисляем vCMO\n",
        "        epsilon = 1e-10\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            vCMO = np.divide(vUD - vDD, vUD + vDD + epsilon)\n",
        "        vCMO = np.nan_to_num(vCMO, nan=0.0)\n",
        "\n",
        "        # Вычисляем VAR\n",
        "        cmo_abs = np.abs(vCMO)\n",
        "        var = np.zeros_like(hl2)\n",
        "        var_before = 0.0\n",
        "        for i in range(len(hl2)):\n",
        "            if i < len(cmo_abs):\n",
        "                var[i] = (valpha * cmo_abs[i] * hl2[i]) + (1 - valpha * cmo_abs[i]) * var_before\n",
        "            else:\n",
        "                var[i] = var_before\n",
        "            var_before = var[i]\n",
        "        del valpha, hl2, vud1, vdd1, var_before, vUD, vDD, vCMO\n",
        "        return var\n",
        "\n",
        "    def generateAma(self, high_array, low_array, close_array, atr_period=14, min_period=5, max_period=50):\n",
        "        \"\"\"\n",
        "        Генерация адаптивного скользящего среднего на основе волатильности.\n",
        "\n",
        "        :param high_array: Массив значений high.\n",
        "        :param low_array: Массив значений low.\n",
        "        :param close_array: Массив значений close.\n",
        "        :param atr_period: Период для расчета ATR.\n",
        "        :param min_period: Минимальный период скользящего среднего.\n",
        "        :param max_period: Максимальный период скользящего среднего.\n",
        "        :return: Массив значений адаптивного скользящего среднего.\n",
        "        \"\"\"\n",
        "        # Рассчитываем ATR\n",
        "        atr = self._calculate_atr(high_array, low_array, close_array, atr_period)\n",
        "\n",
        "        # Нормализуем ATR для использования в качестве коэффициента\n",
        "        normalized_atr = (atr - np.min(atr)) / (np.max(atr) - np.min(atr) + 1e-10)\n",
        "\n",
        "        # Рассчитываем динамический период\n",
        "        dynamic_period = min_period + (max_period - min_period) * normalized_atr\n",
        "\n",
        "        # Рассчитываем адаптивное скользящее среднее (гибрид SMA и EMA)\n",
        "        adaptive_ma = np.zeros_like(close_array)\n",
        "        for i in range(len(close_array)):\n",
        "            if i < int(dynamic_period[i]):\n",
        "                adaptive_ma[i] = np.mean(close_array[:i+1])  # SMA для начальных значений\n",
        "            else:\n",
        "                period = int(dynamic_period[i])\n",
        "                alpha = 2 / (period + 1)\n",
        "                adaptive_ma[i] = alpha * close_array[i] + (1 - alpha) * adaptive_ma[i-1]  # EMA\n",
        "\n",
        "        return adaptive_ma\n",
        "\n",
        "    def _calculate_atr(self, high_array, low_array, close_array, period=14):\n",
        "        \"\"\"\n",
        "        Рассчитывает Average True Range (ATR).\n",
        "\n",
        "        :param high_array: Массив значений high.\n",
        "        :param low_array: Массив значений low.\n",
        "        :param close_array: Массив значений close.\n",
        "        :param period: Период для расчета ATR.\n",
        "        :return: Массив значений ATR.\n",
        "        \"\"\"\n",
        "        tr = np.zeros_like(high_array)\n",
        "        tr[0] = high_array[0] - low_array[0]\n",
        "\n",
        "        for i in range(1, len(high_array)):\n",
        "            hl = high_array[i] - low_array[i]\n",
        "            hc = abs(high_array[i] - close_array[i-1])\n",
        "            lc = abs(low_array[i] - close_array[i-1])\n",
        "            tr[i] = max(hl, hc, lc)\n",
        "\n",
        "        atr = np.zeros_like(tr)\n",
        "        atr[period-1] = np.mean(tr[:period])\n",
        "\n",
        "        for i in range(period, len(tr)):\n",
        "            atr[i] = (atr[i-1] * (period-1) + tr[i]) / period\n",
        "\n",
        "        return atr\n",
        "\n",
        "    def generateEma(self, high_array, low_array, moving_average_length=14):\n",
        "        \"\"\"Вычисление EMA.\"\"\"\n",
        "        if high_array.empty or low_array.empty:\n",
        "            return []\n",
        "\n",
        "        hl2 = [(high + low) / 2 for high, low in zip(high_array, low_array)]\n",
        "        ema = np.full_like(hl2, np.nan)\n",
        "        alpha = 2 / (moving_average_length + 1)\n",
        "\n",
        "        if moving_average_length <= 1:\n",
        "            return hl2\n",
        "\n",
        "        start_idx = moving_average_length - 1\n",
        "        sma = np.mean(hl2[:moving_average_length])\n",
        "        ema[start_idx] = sma\n",
        "\n",
        "        for i in range(start_idx + 1, len(hl2)):\n",
        "            ema[i] = alpha * hl2[i] + (1 - alpha) * ema[i - 1]\n",
        "\n",
        "        del hl2, alpha, start_idx, sma\n",
        "        return ema\n",
        "\n",
        "    def generateAtr(self, high_array, low_array, close_array, length=14):\n",
        "        \"\"\"Вычисление ATR.\"\"\"\n",
        "        if high_array.empty or low_array.empty or close_array.empty:\n",
        "            return []\n",
        "\n",
        "        n = len(high_array)\n",
        "        if n == 0 or length > n:\n",
        "            return []\n",
        "\n",
        "        tr = np.zeros(n)\n",
        "        atr = np.full(n, np.nan)\n",
        "\n",
        "        prev_close = np.roll(close_array, 1)\n",
        "        prev_close[0] = np.nan\n",
        "\n",
        "        tr[0] = high_array[0] - low_array[0]\n",
        "\n",
        "        for i in range(1, n):\n",
        "            hl = high_array[i] - low_array[i]\n",
        "            hc = abs(high_array[i] - prev_close[i])\n",
        "            lc = abs(low_array[i] - prev_close[i])\n",
        "            tr[i] = max(hl, hc, lc)\n",
        "\n",
        "        if n >= length:\n",
        "            atr[length - 1] = np.mean(tr[:length])\n",
        "            alpha = 1.0 / length\n",
        "            for i in range(length, n):\n",
        "                atr[i] = alpha * tr[i] + (1 - alpha) * atr[i - 1]\n",
        "\n",
        "        del n, tr, prev_close, hl, hc, lc, alpha\n",
        "        return atr\n",
        "\n",
        "    def generateSma(self, high_array, low_array, window=14):\n",
        "        if len(high_array) < window or len(low_array) < window:\n",
        "            return np.full(len(high_array), np.nan)\n",
        "\n",
        "        hl2 = (high_array + low_array) * 0.5\n",
        "        sma = np.full_like(hl2, np.nan)\n",
        "        cumsum = np.cumsum(hl2)\n",
        "        shifted_cumsum = np.zeros_like(cumsum)\n",
        "        shifted_cumsum[window:] = cumsum[:-window]\n",
        "        valid = slice(window - 1, None)\n",
        "        sma[valid] = (cumsum[valid] - shifted_cumsum[valid]) / window\n",
        "\n",
        "        return sma\n",
        "\n",
        "    def generatePMax(self, var_array, close_array, high_array, low_array, atr_period=14, atr_multiplier=3):\n",
        "        \"\"\"Вычисление PMAX.\"\"\"\n",
        "        if high_array.size==0 or low_array.size==0 or close_array.size==0 or len(var_array) == 0:\n",
        "            return []\n",
        "\n",
        "        atr = self.generateAtr(high_array, low_array, close_array, length=atr_period)\n",
        "        pmax = []\n",
        "        previous_final_upperband = 0\n",
        "        previous_final_lowerband = 0\n",
        "        previous_var = 0\n",
        "        previous_pmax = 0\n",
        "\n",
        "        for i in range(len(close_array)):\n",
        "            atrc = atr[i] if i < len(atr) and not np.isnan(atr[i]) else 0\n",
        "            varc = var_array[i] if i < len(var_array) else 0\n",
        "\n",
        "            basic_upperband = varc + atr_multiplier * atrc\n",
        "            basic_lowerband = varc - atr_multiplier * atrc\n",
        "\n",
        "            final_upperband = basic_upperband if (\n",
        "                    basic_upperband < previous_final_upperband or previous_var > previous_final_upperband) else previous_final_upperband\n",
        "            final_lowerband = basic_lowerband if (\n",
        "                    basic_lowerband > previous_final_lowerband or previous_var < previous_final_lowerband) else previous_final_lowerband\n",
        "\n",
        "            if previous_pmax == previous_final_upperband:\n",
        "                pmaxc = final_upperband if varc <= final_upperband else final_lowerband\n",
        "            else:\n",
        "                pmaxc = final_lowerband if varc >= final_lowerband else final_upperband\n",
        "\n",
        "            pmax.append(pmaxc)\n",
        "            previous_var = varc\n",
        "            previous_final_upperband = final_upperband\n",
        "            previous_final_lowerband = final_lowerband\n",
        "            previous_pmax = pmaxc\n",
        "\n",
        "        del atr, previous_final_upperband, previous_final_lowerband, previous_var, previous_pmax, pmaxc\n",
        "        return pmax\n",
        "\n",
        "    def generate_signal(self, var, pmax):\n",
        "        \"\"\"Генерация сигнала на основе VAR и PMAX.\"\"\"\n",
        "        if var.size!= 0 or not pmax:\n",
        "            return None\n",
        "\n",
        "        last_var = var[-1]\n",
        "\n",
        "        previous_var = var[-2] if len(var) >= 2 else last_var\n",
        "        last_pmax = pmax[-1]\n",
        "        previous_pmax = pmax[-2] if len(pmax) >= 2 else last_pmax\n",
        "\n",
        "        if last_var > last_pmax and previous_var < previous_pmax:\n",
        "            del last_var, previous_var, last_pmax, previous_pmax\n",
        "            return 'buy'\n",
        "        elif last_var < last_pmax and previous_var > previous_pmax:\n",
        "            del last_var, previous_var, last_pmax, previous_pmax\n",
        "            return 'sell'\n",
        "        else:\n",
        "            del last_var, previous_var, last_pmax, previous_pmax\n",
        "            return 'hold'\n",
        "\n",
        "    async def initialize_tickers(self):\n",
        "        \"\"\"Инициализация тикеров и проверка их торгового статуса.\"\"\"\n",
        "        async with AsyncClient(self.token) as client:\n",
        "            instruments = await client.instruments.shares()\n",
        "            for share in instruments.instruments:\n",
        "                if share.ticker in self.tickers:\n",
        "                    status = await client.market_data.get_trading_status(figi=share.figi)\n",
        "                    if status.api_trade_available_flag and share.ticker in ticker_params.keys():\n",
        "                        self.ticker_to_figi[share.ticker] = share.figi\n",
        "                        self.figi_to_ticker[share.figi] = share.ticker\n",
        "                        self.active_tickers[share.ticker] = {\n",
        "                            'figi': share.figi,\n",
        "                            'name': share.name,\n",
        "                            'status': status.market_order_available_flag\n",
        "                        }\n",
        "            print(f\"[INIT] Активных тикеров: {len(self.ticker_to_figi)}\")\n",
        "\n",
        "    '''async def fetch_historical_data(self, days=365):\n",
        "        \"\"\"Получить исторические данные и обработать каждый тикер последовательно\"\"\"\n",
        "        now = dt.utcnow()\n",
        "\n",
        "        async with AsyncClient(self.token) as client:\n",
        "            tickers_list = list(self.active_tickers.items())\n",
        "            total_tickers = len(tickers_list)\n",
        "\n",
        "            for idx, (ticker, figi) in enumerate(tickers_list, 1):\n",
        "                try:\n",
        "                    print(f\"\\nОбработка тикера {ticker} ({idx}/{total_tickers})\")\n",
        "\n",
        "                    # Загрузка данных для текущего тикера\n",
        "                    df = await self._load_ticker_data(client, figi['figi'], now, days)\n",
        "                    if df.empty:\n",
        "                        continue\n",
        "\n",
        "                    await self.calculate_indicators_and_signals(df, ticker)\n",
        "\n",
        "                    # Инициализируем списки данных\n",
        "                    self.time_last_kline_start[ticker] = [ts.isoformat() for ts in df['time'].tail(self.data_points).tolist()]\n",
        "                    self.time_last_kline_end[ticker] = [ts.isoformat() for ts in df['time_close'].tail(self.data_points).tolist()]\n",
        "                    self.open_price[ticker] = df['open'].tail(self.data_points).tolist()\n",
        "                    self.close_price[ticker] = df['close'].tail(self.data_points).tolist()\n",
        "                    self.high_price[ticker] = df['high'].tail(self.data_points).tolist()\n",
        "                    self.low_price[ticker] = df['low'].tail(self.data_points).tolist()\n",
        "                    self.volume[ticker] = df['volume'].tail(self.data_points).tolist()\n",
        "\n",
        "                    self.ma[ticker] = self.ma[ticker][-self.data_points:].tolist()\n",
        "                    self.pmax[ticker] = self.pmax[ticker][-self.data_points:]\n",
        "\n",
        "                    await self.save_data()\n",
        "\n",
        "\n",
        "\n",
        "                    # Явная очистка памяти\n",
        "                    del df\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Ошибка при обработке {ticker}: {str(e)}\")\n",
        "                finally:\n",
        "                    # Задержка для соблюдения лимитов API\n",
        "                    await asyncio.sleep(0.5)'''\n",
        "\n",
        "    async def compute_predictions_full(self, df, ticker: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Глобальный расчёт предиктов для стартового бота:\n",
        "          - не пересчитывает MA/PMax;\n",
        "          - формирует buy/sell интервалы через event_time/event_sell_time,\n",
        "            trade_bars_counter и batch, как в FeatureCalculatorForRegression;\n",
        "          - предсказания только внутри батчей (интервалы buy→sell, либо buy→конец);\n",
        "          - вне батчей — np.nan;\n",
        "          - обрезает хвост до self.data_points и сохраняет в self.predictions[ticker].\n",
        "        \"\"\"\n",
        "        try:\n",
        "            df['ma'] = self.ma[ticker]\n",
        "            df['pmax'] = self.pmax[ticker]\n",
        "\n",
        "            n_total = len(df)\n",
        "\n",
        "            if len(df) == 0:\n",
        "               self.close_preds[ticker] = np.array([], dtype=float)\n",
        "               return self.close_preds[ticker]\n",
        "\n",
        "            # 2) Режимы (кластеризация + сглаживание)\n",
        "            params_phase = phase_ticker_params[ticker]['params']\n",
        "            window_feat = int(params_phase['moving_average_length'] * 9.5)\n",
        "            scaler_global = MODELS_CACHE.scaler_global\n",
        "            kmeans_global = MODELS_CACHE.kmeans_global\n",
        "\n",
        "            # extract_features ожидает high/low/close/volume\n",
        "            feat_for_cluster = extract_features(\n",
        "                df[['high', 'low', 'close', 'volume']].copy(),\n",
        "                window=window_feat\n",
        "            )\n",
        "            if len(feat_for_cluster) == 0:\n",
        "                out = np.full(n_total, np.nan, dtype=float)\n",
        "                out = out[-self.data_points:] if hasattr(self, 'data_points') and self.data_points > 0 else out\n",
        "                if not hasattr(self, 'predictions'):\n",
        "                    self.close_preds = {}\n",
        "                self.close_preds[ticker] = out\n",
        "                return out\n",
        "\n",
        "            labels = kmeans_global.predict(scaler_global.transform(feat_for_cluster))\n",
        "            window_smooth = int(params_phase['atr_period'] * 5.5)\n",
        "            smoother = FastRollingMode(window_size=window_smooth)\n",
        "            regimes_smoothed = np.array([smoother.update(int(x)) for x in labels], dtype=int)\n",
        "            df['regime'] = regimes_smoothed\n",
        "\n",
        "            # 3) Восстановление buy/sell и событий\n",
        "            # 3.0: первичные buy/sell по ma/pmax, как в calculate_indicators_and_signals\n",
        "            v = df['ma'].to_numpy()\n",
        "            p = df['pmax'].to_numpy()\n",
        "            v_prev = np.concatenate(([v[0]], v[:-1]))\n",
        "            p_prev = np.concatenate(([p[0]], p[:-1]))\n",
        "            df['buy_signal'] = (v_prev < p_prev) & (v > p)\n",
        "            df['sell_signal'] = (v_prev > p_prev) & (v < p)\n",
        "\n",
        "            # 3.1: Проставляем event_time/event_sell_time (если ещё не готовы в вашем объекте)\n",
        "            # Если у вас уже есть эти колонки — закомментируйте этот блок и присвойте из ваших структур.\n",
        "            df['event_time'] = pd.NaT\n",
        "            df['event_price'] = np.nan\n",
        "            df['event_sell_time'] = pd.NaT\n",
        "            df['event_sell_price'] = np.nan\n",
        "\n",
        "            buy_rows = df.index[df['buy_signal'] == True]\n",
        "            sell_rows = df.index[df['sell_signal'] == True]\n",
        "            sell_times = df.loc[sell_rows, 'time']\n",
        "\n",
        "            for st in buy_rows:\n",
        "                # находим первый sell после buy\n",
        "                later_sell = sell_times[sell_times > df.at[st, 'time']]\n",
        "                if len(later_sell) > 0:\n",
        "                    end_time = later_sell.iloc[0]\n",
        "                    end_idx = int(df.index[df['time'] == end_time][0])\n",
        "                    df.at[st, 'event_time'] = df.at[st, 'time']\n",
        "                    df.at[st, 'event_price'] = df.at[st, 'close']\n",
        "                    df.at[st, 'event_sell_time'] = df.at[end_idx, 'time']\n",
        "                    df.at[st, 'event_sell_price'] = df.at[end_idx, 'close']\n",
        "                else:\n",
        "                    # активная сделка до конца — sell_time = NaT (это важно для _feat_trade_duration)\n",
        "                    df.at[st, 'event_time'] = df.at[st, 'time']\n",
        "                    df.at[st, 'event_price'] = df.at[st, 'close']\n",
        "                    # event_sell_time останется NaT\n",
        "\n",
        "            # 3.2: PnL чисто для совместимости с вашими функциями (не обязателен для прогнозов)\n",
        "            # Если есть пара buy→sell — расчёт как у вас:\n",
        "            with np.errstate(divide='ignore', invalid='ignore'):\n",
        "                df['pnl'] = ((df['event_sell_price'] * (1 - 0.003)) /\n",
        "                            (df['event_price'] * (1 + 0.003)) - 1) * 100\n",
        "\n",
        "            # 3.4: Нормализованный таргет + batch, как в calculate_smoothed_target_qnorm\n",
        "            # Эта функция назначает batch для каждого интервала buy→sell и создаёт normalized_target.\n",
        "            df_q = calculate_smoothed_target_qnorm(\n",
        "                df.copy(),\n",
        "                smooth_method='whittaker',\n",
        "                whittaker_lambda=10,\n",
        "                savgol_window=15,\n",
        "                savgol_poly=3,\n",
        "                per_batch_equalize=True,\n",
        "                per_batch_q=0.01\n",
        "            )\n",
        "            # переносим batch и normalized_target обратно\n",
        "            df['batch'] = df_q['batch']\n",
        "            df['normalized_target'] = df_q['normalized_target']\n",
        "\n",
        "            # 4) Готовим финальные признаки через calculate_indicators (строго как у вас)\n",
        "            final_cols = MODELS_CACHE.final_cols\n",
        "            final_params = MODELS_CACHE.final_params\n",
        "            feats_list = final_cols[ticker]\n",
        "            params = build_feature_params(final_params[ticker])\n",
        "\n",
        "            # calculate_indicators внутри себя применит:\n",
        "            # - FeatureCalculatorForRegression\n",
        "            # - отфильтрует строки по trade_bars_counter >= 0\n",
        "            # - приведет типы и удалит служебные колонки\n",
        "            gh, _ = calculate_indicators_pred(\n",
        "                df.copy(),\n",
        "                features=feats_list,\n",
        "                params=params,\n",
        "                multy=False\n",
        "            )\n",
        "\n",
        "            if len(gh) == 0:\n",
        "                out = np.full(n_total, np.nan, dtype=float)\n",
        "                out = out[-self.data_points:] if hasattr(self, 'data_points') and self.data_points > 0 else out\n",
        "                if not hasattr(self, 'predictions'):\n",
        "                    self.close_preds = {}\n",
        "                self.close_preds[ticker] = out\n",
        "                return out\n",
        "\n",
        "            # 5) Прогон через transformer\n",
        "            pipeline_trans = MODELS_CACHE.load_transformer_for(ticker, device='cpu')\n",
        "\n",
        "            # Собираем вход для transformer: feats_list + ['batch','regime','time_idx']\n",
        "            # В gh уже есть 'regime' (object) и 'batch' (int), но time мы удалили раньше — вернём time в gh\n",
        "            # 1) Подготовка входа для трансформера\n",
        "            gh = gh.rename(columns={'time': 'time_idx'})\n",
        "            indexes = gh.index\n",
        "            columns_for_neuro = feats_list + ['batch', 'regime', 'time_idx']\n",
        "            gh_test = gh[columns_for_neuro].copy()\n",
        "\n",
        "            # 2) Маска валидных строк для pipeline_trans (нет пропусков во входных признаках)\n",
        "            valid_mask = ~gh_test.isna().any(axis=1)\n",
        "\n",
        "            # 3) Предсказываем только по валидным строкам\n",
        "            predd_full = np.full(len(gh_test), np.nan, dtype=float)\n",
        "            if valid_mask.any():\n",
        "                with warnings.catch_warnings(record=True):\n",
        "                    warnings.simplefilter(\"always\")\n",
        "                    predd_valid = pipeline_trans.predict(gh_test.loc[valid_mask])\n",
        "                predd_full[valid_mask.values] = np.asarray(predd_valid, dtype=float)\n",
        "\n",
        "            # 4) Записываем ровно в gh той же длины\n",
        "            gh['predd'] = predd_full\n",
        "\n",
        "            # 5) Производные признаки из предсказаний\n",
        "            gh['predd_shift_5'] = gh['predd'].shift(5).fillna(0.0)\n",
        "            gh['predd_pct'] = gh['predd'].pct_change(3).fillna(0.0)\n",
        "            gh['predd_var'] = gh['predd'].rolling(10).var().fillna(0.0)\n",
        "\n",
        "            # 6) Модель (LightGBM/Ranker/Combined)\n",
        "            model_data = MODELS_CACHE.load_lgb_for(ticker)\n",
        "            columns_for_model = feats_list + ['regime', 'predd', 'predd_var', 'predd_shift_5', 'predd_pct']\n",
        "            X_pred_all = gh[columns_for_model].copy()\n",
        "\n",
        "            best_method = getattr(model_data, 'best_method', 'combined')\n",
        "            if best_method == 'regressor':\n",
        "                pred_all = model_data.pipe_reg.predict(X_pred_all)\n",
        "                pred_all = apply_linear_calibration(pred_all, model_data.calib_reg)\n",
        "            elif best_method == 'ranker':\n",
        "                pred_all = model_data.pipe_rank.predict(X_pred_all)\n",
        "                pred_all = ranker_postprocess_minus1_1(pred_all)\n",
        "            elif best_method == 'combined':\n",
        "                pred_reg = model_data.pipe_reg.predict(X_pred_all)\n",
        "                pred_reg = apply_linear_calibration(pred_reg, model_data.calib_reg)\n",
        "                pred_rank = model_data.pipe_rank.predict(X_pred_all)\n",
        "                pred_rank = ranker_postprocess_minus1_1(pred_rank)\n",
        "                w = model_data.w_reg if getattr(model_data, 'w_reg', None) is not None else 0.5\n",
        "                pred_all = pred_reg * w + pred_rank * (1 - w)\n",
        "            else:\n",
        "                pred_all = np.full(len(X_pred_all), np.nan, dtype=float)\n",
        "\n",
        "            pred_all = np.asarray(pred_all, dtype=float).ravel()\n",
        "\n",
        "            # 7) Сведение к исходному df по времени\n",
        "            out_full = np.full(n_total, np.nan, dtype=float)\n",
        "            gh_times = pd.to_datetime(gh['time_idx'], utc=True)\n",
        "            df_times = df['time']\n",
        "            pos_in_df = pd.Index(df_times).get_indexer(gh_times)\n",
        "            valid = pos_in_df >= 0\n",
        "            out_full[pos_in_df[valid]] = pred_all[valid]\n",
        "            self.close_preds[ticker] = out_full\n",
        "\n",
        "        except Exception as e:\n",
        "            # Лог и безопасный возврат\n",
        "            logging.exception(f\"[{ticker}] Ошибка compute_predictions_full: {e}\")\n",
        "            if not hasattr(self, 'predictions'):\n",
        "                self.close_preds = {}\n",
        "            self.close_preds[ticker] = np.array([], dtype=float)\n",
        "            return self.close_preds[ticker]\n",
        "\n",
        "\n",
        "    def _compute_buy_sell_ranges_from_ma_pmax(self, ma_arr: Sequence[float], pmax_arr: Sequence[float]) -> list[tuple[int, typing.Optional[int]]]:\n",
        "        \"\"\"\n",
        "        Восстанавливает интервалы сделок по логике пересечений var=pmax:\n",
        "        - buy, когда var пересекает pmax снизу вверх (v_prev < p_prev) & (v_now > p_now)\n",
        "        - sell, когда var пересекает pmax сверху вниз (v_prev > p_prev) & (v_now < p_now)\n",
        "        Возвращает список кортежей (buy_idx, sell_idx_or_None), где sell_idx None если сделка не закрыта до конца.\n",
        "        \"\"\"\n",
        "        v = np.asarray(ma_arr, dtype=float)\n",
        "        p = np.asarray(pmax_arr, dtype=float)\n",
        "        n = len(v)\n",
        "        if n == 0:\n",
        "            return []\n",
        "\n",
        "        v_prev = np.concatenate(([v[0]], v[:-1]))\n",
        "        p_prev = np.concatenate(([p[0]], p[:-1]))\n",
        "\n",
        "        buy_mask = (v_prev < p_prev) & (v > p)\n",
        "        sell_mask = (v_prev > p_prev) & (v < p)\n",
        "\n",
        "        buy_idx = np.where(buy_mask)[0].tolist()\n",
        "        sell_idx = np.where(sell_mask)[0].tolist()\n",
        "\n",
        "        ranges = []\n",
        "        si = 0\n",
        "        for b in buy_idx:\n",
        "            # ищем первый sell строго после b\n",
        "            s = None\n",
        "            while si < len(sell_idx) and sell_idx[si] <= b:\n",
        "                si += 1\n",
        "            if si < len(sell_idx):\n",
        "                s = sell_idx[si]\n",
        "                si += 1\n",
        "            ranges.append((b, s))\n",
        "        # если первых событий sell больше, чем buy, они игнорируются (нет открытой сделки до них)\n",
        "        return ranges\n",
        "\n",
        "    async def fetch_historical_data(self, days=800):\n",
        "          \"\"\"Получить исторические данные и обработать каждый тикер с контролем длительности.\"\"\"\n",
        "          now = dt.utcnow()\n",
        "\n",
        "          async with AsyncClient(self.token) as client:\n",
        "              tickers_list = list(self.active_tickers.items())\n",
        "              total_tickers = len(tickers_list)\n",
        "\n",
        "              for idx, (ticker, figi) in enumerate(tickers_list, 1):\n",
        "                  start_time = time.monotonic()  # Зафиксируем старт времени\n",
        "\n",
        "                  try:\n",
        "                      print(f\"\\nОбработка тикера {ticker} ({idx}/{total_tickers})\")\n",
        "\n",
        "                      # Загрузка данных\n",
        "                      df = await self._load_ticker_data(client, figi['figi'], now, days)\n",
        "                      if df.empty:\n",
        "                          continue\n",
        "\n",
        "                      await self.calculate_indicators_and_signals(df, ticker)\n",
        "\n",
        "                      await self.compute_predictions_full(df, ticker)\n",
        "\n",
        "                      # Инициализация списков\n",
        "                      self.time_last_kline_start[ticker] = [ts.isoformat() for ts in df['time'].tail(self.data_points).tolist()]\n",
        "                      self.time_last_kline_end[ticker] = [ts.isoformat() for ts in df['time_close'].tail(self.data_points).tolist()]\n",
        "                      self.open_price[ticker] = df['open'].tail(self.data_points).tolist()\n",
        "                      self.close_price[ticker] = df['close'].tail(self.data_points).tolist()\n",
        "                      self.high_price[ticker] = df['high'].tail(self.data_points).tolist()\n",
        "                      self.low_price[ticker] = df['low'].tail(self.data_points).tolist()\n",
        "                      self.volume[ticker] = df['volume'].tail(self.data_points).tolist()\n",
        "\n",
        "                      self.ma[ticker] = self.ma[ticker][-self.data_points:].tolist()\n",
        "                      self.pmax[ticker] = self.pmax[ticker][-self.data_points:].tolist()\n",
        "\n",
        "                      self.close_preds[ticker] = self.close_preds[ticker][-self.data_points:].tolist()\n",
        "\n",
        "                      '''ress[ticker] = pd.DataFrame({\n",
        "                        'time': self.time_last_kline_start[ticker],\n",
        "                        'time_close': self.time_last_kline_end[ticker],\n",
        "                        'open':self.open_price[ticker],\n",
        "                        'high':self.high_price[ticker],\n",
        "                        'low':self.low_price[ticker],\n",
        "                        'close':self.close_price[ticker],\n",
        "                        'volume':self.volume[ticker],\n",
        "                        'ma':self.ma[ticker],\n",
        "                        'pmax':self.pmax[ticker],\n",
        "                        'preds':self.close_preds[ticker]\n",
        "                      }\n",
        "                      )'''\n",
        "\n",
        "                      await self.save_data()\n",
        "\n",
        "                      del df  # Очистка памяти\n",
        "\n",
        "                  except Exception as e:\n",
        "                      print(f\"Ошибка при обработке {ticker}: {str(e)}\")\n",
        "\n",
        "                  finally:\n",
        "                      elapsed = time.monotonic() - start_time\n",
        "                      remaining = 60 - elapsed\n",
        "                      if remaining > 0:\n",
        "                          # Обеспечим, чтобы обработка одного тикера занимала не менее 60 секунд\n",
        "                          await asyncio.sleep(remaining)\n",
        "\n",
        "\n",
        "\n",
        "    async def _load_ticker_data(self, client, figi, now, days, retries=3):\n",
        "        candles = []\n",
        "        total_blocks = (days // 90) + (1 if days % 90 else 0)\n",
        "\n",
        "        for block in range(total_blocks):\n",
        "            for attempt in range(retries):\n",
        "                try:\n",
        "                    from_time = now - timedelta(days=(block+1)*90)\n",
        "                    to_time = now - timedelta(days=block*90)\n",
        "\n",
        "                    async for candle in client.get_all_candles(\n",
        "                        figi=figi,\n",
        "                        from_=from_time,\n",
        "                        to=to_time,\n",
        "                        interval=self.interval\n",
        "                    ):\n",
        "                        candles.append({\n",
        "                            \"time\": candle.time + timedelta(hours=3),\n",
        "                            \"time_close\": candle.time + timedelta(hours=3)+timedelta(minutes=self.timeframe_minutes),\n",
        "                            \"open\": float(candle.open.units + candle.open.nano * 1e-9),\n",
        "                            \"close\": float(candle.close.units + candle.close.nano * 1e-9),\n",
        "                            \"high\": float(candle.high.units + candle.high.nano * 1e-9),\n",
        "                            \"low\": float(candle.low.units + candle.low.nano * 1e-9),\n",
        "                            \"volume\": candle.volume,\n",
        "                        })\n",
        "\n",
        "                    break  # успешная попытка — выходим из цикла retry\n",
        "                except RequestError as e:\n",
        "                    if e.status == StatusCode.INTERNAL and attempt < retries - 1:\n",
        "                        logging.warning(f\"[{figi}] INTERNAL ERROR. Повтор {attempt+1}/{retries}\")\n",
        "                        await asyncio.sleep(1 + attempt)\n",
        "                    else:\n",
        "                        raise\n",
        "        return self._clean_data(candles)\n",
        "\n",
        "    async def _load_ticker_data_back(self, client, figi, now, days):\n",
        "        \"\"\"Загрузка данных для одного тикера\"\"\"\n",
        "        candles = []\n",
        "        total_blocks = (days // 90) + (1 if days % 90 else 0)\n",
        "\n",
        "        try:\n",
        "            for block in range(total_blocks):\n",
        "                from_time = now - timedelta(days=(block+1)*90)\n",
        "                to_time = now - timedelta(days=block*90)\n",
        "\n",
        "                async for candle in client.get_all_candles(\n",
        "                    figi=figi,\n",
        "                    from_=from_time,\n",
        "                    to=to_time,\n",
        "                    interval=self.interval\n",
        "                ):\n",
        "                    candles.append({\n",
        "                        \"time\": candle.time + timedelta(hours=3),\n",
        "                        \"time_close\": candle.time + timedelta(hours=3)+timedelta(minutes=self.timeframe_minutes),\n",
        "                        \"open\": float(candle.open.units + candle.open.nano * 1e-9),\n",
        "                        \"close\": float(candle.close.units + candle.close.nano * 1e-9),\n",
        "                        \"high\": float(candle.high.units + candle.high.nano * 1e-9),\n",
        "                        \"low\": float(candle.low.units + candle.low.nano * 1e-9),\n",
        "                        \"volume\": candle.volume,\n",
        "                    })\n",
        "\n",
        "                # Обновление прогресса\n",
        "                print(f\"Загружено блоков: {block+1}/{total_blocks}\", end='\\r')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки данных: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        return self._clean_data(candles)\n",
        "\n",
        "    def _clean_data(self, candles):\n",
        "        \"\"\"Очистка и преобразование данных\"\"\"\n",
        "        if not candles:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame(candles)\n",
        "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "        return df.sort_values(\"time\").drop_duplicates(\"time\").reset_index(drop=True)\n",
        "\n",
        "    async def process_candle_stream(self, candle: Candle):\n",
        "        \"\"\"Обработка новых свечей в реальном времени.\"\"\"\n",
        "        ticker = self.figi_to_ticker.get(candle.figi)\n",
        "        if not ticker:\n",
        "            return\n",
        "\n",
        "\n",
        "        ts = int(candle.time.timestamp() * 1000)\n",
        "        self.open_price[ticker] = self.open_price[ticker][1:] + [float(candle.open.units + candle.open.nano * 1e-9)]\n",
        "        self.close_price[ticker] = self.close_price[ticker][1:] + [float(candle.close.units + candle.close.nano * 1e-9)]\n",
        "        self.high_price[ticker] = self.high_price[ticker][1:] + [float(candle.high.units + candle.high.nano * 1e-9)]\n",
        "        self.low_price[ticker] = self.low_price[ticker][1:] + [float(candle.low.units + candle.low.nano * 1e-9)]\n",
        "        self.volume[ticker] = self.volume[ticker][1:] + [candle.volume]\n",
        "        self.time_last_kline_start[ticker] = time_last_kline_start[ticker][1:] + [ts]\n",
        "        self.time_last_kline_end[ticker] = self.time_last_kline_end[ticker][1:] + [ts + 60000 * self.timeframe_minutes]\n",
        "\n",
        "        print(f\"[{ticker}] Time: {candle.time:%Y-%m-%d %H:%M} \"\n",
        "              f\"O: {self.open_price[ticker][-1]:.2f} H: {self.high_price[ticker][-1]:.2f} \"\n",
        "              f\"L: {self.low_price[ticker][-1]:.2f} C: {self.close_price[ticker][-1]:.2f}\")\n",
        "\n",
        "    async def candle_stream_handler(self):\n",
        "        \"\"\"Обработка реального потока данных.\"\"\"\n",
        "        async with AsyncClient(self.token) as client:\n",
        "            figi_list = list(self.figi_to_ticker.keys())\n",
        "\n",
        "            async def request_iterator():\n",
        "                yield MarketDataRequest(\n",
        "                    subscribe_candles_request=SubscribeCandlesRequest(\n",
        "                        subscription_action=SubscriptionAction.SUBSCRIPTION_ACTION_SUBSCRIBE,\n",
        "                        instruments=[\n",
        "                            CandleInstrument(\n",
        "                                figi=figi,\n",
        "                                interval=self.interval\n",
        "                            ) for figi in figi_list\n",
        "                        ],\n",
        "                        waiting_close=True\n",
        "                    )\n",
        "                )\n",
        "                while True:\n",
        "                    await asyncio.sleep(1)\n",
        "\n",
        "            try:\n",
        "                stream = client.market_data_stream.market_data_stream(request_iterator())\n",
        "                async for response in stream:\n",
        "                    if response.candle:\n",
        "                        await self.process_candle_stream(response.candle)\n",
        "            except Exception as e:\n",
        "                print(f\"[Stream Error] {e}\")\n",
        "                await asyncio.sleep(10)\n",
        "\n",
        "    async def save_data(self):\n",
        "        \"\"\"Save data to files periodically.\"\"\"\n",
        "        try:\n",
        "            with open(f'{self.data_path}open_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.open_price))\n",
        "\n",
        "            with open(f'{self.data_path}close_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.close_price))\n",
        "\n",
        "            with open(f'{self.data_path}high_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.high_price))\n",
        "\n",
        "            with open(f'{self.data_path}low_price.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.low_price))\n",
        "\n",
        "            with open(f'{self.data_path}volume.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.volume))\n",
        "\n",
        "            with open(f'{self.data_path}ma.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.ma))\n",
        "\n",
        "            with open(f'{self.data_path}pmax.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.pmax))\n",
        "\n",
        "            with open(f'{self.data_path}close_preds.txt', 'w') as f:\n",
        "                f.write(json.dumps(self.close_preds))\n",
        "\n",
        "            with open(f'{self.data_path}time_last_kline_start.txt', 'w') as f:\n",
        "                json.dump(self.time_last_kline_start, f)\n",
        "\n",
        "            with open(f'{self.data_path}time_last_kline_end.txt', 'w') as f:\n",
        "                json.dump(self.time_last_kline_end, f)\n",
        "\n",
        "            print(\"Данные успешно сохранены.\")\n",
        "        except Exception as e:\n",
        "            print(f'Ошибка сохранения в {e}')\n",
        "            await asyncio.sleep(0.5)\n",
        "\n",
        "    async def run(self):\n",
        "        \"\"\"Запуск бота.\"\"\"\n",
        "\n",
        "        await self.initialize_tickers()\n",
        "        MODELS_CACHE.init_metadata(path_to_save=self.data_path)\n",
        "        await self.fetch_historical_data()\n",
        "\n",
        "\n",
        "# Запуск бота\n",
        "if __name__ == \"__main__\":\n",
        "    bot = TradingBot(\n",
        "        token=TOKEN,\n",
        "        tickers=TICKERS,\n",
        "        data_path=DATA_PATH,\n",
        "        interval=CANDLE_INTERVAL,\n",
        "        timeframe_minutes=TIMEFRAME_MINUTES,\n",
        "        data_points=HISTORY_DATA_POINTS\n",
        "    )\n",
        "    asyncio.run(bot.run())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ress['MRKV']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MWCGCf0mId3e",
        "outputId": "225c5e60-351b-4098-f59d-1f4a1071a9cd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           time                 time_close     open     high  \\\n",
              "0     2025-08-06T17:30:00+00:00  2025-08-06T17:45:00+00:00  0.12475  0.12490   \n",
              "1     2025-08-06T17:45:00+00:00  2025-08-06T18:00:00+00:00  0.12485  0.12515   \n",
              "2     2025-08-06T18:00:00+00:00  2025-08-06T18:15:00+00:00  0.12500  0.12510   \n",
              "3     2025-08-06T18:15:00+00:00  2025-08-06T18:30:00+00:00  0.12465  0.12515   \n",
              "4     2025-08-06T18:30:00+00:00  2025-08-06T18:45:00+00:00  0.12505  0.12550   \n",
              "...                         ...                        ...      ...      ...   \n",
              "4995  2025-10-23T16:00:00+00:00  2025-10-23T16:15:00+00:00  0.11165  0.11170   \n",
              "4996  2025-10-23T16:15:00+00:00  2025-10-23T16:30:00+00:00  0.11135  0.11135   \n",
              "4997  2025-10-23T16:30:00+00:00  2025-10-23T16:45:00+00:00  0.11135  0.11150   \n",
              "4998  2025-10-23T16:45:00+00:00  2025-10-23T17:00:00+00:00  0.11135  0.11135   \n",
              "4999  2025-10-23T17:00:00+00:00  2025-10-23T17:15:00+00:00  0.11125  0.11180   \n",
              "\n",
              "          low    close  volume        ma      pmax     preds  \n",
              "0     0.12400  0.12485     864  0.122258  0.117625  0.231726  \n",
              "1     0.12455  0.12515     730  0.122274  0.117625  0.231557  \n",
              "2     0.12460  0.12485     393  0.122288  0.117625  0.228486  \n",
              "3     0.12465  0.12480     906  0.122301  0.117625  0.229538  \n",
              "4     0.12500  0.12550     619  0.122309  0.117625  0.235263  \n",
              "...       ...      ...     ...       ...       ...       ...  \n",
              "4995  0.11135  0.11165     208  0.114110  0.111529 -0.138131  \n",
              "4996  0.11135  0.11135       3  0.114097  0.111529 -0.140691  \n",
              "4997  0.11100  0.11115      25  0.114081  0.111529 -0.129006  \n",
              "4998  0.11135  0.11135       1  0.114072  0.111529 -0.030208  \n",
              "4999  0.11125  0.11130     345  0.114070  0.111529 -0.040393  \n",
              "\n",
              "[5000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c32f5221-4f00-43a7-8bd9-dd186be33848\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>time_close</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>ma</th>\n",
              "      <th>pmax</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-08-06T17:30:00+00:00</td>\n",
              "      <td>2025-08-06T17:45:00+00:00</td>\n",
              "      <td>0.12475</td>\n",
              "      <td>0.12490</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.12485</td>\n",
              "      <td>864</td>\n",
              "      <td>0.122258</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.231726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-08-06T17:45:00+00:00</td>\n",
              "      <td>2025-08-06T18:00:00+00:00</td>\n",
              "      <td>0.12485</td>\n",
              "      <td>0.12515</td>\n",
              "      <td>0.12455</td>\n",
              "      <td>0.12515</td>\n",
              "      <td>730</td>\n",
              "      <td>0.122274</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.231557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-08-06T18:00:00+00:00</td>\n",
              "      <td>2025-08-06T18:15:00+00:00</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.12510</td>\n",
              "      <td>0.12460</td>\n",
              "      <td>0.12485</td>\n",
              "      <td>393</td>\n",
              "      <td>0.122288</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.228486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-08-06T18:15:00+00:00</td>\n",
              "      <td>2025-08-06T18:30:00+00:00</td>\n",
              "      <td>0.12465</td>\n",
              "      <td>0.12515</td>\n",
              "      <td>0.12465</td>\n",
              "      <td>0.12480</td>\n",
              "      <td>906</td>\n",
              "      <td>0.122301</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.229538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-08-06T18:30:00+00:00</td>\n",
              "      <td>2025-08-06T18:45:00+00:00</td>\n",
              "      <td>0.12505</td>\n",
              "      <td>0.12550</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.12550</td>\n",
              "      <td>619</td>\n",
              "      <td>0.122309</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.235263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>2025-10-23T16:00:00+00:00</td>\n",
              "      <td>2025-10-23T16:15:00+00:00</td>\n",
              "      <td>0.11165</td>\n",
              "      <td>0.11170</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11165</td>\n",
              "      <td>208</td>\n",
              "      <td>0.114110</td>\n",
              "      <td>0.111529</td>\n",
              "      <td>-0.138131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>2025-10-23T16:15:00+00:00</td>\n",
              "      <td>2025-10-23T16:30:00+00:00</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>3</td>\n",
              "      <td>0.114097</td>\n",
              "      <td>0.111529</td>\n",
              "      <td>-0.140691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>2025-10-23T16:30:00+00:00</td>\n",
              "      <td>2025-10-23T16:45:00+00:00</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11150</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11115</td>\n",
              "      <td>25</td>\n",
              "      <td>0.114081</td>\n",
              "      <td>0.111529</td>\n",
              "      <td>-0.129006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>2025-10-23T16:45:00+00:00</td>\n",
              "      <td>2025-10-23T17:00:00+00:00</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>0.11135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114072</td>\n",
              "      <td>0.111529</td>\n",
              "      <td>-0.030208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>2025-10-23T17:00:00+00:00</td>\n",
              "      <td>2025-10-23T17:15:00+00:00</td>\n",
              "      <td>0.11125</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.11125</td>\n",
              "      <td>0.11130</td>\n",
              "      <td>345</td>\n",
              "      <td>0.114070</td>\n",
              "      <td>0.111529</td>\n",
              "      <td>-0.040393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c32f5221-4f00-43a7-8bd9-dd186be33848')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c32f5221-4f00-43a7-8bd9-dd186be33848 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c32f5221-4f00-43a7-8bd9-dd186be33848');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cc6d691f-1204-4d4e-8406-d1814b557930\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc6d691f-1204-4d4e-8406-d1814b557930')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cc6d691f-1204-4d4e-8406-d1814b557930 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"ress['MRKV']\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"2025-08-29T11:00:00+00:00\",\n          \"2025-09-15T16:00:00+00:00\",\n          \"2025-09-16T16:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_close\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"2025-08-29T11:15:00+00:00\",\n          \"2025-09-15T16:15:00+00:00\",\n          \"2025-09-16T16:15:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00705916556579436,\n        \"min\": 0.0956,\n        \"max\": 0.136,\n        \"num_unique_values\": 608,\n        \"samples\": [\n          0.1298,\n          0.1267,\n          0.13590000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007003828836663162,\n        \"min\": 0.09745000000000001,\n        \"max\": 0.136,\n        \"num_unique_values\": 586,\n        \"samples\": [\n          0.11530000000000001,\n          0.12110000000000001,\n          0.10005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007112014049470676,\n        \"min\": 0.09475,\n        \"max\": 0.13590000000000002,\n        \"num_unique_values\": 611,\n        \"samples\": [\n          0.12745,\n          0.13440000000000002,\n          0.12675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007060706562025583,\n        \"min\": 0.0956,\n        \"max\": 0.13595000000000002,\n        \"num_unique_values\": 612,\n        \"samples\": [\n          0.12705,\n          0.13165000000000002,\n          0.12805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1023,\n        \"min\": 1,\n        \"max\": 29705,\n        \"num_unique_values\": 992,\n        \"samples\": [\n          220,\n          55,\n          204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005747323653356196,\n        \"min\": 0.10714531771379039,\n        \"max\": 0.1311739487417502,\n        \"num_unique_values\": 4918,\n        \"samples\": [\n          0.12619556201751425,\n          0.11409702260442398,\n          0.1081421526806098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005755008075368253,\n        \"min\": 0.10696385679464543,\n        \"max\": 0.13126376015162883,\n        \"num_unique_values\": 1540,\n        \"samples\": [\n          0.12181218790499139,\n          0.12205480690711693,\n          0.11833073929473276\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2434667236912098,\n        \"min\": -0.7551041062955381,\n        \"max\": 0.5983170746738514,\n        \"num_unique_values\": 2382,\n        \"samples\": [\n          0.009086144332691105,\n          0.3059289560743795,\n          0.17959382267848603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.use(\"agg\")\n",
        "%matplotlib inline\n",
        "plot_price_with_indicators_mplfinance1(ress['MRKV'].iloc[:], 'MRKV')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "IEranmM5Ki3j",
        "outputId": "c2795d27-0683-4661-e95e-b37174a50732"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_price_with_indicators_mplfinance1(df, ticker, save_path=None):\n",
        "    \"\"\"\n",
        "    Отрисовывает график движения цены с индикаторами, используя mplfinance.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame с данными о цене и индикаторах.\n",
        "        ticker (str): Тикер акции для заголовка графика.\n",
        "        save_path (str, optional): Путь для сохранения графика. Если None, то график покажется.\n",
        "    \"\"\"\n",
        "    # Копируем DataFrame, чтобы не менять оригинал\n",
        "    df = df.copy()\n",
        "\n",
        "    # Преобразуем столбец time в datetime и делаем индексом\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
        "    df = df.set_index(\"time\")\n",
        "\n",
        "    # Проверяем, что необходимые столбцы существуют\n",
        "    required_columns = [\"open\", \"high\", \"low\", \"close\"]\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Отсутствует необходимый столбец: {col}\")\n",
        "\n",
        "    # Создаем список дополнительных панелей для индикаторов\n",
        "    apds = []\n",
        "    #if \"pmax_f\" in df.columns:\n",
        "    #    apds.append(mpf.make_addplot(df[\"pmax_f\"], color=\"red\", ylabel=\"PMAX\", panel=0))\n",
        "    #if \"ma_f\" in df.columns:\n",
        "    #    apds.append(mpf.make_addplot(df[\"ma_f\"], color=\"blue\", ylabel=\"MA\", panel=0))\n",
        "    if \"pmax_adaptive\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"pmax_adaptive\"], color=\"red\", ylabel=\"PMAX\", panel=0))\n",
        "    if \"ma_adaptive\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"ma_adaptive\"], color=\"blue\", ylabel=\"MA\", panel=0))\n",
        "    if \"pmax\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"pmax\"], color=\"black\", ylabel=\"PMAX\", panel=0))\n",
        "    if \"ma\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"ma\"], color=\"green\", ylabel=\"MA\", panel=0))\n",
        "    if \"preds\" in df.columns:\n",
        "        apds.append(mpf.make_addplot(df[\"preds\"], color=\"black\", panel=2, ylabel='close_preds',width=1.0))\n",
        "\n",
        "    # Отрисовка графика с mplfinance\n",
        "    plot_kwargs = dict(\n",
        "        type=\"candle\",\n",
        "        style=\"yahoo\",\n",
        "        title=f\"График цены {ticker} с индикаторами\",\n",
        "        ylabel=\"Цена\",\n",
        "        addplot=apds,\n",
        "        show_nontrading=False,\n",
        "        figsize=(18, 10),\n",
        "    )\n",
        "\n",
        "    if \"volume\" in df.columns:\n",
        "        plot_kwargs[\"volume\"] = True\n",
        "        plot_kwargs[\"panel_ratios\"] = (6, 3)\n",
        "\n",
        "    if save_path:\n",
        "        plot_kwargs[\"savefig\"] = save_path\n",
        "        mpf.plot(df, **plot_kwargs)\n",
        "    else:\n",
        "        mpf.plot(df, **plot_kwargs)\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "4x3jOSGNGEZe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FhlkyZXiq94"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Dmu2HvYTI77CkgCzZ9gSxz4FHKD08DcI",
      "authorship_tag": "ABX9TyMXr6n7AhgLANGzP+PgVT3S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}