{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b2e3851-7f24-4dd1-9846-17d81405c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#plt.style.use('ggplot')\n",
    "#plt.rcParams['figure.figsize'] = (18, 10)\n",
    "#plt.rcParams['axes.facecolor'] = 'black'\n",
    "sns.set_palette('Spectral')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "def plot_3d_metrics(trials, x_label='среднее значение f1', y_label='среднее значение AUC ROC', z_label='стандартное отклонение f1', deffs=None, directions=['максимизировать', 'максимизировать', 'минимизировать']):\n",
    "    \"\"\"\n",
    "    Функция для построения 3D-графика на основе результатов Optuna.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    trials : list\n",
    "        Список объектов `optuna.trial.FrozenTrial` из study.trials.\n",
    "    x_label : str, optional\n",
    "        Название для оси X (по умолчанию 'среднее значение f1').\n",
    "    y_label : str, optional\n",
    "        Название для оси Y (по умолчанию 'среднее значение AUC ROC').\n",
    "    z_label : str, optional\n",
    "        Название для оси Z (по умолчанию 'стандартное отклонение f1').\n",
    "    deffs : list, optional\n",
    "        Пороговые значения для фильтрации trials (по умолчанию None).\n",
    "    directions : list, optional\n",
    "        Направления оптимизации для каждой метрики (по умолчанию ['максимизировать', 'максимизировать', 'минимизировать']).\n",
    "    \"\"\"\n",
    "    print(len(trials))\n",
    "\n",
    "    # Сопоставление направлений с операторами сравнения\n",
    "    direction_to_operator = {\n",
    "        'максимизировать': lambda a, b: a > b,\n",
    "        'минимизировать': lambda a, b: a < b\n",
    "    }\n",
    "\n",
    "    # Фильтрация trials\n",
    "    if deffs is None:\n",
    "        trials = [trial for trial in trials if trial.values is not None]\n",
    "    else:\n",
    "        trials = [\n",
    "            trial for trial in trials\n",
    "            if trial.values is not None\n",
    "            and direction_to_operator[directions[0]](trial.values[0], deffs[0])\n",
    "            and direction_to_operator[directions[1]](trial.values[1], deffs[1])\n",
    "            and direction_to_operator[directions[2]](trial.values[2], deffs[2])\n",
    "        ]\n",
    "\n",
    "    print(len(trials))\n",
    "\n",
    "    # Извлечение значений метрик\n",
    "    x_vals = [trial.values[0] for trial in trials]\n",
    "    y_vals = [trial.values[1] for trial in trials]\n",
    "    z_vals = [trial.values[2] for trial in trials]\n",
    "\n",
    "    # Форматирование параметров для hover text\n",
    "    def format_params(params):\n",
    "        return '<br>'.join([f\"{key}: {value}\" for key, value in params.items()])\n",
    "\n",
    "    # Создание текста для hover\n",
    "    hover_texts = [\n",
    "        f\"Number: {trial.number}<br>\"\n",
    "        f\"{x_label}: {trial.values[0]:.4f}<br>\"\n",
    "        f\"{y_label}: {trial.values[1]:.4f}<br>\"\n",
    "        f\"{z_label}: {trial.values[2]:.4f}<br>\"\n",
    "        f\"Params:<br>{format_params(trial.params)}\"\n",
    "        for trial in trials\n",
    "    ]\n",
    "\n",
    "    # Создание 3D-графика\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x_vals, y=y_vals, z=z_vals,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=x_vals,  # Цветовая шкала может быть привязана к одной из метрик\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=hover_texts,  # Добавляем hover text\n",
    "        hoverinfo='text'   # Указываем, что при наведении нужно показывать текст\n",
    "    )])\n",
    "\n",
    "    # Добавление меток к осям\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=x_label,\n",
    "            yaxis_title=y_label,\n",
    "            zaxis_title=z_label\n",
    "        ),\n",
    "        title=\"3 метрики через Optuna\"\n",
    "    )\n",
    "\n",
    "    # Отображение графика\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72940fe4-ca02-4904-ae1c-d03a06af731f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MOEX</th>\n",
       "      <td>MOEX.db</td>\n",
       "      <td>{'sl_pct': 0.02155334917598318}</td>\n",
       "      <td>83.444535</td>\n",
       "      <td>84.908612</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.464077</td>\n",
       "      <td>С трендовой линией</td>\n",
       "      <td>{'alma_sigma': 5, 'ama_atr_period': None, 'ama...</td>\n",
       "      <td>84.908612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                1          2          3      4  \\\n",
       "MOEX  MOEX.db  {'sl_pct': 0.02155334917598318}  83.444535  84.908612  False   \n",
       "\n",
       "             5                   6  \\\n",
       "MOEX -1.464077  С трендовой линией   \n",
       "\n",
       "                                                      7        res  \n",
       "MOEX  {'alma_sigma': 5, 'ama_atr_period': None, 'ama...  84.908612  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = 'MOEX'\n",
    "rtert = pd.read_parquet('C:/Users/aleksandrovva1/Downloads/list_of_restults1.pq')\n",
    "rtert[rtert.index==ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06066157-c2d7-46e9-8b0f-feae554602af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import sqlite3\n",
    "\n",
    "# Подключаемся к БД Optuna\n",
    "conn = sqlite3.connect('C:/Users/aleksandrovva1/Downloads/ZILLP_15.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Получаем последние 3 trial_id для конкретного study_id\n",
    "study_id = 1  # замените на ваш study_id\n",
    "cursor.execute(\n",
    "    \"SELECT trial_id FROM trials WHERE study_id = ? ORDER BY trial_id DESC LIMIT 3\",\n",
    "    (study_id,)\n",
    ")\n",
    "last_three_trials = cursor.fetchall()\n",
    "\n",
    "# Удаляем данные из всех связанных таблиц\n",
    "for (trial_id,) in last_three_trials:\n",
    "    cursor.execute(\"DELETE FROM trial_params WHERE trial_id = ?\", (trial_id,))\n",
    "    cursor.execute(\"DELETE FROM trial_values WHERE trial_id = ?\", (trial_id,))\n",
    "    #cursor.execute(\"DELETE FROM trial_user_attribute WHERE trial_id = ?\", (trial_id,))\n",
    "    #cursor.execute(\"DELETE FROM trial_system_attribute WHERE trial_id = ?\", (trial_id,))\n",
    "    cursor.execute(\"DELETE FROM trials WHERE trial_id = ?\", (trial_id,))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de31d45-cb7c-4200-a4f0-c7fa6ca475db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/test_files_15/MTLR_materials_CANDLE_INTERVAL_15_MIN_SECOND.pq'\n",
    "df_init = pd.read_parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecd45e9-641f-4383-b01d-57b3fc2d3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "db_path = \"sqlite:///C:/Users/aleksandrovva1/Downloads/MTLR.db\"\n",
    "study = optuna.create_study(study_name='Поиск параметров для Pmax_MTLR', directions=['maximize', 'maximize', 'maximize', 'maximize', 'maximize'], storage=db_path, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28f8df3-908a-46f5-86bf-0f6201bb6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtert = pd.read_parquet('C:/Users/aleksandrovva1/Downloads/list_of_restults1.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e060fae6-1bd6-4283-ad73-8627dd985ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MTLR</th>\n",
       "      <td>MTLR.db</td>\n",
       "      <td>{'sl_pct': 0.04306541042188011}</td>\n",
       "      <td>108.308944</td>\n",
       "      <td>108.064475</td>\n",
       "      <td>True</td>\n",
       "      <td>0.24447</td>\n",
       "      <td>С трендовой линией</td>\n",
       "      <td>{'alma_sigma': 6, 'ama_atr_period': 42.0, 'ama...</td>\n",
       "      <td>108.308944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                1           2           3     4  \\\n",
       "MTLR  MTLR.db  {'sl_pct': 0.04306541042188011}  108.308944  108.064475  True   \n",
       "\n",
       "            5                   6  \\\n",
       "MTLR  0.24447  С трендовой линией   \n",
       "\n",
       "                                                      7         res  \n",
       "MTLR  {'alma_sigma': 6, 'ama_atr_period': 42.0, 'ama...  108.308944  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtert[rtert.index=='MTLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c142b2-268b-4ddd-839f-e44541bb5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_metrics(trials, x_label='среднее значение f1', y_label='среднее значение AUC ROC', z_label='стандартное отклонение f1', deffs=None, directions=['максимизировать', 'максимизировать', 'минимизировать']):\n",
    "    \"\"\"\n",
    "    Функция для построения 3D-графика на основе результатов Optuna.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    trials : list\n",
    "        Список объектов `optuna.trial.FrozenTrial` из study.trials.\n",
    "    x_label : str, optional\n",
    "        Название для оси X (по умолчанию 'среднее значение f1').\n",
    "    y_label : str, optional\n",
    "        Название для оси Y (по умолчанию 'среднее значение AUC ROC').\n",
    "    z_label : str, optional\n",
    "        Название для оси Z (по умолчанию 'стандартное отклонение f1').\n",
    "    deffs : list, optional\n",
    "        Пороговые значения для фильтрации trials (по умолчанию None).\n",
    "    directions : list, optional\n",
    "        Направления оптимизации для каждой метрики (по умолчанию ['максимизировать', 'максимизировать', 'минимизировать']).\n",
    "    \"\"\"\n",
    "    print(len(trials))\n",
    "\n",
    "    # Сопоставление направлений с операторами сравнения\n",
    "    direction_to_operator = {\n",
    "        'максимизировать': lambda a, b: a > b,\n",
    "        'минимизировать': lambda a, b: a < b\n",
    "    }\n",
    "\n",
    "    # Фильтрация trials\n",
    "    if deffs is None:\n",
    "        trials = [trial for trial in trials if trial.values is not None]\n",
    "    else:\n",
    "        trials = [\n",
    "            trial for trial in trials\n",
    "            if trial.values is not None\n",
    "            and direction_to_operator[directions[0]](trial.values[0], deffs[0])\n",
    "            and direction_to_operator[directions[1]](trial.values[1], deffs[1])\n",
    "            and direction_to_operator[directions[2]](trial.values[2], deffs[2])\n",
    "        ]\n",
    "\n",
    "    print(len(trials))\n",
    "\n",
    "    # Извлечение значений метрик\n",
    "    x_vals = [trial.values[0] for trial in trials]\n",
    "    y_vals = [trial.values[1] for trial in trials]\n",
    "    z_vals = [trial.values[2] for trial in trials]\n",
    "\n",
    "    # Форматирование параметров для hover text\n",
    "    def format_params(params):\n",
    "        return '<br>'.join([f\"{key}: {value}\" for key, value in params.items()])\n",
    "\n",
    "    # Создание текста для hover\n",
    "    hover_texts = [\n",
    "        f\"Number: {trial.number}<br>\"\n",
    "        f\"{x_label}: {trial.values[0]:.4f}<br>\"\n",
    "        f\"{y_label}: {trial.values[1]:.4f}<br>\"\n",
    "        f\"{z_label}: {trial.values[2]:.4f}<br>\"\n",
    "        f\"Params:<br>{format_params(trial.params)}\"\n",
    "        for trial in trials\n",
    "    ]\n",
    "\n",
    "    # Создание 3D-графика\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x_vals, y=y_vals, z=z_vals,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=x_vals,  # Цветовая шкала может быть привязана к одной из метрик\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=hover_texts,  # Добавляем hover text\n",
    "        hoverinfo='text'   # Указываем, что при наведении нужно показывать текст\n",
    "    )])\n",
    "\n",
    "    # Добавление меток к осям\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=x_label,\n",
    "            yaxis_title=y_label,\n",
    "            zaxis_title=z_label\n",
    "        ),\n",
    "        title=\"3 метрики через Optuna\"\n",
    "    )\n",
    "\n",
    "    # Отображение графика\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "343e0f6d-de12-4bc7-8a07-6ac005adb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "# =====================================================================================\n",
    "#                            📊 Machine Learning RSI (BullVision)\n",
    "# =====================================================================================\n",
    "\n",
    "\n",
    "class MachineLearningRSI:\n",
    "    def __init__(self,\n",
    "                 rsi_length=300,\n",
    "                 use_smoothing=True,\n",
    "                 smoothing_length=268,\n",
    "                 smoothing_type='ALMA',\n",
    "                 alma_sigma=6,\n",
    "                 rsi_overbought=70,\n",
    "                 rsi_oversold=30,\n",
    "                 use_knn=True,\n",
    "                 knn_neighbors=7,\n",
    "                 knn_lookback=500,\n",
    "                 knn_weight=0.6,\n",
    "                 feature_count=5,\n",
    "                 use_filter=True,\n",
    "                 filter_method='Kalman',\n",
    "                 filter_strength=0.7,\n",
    "                 sma_length=20 + 7*24*4*3,\n",
    "                 ema_length=21 + 7*24*4*3\n",
    "                 ):\n",
    "\n",
    "        # Базовые параметры\n",
    "        self.rsi_length = rsi_length\n",
    "        self.use_smoothing = use_smoothing\n",
    "        self.smoothing_length = smoothing_length\n",
    "        self.smoothing_type = smoothing_type\n",
    "        self.alma_sigma = alma_sigma\n",
    "\n",
    "        # Пороговые уровни\n",
    "        self.rsi_overbought = rsi_overbought\n",
    "        self.rsi_oversold = rsi_oversold\n",
    "\n",
    "        # Параметры KNN\n",
    "        self.use_knn = use_knn\n",
    "        self.knn_neighbors = knn_neighbors\n",
    "        self.knn_lookback = knn_lookback\n",
    "        self.knn_weight = knn_weight\n",
    "        self.feature_count = feature_count\n",
    "\n",
    "        # Фильтрация\n",
    "        self.use_filter = use_filter\n",
    "        self.filter_method = filter_method\n",
    "        self.filter_strength = filter_strength\n",
    "\n",
    "        self.sma_length = sma_length\n",
    "        self.ema_length = ema_length\n",
    "\n",
    "    def calculate_rsi(self, close: pd.Series, length: int) -> pd.Series:\n",
    "        \"\"\"Расчет RSI через RMA аналогично PineScript ta.rsi\"\"\"\n",
    "        delta = close.diff()\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "        avg_gain = gain.ewm(alpha=1/length, min_periods=length, adjust=False).mean()\n",
    "        avg_loss = loss.ewm(alpha=1/length, min_periods=length, adjust=False).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def smooth(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Корректный ALMA\"\"\"\n",
    "        if self.smoothing_type == 'SMA':\n",
    "            return series.rolling(self.smoothing_length).mean()\n",
    "        elif self.smoothing_type == 'EMA':\n",
    "            return series.ewm(span=self.smoothing_length, adjust=False).mean()\n",
    "        elif self.smoothing_type == 'ALMA':\n",
    "            m = self.smoothing_length\n",
    "            offset = 0.85\n",
    "            sigma = self.alma_sigma\n",
    "\n",
    "            def alma(series):\n",
    "                window = np.arange(m)\n",
    "                weights = np.exp(-((window - offset * (m-1))**2) / (2*(sigma**2)))\n",
    "                weights /= weights.sum()\n",
    "                return np.convolve(series, weights, mode='valid')\n",
    "\n",
    "            def alma_causal(series: pd.Series, length: int = 9, offset: float = 0.85, sigma: float = 6) -> pd.Series:\n",
    "                \"\"\"\n",
    "                Казуальная реализация ALMA (Arnaud Legoux Moving Average)\n",
    "                Использует только прошлые и текущие значения, без lookahead bias.\n",
    "                \"\"\"\n",
    "                if length > len(series):\n",
    "                    return pd.Series(np.nan, index=series.index)\n",
    "\n",
    "                # Предвычисление весов ALMA\n",
    "                window = np.arange(length)\n",
    "                m = offset * (length - 1)\n",
    "                s = length / sigma\n",
    "                weights = np.exp(-((window - m) ** 2) / (2 * s ** 2))\n",
    "                weights /= weights.sum()\n",
    "\n",
    "                # Применяем ALMA казуально (rolling + dot product)\n",
    "                alma_vals = []\n",
    "                for i in range(length - 1, len(series)):\n",
    "                    window_data = series.iloc[i - length + 1:i + 1]\n",
    "                    if window_data.isnull().any():\n",
    "                        alma_vals.append(np.nan)\n",
    "                    else:\n",
    "                        alma_vals.append(np.dot(weights, window_data.values))\n",
    "\n",
    "                # Паддинг NaN в начало, чтобы сохранить индекс\n",
    "                alma_series = pd.Series([np.nan] * (length - 1) + alma_vals, index=series.index)\n",
    "\n",
    "                return alma_series\n",
    "\n",
    "            alma_series = alma_causal(series.fillna(method='ffill'), m, offset, sigma)#, index=series.index[pad:-pad])\n",
    "            #alma_series = alma_series.reindex(series.index, method='nearest')\n",
    "            return alma_series\n",
    "        else:\n",
    "            return series\n",
    "\n",
    "    def feature_extraction(self, close: pd.Series, rsi: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Извлечение признаков для KNN\"\"\"\n",
    "        features = pd.DataFrame(index=close.index)\n",
    "        features['rsi'] = self.normalize(rsi, self.knn_lookback)\n",
    "\n",
    "        if self.feature_count >= 2:\n",
    "            features['momentum_rsi'] = self.normalize(rsi.diff(3), self.knn_lookback)\n",
    "        if self.feature_count >= 3:\n",
    "            features['volatility_rsi'] = self.normalize(rsi.rolling(10).std(), self.knn_lookback)\n",
    "        if self.feature_count >= 4:\n",
    "            features['slope_rsi'] = self.normalize(self.get_slope(rsi, 5), self.knn_lookback)\n",
    "        if self.feature_count >= 5:\n",
    "            features['momentum_price'] = self.normalize(close.diff(5), self.knn_lookback)\n",
    "\n",
    "        return features.dropna()\n",
    "\n",
    "    def normalize(self, series: pd.Series, period: int) -> pd.Series:\n",
    "        \"\"\"Мин-макс нормализация\"\"\"\n",
    "        min_val = series.rolling(period).min()\n",
    "        max_val = series.rolling(period).max()\n",
    "        norm = (series - min_val) / (max_val - min_val)\n",
    "        return norm.clip(0, 1)\n",
    "\n",
    "    def get_slope(self, series: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"Расчет наклона линейной регрессии\"\"\"\n",
    "        idx = np.arange(window)\n",
    "        def linreg(x):\n",
    "            A = np.vstack([idx, np.ones(len(idx))]).T\n",
    "            m, c = np.linalg.lstsq(A, x, rcond=None)[0]\n",
    "            return m\n",
    "        return series.rolling(window).apply(linreg, raw=True)\n",
    "\n",
    "    def apply_knn(self, features: pd.DataFrame, rsi: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Строго казуальная реализация KNN с сохранением полного временного индекса:\n",
    "        возвращает enhanced_rsi такой же длины, как исходный RSI, с NaN в начале.\n",
    "        \"\"\"\n",
    "        # Сохраняем оригинальный индекс\n",
    "        full_index = rsi.index\n",
    "        full_rsi = rsi.copy()\n",
    "\n",
    "        # Совместим по общим индексам (временной интервал, где есть все признаки)\n",
    "        common_index = features.index.intersection(rsi.index)\n",
    "        features = features.loc[common_index]\n",
    "        rsi = rsi.loc[common_index]\n",
    "\n",
    "        # Создаём структуру для результата, инициализированную NaN\n",
    "        enhanced_rsi = pd.Series(index=full_index, data=np.nan)\n",
    "\n",
    "        # Начальные значения RSI остаются как есть (в пределах common_index)\n",
    "        enhanced_rsi.loc[rsi.index] = rsi\n",
    "\n",
    "        feature_array = features.values\n",
    "        rsi_array = rsi.values\n",
    "        valid_index = features.index  # это уже отсечённый index\n",
    "\n",
    "        for t in range(self.knn_lookback, len(feature_array)):\n",
    "            # Используем только прошлые значения до момента t\n",
    "            X_hist = feature_array[t - self.knn_lookback:t]\n",
    "            y_hist = rsi_array[t - self.knn_lookback:t]\n",
    "            x_curr = feature_array[t].reshape(1, -1)\n",
    "\n",
    "            if len(X_hist) < self.knn_neighbors:\n",
    "                continue\n",
    "\n",
    "            # Поиск ближайших соседей\n",
    "            knn = NearestNeighbors(n_neighbors=self.knn_neighbors, metric='euclidean')\n",
    "            knn.fit(X_hist)\n",
    "            distances, indices = knn.kneighbors(x_curr)\n",
    "\n",
    "            # Получение значений RSI соседей\n",
    "            neighbor_rsi = y_hist[indices[0]]\n",
    "            weights = np.where(distances[0] < 1e-6, 1.0, 1.0 / distances[0])\n",
    "            prediction = np.average(neighbor_rsi, weights=weights)\n",
    "\n",
    "            # Обновляем значение RSI в выходной серии (в полном индексе!)\n",
    "            idx = valid_index[t]  # текущий временной индекс\n",
    "            original_val = enhanced_rsi.loc[idx]\n",
    "            enhanced_rsi.loc[idx] = (1.0 - self.knn_weight) * original_val + self.knn_weight * prediction\n",
    "\n",
    "        return enhanced_rsi\n",
    "\n",
    "    def apply_knn_b(self, features: pd.DataFrame, rsi: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Строго казуальная реализация KNN:\n",
    "        На каждом времени t используем только исторические данные t - lookback до t-1.\n",
    "        \"\"\"\n",
    "        enhanced_rsi = rsi.copy()\n",
    "\n",
    "        # Совместить индексы features и rsi\n",
    "        common_index = features.index.intersection(rsi.index)\n",
    "        features = features.loc[common_index]\n",
    "        rsi = rsi.loc[common_index]\n",
    "        enhanced_rsi = enhanced_rsi.loc[common_index]\n",
    "\n",
    "        # Преобразуем в массивы\n",
    "        feature_array = features.values\n",
    "        rsi_array = rsi.values\n",
    "\n",
    "        for t in range(self.knn_lookback, len(feature_array)):\n",
    "            # Исторические данные до момента t (исключая текущий t)\n",
    "            X_hist = feature_array[t - self.knn_lookback:t]\n",
    "            y_hist = rsi_array[t - self.knn_lookback:t]\n",
    "\n",
    "            # Текущий вектор признаков — только на момент t\n",
    "            x_curr = feature_array[t].reshape(1, -1)\n",
    "\n",
    "            if X_hist.shape[0] < self.knn_neighbors:\n",
    "                continue\n",
    "\n",
    "            # Обучаем KNN и ищем соседей\n",
    "            knn = NearestNeighbors(n_neighbors=self.knn_neighbors, metric='euclidean')\n",
    "            knn.fit(X_hist)\n",
    "            distances, indices = knn.kneighbors(x_curr)\n",
    "\n",
    "            # Получаем значения RSI по индексам соседей\n",
    "            neighbor_rsi = y_hist[indices[0]]\n",
    "\n",
    "            # Веса: обратная величина расстояния\n",
    "            weights = np.where(distances[0] < 1e-6, 1.0, 1.0 / distances[0])\n",
    "            prediction = np.average(neighbor_rsi, weights=weights)\n",
    "\n",
    "            # Казуальное обновление RSI\n",
    "            enhanced_rsi.iloc[t] = (1.0 - self.knn_weight) * rsi.iloc[t] + self.knn_weight * prediction\n",
    "\n",
    "        # Вернуть обратно в оригинальный индекс\n",
    "        return enhanced_rsi.reindex(rsi.index)\n",
    "\n",
    "    def kalman_filter(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Калман-фильтр с параметрами ближе к PineScript\"\"\"\n",
    "        n = len(series)\n",
    "        xhat = np.full(n, np.nan)\n",
    "        P = np.zeros(n)\n",
    "        R = self.filter_strength * 0.1  # Очень маленький measurement noise\n",
    "        Q = self.filter_strength * 0.01  # Очень маленький process noise\n",
    "\n",
    "        first_valid_idx = series.first_valid_index()\n",
    "        if first_valid_idx is None:\n",
    "            return pd.Series(xhat, index=series.index)\n",
    "\n",
    "        first_idx = series.index.get_loc(first_valid_idx)\n",
    "        xhat[first_idx] = series.iloc[first_idx]\n",
    "        P[first_idx] = 1.0\n",
    "\n",
    "        for k in range(first_idx + 1, n):\n",
    "            if np.isnan(series.iloc[k]):\n",
    "                xhat[k] = xhat[k - 1]\n",
    "                P[k] = P[k - 1] + Q\n",
    "            else:\n",
    "                xhatminus = xhat[k-1]\n",
    "                Pminus = P[k-1] + Q\n",
    "                K = Pminus / (Pminus + R)\n",
    "                xhat[k] = xhatminus + K * (series.iloc[k] - xhatminus)\n",
    "                P[k] = (1 - K) * Pminus\n",
    "\n",
    "        return pd.Series(xhat, index=series.index)\n",
    "\n",
    "    def filter_series(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Применение фильтрации к финальному RSI\"\"\"\n",
    "        if self.filter_method == 'None':\n",
    "            return series\n",
    "        elif self.filter_method == 'Kalman':\n",
    "            return self.kalman_filter(series)\n",
    "        elif self.filter_method == 'DoubleEMA':\n",
    "            ema1 = series.ewm(span=int(self.filter_strength * 10)).mean()\n",
    "            ema2 = ema1.ewm(span=int(self.filter_strength * 5)).mean()\n",
    "            return ema2\n",
    "        elif self.filter_method == 'ALMA':\n",
    "            return self.smooth(series)\n",
    "        else:\n",
    "            return series\n",
    "\n",
    "    def week_level(self, close):\n",
    "        sma_length = self.sma_length\n",
    "        ema_length = self.ema_length\n",
    "\n",
    "        # Вычисление 20-недельной SMA\n",
    "        SMA_20w = close.rolling(window=sma_length, min_periods=1).mean()\n",
    "\n",
    "        # Вычисление 21-недельной EMA\n",
    "        MA_21w = close.ewm(span=ema_length, adjust=False).mean()\n",
    "\n",
    "        return SMA_20w, MA_21w\n",
    "\n",
    "\n",
    "    def fit(self, close: pd.Series) -> pd.Series:\n",
    "        \"\"\"Основная функция расчёта\"\"\"\n",
    "        rsi = self.calculate_rsi(close, self.rsi_length)\n",
    "        if self.use_smoothing:\n",
    "            rsi = self.smooth(rsi)\n",
    "        if self.use_knn:\n",
    "            features = self.feature_extraction(close, rsi)\n",
    "\n",
    "            rsi = self.apply_knn(features, rsi)\n",
    "\n",
    "        if self.use_filter:\n",
    "            rsi = self.filter_series(rsi)\n",
    "\n",
    "        sma, ma = self.week_level(close)\n",
    "\n",
    "        return rsi.clip(0, 100), sma, ma\n",
    "\n",
    "\n",
    "class TinkoffHistoricalDataCollector:\n",
    "    def __init__(self):\n",
    "        self.sma_state = {}\n",
    "\n",
    "    def generateVar(self, high_array, low_array, moving_average_length=10):\n",
    "        valpha = 2 / (moving_average_length + 1)\n",
    "        hl2 = (high_array + low_array) / 2\n",
    "\n",
    "        before_val = hl2[0] if len(hl2) > 0 else 0\n",
    "\n",
    "        vud1 = []\n",
    "        vdd1 = []\n",
    "        for current_hl2 in hl2:\n",
    "            if current_hl2 > before_val:\n",
    "                vud1.append(current_hl2 - before_val)\n",
    "                vdd1.append(0)\n",
    "            elif current_hl2 < before_val:\n",
    "                vdd1.append(before_val - current_hl2)\n",
    "                vud1.append(0)\n",
    "            else:\n",
    "                vud1.append(0)\n",
    "                vdd1.append(0)\n",
    "            before_val = current_hl2\n",
    "\n",
    "        def calculate_window_sums(arr, window_size=9):\n",
    "          return [sum(arr[max(0, i - window_size + 1):i+1]) for i in range(len(arr))]\n",
    "\n",
    "        vUD = calculate_window_sums(vud1, 9)\n",
    "        vDD = calculate_window_sums(vdd1, 9)\n",
    "\n",
    "        vUD_ar = np.array(vUD)\n",
    "        vDD_ar = np.array(vDD)\n",
    "\n",
    "        epsilon = 1e-10\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            vCMO = np.divide(vUD_ar - vDD_ar, vUD_ar + vDD_ar + epsilon)\n",
    "\n",
    "        vCMO = np.nan_to_num(vCMO, nan=0.0)\n",
    "\n",
    "        var = []\n",
    "        var_before = 0.0\n",
    "        for i in range(len(hl2)):\n",
    "            if i < len(vCMO):\n",
    "                cmo = abs(vCMO[i])\n",
    "                var_current = (valpha * cmo * hl2[i]) + (1 - valpha * cmo) * var_before\n",
    "            else:\n",
    "                var_current = var_before\n",
    "            var.append(var_current)\n",
    "            var_before = var_current\n",
    "\n",
    "        return np.array(var)\n",
    "\n",
    "    def generateAma(self, high_array, low_array, close_array, atr_period=14, min_period=5, max_period=50):\n",
    "        \"\"\"\n",
    "        Генерация адаптивного скользящего среднего на основе волатильности.\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param min_period: Минимальный период скользящего среднего.\n",
    "        :param max_period: Максимальный период скользящего среднего.\n",
    "        :return: Массив значений адаптивного скользящего среднего.\n",
    "        \"\"\"\n",
    "        # Рассчитываем ATR\n",
    "        atr = self._calculate_atr(high_array, low_array, close_array, atr_period)\n",
    "\n",
    "        # Нормализуем ATR для использования в качестве коэффициента\n",
    "        normalized_atr = (atr - np.min(atr)) / (np.max(atr) - np.min(atr) + 1e-10)\n",
    "\n",
    "        # Рассчитываем динамический период\n",
    "        dynamic_period = min_period + (max_period - min_period) * normalized_atr\n",
    "\n",
    "        # Рассчитываем адаптивное скользящее среднее (гибрид SMA и EMA)\n",
    "        adaptive_ma = np.zeros_like(close_array)\n",
    "        for i in range(len(close_array)):\n",
    "            if i < int(dynamic_period[i]):\n",
    "                adaptive_ma[i] = np.mean(close_array[:i+1])  # SMA для начальных значений\n",
    "            else:\n",
    "                period = int(dynamic_period[i])\n",
    "                alpha = 2 / (period + 1)\n",
    "                adaptive_ma[i] = alpha * close_array[i] + (1 - alpha) * adaptive_ma[i-1]  # EMA\n",
    "\n",
    "        return adaptive_ma\n",
    "\n",
    "    def _calculate_atr(self, high_array, low_array, close_array, period=14):\n",
    "        \"\"\"\n",
    "        Рассчитывает Average True Range (ATR).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param period: Период для расчета ATR.\n",
    "        :return: Массив значений ATR.\n",
    "        \"\"\"\n",
    "        tr = np.zeros_like(high_array)\n",
    "        tr[0] = high_array[0] - low_array[0]\n",
    "\n",
    "        for i in range(1, len(high_array)):\n",
    "            hl = high_array[i] - low_array[i]\n",
    "            hc = abs(high_array[i] - close_array[i-1])\n",
    "            lc = abs(low_array[i] - close_array[i-1])\n",
    "            tr[i] = max(hl, hc, lc)\n",
    "\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period-1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i-1] * (period-1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateAtr(self, high_array, low_array, close_array, period=14):\n",
    "\n",
    "        # Рассчитываем True Range (TR)\n",
    "        tr1 = high_array - low_array\n",
    "        tr2 = np.abs(high_array - np.roll(close_array, 1))\n",
    "        tr3 = np.abs(low_array - np.roll(close_array, 1))\n",
    "\n",
    "        tr = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "\n",
    "        # Рассчитываем ATR\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period - 1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i - 1] * (period - 1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateSma(self, high_array, low_array, window=10):\n",
    "        \"\"\"\n",
    "        Генерация Simple Moving Average (SMA).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param window: Период SMA.\n",
    "        :return: Массив значений SMA.\n",
    "        \"\"\"\n",
    "        hl2 = (high_array + low_array) * 0.5\n",
    "\n",
    "        if window <= 1:\n",
    "            return hl2\n",
    "\n",
    "        # Создаем массив для результатов с NaN\n",
    "        sma = np.full_like(hl2, np.nan)\n",
    "\n",
    "        # Рассчитываем кумулятивную сумму\n",
    "        cumsum = np.cumsum(hl2)\n",
    "\n",
    "        # Создаем сдвинутый кумулятивный массив\n",
    "        shifted_cumsum = np.zeros_like(cumsum)\n",
    "        shifted_cumsum[window:] = cumsum[:-window]\n",
    "\n",
    "        # Вычисляем SMA для валидных периодов\n",
    "        valid = slice(window - 1, None)\n",
    "        sma[valid] = (cumsum[valid] - shifted_cumsum[valid]) / window\n",
    "\n",
    "        return sma\n",
    "\n",
    "    def generatePMax(self, var_array, close_array, high_array, low_array, atr_period, atr_multiplier):\n",
    "        \"\"\"\n",
    "        Генерация PMax (Profit Maximizer).\n",
    "\n",
    "        :param var_array: Массив значений скользящего среднего.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :return: Массив значений PMax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            atr = self.generateAtr(high_array, low_array, close_array, period=atr_period)\n",
    "        except Exception as exp:\n",
    "            print('exception in atr:', str(exp), flush=True)\n",
    "            return []\n",
    "\n",
    "        previous_final_upperband = 0\n",
    "        previous_final_lowerband = 0\n",
    "        final_upperband = 0\n",
    "        final_lowerband = 0\n",
    "        previous_var = 0\n",
    "        previous_pmax = 0\n",
    "        pmax = []\n",
    "        pmaxc = 0\n",
    "\n",
    "        for i in range(0, len(close_array)):\n",
    "            if np.isnan(close_array[i]):\n",
    "                pass\n",
    "            else:\n",
    "                atrc = atr[i]\n",
    "                varc = var_array[i]\n",
    "\n",
    "                if math.isnan(atrc):\n",
    "                    atrc = 0\n",
    "\n",
    "                basic_upperband = varc + atr_multiplier * atrc\n",
    "                basic_lowerband = varc - atr_multiplier * atrc\n",
    "\n",
    "                if basic_upperband < previous_final_upperband or previous_var > previous_final_upperband:\n",
    "                    final_upperband = basic_upperband\n",
    "                else:\n",
    "                    final_upperband = previous_final_upperband\n",
    "\n",
    "                if basic_lowerband > previous_final_lowerband or previous_var < previous_final_lowerband:\n",
    "                    final_lowerband = basic_lowerband\n",
    "                else:\n",
    "                    final_lowerband = previous_final_lowerband\n",
    "\n",
    "                if previous_pmax == previous_final_upperband and varc <= final_upperband:\n",
    "                    pmaxc = final_upperband\n",
    "                else:\n",
    "                    if previous_pmax == previous_final_upperband and varc >= final_upperband:\n",
    "                        pmaxc = final_lowerband\n",
    "                    else:\n",
    "                        if previous_pmax == previous_final_lowerband and varc >= final_lowerband:\n",
    "                            pmaxc = final_lowerband\n",
    "                        elif previous_pmax == previous_final_lowerband and varc <= final_lowerband:\n",
    "                            pmaxc = final_upperband\n",
    "\n",
    "                pmax.append(pmaxc)\n",
    "\n",
    "                previous_var = varc\n",
    "\n",
    "                previous_final_upperband = final_upperband\n",
    "\n",
    "                previous_final_lowerband = final_lowerband\n",
    "\n",
    "                previous_pmax = pmaxc\n",
    "\n",
    "        return pmax\n",
    "\n",
    "    def generate_signals(self, df, moving_average_length=10, atr_period=10, atr_multiplier=3, average_type='SMA',\n",
    "                        ama_params=None):\n",
    "        \"\"\"\n",
    "        Генерация сигналов на основе SMA или AMA.\n",
    "\n",
    "        :param df: DataFrame с данными.\n",
    "        :param moving_average_length: Период скользящего среднего.\n",
    "        :param atr_period: Период ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :param average_type: Тип скользящего среднего ('SMA' или 'AMA').\n",
    "        :param ama_params: Параметры для AMA (если используется).\n",
    "        :return: DataFrame с добавленными сигналами.\n",
    "        \"\"\"\n",
    "        high_array = df[\"high\"].values\n",
    "        low_array = df[\"low\"].values\n",
    "        close_array = df[\"close\"].values\n",
    "        df = df.copy()\n",
    "\n",
    "        if average_type == 'SMA':\n",
    "            ma_arr = self.generateSma(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'VAR':\n",
    "            ma_arr = self.generateVar(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'AMA':\n",
    "            if ama_params is None:\n",
    "                raise ValueError(\"Для AMA необходимо указать параметры ama_params.\")\n",
    "            ma_arr = self.generateAma(high_array, low_array, close_array, **ama_params)\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемый тип скользящего среднего.\")\n",
    "\n",
    "        pmax = self.generatePMax(ma_arr, close_array, high_array, low_array, atr_period, atr_multiplier)\n",
    "        df[\"pmax\"] = pmax\n",
    "        df[\"ma\"] = ma_arr\n",
    "        df[\"buy_signal\"] = (df[\"ma\"] > df[\"pmax\"]) & (df[\"ma\"].shift(1) < df[\"pmax\"].shift(1))\n",
    "        df[\"sell_signal\"] = (df[\"ma\"] < df[\"pmax\"]) & (df[\"ma\"].shift(1) > df[\"pmax\"].shift(1))\n",
    "\n",
    "        return df\n",
    "\n",
    "def calculate_target(df, threshold=3.0):\n",
    "    # Проверка необходимых колонок\n",
    "    required_columns = ['event_price', 'event_sell_price']\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Отсутствуют необходимые колонки: {missing_cols}\")\n",
    "\n",
    "    # Копируем DataFrame чтобы не менять оригинал\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Рассчитываем процентное изменение\n",
    "    result_df['price_change_pct'] = (\n",
    "        (result_df['event_sell_price'] / result_df['event_price'] - 1) * 100\n",
    "    )\n",
    "\n",
    "    # Создаем целевой признак\n",
    "    result_df['target'] = (result_df['price_change_pct'] >= threshold).astype(int)\n",
    "\n",
    "    # Обработка случаев с отсутствующими данными\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df[['event_price', 'event_sell_price']].notnull().all(axis=1),\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Обработка случаев с нулевой ценой покупки (если такие есть)\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df['event_price'] != 0,\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Удаляем временную колонку\n",
    "    result_df.drop('price_change_pct', axis=1, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "      try:\n",
    "        # --------- Гиперпараметры TinkoffHistoricalDataCollector -----------\n",
    "        moving_average_length = trial.suggest_int('moving_average_length', 10, 80)\n",
    "        atr_period = trial.suggest_int('atr_period', 5, 100)\n",
    "        atr_multiplier = trial.suggest_float('atr_multiplier', 1.5, 8)\n",
    "        average_type = trial.suggest_categorical('average_type', ['SMA', 'VAR', 'AMA'])\n",
    "        # AMA параметры если выбран AMA\n",
    "        ama_params = None\n",
    "        if average_type == 'AMA':\n",
    "            ama_atr_period = trial.suggest_int('ama_atr_period', 7, 50)\n",
    "            ama_min_period = trial.suggest_int('ama_min_period', 2, 15)\n",
    "            ama_max_period = trial.suggest_int('ama_max_period', 15, 60)\n",
    "            ama_params = {\n",
    "                'atr_period': ama_atr_period,\n",
    "                'min_period': ama_min_period,\n",
    "                'max_period': ama_max_period\n",
    "            }\n",
    "\n",
    "        # --------- Гиперпараметры MachineLearningRSI -----------\n",
    "        rsi_length = trial.suggest_int('rsi_length', 50, 500)\n",
    "        use_smoothing = trial.suggest_categorical('use_smoothing', [True, False])\n",
    "        smoothing_length = trial.suggest_int('smoothing_length', 10, 500)\n",
    "        smoothing_type = trial.suggest_categorical('smoothing_type', ['SMA', 'EMA', 'ALMA'])\n",
    "        alma_sigma = trial.suggest_int('alma_sigma', 3, 8)\n",
    "        rsi_overbought = trial.suggest_int('rsi_overbought', 60, 90)\n",
    "        rsi_oversold = trial.suggest_int('rsi_oversold', 10, 40)\n",
    "        use_knn = trial.suggest_categorical('use_knn', [True, False])\n",
    "        knn_neighbors = trial.suggest_int('knn_neighbors', 3, 20)\n",
    "        knn_lookback = trial.suggest_int('knn_lookback', 50, 1000)\n",
    "        knn_weight = trial.suggest_float('knn_weight', 0.1, 0.9)\n",
    "        feature_count = trial.suggest_int('feature_count', 2, 5)\n",
    "        use_filter = trial.suggest_categorical('use_filter', [True, False])\n",
    "        filter_method = trial.suggest_categorical('filter_method', ['None', 'Kalman', 'DoubleEMA', 'ALMA'])\n",
    "        filter_strength = trial.suggest_float('filter_strength', 0.2, 1)\n",
    "        sma_length = trial.suggest_int('sma_length', 24, 5000)\n",
    "        ema_length = trial.suggest_int('ema_length', 24, 5000)\n",
    "\n",
    "        # Копирование данных (чтобы не портить исходник)\n",
    "        df = df_init.copy()\n",
    "\n",
    "        # --- Генерация сигналов ---\n",
    "        collector = TinkoffHistoricalDataCollector()\n",
    "        df = collector.generate_signals(\n",
    "            df,\n",
    "            moving_average_length=moving_average_length,\n",
    "            atr_period=atr_period,\n",
    "            atr_multiplier=atr_multiplier,\n",
    "            average_type=average_type,\n",
    "            ama_params=ama_params\n",
    "        )\n",
    "\n",
    "        # --- Поиск сигналов ---\n",
    "        buy_signals = df[df['buy_signal']]\n",
    "        sell_signals = df[df['sell_signal']]\n",
    "        for _, buy in buy_signals.iterrows():\n",
    "            sell = sell_signals[sell_signals.time > buy.time].head(1)\n",
    "            if not sell.empty:\n",
    "                df.loc[buy.name, \"event_time\"] = buy.time\n",
    "                df.loc[buy.name, \"event_price\"] = buy.close\n",
    "                df.loc[buy.name, \"event_sell_time\"] = sell.time.values[0]\n",
    "                df.loc[buy.name, \"event_sell_price\"] = sell.close.values[0]\n",
    "\n",
    "        df['pnl'] = ((df['event_sell_price'] * (1 - 0.003)) / (df['event_price'] * (1 + 0.003)) - 1) * 100\n",
    "        df = calculate_target(df, threshold=1.9)\n",
    "\n",
    "        # --- MachineLearningRSI ---\n",
    "        ml_rsi = MachineLearningRSI(\n",
    "            rsi_length=rsi_length,\n",
    "            use_smoothing=use_smoothing,\n",
    "            smoothing_length=smoothing_length,\n",
    "            smoothing_type=smoothing_type,\n",
    "            alma_sigma=alma_sigma,\n",
    "            rsi_overbought=rsi_overbought,\n",
    "            rsi_oversold=rsi_oversold,\n",
    "            use_knn=use_knn,\n",
    "            knn_neighbors=knn_neighbors,\n",
    "            knn_lookback=knn_lookback,\n",
    "            knn_weight=knn_weight,\n",
    "            feature_count=feature_count,\n",
    "            use_filter=use_filter,\n",
    "            filter_method=filter_method,\n",
    "            filter_strength=filter_strength,\n",
    "            sma_length=sma_length,\n",
    "            ema_length=ema_length\n",
    "        )\n",
    "\n",
    "        rsi_series, sma, ma = ml_rsi.fit(df['close'].reset_index(drop=True))\n",
    "        df['rsi'] = rsi_series.values\n",
    "        df['SMA_20w'] = sma.values\n",
    "        df['EMA_21w'] = ma.values\n",
    "\n",
    "        # ----------- Метрики для оптимизации ------------\n",
    "        # 1. Базовый pnl\n",
    "        base_pnl = np.nansum(df[df['buy_signal']==True]['pnl'])\n",
    "\n",
    "        # 2. Только RSI\n",
    "        mask_rsi = (df['buy_signal']==True) & (df['rsi'] >= 50)\n",
    "        pnl_rsi = np.nansum(df[mask_rsi]['pnl'])\n",
    "        profit_trades_rsi = np.nansum((df[mask_rsi]['target'] == 1))\n",
    "        loss_trades_rsi = np.nansum((df[mask_rsi]['target'] == 0))\n",
    "        diff_rsi = profit_trades_rsi/ len(df[mask_rsi])\n",
    "\n",
    "        # 3. RSI + SMA/EMA\n",
    "        mask_full = (df['buy_signal']==True) & (df['rsi']>=50) & (df['close']<=df['SMA_20w']) & (df['close']<=df['EMA_21w'])\n",
    "        pnl_full = np.nansum(df[mask_full]['pnl'])\n",
    "        profit_trades_full = np.nansum((df[mask_full]['target'] == 1))\n",
    "        loss_trades_full = np.nansum((df[mask_full]['target'] == 0))\n",
    "        diff_full = profit_trades_full/ len(df[mask_full])\n",
    "\n",
    "        def safe_float(x):\n",
    "            try:\n",
    "                x = float(x)\n",
    "                if np.isnan(x):\n",
    "                    return 0.0\n",
    "                return x\n",
    "            except:\n",
    "                return 0.0\n",
    "\n",
    "        if len(df[mask_full]) == 0:\n",
    "            return tuple(map(safe_float, [base_pnl, pnl_rsi, pnl_full, diff_rsi, 0]))\n",
    "        else:\n",
    "            return tuple(map(safe_float, [base_pnl, pnl_rsi, pnl_full, diff_rsi, diff_full]))\n",
    "      except Exception as e:\n",
    "        print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise  # <-- пусть Optuna знает, что trial невалиден\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ac2ab3-f68d-4835-b442-5683b7d0b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'SIBN'\n",
    "base = ticker+'_15_1.db'\n",
    "data_path = 'C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/test_files_15/SIBN_energy_CANDLE_INTERVAL_15_MIN_SECOND.pq'\n",
    "base_db_dir = f'sqlite:///C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params/{base}'\n",
    "study_name = f'Поиск параметров для Pmax_{ticker}'\n",
    "\n",
    "df_init = pd.read_parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4527425d-af36-4e51-a418-0c0ef2ac26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#study = optuna.create_study(study_name=study_name,directions=['maximize'] * 5,storage=base_db_dir,load_if_exists=True)\n",
    "#study.optimize(objective,n_trials=250 - len([trial for trial in study.trials if trial.values is not None]),n_jobs=1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19c78f57-8f29-40b6-9b1c-107ffa41320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''\n",
    "ABRD_consumer_CANDLE_INTERVAL_15_MIN_SECOND.pq\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d25d4bbe-205a-4298-9ae0-d2437e8208d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinkoffHistoricalDataCollector:\n",
    "    def __init__(self):\n",
    "        self.sma_state = {}\n",
    "\n",
    "    def generateVar(self, high_array, low_array, moving_average_length=10):\n",
    "        valpha = 2 / (moving_average_length + 1)\n",
    "        hl2 = (high_array + low_array) / 2\n",
    "\n",
    "        before_val = hl2[0] if len(hl2) > 0 else 0\n",
    "\n",
    "        vud1 = []\n",
    "        vdd1 = []\n",
    "        for current_hl2 in hl2:\n",
    "            if current_hl2 > before_val:\n",
    "                vud1.append(current_hl2 - before_val)\n",
    "                vdd1.append(0)\n",
    "            elif current_hl2 < before_val:\n",
    "                vdd1.append(before_val - current_hl2)\n",
    "                vud1.append(0)\n",
    "            else:\n",
    "                vud1.append(0)\n",
    "                vdd1.append(0)\n",
    "            before_val = current_hl2\n",
    "\n",
    "        def calculate_window_sums(arr, window_size=9):\n",
    "          return [sum(arr[max(0, i - window_size + 1):i+1]) for i in range(len(arr))]\n",
    "\n",
    "        vUD = calculate_window_sums(vud1, 9)\n",
    "        vDD = calculate_window_sums(vdd1, 9)\n",
    "\n",
    "        vUD_ar = np.array(vUD)\n",
    "        vDD_ar = np.array(vDD)\n",
    "\n",
    "        epsilon = 1e-10\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            vCMO = np.divide(vUD_ar - vDD_ar, vUD_ar + vDD_ar + epsilon)\n",
    "\n",
    "        vCMO = np.nan_to_num(vCMO, nan=0.0)\n",
    "\n",
    "        var = []\n",
    "        var_before = 0.0\n",
    "        for i in range(len(hl2)):\n",
    "            if i < len(vCMO):\n",
    "                cmo = abs(vCMO[i])\n",
    "                var_current = (valpha * cmo * hl2[i]) + (1 - valpha * cmo) * var_before\n",
    "            else:\n",
    "                var_current = var_before\n",
    "            var.append(var_current)\n",
    "            var_before = var_current\n",
    "\n",
    "        return np.array(var)\n",
    "\n",
    "    def generateAma(self, high_array, low_array, close_array, atr_period=14, min_period=5, max_period=50):\n",
    "        \"\"\"\n",
    "        Генерация адаптивного скользящего среднего на основе волатильности.\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param min_period: Минимальный период скользящего среднего.\n",
    "        :param max_period: Максимальный период скользящего среднего.\n",
    "        :return: Массив значений адаптивного скользящего среднего.\n",
    "        \"\"\"\n",
    "        # Рассчитываем ATR\n",
    "        atr = self._calculate_atr(high_array, low_array, close_array, atr_period)\n",
    "\n",
    "        # Нормализуем ATR для использования в качестве коэффициента\n",
    "        normalized_atr = (atr - np.min(atr)) / (np.max(atr) - np.min(atr) + 1e-10)\n",
    "\n",
    "        # Рассчитываем динамический период\n",
    "        dynamic_period = min_period + (max_period - min_period) * normalized_atr\n",
    "\n",
    "        # Рассчитываем адаптивное скользящее среднее (гибрид SMA и EMA)\n",
    "        adaptive_ma = np.zeros_like(close_array)\n",
    "        for i in range(len(close_array)):\n",
    "            if i < int(dynamic_period[i]):\n",
    "                adaptive_ma[i] = np.mean(close_array[:i+1])  # SMA для начальных значений\n",
    "            else:\n",
    "                period = int(dynamic_period[i])\n",
    "                alpha = 2 / (period + 1)\n",
    "                adaptive_ma[i] = alpha * close_array[i] + (1 - alpha) * adaptive_ma[i-1]  # EMA\n",
    "\n",
    "        return adaptive_ma\n",
    "\n",
    "    def _calculate_atr(self, high_array, low_array, close_array, period=14):\n",
    "        \"\"\"\n",
    "        Рассчитывает Average True Range (ATR).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param period: Период для расчета ATR.\n",
    "        :return: Массив значений ATR.\n",
    "        \"\"\"\n",
    "        tr = np.zeros_like(high_array)\n",
    "        tr[0] = high_array[0] - low_array[0]\n",
    "\n",
    "        for i in range(1, len(high_array)):\n",
    "            hl = high_array[i] - low_array[i]\n",
    "            hc = abs(high_array[i] - close_array[i-1])\n",
    "            lc = abs(low_array[i] - close_array[i-1])\n",
    "            tr[i] = max(hl, hc, lc)\n",
    "\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period-1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i-1] * (period-1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateAtr(self, high_array, low_array, close_array, period=14):\n",
    "\n",
    "        # Рассчитываем True Range (TR)\n",
    "        tr1 = high_array - low_array\n",
    "        tr2 = np.abs(high_array - np.roll(close_array, 1))\n",
    "        tr3 = np.abs(low_array - np.roll(close_array, 1))\n",
    "\n",
    "        tr = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "\n",
    "        # Рассчитываем ATR\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period - 1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i - 1] * (period - 1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateSma(self, high_array, low_array, window=10):\n",
    "        \"\"\"\n",
    "        Генерация Simple Moving Average (SMA).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param window: Период SMA.\n",
    "        :return: Массив значений SMA.\n",
    "        \"\"\"\n",
    "        hl2 = (high_array + low_array) * 0.5\n",
    "\n",
    "        if window <= 1:\n",
    "            return hl2\n",
    "\n",
    "        # Создаем массив для результатов с NaN\n",
    "        sma = np.full_like(hl2, np.nan)\n",
    "\n",
    "        # Рассчитываем кумулятивную сумму\n",
    "        cumsum = np.cumsum(hl2)\n",
    "\n",
    "        # Создаем сдвинутый кумулятивный массив\n",
    "        shifted_cumsum = np.zeros_like(cumsum)\n",
    "        shifted_cumsum[window:] = cumsum[:-window]\n",
    "\n",
    "        # Вычисляем SMA для валидных периодов\n",
    "        valid = slice(window - 1, None)\n",
    "        sma[valid] = (cumsum[valid] - shifted_cumsum[valid]) / window\n",
    "\n",
    "        return sma\n",
    "\n",
    "    def generatePMax(self, var_array, close_array, high_array, low_array, atr_period, atr_multiplier):\n",
    "        \"\"\"\n",
    "        Генерация PMax (Profit Maximizer).\n",
    "\n",
    "        :param var_array: Массив значений скользящего среднего.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :return: Массив значений PMax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            atr = self.generateAtr(high_array, low_array, close_array, period=atr_period)\n",
    "        except Exception as exp:\n",
    "            print('exception in atr:', str(exp), flush=True)\n",
    "            return []\n",
    "\n",
    "        previous_final_upperband = 0\n",
    "        previous_final_lowerband = 0\n",
    "        final_upperband = 0\n",
    "        final_lowerband = 0\n",
    "        previous_var = 0\n",
    "        previous_pmax = 0\n",
    "        pmax = []\n",
    "        pmaxc = 0\n",
    "\n",
    "        for i in range(0, len(close_array)):\n",
    "            if np.isnan(close_array[i]):\n",
    "                pass\n",
    "            else:\n",
    "                atrc = atr[i]\n",
    "                varc = var_array[i]\n",
    "\n",
    "                if math.isnan(atrc):\n",
    "                    atrc = 0\n",
    "\n",
    "                basic_upperband = varc + atr_multiplier * atrc\n",
    "                basic_lowerband = varc - atr_multiplier * atrc\n",
    "\n",
    "                if basic_upperband < previous_final_upperband or previous_var > previous_final_upperband:\n",
    "                    final_upperband = basic_upperband\n",
    "                else:\n",
    "                    final_upperband = previous_final_upperband\n",
    "\n",
    "                if basic_lowerband > previous_final_lowerband or previous_var < previous_final_lowerband:\n",
    "                    final_lowerband = basic_lowerband\n",
    "                else:\n",
    "                    final_lowerband = previous_final_lowerband\n",
    "\n",
    "                if previous_pmax == previous_final_upperband and varc <= final_upperband:\n",
    "                    pmaxc = final_upperband\n",
    "                else:\n",
    "                    if previous_pmax == previous_final_upperband and varc >= final_upperband:\n",
    "                        pmaxc = final_lowerband\n",
    "                    else:\n",
    "                        if previous_pmax == previous_final_lowerband and varc >= final_lowerband:\n",
    "                            pmaxc = final_lowerband\n",
    "                        elif previous_pmax == previous_final_lowerband and varc <= final_lowerband:\n",
    "                            pmaxc = final_upperband\n",
    "\n",
    "                pmax.append(pmaxc)\n",
    "\n",
    "                previous_var = varc\n",
    "\n",
    "                previous_final_upperband = final_upperband\n",
    "\n",
    "                previous_final_lowerband = final_lowerband\n",
    "\n",
    "                previous_pmax = pmaxc\n",
    "\n",
    "        return pmax\n",
    "\n",
    "    def generate_signals(self, df, moving_average_length=10, atr_period=10, atr_multiplier=3, average_type='SMA',\n",
    "                        ama_params=None):\n",
    "        \"\"\"\n",
    "        Генерация сигналов на основе SMA или AMA.\n",
    "\n",
    "        :param df: DataFrame с данными.\n",
    "        :param moving_average_length: Период скользящего среднего.\n",
    "        :param atr_period: Период ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :param average_type: Тип скользящего среднего ('SMA' или 'AMA').\n",
    "        :param ama_params: Параметры для AMA (если используется).\n",
    "        :return: DataFrame с добавленными сигналами.\n",
    "        \"\"\"\n",
    "        high_array = df[\"high\"].values\n",
    "        low_array = df[\"low\"].values\n",
    "        close_array = df[\"close\"].values\n",
    "        df = df.copy()\n",
    "\n",
    "        if average_type == 'SMA':\n",
    "            ma_arr = self.generateSma(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'VAR':\n",
    "            ma_arr = self.generateVar(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'AMA':\n",
    "            if ama_params is None:\n",
    "                raise ValueError(\"Для AMA необходимо указать параметры ama_params.\")\n",
    "            ma_arr = self.generateAma(high_array, low_array, close_array, **ama_params)\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемый тип скользящего среднего.\")\n",
    "\n",
    "        pmax = self.generatePMax(ma_arr, close_array, high_array, low_array, atr_period, atr_multiplier)\n",
    "        df[\"pmax\"] = pmax\n",
    "        df[\"ma\"] = ma_arr\n",
    "        df[\"buy_signal\"] = (df[\"ma\"] > df[\"pmax\"]) & (df[\"ma\"].shift(1) < df[\"pmax\"].shift(1))\n",
    "        df[\"sell_signal\"] = (df[\"ma\"] < df[\"pmax\"]) & (df[\"ma\"].shift(1) > df[\"pmax\"].shift(1))\n",
    "\n",
    "        return df\n",
    "\n",
    "def calculate_target(df, threshold=3.0):\n",
    "    # Проверка необходимых колонок\n",
    "    required_columns = ['event_price', 'event_sell_price']\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Отсутствуют необходимые колонки: {missing_cols}\")\n",
    "\n",
    "    # Копируем DataFrame чтобы не менять оригинал\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Рассчитываем процентное изменение\n",
    "    result_df['price_change_pct'] = (\n",
    "        (result_df['event_sell_price'] / result_df['event_price'] - 1) * 100\n",
    "    )\n",
    "\n",
    "    # Создаем целевой признак\n",
    "    result_df['target'] = (result_df['price_change_pct'] >= threshold).astype(int)\n",
    "\n",
    "    # Обработка случаев с отсутствующими данными\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df[['event_price', 'event_sell_price']].notnull().all(axis=1),\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Обработка случаев с нулевой ценой покупки (если такие есть)\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df['event_price'] != 0,\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Удаляем временную колонку\n",
    "    result_df.drop('price_change_pct', axis=1, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def robust_score(df):\n",
    "    df = df.copy()\n",
    "    mask = df['buy_signal']\n",
    "    pnl = df.loc[mask, 'pnl']\n",
    "    pnl = pnl.clip(lower=-10, upper=10)  # Усечение\n",
    "    win_rate = (pnl > 0).mean()\n",
    "    sharpe_ratio = pnl.mean() / (pnl.std() + 1e-10)\n",
    "    return float(pnl.sum()), float(win_rate), float(sharpe_ratio)\n",
    "\n",
    "\n",
    "def optimize_for_ticker(df_path, db_path, study_name):\n",
    "\n",
    "    data_path = 'C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/test_files_15_2'\n",
    "    file_path = os.path.join(data_path, df_path)\n",
    "    df_init = pd.read_parquet(file_path)\n",
    "\n",
    "    def objective(trial):\n",
    "    \n",
    "          try:\n",
    "            # --------- Гиперпараметры TinkoffHistoricalDataCollector -----------\n",
    "            moving_average_length = trial.suggest_int('moving_average_length', 10, 100)\n",
    "            atr_period = trial.suggest_int('atr_period', 5, 120)\n",
    "            atr_multiplier = trial.suggest_float('atr_multiplier', 1.5, 8)\n",
    "            average_type = trial.suggest_categorical('average_type', ['SMA', 'VAR', 'AMA'])\n",
    "            # AMA параметры если выбран AMA\n",
    "            ama_params = None\n",
    "            if average_type == 'AMA':\n",
    "                ama_atr_period = trial.suggest_int('ama_atr_period', 7, 60)\n",
    "                ama_min_period = trial.suggest_int('ama_min_period', 2, 80)\n",
    "                ama_max_period = trial.suggest_int('ama_max_period', 15, 90)\n",
    "                ama_params = {\n",
    "                    'atr_period': ama_atr_period,\n",
    "                    'min_period': ama_min_period,\n",
    "                    'max_period': ama_max_period\n",
    "                }\n",
    "    \n",
    "            # Копирование данных (чтобы не портить исходник)\n",
    "            df = df_init.copy()\n",
    "    \n",
    "            # --- Генерация сигналов ---\n",
    "            collector = TinkoffHistoricalDataCollector()\n",
    "            df = collector.generate_signals(\n",
    "                df,\n",
    "                moving_average_length=moving_average_length,\n",
    "                atr_period=atr_period,\n",
    "                atr_multiplier=atr_multiplier,\n",
    "                average_type=average_type,\n",
    "                ama_params=ama_params\n",
    "            )\n",
    "    \n",
    "            # --- Поиск сигналов ---\n",
    "            buy_signals = df[df['buy_signal']]\n",
    "            sell_signals = df[df['sell_signal']]\n",
    "            for _, buy in buy_signals.iterrows():\n",
    "                sell = sell_signals[sell_signals.time > buy.time].head(1)\n",
    "                if not sell.empty:\n",
    "                    df.loc[buy.name, \"event_time\"] = buy.time\n",
    "                    df.loc[buy.name, \"event_price\"] = buy.close\n",
    "                    df.loc[buy.name, \"event_sell_time\"] = sell.time.values[0]\n",
    "                    df.loc[buy.name, \"event_sell_price\"] = sell.close.values[0]\n",
    "\n",
    "            if len(sell_signals)==0:\n",
    "                raise\n",
    "            else:\n",
    "                df['pnl'] = ((df['event_sell_price'] * (1 - 0.003)) / (df['event_price'] * (1 + 0.003)) - 1) * 100\n",
    "                df = calculate_target(df, threshold=1.9)\n",
    "        \n",
    "                # ----------- Метрики для оптимизации ------------\n",
    "                # 1. Базовый pnl\n",
    "                base_pnl = np.nansum(df[df['buy_signal']==True]['pnl'])\n",
    "                mask = (df['buy_signal']==True)\n",
    "                profit_trades_rsi = np.nansum((df[mask]['target'] == 1))\n",
    "                loss_trades_rsi = np.nansum((df[mask]['target'] == 0))\n",
    "                diff = profit_trades_rsi/ len(df[mask])\n",
    "                score = float(len(df[df['buy_signal']==True]))\n",
    "        \n",
    "                def safe_float(x):\n",
    "                    try:\n",
    "                        x = float(x)\n",
    "                        if np.isnan(x):\n",
    "                            return 0.0\n",
    "                        return x\n",
    "                    except:\n",
    "                        return 0.0\n",
    "        \n",
    "                if len(df[mask]) == 0:\n",
    "                    return tuple(map(safe_float, [base_pnl, 0, score]))\n",
    "                else:\n",
    "                    return robust_score(df)#return tuple(map(safe_float, [base_pnl, diff, score]))\n",
    "          except Exception as e:\n",
    "            print(f\"Ошибка в trial {trial.number}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            raise  # <-- пусть Optuna знает, что trial невалиден\n",
    "              \n",
    "    study = optuna.create_study(\n",
    "          study_name=study_name,\n",
    "          directions=['maximize', 'maximize', 'maximize'],\n",
    "          storage=db_path,\n",
    "          load_if_exists=True\n",
    "      )\n",
    "    study.optimize(\n",
    "          objective,\n",
    "          n_trials=800 - len([trial for trial in study.trials if trial.values is not None]),\n",
    "          n_jobs=-1,\n",
    "          show_progress_bar=False\n",
    "      )\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9525785c-69aa-435f-a63d-79e904b9e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd72d8ad-5944-4d3b-9acd-34d169d0effc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "tickers = []\n",
    "for i in tqdm([i for i in os.listdir(r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\test_files_15_2')]):\n",
    "    if 'ABRD' in i:\n",
    "        tickers.append((i.replace(\"'\", \"\").split('_')[0], i.replace(\"'\", \"\").replace(\",\", \"\"), i.replace(\"'\", \"\").split('_')[0]+'.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8b271d3-8525-44e2-8c50-b962b8662825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ABRD', 'ABRD_consumer_CANDLE_INTERVAL_15_MIN_SECOND.pq', 'ABRD.db')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8ba8be6-622b-4058-aa14-c586f384b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:51<00:00, 171.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for ticks in tqdm(tickers[:]):\n",
    "  db_path = f\"sqlite:///C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params_4/{ticks[2]}\"\n",
    "  study_name=f'Поиск параметров для Pmax_{ticks[0]}'\n",
    "  optimize_for_ticker(ticks[1], db_path, study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ad2600f-6c72-4dfa-b8b3-54d019d6677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = []\n",
    "\n",
    "for i in test.split():\n",
    "  tickers.append((i.replace(\"'\", \"\").split('_')[0], i.replace(\"'\", \"\").replace(\",\", \"\"), i.replace(\"'\", \"\").split('_')[0]+'_15.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d7177-5e5e-4f3b-93b5-411e87dca945",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticks in tqdm(tickers):\n",
    "  db_path = f\"sqlite:////content/drive/MyDrive/t_ml/tickers_params/tltp/{ticks[2]}\"\n",
    "  study_name=f'Поиск параметров для Pmax_{ticks[0]}'\n",
    "  optimize_for_ticker(ticks[0], db_path, study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb82acec-8778-4b7f-8574-02151bc1ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import mplfinance as mpf\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#plt.style.use('ggplot')\n",
    "#plt.rcParams['figure.figsize'] = (18, 10)\n",
    "#plt.rcParams['axes.facecolor'] = 'black'\n",
    "sns.set_palette('Spectral')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "from optuna.trial import FrozenTrial\n",
    "\n",
    "def find_best_trial_by_weighted_three_score(\n",
    "    trials: List[FrozenTrial],\n",
    "    pnl_score = 0.45,\n",
    "    diff_score = 0.45,\n",
    "    weight_score = 0.10\n",
    ") -> Tuple[float, int, float, float, int, Dict]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме двух метрик:\n",
    "        - pnl (trial.values[0]), вес 0.65, диапазон 0..600\n",
    "        - diff (trial.values[1]), вес 0.35, диапазон 0..1\n",
    "\n",
    "    Возвращает:\n",
    "        - score: float — итоговый взвешенный скор\n",
    "        - trial_number: int — номер трейла\n",
    "        - pnl: float — значение pnl\n",
    "        - diff: float — значение diff\n",
    "        - params: dict — параметры трейла\n",
    "    \"\"\"\n",
    "    WEIGHT_PNL = pnl_score\n",
    "    WEIGHT_DIFF = diff_score\n",
    "    WEIGHT_SCORE = weight_score\n",
    "    MAX_PNL = np.max([i.values[0] for i in [trial for trial in trials if trial.values is not None]])*2.5  # для нормализации\n",
    "    MAX_SCORE = np.max([i.values[2] for i in [trial for trial in study.trials if trial.values is not None]])  # для нормализации\n",
    "    MAX_DIFF = 1   # для нормализации\n",
    "\n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    best_score_n = None\n",
    "    best_params = None\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит обе метрики\n",
    "        if not trial.values or len(trial.values) < 3:\n",
    "            continue\n",
    "\n",
    "        pnl = trial.values[0]\n",
    "        diff = trial.values[1]\n",
    "        score_n = trial.values[2]\n",
    "\n",
    "        # Нормализуем значения\n",
    "        norm_pnl = pnl / MAX_PNL if MAX_PNL else 0\n",
    "        norm_diff = diff / MAX_DIFF if MAX_DIFF else 0\n",
    "        norm_score = score_n / MAX_SCORE if WEIGHT_SCORE else 0\n",
    "\n",
    "        # Взвешенная сумма\n",
    "        score = WEIGHT_PNL * norm_pnl + WEIGHT_DIFF * norm_diff + WEIGHT_SCORE * norm_score\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_trial_number = trial.number\n",
    "            best_pnl = pnl\n",
    "            best_diff = diff\n",
    "            best_score_n = score_n\n",
    "            best_params = trial.params\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с двумя метриками (pnl и diff).\")\n",
    "\n",
    "    return best_score, best_trial_number, best_pnl, best_diff, best_score_n, best_params\n",
    "\n",
    "def find_best_trial_by_weighted_score(\n",
    "    trials: List[FrozenTrial]\n",
    ") -> Tuple[float, int, float, float, Dict]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме двух метрик:\n",
    "        - pnl (trial.values[0]), вес 0.65, диапазон 0..600\n",
    "        - diff (trial.values[1]), вес 0.35, диапазон 0..1\n",
    "\n",
    "    Возвращает:\n",
    "        - score: float — итоговый взвешенный скор\n",
    "        - trial_number: int — номер трейла\n",
    "        - pnl: float — значение pnl\n",
    "        - diff: float — значение diff\n",
    "        - params: dict — параметры трейла\n",
    "    \"\"\"\n",
    "    WEIGHT_PNL = 0.60\n",
    "    WEIGHT_DIFF = 0.40\n",
    "    MAX_PNL = np.max([i.values for i in [trial for trial in trials if trial.values is not None]])*2.5  # для нормализации\n",
    "    MAX_DIFF = 1   # для нормализации\n",
    "\n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    best_params = None\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит обе метрики\n",
    "        if not trial.values or len(trial.values) < 2:\n",
    "            continue\n",
    "\n",
    "        pnl = trial.values[0]\n",
    "        diff = trial.values[1]\n",
    "\n",
    "        # Нормализуем значения\n",
    "        norm_pnl = pnl / MAX_PNL if MAX_PNL else 0\n",
    "        norm_diff = diff / MAX_DIFF if MAX_DIFF else 0\n",
    "\n",
    "        # Взвешенная сумма\n",
    "        score = WEIGHT_PNL * norm_pnl + WEIGHT_DIFF * norm_diff\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_trial_number = trial.number\n",
    "            best_pnl = pnl\n",
    "            best_diff = diff\n",
    "            best_params = trial.params\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с двумя метриками (pnl и diff).\")\n",
    "\n",
    "    return best_score, best_trial_number, best_pnl, best_diff, best_params\n",
    "\n",
    "def find_best_trial_by_weighted_score_extended(\n",
    "    trials: List[FrozenTrial]\n",
    ") -> Tuple[float, int, Dict, str, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме метрик для двух стратегий:\n",
    "        - Стратегия RSI: pnl_rsi и diff_rsi\n",
    "        - Стратегия RSI+SMA/EMA: pnl_full и diff_full\n",
    "    \n",
    "    Возвращает:\n",
    "        - best_score: float - наивысший взвешенный скор среди всех стратегий\n",
    "        - best_trial_number: int - номер лучшего трейла\n",
    "        - best_params: dict - параметры лучшего трейла\n",
    "        - best_strategy: str - название лучшей стратегии ('RSI' или 'RSI_SMA_EMA')\n",
    "        - best_pnl: float - лучшее значение PnL (из выбранной стратегии)\n",
    "        - best_diff: float - лучшее значение diff (из выбранной стратегии)\n",
    "        - pnl_rsi: float - значение PnL для стратегии RSI\n",
    "        - diff_rsi: float - значение diff для стратегии RSI\n",
    "        - pnl_full: float - значение PnL для стратегии RSI+SMA/EMA\n",
    "        - diff_full: float - значение diff для стратегии RSI+SMA/EMA\n",
    "    \"\"\"\n",
    "    # Веса для метрик\n",
    "    WEIGHT_PNL = 0.80\n",
    "    WEIGHT_DIFF = 0.20\n",
    "    \n",
    "    # Максимальные значения для нормализации (можно настроить)\n",
    "    MAX_PNL = np.max([i.values for i in [trial for trial in study.trials if trial.values is not None]])  # предполагаемый максимум PnL\n",
    "    MAX_DIFF = 1    # максимум для diff (уже нормализован)\n",
    "    \n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_params = None\n",
    "    best_strategy = None\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    \n",
    "    # Для хранения всех метрик (для отладки/анализа)\n",
    "    full_results = []\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит все 4 метрики\n",
    "        if not trial.values or len(trial.values) < 4 and trial.values:\n",
    "            continue\n",
    "            \n",
    "        pnl_rsi, pnl_full, diff_rsi, diff_full = trial.values\n",
    "        \n",
    "        # Нормализация значений (защита от деления на 0)\n",
    "        norm_pnl_rsi = pnl_rsi / MAX_PNL if MAX_PNL != 0 else 0\n",
    "        norm_pnl_full = pnl_full / MAX_PNL if MAX_PNL != 0 else 0\n",
    "        norm_diff_rsi = diff_rsi / MAX_DIFF if MAX_DIFF != 0 else 0\n",
    "        norm_diff_full = diff_full / MAX_DIFF if MAX_DIFF != 0 else 0\n",
    "        \n",
    "        # Вычисляем скоринг для обеих стратегий\n",
    "        score_rsi = WEIGHT_PNL * norm_pnl_rsi + WEIGHT_DIFF * norm_diff_rsi\n",
    "        score_full = WEIGHT_PNL * norm_pnl_full + WEIGHT_DIFF * norm_diff_full\n",
    "        \n",
    "        # Определяем какая стратегия лучше в этом трейле\n",
    "        if score_rsi > score_full:\n",
    "            current_score = score_rsi\n",
    "            current_strategy = 'С трендовой линией'\n",
    "            current_pnl = pnl_rsi\n",
    "            current_diff = diff_rsi\n",
    "        else:\n",
    "            current_score = score_full\n",
    "            current_strategy = 'Трендовая + недельные скользящие'\n",
    "            current_pnl = pnl_full\n",
    "            current_diff = diff_full\n",
    "        \n",
    "        # Сохраняем все метрики для анализа\n",
    "        full_results.append({\n",
    "            'trial_number': trial.number,\n",
    "            'score_rsi': score_rsi,\n",
    "            'score_full': score_full,\n",
    "            'strategy': current_strategy,\n",
    "            'score': current_score,\n",
    "            'params': trial.params\n",
    "        })\n",
    "        \n",
    "        # Обновляем лучший результат\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_trial_number = trial.number\n",
    "            best_params = trial.params\n",
    "            best_strategy = current_strategy\n",
    "            best_pnl = current_pnl\n",
    "            best_diff = current_diff\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с четырьмя метриками (pnl_rsi, pnl_full, diff_rsi, diff_full).\")\n",
    "\n",
    "    return (\n",
    "        best_score,\n",
    "        best_trial_number,\n",
    "        best_params,\n",
    "        best_strategy,\n",
    "        best_pnl,\n",
    "        best_diff,\n",
    "        # Возвращаем также все метрики для лучшего трейла\n",
    "        #next(t.values[0] for t in trials if t.number == best_trial_number),  # pnl_rsi\n",
    "        #next(t.values[2] for t in trials if t.number == best_trial_number),  # diff_rsi\n",
    "        #next(t.values[1] for t in trials if t.number == best_trial_number),  # pnl_full\n",
    "        #next(t.values[3] for t in trials if t.number == best_trial_number)   # diff_full\n",
    "    )\n",
    "\n",
    "def plot_price_with_indicators_mplfinance(df, ticker, save_path=None):\n",
    "    \"\"\"\n",
    "    Отрисовывает график движения цены с индикаторами и сигналами покупки/продажи, используя mplfinance.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame с данными о цене и индикаторах.\n",
    "        ticker (str): Тикер акции для заголовка графика.\n",
    "        save_path (str, optional): Путь для сохранения графика. Если None, то график покажется.\n",
    "    \"\"\"\n",
    "    # Копируем DataFrame, чтобы не менять оригинал\n",
    "    df = df.copy()\n",
    "\n",
    "    # Преобразуем столбец time в datetime и делаем индексом\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df = df.set_index(\"time\")\n",
    "\n",
    "    # Создаем список дополнительных панелей для индикаторов (без объема)\n",
    "    apds = []\n",
    "\n",
    "    if \"pmax\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"pmax\"], color=\"red\", ylabel=\"PMAX\", panel=0))\n",
    "    if \"var\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"var\"], color=\"blue\", ylabel=\"VAR\", panel=0))\n",
    "    if \"ema\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"ema\"], color=\"purple\", ylabel=\"EMA\", panel=0))\n",
    "\n",
    "    # Подготовка сигналов для отрисовки\n",
    "    buy_signals = df[df[\"buy_signal\"]]\n",
    "    sell_signals = df[df[\"sell_signal\"]]\n",
    "\n",
    "    # Создаем Series для сигналов, выровненные по индексу основного DataFrame\n",
    "    buy_series = pd.Series(index=df.index, dtype='float64')\n",
    "    buy_series[buy_signals.index] = buy_signals['open']\n",
    "\n",
    "    sell_series = pd.Series(index=df.index, dtype='float64')\n",
    "    sell_series[sell_signals.index] = sell_signals['open']\n",
    "\n",
    "    # Добавляем сигналы покупки\n",
    "    if not buy_signals.empty:\n",
    "        apds.append(mpf.make_addplot(\n",
    "            buy_series,\n",
    "            type='scatter',\n",
    "            markersize=50,\n",
    "            marker='^',\n",
    "            color='green',\n",
    "            label='Buy Signal',\n",
    "            panel=0\n",
    "        ))\n",
    "\n",
    "    # Добавляем сигналы продажи\n",
    "    if not sell_signals.empty:\n",
    "        apds.append(mpf.make_addplot(\n",
    "            sell_series,\n",
    "            type='scatter',\n",
    "            markersize=50,\n",
    "            marker='v',\n",
    "            color='red',\n",
    "            label='Sell Signal',\n",
    "            panel=0\n",
    "        ))\n",
    "\n",
    "    # Подготовка vlines (единый словарь)\n",
    "    vlines_dict = {}\n",
    "    if not buy_signals.empty:\n",
    "        vlines_dict['vlines'] = buy_signals.index.to_list()\n",
    "        vlines_dict['linewidths'] = 0.5\n",
    "        vlines_dict['colors'] = ['green'] * len(buy_signals)\n",
    "        vlines_dict['alpha'] = 0.5\n",
    "\n",
    "    if not sell_signals.empty:\n",
    "        if 'vlines' in vlines_dict:\n",
    "            vlines_dict['vlines'].extend(sell_signals.index.to_list())\n",
    "            vlines_dict['colors'].extend(['red'] * len(sell_signals))\n",
    "        else:\n",
    "            vlines_dict['vlines'] = sell_signals.index.to_list()\n",
    "            vlines_dict['linewidths'] = 0.5\n",
    "            vlines_dict['colors'] = ['red'] * len(sell_signals)\n",
    "            vlines_dict['alpha'] = 0.5\n",
    "\n",
    "    # Отрисовка графика с mplfinance\n",
    "    plot_kwargs = dict(\n",
    "        type=\"candle\",\n",
    "        style=\"yahoo\",\n",
    "        title=f\"График цены {ticker} с индикаторами\",\n",
    "        ylabel=\"Цена\",\n",
    "        addplot=apds,\n",
    "        show_nontrading=False,\n",
    "        figsize=(18, 10),\n",
    "        warn_too_much_data=len(df) + 1,\n",
    "    )\n",
    "\n",
    "    if \"volume\" in df.columns:\n",
    "        plot_kwargs[\"volume\"] = True\n",
    "        plot_kwargs[\"panel_ratios\"] = (6, 3)\n",
    "    if vlines_dict:\n",
    "        plot_kwargs[\"vlines\"] = vlines_dict\n",
    "\n",
    "    if save_path:\n",
    "        plot_kwargs[\"savefig\"] = save_path\n",
    "\n",
    "    mpf.plot(df, **plot_kwargs)\n",
    "    \n",
    "def plot_3d_metrics(trials, x_label='среднее значение f1', y_label='среднее значение AUC ROC', z_label='стандартное отклонение f1', deffs=None, directions=['максимизировать', 'максимизировать', 'минимизировать']):\n",
    "    \"\"\"\n",
    "    Функция для построения 3D-графика на основе результатов Optuna.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    trials : list\n",
    "        Список объектов `optuna.trial.FrozenTrial` из study.trials.\n",
    "    x_label : str, optional\n",
    "        Название для оси X (по умолчанию 'среднее значение f1').\n",
    "    y_label : str, optional\n",
    "        Название для оси Y (по умолчанию 'среднее значение AUC ROC').\n",
    "    z_label : str, optional\n",
    "        Название для оси Z (по умолчанию 'стандартное отклонение f1').\n",
    "    deffs : list, optional\n",
    "        Пороговые значения для фильтрации trials (по умолчанию None).\n",
    "    directions : list, optional\n",
    "        Направления оптимизации для каждой метрики (по умолчанию ['максимизировать', 'максимизировать', 'минимизировать']).\n",
    "    \"\"\"\n",
    "    print(len(trials))\n",
    "\n",
    "    # Сопоставление направлений с операторами сравнения\n",
    "    direction_to_operator = {\n",
    "        'максимизировать': lambda a, b: a > b,\n",
    "        'минимизировать': lambda a, b: a < b\n",
    "    }\n",
    "\n",
    "    # Фильтрация trials\n",
    "    if deffs is None:\n",
    "        trials = [trial for trial in trials if trial.values is not None]\n",
    "    else:\n",
    "        trials = [\n",
    "            trial for trial in trials\n",
    "            if trial.values is not None\n",
    "            and direction_to_operator[directions[0]](trial.values[0], deffs[0])\n",
    "            and direction_to_operator[directions[1]](trial.values[1], deffs[1])\n",
    "            and direction_to_operator[directions[2]](trial.values[2], deffs[2])\n",
    "        ]\n",
    "\n",
    "    print(len(trials))\n",
    "\n",
    "    # Извлечение значений метрик\n",
    "    x_vals = [trial.values[0] for trial in trials]\n",
    "    y_vals = [trial.values[1] for trial in trials]\n",
    "    z_vals = [trial.values[2] for trial in trials]\n",
    "\n",
    "    # Форматирование параметров для hover text\n",
    "    def format_params(params):\n",
    "        return '<br>'.join([f\"{key}: {value}\" for key, value in params.items()])\n",
    "\n",
    "    # Создание текста для hover\n",
    "    hover_texts = [\n",
    "        f\"Number: {trial.number}<br>\"\n",
    "        f\"{x_label}: {trial.values[0]:.4f}<br>\"\n",
    "        f\"{y_label}: {trial.values[1]:.4f}<br>\"\n",
    "        f\"{z_label}: {trial.values[2]:.4f}<br>\"\n",
    "        f\"Params:<br>{format_params(trial.params)}\"\n",
    "        for trial in trials\n",
    "    ]\n",
    "\n",
    "    # Создание 3D-графика\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x_vals, y=y_vals, z=z_vals,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=x_vals,  # Цветовая шкала может быть привязана к одной из метрик\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=hover_texts,  # Добавляем hover text\n",
    "        hoverinfo='text'   # Указываем, что при наведении нужно показывать текст\n",
    "    )])\n",
    "\n",
    "    # Добавление меток к осям\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=x_label,\n",
    "            yaxis_title=y_label,\n",
    "            zaxis_title=z_label\n",
    "        ),\n",
    "        title=\"3 метрики через Optuna\"\n",
    "    )\n",
    "\n",
    "    # Отображение графика\n",
    "    fig.show()\n",
    "\n",
    "def prepare_regime_params(optuna_params):\n",
    "    \"\"\"\n",
    "    Преобразует параметры из формата Optuna в формат для generate_signals_with_regime_v8\n",
    "    с поддержкой AMA во всех режимах.\n",
    "    \n",
    "    Args:\n",
    "        optuna_params (dict): Словарь с параметрами из Optuna\n",
    "        \n",
    "    Returns:\n",
    "        dict: Словарь с параметрами в нужном формате\n",
    "    \"\"\"\n",
    "    base_params = {}\n",
    "    regime_params = {}\n",
    "    \n",
    "\n",
    "    base_params['threshold_atr_factor'] = optuna_params['threshold_atr_factor']\n",
    "    base_params['smoothing_alpha'] = optuna_params['smoothing_alpha']\n",
    "    base_params['min_atr_period'] = optuna_params['min_atr_period']\n",
    "    \n",
    "    for regime in range(5):  # Режимы от 0 до 4\n",
    "        regime_key = f'regime_{regime}_'\n",
    "        average_type = optuna_params.get(f'{regime_key}average_type', 'SMA')\n",
    "        \n",
    "        # Базовые параметры для всех типов скользящих средних\n",
    "        regime_params[regime] = {\n",
    "            'average_type': average_type,\n",
    "            'moving_average_length': optuna_params.get(f'{regime_key}ma_length', 50),\n",
    "            'atr_period': optuna_params.get(f'{regime_key}atr_period', 14),\n",
    "            'atr_multiplier': optuna_params.get(f'{regime_key}atr_multiplier', 3.0)\n",
    "        }\n",
    "        \n",
    "        # Дополнительные параметры для AMA\n",
    "        if average_type == 'AMA':\n",
    "            regime_params[regime]['ama_params'] = {\n",
    "                'atr_period': optuna_params.get(f'{regime_key}ama_atr_period', 10),\n",
    "                'min_period': optuna_params.get(f'{regime_key}ama_min_period', 5),\n",
    "                'max_period': optuna_params.get(f'{regime_key}ama_max_period', 50)\n",
    "            }\n",
    "    \n",
    "    return base_params, regime_params\n",
    "\n",
    "def pair_and_clean_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Оставляет только первый buy после flat и первый sell после buy.\n",
    "    Гарантирует, что каждая покупка имеет свою продажу.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # пусть V5 уже записал нам в df['buy_signal'], df['sell_signal'] — raw-сигналы\n",
    "    buy_raw  = df['buy_signal'].values\n",
    "    sell_raw = df['sell_signal'].values\n",
    "\n",
    "    # обнуляем\n",
    "    df['buy_signal']  = False\n",
    "    df['sell_signal'] = False\n",
    "\n",
    "    in_pos = False\n",
    "    for i in range(len(df)):\n",
    "        if not in_pos and buy_raw[i]:\n",
    "            # открываем новую сделку\n",
    "            df.iat[i, df.columns.get_loc('buy_signal')] = True\n",
    "            in_pos = True\n",
    "        elif in_pos and sell_raw[i]:\n",
    "            # закрываем\n",
    "            df.iat[i, df.columns.get_loc('sell_signal')] = True\n",
    "            in_pos = False\n",
    "        # все остальные raw-сигналы игнорируем\n",
    "\n",
    "    # если позиция осталась открытой — принудительный выход на последнем баре\n",
    "    if in_pos and len(df)>0:\n",
    "        df.iat[len(df)-1, df.columns.get_loc('sell_signal')] = True\n",
    "\n",
    "    return df\n",
    "\n",
    "import joblib\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "class MachineLearningRSI:\n",
    "    def __init__(self,\n",
    "                 rsi_length=300,\n",
    "                 use_smoothing=True,\n",
    "                 smoothing_length=268,\n",
    "                 smoothing_type='ALMA',\n",
    "                 alma_sigma=6,\n",
    "                 rsi_overbought=70,\n",
    "                 rsi_oversold=30,\n",
    "                 use_knn=True,\n",
    "                 knn_neighbors=7,\n",
    "                 knn_lookback=500,\n",
    "                 knn_weight=0.6,\n",
    "                 feature_count=5,\n",
    "                 use_filter=True,\n",
    "                 filter_method='Kalman',\n",
    "                 filter_strength=0.7,\n",
    "                 sma_length=20 + 7*24*4*3,\n",
    "                 ema_length=21 + 7*24*4*3\n",
    "                 ):\n",
    "\n",
    "        # Базовые параметры\n",
    "        self.rsi_length = rsi_length\n",
    "        self.use_smoothing = use_smoothing\n",
    "        self.smoothing_length = smoothing_length\n",
    "        self.smoothing_type = smoothing_type\n",
    "        self.alma_sigma = alma_sigma\n",
    "\n",
    "        # Пороговые уровни\n",
    "        self.rsi_overbought = rsi_overbought\n",
    "        self.rsi_oversold = rsi_oversold\n",
    "\n",
    "        # Параметры KNN\n",
    "        self.use_knn = use_knn\n",
    "        self.knn_neighbors = knn_neighbors\n",
    "        self.knn_lookback = knn_lookback\n",
    "        self.knn_weight = knn_weight\n",
    "        self.feature_count = feature_count\n",
    "\n",
    "        # Фильтрация\n",
    "        self.use_filter = use_filter\n",
    "        self.filter_method = filter_method\n",
    "        self.filter_strength = filter_strength\n",
    "\n",
    "        self.sma_length = sma_length\n",
    "        self.ema_length = ema_length\n",
    "\n",
    "    def calculate_rsi(self, close: pd.Series, length: int) -> pd.Series:\n",
    "        \"\"\"Расчет RSI через RMA аналогично PineScript ta.rsi\"\"\"\n",
    "        delta = close.diff()\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "        avg_gain = gain.ewm(alpha=1/length, min_periods=length, adjust=False).mean()\n",
    "        avg_loss = loss.ewm(alpha=1/length, min_periods=length, adjust=False).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def smooth(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Корректный ALMA\"\"\"\n",
    "        if self.smoothing_type == 'SMA':\n",
    "            return series.rolling(self.smoothing_length).mean()\n",
    "        elif self.smoothing_type == 'EMA':\n",
    "            return series.ewm(span=self.smoothing_length, adjust=False).mean()\n",
    "        elif self.smoothing_type == 'ALMA':\n",
    "            m = self.smoothing_length\n",
    "            offset = 0.85\n",
    "            sigma = self.alma_sigma\n",
    "\n",
    "            def alma(series):\n",
    "                window = np.arange(m)\n",
    "                weights = np.exp(-((window - offset * (m-1))**2) / (2*(sigma**2)))\n",
    "                weights /= weights.sum()\n",
    "                return np.convolve(series, weights, mode='valid')\n",
    "\n",
    "            def alma_causal(series: pd.Series, length: int = 9, offset: float = 0.85, sigma: float = 6) -> pd.Series:\n",
    "                \"\"\"\n",
    "                Казуальная реализация ALMA (Arnaud Legoux Moving Average)\n",
    "                Использует только прошлые и текущие значения, без lookahead bias.\n",
    "                \"\"\"\n",
    "                if length > len(series):\n",
    "                    return pd.Series(np.nan, index=series.index)\n",
    "\n",
    "                # Предвычисление весов ALMA\n",
    "                window = np.arange(length)\n",
    "                m = offset * (length - 1)\n",
    "                s = length / sigma\n",
    "                weights = np.exp(-((window - m) ** 2) / (2 * s ** 2))\n",
    "                weights /= weights.sum()\n",
    "\n",
    "                # Применяем ALMA казуально (rolling + dot product)\n",
    "                alma_vals = []\n",
    "                for i in range(length - 1, len(series)):\n",
    "                    window_data = series.iloc[i - length + 1:i + 1]\n",
    "                    if window_data.isnull().any():\n",
    "                        alma_vals.append(np.nan)\n",
    "                    else:\n",
    "                        alma_vals.append(np.dot(weights, window_data.values))\n",
    "\n",
    "                # Паддинг NaN в начало, чтобы сохранить индекс\n",
    "                alma_series = pd.Series([np.nan] * (length - 1) + alma_vals, index=series.index)\n",
    "\n",
    "                return alma_series\n",
    "\n",
    "            alma_series = alma_causal(series.fillna(method='ffill'), m, offset, sigma)#, index=series.index[pad:-pad])\n",
    "            #alma_series = alma_series.reindex(series.index, method='nearest')\n",
    "            return alma_series\n",
    "        else:\n",
    "            return series\n",
    "\n",
    "    def feature_extraction(self, close: pd.Series, rsi: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Извлечение признаков для KNN\"\"\"\n",
    "        features = pd.DataFrame(index=close.index)\n",
    "        features['rsi'] = self.normalize(rsi, self.knn_lookback)\n",
    "\n",
    "        if self.feature_count >= 2:\n",
    "            features['momentum_rsi'] = self.normalize(rsi.diff(3), self.knn_lookback)\n",
    "        if self.feature_count >= 3:\n",
    "            features['volatility_rsi'] = self.normalize(rsi.rolling(10).std(), self.knn_lookback)\n",
    "        if self.feature_count >= 4:\n",
    "            features['slope_rsi'] = self.normalize(self.get_slope(rsi, 5), self.knn_lookback)\n",
    "        if self.feature_count >= 5:\n",
    "            features['momentum_price'] = self.normalize(close.diff(5), self.knn_lookback)\n",
    "\n",
    "        return features.dropna()\n",
    "\n",
    "    def normalize(self, series: pd.Series, period: int) -> pd.Series:\n",
    "        \"\"\"Мин-макс нормализация\"\"\"\n",
    "        min_val = series.rolling(period).min()\n",
    "        max_val = series.rolling(period).max()\n",
    "        norm = (series - min_val) / (max_val - min_val)\n",
    "        return norm.clip(0, 1)\n",
    "\n",
    "    def get_slope(self, series: pd.Series, window: int) -> pd.Series:\n",
    "        \"\"\"Расчет наклона линейной регрессии\"\"\"\n",
    "        idx = np.arange(window)\n",
    "        def linreg(x):\n",
    "            A = np.vstack([idx, np.ones(len(idx))]).T\n",
    "            m, c = np.linalg.lstsq(A, x, rcond=None)[0]\n",
    "            return m\n",
    "        return series.rolling(window).apply(linreg, raw=True)\n",
    "\n",
    "    def apply_knn(self, features: pd.DataFrame, rsi: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Оптимизированная, но идентичная оригиналу версия KNN.\n",
    "        Сохраняет точную математику оригинального apply_knn_b с ускорением через BallTree.\n",
    "        \"\"\"\n",
    "        # Сохраняем структуру как в оригинале\n",
    "        full_index = rsi.index\n",
    "        common_index = features.index.intersection(rsi.index)\n",
    "        features = features.loc[common_index]\n",
    "        rsi = rsi.loc[common_index]\n",
    "\n",
    "        enhanced_rsi = pd.Series(index=full_index, data=np.nan)\n",
    "        enhanced_rsi.loc[rsi.index] = rsi\n",
    "\n",
    "        if len(features) < self.knn_lookback:\n",
    "            return enhanced_rsi\n",
    "\n",
    "        feature_array = features.values\n",
    "        rsi_array = rsi.values\n",
    "\n",
    "        # Основное изменение: BallTree строится на скользящем окне\n",
    "        for t in range(self.knn_lookback, len(feature_array)):\n",
    "            window_start = t - self.knn_lookback\n",
    "            window_end = t\n",
    "            X_window = feature_array[window_start:window_end]\n",
    "            y_window = rsi_array[window_start:window_end]\n",
    "\n",
    "            # Строим дерево только на текущем окне\n",
    "            tree = BallTree(X_window, metric='euclidean')\n",
    "            distances, indices = tree.query(feature_array[t].reshape(1, -1),\n",
    "                                          k=self.knn_neighbors)\n",
    "\n",
    "            # Точное воспроизведение оригинальной логики взвешивания\n",
    "            weights = np.where(distances[0] < 1e-6, 1.0, 1.0 / distances[0])\n",
    "            prediction = np.average(y_window[indices[0]], weights=weights)\n",
    "\n",
    "            idx = common_index[t]\n",
    "            enhanced_rsi.loc[idx] = (1 - self.knn_weight) * rsi.loc[idx] + self.knn_weight * prediction\n",
    "\n",
    "        return enhanced_rsi\n",
    "\n",
    "    def kalman_filter(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Калман-фильтр с параметрами ближе к PineScript\"\"\"\n",
    "        n = len(series)\n",
    "        xhat = np.full(n, np.nan)\n",
    "        P = np.zeros(n)\n",
    "        R = self.filter_strength * 0.1  # Очень маленький measurement noise\n",
    "        Q = self.filter_strength * 0.01  # Очень маленький process noise\n",
    "\n",
    "        first_valid_idx = series.first_valid_index()\n",
    "        if first_valid_idx is None:\n",
    "            return pd.Series(xhat, index=series.index)\n",
    "\n",
    "        first_idx = series.index.get_loc(first_valid_idx)\n",
    "        xhat[first_idx] = series.iloc[first_idx]\n",
    "        P[first_idx] = 1.0\n",
    "\n",
    "        for k in range(first_idx + 1, n):\n",
    "            if np.isnan(series.iloc[k]):\n",
    "                xhat[k] = xhat[k - 1]\n",
    "                P[k] = P[k - 1] + Q\n",
    "            else:\n",
    "                xhatminus = xhat[k-1]\n",
    "                Pminus = P[k-1] + Q\n",
    "                K = Pminus / (Pminus + R)\n",
    "                xhat[k] = xhatminus + K * (series.iloc[k] - xhatminus)\n",
    "                P[k] = (1 - K) * Pminus\n",
    "\n",
    "        return pd.Series(xhat, index=series.index)\n",
    "\n",
    "    def filter_series(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Применение фильтрации к финальному RSI\"\"\"\n",
    "        if self.filter_method == 'None':\n",
    "            return series\n",
    "        elif self.filter_method == 'Kalman':\n",
    "            return self.kalman_filter(series)\n",
    "        elif self.filter_method == 'DoubleEMA':\n",
    "            ema1 = series.ewm(span=int(self.filter_strength * 10)).mean()\n",
    "            ema2 = ema1.ewm(span=int(self.filter_strength * 5)).mean()\n",
    "            return ema2\n",
    "        elif self.filter_method == 'ALMA':\n",
    "            return self.smooth(series)\n",
    "        else:\n",
    "            return series\n",
    "\n",
    "    def week_level(self, close):\n",
    "        sma_length = self.sma_length\n",
    "        ema_length = self.ema_length\n",
    "\n",
    "        # Вычисление 20-недельной SMA\n",
    "        SMA_20w = close.rolling(window=sma_length, min_periods=1).mean()\n",
    "\n",
    "        # Вычисление 21-недельной EMA\n",
    "        MA_21w = close.ewm(span=ema_length, adjust=False).mean()\n",
    "\n",
    "        return SMA_20w, MA_21w\n",
    "\n",
    "\n",
    "    def fit(self, close: pd.Series) -> pd.Series:\n",
    "        \"\"\"Основная функция расчёта\"\"\"\n",
    "        rsi = self.calculate_rsi(close, self.rsi_length)\n",
    "        if self.use_smoothing:\n",
    "            rsi = self.smooth(rsi)\n",
    "        if self.use_knn:\n",
    "            features = self.feature_extraction(close, rsi)\n",
    "\n",
    "            rsi = self.apply_knn(features, rsi)\n",
    "\n",
    "        if self.use_filter:\n",
    "            rsi = self.filter_series(rsi)\n",
    "\n",
    "        sma, ma = self.week_level(close)\n",
    "\n",
    "        return rsi.clip(0, 100), sma, ma\n",
    "\n",
    "\n",
    "class TinkoffHistoricalDataCollector:\n",
    "    def __init__(self):\n",
    "        self.sma_state = {}\n",
    "\n",
    "    def generateVar(self, high_array, low_array, moving_average_length=10):\n",
    "        valpha = 2 / (moving_average_length + 1)\n",
    "        hl2 = (high_array + low_array) / 2\n",
    "\n",
    "        before_val = hl2[0] if len(hl2) > 0 else 0\n",
    "\n",
    "        vud1 = []\n",
    "        vdd1 = []\n",
    "        for current_hl2 in hl2:\n",
    "            if current_hl2 > before_val:\n",
    "                vud1.append(current_hl2 - before_val)\n",
    "                vdd1.append(0)\n",
    "            elif current_hl2 < before_val:\n",
    "                vdd1.append(before_val - current_hl2)\n",
    "                vud1.append(0)\n",
    "            else:\n",
    "                vud1.append(0)\n",
    "                vdd1.append(0)\n",
    "            before_val = current_hl2\n",
    "\n",
    "        def calculate_window_sums(arr, window_size=9):\n",
    "          return [sum(arr[max(0, i - window_size + 1):i+1]) for i in range(len(arr))]\n",
    "\n",
    "        vUD = calculate_window_sums(vud1, 9)\n",
    "        vDD = calculate_window_sums(vdd1, 9)\n",
    "\n",
    "        vUD_ar = np.array(vUD)\n",
    "        vDD_ar = np.array(vDD)\n",
    "\n",
    "        epsilon = 1e-10\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            vCMO = np.divide(vUD_ar - vDD_ar, vUD_ar + vDD_ar + epsilon)\n",
    "\n",
    "        vCMO = np.nan_to_num(vCMO, nan=0.0)\n",
    "\n",
    "        var = []\n",
    "        var_before = 0.0\n",
    "        for i in range(len(hl2)):\n",
    "            if i < len(vCMO):\n",
    "                cmo = abs(vCMO[i])\n",
    "                var_current = (valpha * cmo * hl2[i]) + (1 - valpha * cmo) * var_before\n",
    "            else:\n",
    "                var_current = var_before\n",
    "            var.append(var_current)\n",
    "            var_before = var_current\n",
    "\n",
    "        return np.array(var)\n",
    "\n",
    "    def generateAma(self, high_array, low_array, close_array, atr_period=14, min_period=5, max_period=50):\n",
    "        \"\"\"\n",
    "        Генерация адаптивного скользящего среднего на основе волатильности.\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param min_period: Минимальный период скользящего среднего.\n",
    "        :param max_period: Максимальный период скользящего среднего.\n",
    "        :return: Массив значений адаптивного скользящего среднего.\n",
    "        \"\"\"\n",
    "        # Рассчитываем ATR\n",
    "        atr = self._calculate_atr(high_array, low_array, close_array, atr_period)\n",
    "\n",
    "        # Нормализуем ATR для использования в качестве коэффициента\n",
    "        normalized_atr = (atr - np.min(atr)) / (np.max(atr) - np.min(atr) + 1e-10)\n",
    "\n",
    "        # Рассчитываем динамический период\n",
    "        dynamic_period = min_period + (max_period - min_period) * normalized_atr\n",
    "\n",
    "        # Рассчитываем адаптивное скользящее среднее (гибрид SMA и EMA)\n",
    "        adaptive_ma = np.zeros_like(close_array)\n",
    "        for i in range(len(close_array)):\n",
    "            if i < int(dynamic_period[i]):\n",
    "                adaptive_ma[i] = np.mean(close_array[:i+1])  # SMA для начальных значений\n",
    "            else:\n",
    "                period = int(dynamic_period[i])\n",
    "                alpha = 2 / (period + 1)\n",
    "                adaptive_ma[i] = alpha * close_array[i] + (1 - alpha) * adaptive_ma[i-1]  # EMA\n",
    "\n",
    "        return adaptive_ma\n",
    "\n",
    "    def _calculate_atr(self, high_array, low_array, close_array, period=14):\n",
    "        \"\"\"\n",
    "        Рассчитывает Average True Range (ATR).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param period: Период для расчета ATR.\n",
    "        :return: Массив значений ATR.\n",
    "        \"\"\"\n",
    "        tr = np.zeros_like(high_array)\n",
    "        tr[0] = high_array[0] - low_array[0]\n",
    "\n",
    "        for i in range(1, len(high_array)):\n",
    "            hl = high_array[i] - low_array[i]\n",
    "            hc = abs(high_array[i] - close_array[i-1])\n",
    "            lc = abs(low_array[i] - close_array[i-1])\n",
    "            tr[i] = max(hl, hc, lc)\n",
    "\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period-1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i-1] * (period-1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateAtr(self, high_array, low_array, close_array, period=14):\n",
    "\n",
    "        # Рассчитываем True Range (TR)\n",
    "        tr1 = high_array - low_array\n",
    "        tr2 = np.abs(high_array - np.roll(close_array, 1))\n",
    "        tr3 = np.abs(low_array - np.roll(close_array, 1))\n",
    "\n",
    "        tr = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "\n",
    "        # Рассчитываем ATR\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period - 1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i - 1] * (period - 1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateSma(self, high_array, low_array, window=10):\n",
    "        \"\"\"\n",
    "        Генерация Simple Moving Average (SMA).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param window: Период SMA.\n",
    "        :return: Массив значений SMA.\n",
    "        \"\"\"\n",
    "        hl2 = (high_array + low_array) * 0.5\n",
    "\n",
    "        if window <= 1:\n",
    "            return hl2\n",
    "\n",
    "        # Создаем массив для результатов с NaN\n",
    "        sma = np.full_like(hl2, np.nan)\n",
    "\n",
    "        # Рассчитываем кумулятивную сумму\n",
    "        cumsum = np.cumsum(hl2)\n",
    "\n",
    "        # Создаем сдвинутый кумулятивный массив\n",
    "        shifted_cumsum = np.zeros_like(cumsum)\n",
    "        shifted_cumsum[window:] = cumsum[:-window]\n",
    "\n",
    "        # Вычисляем SMA для валидных периодов\n",
    "        valid = slice(window - 1, None)\n",
    "        sma[valid] = (cumsum[valid] - shifted_cumsum[valid]) / window\n",
    "\n",
    "        return sma\n",
    "\n",
    "    def generatePMax(self, var_array, close_array, high_array, low_array, atr_period, atr_multiplier):\n",
    "        \"\"\"\n",
    "        Генерация PMax (Profit Maximizer).\n",
    "\n",
    "        :param var_array: Массив значений скользящего среднего.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :return: Массив значений PMax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            atr = self.generateAtr(high_array, low_array, close_array, period=atr_period)\n",
    "        except Exception as exp:\n",
    "            print('exception in atr:', str(exp), flush=True)\n",
    "            return []\n",
    "\n",
    "        previous_final_upperband = 0\n",
    "        previous_final_lowerband = 0\n",
    "        final_upperband = 0\n",
    "        final_lowerband = 0\n",
    "        previous_var = 0\n",
    "        previous_pmax = 0\n",
    "        pmax = []\n",
    "        pmaxc = 0\n",
    "\n",
    "        for i in range(0, len(close_array)):\n",
    "            if np.isnan(close_array[i]):\n",
    "                pass\n",
    "            else:\n",
    "                atrc = atr[i]\n",
    "                varc = var_array[i]\n",
    "\n",
    "                if math.isnan(atrc):\n",
    "                    atrc = 0\n",
    "\n",
    "                basic_upperband = varc + atr_multiplier * atrc\n",
    "                basic_lowerband = varc - atr_multiplier * atrc\n",
    "\n",
    "                if basic_upperband < previous_final_upperband or previous_var > previous_final_upperband:\n",
    "                    final_upperband = basic_upperband\n",
    "                else:\n",
    "                    final_upperband = previous_final_upperband\n",
    "\n",
    "                if basic_lowerband > previous_final_lowerband or previous_var < previous_final_lowerband:\n",
    "                    final_lowerband = basic_lowerband\n",
    "                else:\n",
    "                    final_lowerband = previous_final_lowerband\n",
    "\n",
    "                if previous_pmax == previous_final_upperband and varc <= final_upperband:\n",
    "                    pmaxc = final_upperband\n",
    "                else:\n",
    "                    if previous_pmax == previous_final_upperband and varc >= final_upperband:\n",
    "                        pmaxc = final_lowerband\n",
    "                    else:\n",
    "                        if previous_pmax == previous_final_lowerband and varc >= final_lowerband:\n",
    "                            pmaxc = final_lowerband\n",
    "                        elif previous_pmax == previous_final_lowerband and varc <= final_lowerband:\n",
    "                            pmaxc = final_upperband\n",
    "\n",
    "                pmax.append(pmaxc)\n",
    "\n",
    "                previous_var = varc\n",
    "\n",
    "                previous_final_upperband = final_upperband\n",
    "\n",
    "                previous_final_lowerband = final_lowerband\n",
    "\n",
    "                previous_pmax = pmaxc\n",
    "\n",
    "        return pmax\n",
    "    def generate_signals(self, df, moving_average_length=10, atr_period=10, atr_multiplier=3, average_type='SMA',\n",
    "        ama_params=None):\n",
    "        \"\"\"\n",
    "        Генерация сигналов на основе SMA или AMA.\n",
    "        \n",
    "        asciidoc\n",
    "        \n",
    "        Copy\n",
    "        :param df: DataFrame с данными.\n",
    "        :param moving_average_length: Период скользящего среднего.\n",
    "        :param atr_period: Период ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :param average_type: Тип скользящего среднего ('SMA' или 'AMA').\n",
    "        :param ama_params: Параметры для AMA (если используется).\n",
    "        :return: DataFrame с добавленными сигналами.\n",
    "        \"\"\"\n",
    "        high_array = df[\"high\"].values\n",
    "        low_array = df[\"low\"].values\n",
    "        close_array = df[\"close\"].values\n",
    "        df = df.copy()\n",
    "        \n",
    "        if average_type == 'SMA':\n",
    "            ma_arr = self.generateSma(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'VAR':\n",
    "            ma_arr = self.generateVar(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'AMA':\n",
    "            if ama_params is None:\n",
    "                raise ValueError(\"Для AMA необходимо указать параметры ama_params.\")\n",
    "            ma_arr = self.generateAma(high_array, low_array, close_array, **ama_params)\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемый тип скользящего среднего.\")\n",
    "        \n",
    "        pmax = self.generatePMax(ma_arr, close_array, high_array, low_array, atr_period, atr_multiplier)\n",
    "        df[\"pmax\"] = pmax\n",
    "        df[\"ma\"] = ma_arr\n",
    "        df[\"buy_signal\"] = (df[\"ma\"] > df[\"pmax\"]) & (df[\"ma\"].shift(1) < df[\"pmax\"].shift(1))\n",
    "        df[\"sell_signal\"] = (df[\"ma\"] < df[\"pmax\"]) & (df[\"ma\"].shift(1) > df[\"pmax\"].shift(1))\n",
    "        \n",
    "        return df\n",
    "    def generate_signals_with_regime_v8(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        regime_series: pd.Series,\n",
    "        regime_params: dict,\n",
    "        fallback_type: str = 'SMA',\n",
    "        threshold_atr_factor: float = 0.05,\n",
    "        smoothing_alpha: float = 0.2,\n",
    "        min_atr_period: int = 5  # Минимальный период ATR для стабильности\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        V8 — Улучшенная версия с обработкой NaN и проверкой параметров.\n",
    "        \n",
    "        Добавлены:\n",
    "        - Проверка и коррекция параметров ATR\n",
    "        - Обработка NaN в промежуточных расчетах\n",
    "        - Более стабильная инициализация\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        high = df['high'].values\n",
    "        low = df['low'].values\n",
    "        close = df['close'].values\n",
    "        regs = regime_series.reindex(df.index).fillna(0).astype(int).values\n",
    "        n = len(df)\n",
    "        \n",
    "        # Корректируем параметры ATR, чтобы они не были слишком большими\n",
    "        for r in regime_params:\n",
    "            regime_params[r]['atr_period'] = max(min_atr_period, \n",
    "                min(regime_params[r].get('atr_period', 14), len(df)//2))\n",
    "        \n",
    "        # 1) Предварительно векторно считаем для каждого режима MA и ATR\n",
    "        var_dict, atr_dict = {}, {}\n",
    "        for r, prm in regime_params.items():\n",
    "            atype = prm.get('average_type', fallback_type).upper()\n",
    "            L = max(1, prm.get('moving_average_length', 10))  # Гарантируем минимум 1\n",
    "            \n",
    "            try:\n",
    "                if atype == 'SMA':\n",
    "                    var_r = self.generateSma(high, low, window=L)\n",
    "                elif atype == 'VAR':\n",
    "                    var_r = self.generateVar(high, low, moving_average_length=L)\n",
    "                elif atype == 'AMA':\n",
    "                    ama_p = prm.get('ama_params', \n",
    "                        {'atr_period':14, 'min_period':5, 'max_period':50})\n",
    "                    var_r = self.generateAma(high, low, close, **ama_p)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown MA type `{atype}` for regime {r}\")\n",
    "                \n",
    "                # Заменяем возможные NaN на последнее валидное значение\n",
    "                var_r = pd.Series(var_r).fillna(method='ffill').fillna(0).values\n",
    "                var_dict[r] = np.array(var_r, dtype=float)\n",
    "                \n",
    "                # ATR с проверкой периода\n",
    "                ap = max(min_atr_period, prm.get('atr_period', 14))\n",
    "                atr_r = self.generateAtr(high, low, close, period=ap)\n",
    "                atr_r = pd.Series(atr_r).fillna(method='ffill').fillna(0).values\n",
    "                atr_dict[r] = np.array(atr_r, dtype=float)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing regime {r}: {str(e)}\")\n",
    "                # Используем fallback значения\n",
    "                var_dict[r] = np.zeros(n)\n",
    "                atr_dict[r] = np.zeros(n)\n",
    "\n",
    "        # 2) Проходим по барам и считаем \"raw\" PMax\n",
    "        final_upper = np.zeros(n, dtype=float)\n",
    "        final_lower = np.zeros(n, dtype=float)\n",
    "        pmax_raw = np.zeros(n, dtype=float)\n",
    "\n",
    "        prev_fu, prev_fl, prev_var, prev_pm, prev_reg = [None]*5\n",
    "        for i in range(n):\n",
    "            r = regs[i]\n",
    "            var_c = var_dict[r][i]\n",
    "            atr_c = atr_dict[r][i]\n",
    "            mult = regime_params[r].get('atr_multiplier', 3.0)\n",
    "\n",
    "            bu = var_c + mult * atr_c\n",
    "            bl = var_c - mult * atr_c\n",
    "\n",
    "            # Инициализация или сброс при смене режима\n",
    "            if i == 0 or r != prev_reg:\n",
    "                u = bu\n",
    "                l = bl\n",
    "                pm = var_c\n",
    "            else:\n",
    "                # final upper\n",
    "                if bu < prev_fu or prev_var > prev_fu:\n",
    "                    u = bu\n",
    "                else:\n",
    "                    u = prev_fu\n",
    "                # final lower\n",
    "                if bl > prev_fl or prev_var < prev_fl:\n",
    "                    l = bl\n",
    "                else:\n",
    "                    l = prev_fl\n",
    "                # state-machine PMax\n",
    "                if prev_pm == prev_fu and var_c <= u:\n",
    "                    pm = u\n",
    "                elif prev_pm == prev_fu and var_c >= u:\n",
    "                    pm = l\n",
    "                elif prev_pm == prev_fl and var_c >= l:\n",
    "                    pm = l\n",
    "                elif prev_pm == prev_fl and var_c <= l:\n",
    "                    pm = u\n",
    "                else:\n",
    "                    pm = prev_pm\n",
    "\n",
    "            # Сохраняем значения\n",
    "            final_upper[i] = u\n",
    "            final_lower[i] = l\n",
    "            pmax_raw[i] = pm\n",
    "\n",
    "            # Обновляем предыдущие значения\n",
    "            prev_fu, prev_fl, prev_var, prev_pm, prev_reg = u, l, var_c, pm, r\n",
    "\n",
    "        # 3) EMA-сглаживание PMax с обработкой NaN\n",
    "        pmax_smooth = np.zeros(n, dtype=float)\n",
    "        prev_ps = None\n",
    "        for i in range(n):\n",
    "            raw = pmax_raw[i]\n",
    "            if np.isnan(raw):\n",
    "                raw = prev_ps if prev_ps is not None else 0\n",
    "                \n",
    "            if prev_ps is None or np.isnan(prev_ps):\n",
    "                sm = raw\n",
    "            else:\n",
    "                sm = smoothing_alpha * raw + (1 - smoothing_alpha) * prev_ps\n",
    "                \n",
    "            pmax_smooth[i] = sm\n",
    "            prev_ps = sm\n",
    "\n",
    "        # 4) Формируем финальный DF и сигналы\n",
    "        df['ma'] = np.choose(regs, [var_dict[r] for r in sorted(var_dict)])\n",
    "        df['pmax'] = pmax_smooth\n",
    "        ATR = np.choose(regs, [atr_dict[r] for r in sorted(atr_dict)])\n",
    "\n",
    "        # Фильтрация сигналов\n",
    "        delta = df['ma'].values - df['pmax'].values\n",
    "        thr = threshold_atr_factor * ATR\n",
    "\n",
    "        buy = (delta > 0) & (np.roll(delta, 1) <= 0) & (delta > thr)\n",
    "        sell = (delta < 0) & (np.roll(delta, 1) >= 0) & (-delta > thr)\n",
    "\n",
    "        df['buy_signal'] = buy\n",
    "        df['sell_signal'] = sell\n",
    "        \n",
    "        return df\n",
    "\n",
    "def calculate_target(df, threshold=3.0):\n",
    "    # Проверка необходимых колонок\n",
    "    required_columns = ['event_price', 'event_sell_price']\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Отсутствуют необходимые колонки: {missing_cols}\")\n",
    "\n",
    "    # Копируем DataFrame чтобы не менять оригинал\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Рассчитываем процентное изменение\n",
    "    result_df['price_change_pct'] = (\n",
    "        (result_df['event_sell_price'] / result_df['event_price'] - 1) * 100\n",
    "    )\n",
    "\n",
    "    # Создаем целевой признак\n",
    "    result_df['target'] = (result_df['price_change_pct'] >= threshold).astype(int)\n",
    "\n",
    "    # Обработка случаев с отсутствующими данными\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df[['event_price', 'event_sell_price']].notnull().all(axis=1),\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Обработка случаев с нулевой ценой покупки (если такие есть)\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df['event_price'] != 0,\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Удаляем временную колонку\n",
    "    result_df.drop('price_change_pct', axis=1, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "class FastRollingMode:\n",
    "    def __init__(self, window_size):\n",
    "        self.window = deque(maxlen=window_size)\n",
    "        self.counts = {}\n",
    "        \n",
    "    def update(self, new_val):\n",
    "        if len(self.window) == self.window.maxlen:\n",
    "            old_val = self.window.popleft()\n",
    "            self.counts[old_val] -= 1\n",
    "            if self.counts[old_val] == 0:\n",
    "                del self.counts[old_val]\n",
    "        \n",
    "        self.window.append(new_val)\n",
    "        self.counts[new_val] = self.counts.get(new_val, 0) + 1\n",
    "        return max(self.counts.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "def extract_features(df: pd.DataFrame, window: int = 126):\n",
    "    \"\"\"\n",
    "    Вычисляет устойчивые признаки для кластеризации рыночных режимов.\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_macd(df, macd_fast_periods=[12], macd_slow_periods=[26], macd_signal_periods=[9]):\n",
    "        \"\"\"\n",
    "        Быстрый расчет нормализованного MACD с использованием векторизованных операций\n",
    "        \"\"\"\n",
    "        close = df['close']\n",
    "\n",
    "        # Создаем множества для уникальных периодов\n",
    "        unique_fast = set(macd_fast_periods)\n",
    "        unique_slow = set(macd_slow_periods)\n",
    "\n",
    "\n",
    "        # Предварительно вычисляем все необходимые EMA и скользящие средние\n",
    "        ema_cache = {}\n",
    "        rolling_cache = {}\n",
    "\n",
    "        # Кешируем быстрые EMA\n",
    "        for fp in unique_fast:\n",
    "            ema_cache[f'ema_{fp}'] = close.ewm(span=fp, adjust=False).mean()\n",
    "\n",
    "        # Кешируем медленные EMA и скользящие средние\n",
    "        for sp in unique_slow:\n",
    "            ema_cache[f'ema_{sp}'] = close.ewm(span=sp, adjust=False).mean()\n",
    "            rolling_cache[f'rolling_{sp}'] = close.rolling(window=sp).mean()\n",
    "\n",
    "        # Основной цикл вычислений\n",
    "        for fp in macd_fast_periods:\n",
    "            ema_fast = ema_cache[f'ema_{fp}']\n",
    "            for sp in macd_slow_periods:\n",
    "                ema_slow = ema_cache[f'ema_{sp}']\n",
    "                rolling_mean = rolling_cache[f'rolling_{sp}']\n",
    "\n",
    "                # Вычисляем MACD и нормализацию\n",
    "                macd = ema_fast - ema_slow\n",
    "                macd_norm = macd / rolling_mean\n",
    "\n",
    "                # Сохраняем MACD только один раз для комбинации fp/sp\n",
    "\n",
    "                # Обрабатываем сигнальные периоды\n",
    "                for sig in macd_signal_periods:\n",
    "                    # Вычисляем сигнальную линию\n",
    "                    signal = macd.ewm(span=sig, adjust=False).mean()\n",
    "                    signal_norm = signal / rolling_mean\n",
    "\n",
    "        return pd.DataFrame([macd_norm, signal_norm, macd_norm - signal_norm]).T.fillna(0)\n",
    "\n",
    "    def calculate_atr(df, atr_window=14):\n",
    "        \"\"\"\n",
    "        Расчет ATR и его сдвигов.\n",
    "        \"\"\"\n",
    "        high = df['high']\n",
    "        low = df['low']\n",
    "        close = df['close']\n",
    "    \n",
    "        tr1 = high - low\n",
    "        tr2 = np.abs(high - close.shift(1))\n",
    "        tr3 = np.abs(low - close.shift(1))\n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        atr = tr.rolling(atr_window).mean()\n",
    "    \n",
    "        return pd.Series(atr).fillna(0)\n",
    "    \n",
    "    def calculate_rsi(df, rsi_period=14):\n",
    "        \"\"\"\n",
    "        Расчет RSI и его сдвиги.\n",
    "        \"\"\"\n",
    "        close = df['close']\n",
    "        delta = close.diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "        avg_gain = gain.rolling(rsi_period).mean()\n",
    "        avg_loss = loss.rolling(rsi_period).mean()\n",
    "        rs = avg_gain / (avg_loss + 1e-10)\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        return pd.Series(rsi).fillna(0)\n",
    "    \n",
    "    def calculate_bollinger_bands(df, bollinger_window=20):\n",
    "        \"\"\"\n",
    "        Расчет Bollinger Bands (ширины полос) и сдвигов.\n",
    "        \"\"\"\n",
    "        close = df['close']\n",
    "        ma = close.rolling(bollinger_window).mean()\n",
    "        std = close.rolling(bollinger_window).std()\n",
    "        bb_width = (2 * std) / ma\n",
    "    \n",
    "        return pd.Series(bb_width).fillna(0)\n",
    "    \n",
    "    def detect_market_regime(df: pd.DataFrame, window: int = 30, n_clusters: int = 3) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Классифицирует рыночную фазу на основе кластеризации признаков: волатильность, автокорреляция, наклон тренда.\n",
    "        Возвращает метку режима рынка для каждого окна.\n",
    "        \"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "    \n",
    "        features = []\n",
    "    \n",
    "        for i in range(len(df) - window + 1):\n",
    "            window_df = df.iloc[i:i+window]\n",
    "            close = window_df['close'].values\n",
    "    \n",
    "            # Волатильность (стандартное отклонение)\n",
    "            volatility = np.std(np.diff(close))\n",
    "    \n",
    "            # Наклон тренда (регрессия по времени)\n",
    "            x = np.arange(window)\n",
    "            y = close\n",
    "            slope = np.polyfit(x, y, deg=1)[0]\n",
    "    \n",
    "            # Автокорреляция лаг-1\n",
    "            autocorr = np.corrcoef(close[:-1], close[1:])[0, 1]\n",
    "    \n",
    "            features.append([volatility, slope, autocorr])\n",
    "    \n",
    "        features = np.array(features)\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "        labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "        # Расширим метки до длины df\n",
    "        regime_series = pd.Series(np.nan, index=df.index)\n",
    "        regime_series.iloc[window - 1:] = labels\n",
    "    \n",
    "        return regime_series.fillna(0).ffill().astype(int)\n",
    "    macd_trend = calculate_macd(df, macd_slow_periods=[window], macd_fast_periods=[window//3], \n",
    "                                 macd_signal_periods=[window//6])\n",
    "    atr = calculate_atr(df, atr_window=window)\n",
    "    rel_volatility = atr / df[\"close\"]\n",
    "    rsi_ind = calculate_rsi(df, rsi_period=window//2)\n",
    "    volume_ratio = df['volume'].rolling(window).apply(\n",
    "        lambda x: x[-1]/x.mean(), raw=True\n",
    "    ).fillna(1).values\n",
    "\n",
    "    features = np.column_stack([\n",
    "        macd_trend,\n",
    "        rel_volatility,\n",
    "        rsi_ind,\n",
    "        volume_ratio\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "ticker = 'VRSB'\n",
    "phase_df = pd.read_parquet('phase_base_params.pq')\n",
    "db_path = f\"sqlite:///C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params_2/{ticker}.db\"\n",
    "study = optuna.create_study(study_name=f'Поиск параметров для Pmax_{ticker}', directions=['maximize', 'maximize'], storage=db_path, load_if_exists=True)\n",
    "file_name = [i for i in os.listdir(r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\test_files_15_2') if ticker in i][0]\n",
    "path = r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\test_files_15_2'\n",
    "df_init = pd.read_parquet(os.path.join(path, file_name))\n",
    "trial_n = find_best_trial_by_weighted_score(study.trials)[1]\n",
    "params = study.trials[trial_n].params\n",
    "values = study.trials[trial_n].values\n",
    "collector = TinkoffHistoricalDataCollector()\n",
    "if params['average_type']=='AMA':\n",
    "\n",
    "  ama_params = {\n",
    "      'atr_period': int(params['ama_atr_period']),\n",
    "      'min_period': int(params['ama_min_period']),\n",
    "      'max_period': int(params['ama_max_period'])\n",
    "  }\n",
    "  df_init = collector.generate_signals(\n",
    "      df_init,\n",
    "      moving_average_length=params['moving_average_length'],\n",
    "      atr_period=params['atr_period'],\n",
    "      atr_multiplier=params['atr_multiplier'],\n",
    "      average_type=params['average_type'],\n",
    "      ama_params=ama_params\n",
    "  )\n",
    "else:\n",
    "  df_init = collector.generate_signals(\n",
    "      df_init,\n",
    "      moving_average_length=params['moving_average_length'],\n",
    "      atr_period=params['atr_period'],\n",
    "      atr_multiplier=params['atr_multiplier'],\n",
    "      average_type=params['average_type'],\n",
    "  )\n",
    "\n",
    "buy_signals = df_init[df_init['buy_signal']]\n",
    "sell_signals = df_init[df_init['sell_signal']]\n",
    "for _, buy in buy_signals.iterrows():\n",
    "    sell = sell_signals[sell_signals.time > buy.time].head(1)\n",
    "    if not sell.empty:\n",
    "        df_init.loc[buy.name, \"event_time\"] = buy.time\n",
    "        df_init.loc[buy.name, \"event_price\"] = buy.close\n",
    "        df_init.loc[buy.name, \"event_sell_time\"] = sell.time.values[0]\n",
    "        df_init.loc[buy.name, \"event_sell_price\"] = sell.close.values[0]\n",
    "\n",
    "df_init['pnl'] = ((df_init['event_sell_price'] * (1 - 0.003)) / (df_init['event_price'] * (1 + 0.003)) - 1) * 100\n",
    "df_init = calculate_target(df_init, threshold=1.9)\n",
    "\n",
    "\n",
    "db_path = f\"sqlite:///C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params_3/{ticker}.db\"\n",
    "study_phase = optuna.create_study(study_name=f'Поиск параметров для Pmax_{ticker}', directions=['maximize', 'maximize', 'maximize'], storage=db_path, load_if_exists=True)\n",
    "df_phase = pd.read_parquet(os.path.join(path, file_name))\n",
    "window = int(phase_df[4][ticker]['moving_average_length']*9.5)\n",
    "features = extract_features(df_phase, window=window)\n",
    "scaled = joblib.load(\"scaler_global.pkl\").transform(features)\n",
    "labels = joblib.load(\"kmeans_global.pkl\").predict(scaled)\n",
    "\n",
    "regime_series = pd.Series(labels, index=df_phase.index)\n",
    "window_size = int(phase_df[4][ticker]['atr_period']*5.5)\n",
    "\n",
    "smoother = FastRollingMode(window_size=window_size)\n",
    "smoothed = [smoother.update(x) for x in labels]\n",
    "smoothed_regime = pd.Series(smoothed, index=df_phase.index)\n",
    "\n",
    "CV = TinkoffHistoricalDataCollector()\n",
    "\n",
    "trial_ph = find_best_trial_by_weighted_score(study_phase.trials)[1]\n",
    "params_ph = study_phase.trials[trial_ph].params\n",
    "values_ph = study_phase.trials[trial_ph].values\n",
    "\n",
    "regime_params = prepare_regime_params(params_ph)\n",
    "\n",
    "df_phase = CV.generate_signals_with_regime_v8(df_phase, \n",
    "                                             regime_series=smoothed_regime,\n",
    "                                             regime_params=regime_params[1],\n",
    "                                             threshold_atr_factor = regime_params[0]['threshold_atr_factor'],\n",
    "                                             smoothing_alpha = regime_params[0]['smoothing_alpha'],\n",
    "                                             min_atr_period = regime_params[0]['min_atr_period']\n",
    "                                            )\n",
    "\n",
    "df_phase = pair_and_clean_signals(df_phase)\n",
    "buy_signals = df_phase[df_phase['buy_signal']]\n",
    "sell_signals = df_phase[df_phase['sell_signal']]\n",
    "for _, buy in buy_signals.iterrows():\n",
    "    sell = sell_signals[sell_signals.time > buy.time].head(1)\n",
    "    if not sell.empty:\n",
    "        df_phase.loc[buy.name, \"event_time\"] = buy.time\n",
    "        df_phase.loc[buy.name, \"event_price\"] = buy.close\n",
    "        df_phase.loc[buy.name, \"event_sell_time\"] = sell.time.values[0]\n",
    "        df_phase.loc[buy.name, \"event_sell_price\"] = sell.close.values[0]\n",
    "\n",
    "df_phase['pnl'] = ((df_phase['event_sell_price'] * (1 - 0.003)) / (df_phase['event_price'] * (1 + 0.003)) - 1) * 100\n",
    "df_phase = calculate_target(df_phase, threshold=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fcd4cdb-014b-442f-86c0-44745a0ee86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>ma</th>\n",
       "      <th>pmax</th>\n",
       "      <th>buy_signal</th>\n",
       "      <th>sell_signal</th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_price</th>\n",
       "      <th>event_sell_time</th>\n",
       "      <th>event_sell_price</th>\n",
       "      <th>pnl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2022-06-17 15:00:00+00:00</td>\n",
       "      <td>162.0</td>\n",
       "      <td>161.5</td>\n",
       "      <td>162.0</td>\n",
       "      <td>161.5</td>\n",
       "      <td>4</td>\n",
       "      <td>162.603801</td>\n",
       "      <td>47.493752</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-17 15:00:00+00:00</td>\n",
       "      <td>161.5</td>\n",
       "      <td>2023-06-06 10:15:00</td>\n",
       "      <td>338.0</td>\n",
       "      <td>108.035954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>2023-07-06 10:15:00+00:00</td>\n",
       "      <td>351.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>375</td>\n",
       "      <td>351.306203</td>\n",
       "      <td>350.930880</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-07-06 10:15:00+00:00</td>\n",
       "      <td>355.0</td>\n",
       "      <td>2024-05-09 14:30:00</td>\n",
       "      <td>661.0</td>\n",
       "      <td>85.083342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time   open  close   high    low  volume  \\\n",
       "170  2022-06-17 15:00:00+00:00  162.0  161.5  162.0  161.5       4   \n",
       "8466 2023-07-06 10:15:00+00:00  351.0  355.0  355.0  349.0     375   \n",
       "\n",
       "              ma        pmax  buy_signal  sell_signal  \\\n",
       "170   162.603801   47.493752        True        False   \n",
       "8466  351.306203  350.930880        True        False   \n",
       "\n",
       "                    event_time  event_price     event_sell_time  \\\n",
       "170  2022-06-17 15:00:00+00:00        161.5 2023-06-06 10:15:00   \n",
       "8466 2023-07-06 10:15:00+00:00        355.0 2024-05-09 14:30:00   \n",
       "\n",
       "      event_sell_price         pnl  target  \n",
       "170              338.0  108.035954       1  \n",
       "8466             661.0   85.083342       1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phase[df_phase['buy_signal']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bdd7b9ac-4ed2-408c-a93b-e33b71a6c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>pmax</th>\n",
       "      <th>ma</th>\n",
       "      <th>buy_signal</th>\n",
       "      <th>sell_signal</th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_price</th>\n",
       "      <th>event_sell_time</th>\n",
       "      <th>event_sell_price</th>\n",
       "      <th>pnl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2022-09-14 16:00:00+00:00</td>\n",
       "      <td>152.5</td>\n",
       "      <td>152.5</td>\n",
       "      <td>152.5</td>\n",
       "      <td>152.5</td>\n",
       "      <td>2</td>\n",
       "      <td>146.815541</td>\n",
       "      <td>152.329545</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-09-14 16:00:00+00:00</td>\n",
       "      <td>152.5</td>\n",
       "      <td>2022-09-22 14:30:00</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-6.138633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>2022-10-28 18:45:00+00:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7</td>\n",
       "      <td>118.936831</td>\n",
       "      <td>127.633523</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-28 18:45:00+00:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2023-05-04 10:15:00</td>\n",
       "      <td>337.0</td>\n",
       "      <td>153.775794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>2023-05-23 15:45:00+00:00</td>\n",
       "      <td>357.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>293</td>\n",
       "      <td>335.477639</td>\n",
       "      <td>359.187500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-23 15:45:00+00:00</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2023-09-14 14:15:00</td>\n",
       "      <td>759.0</td>\n",
       "      <td>111.926860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11184</th>\n",
       "      <td>2023-10-18 13:00:00+00:00</td>\n",
       "      <td>811.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>200</td>\n",
       "      <td>690.172206</td>\n",
       "      <td>735.613636</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-10-18 13:00:00+00:00</td>\n",
       "      <td>807.0</td>\n",
       "      <td>2023-11-06 13:00:00</td>\n",
       "      <td>735.0</td>\n",
       "      <td>-9.466767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>2023-12-20 11:30:00+00:00</td>\n",
       "      <td>516.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>217</td>\n",
       "      <td>425.218225</td>\n",
       "      <td>479.372159</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-12-20 11:30:00+00:00</td>\n",
       "      <td>519.0</td>\n",
       "      <td>2024-02-13 11:15:00</td>\n",
       "      <td>715.0</td>\n",
       "      <td>36.940815</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15254</th>\n",
       "      <td>2024-03-28 17:45:00+00:00</td>\n",
       "      <td>671.5</td>\n",
       "      <td>671.5</td>\n",
       "      <td>671.5</td>\n",
       "      <td>671.5</td>\n",
       "      <td>1</td>\n",
       "      <td>646.604037</td>\n",
       "      <td>671.965909</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-03-28 17:45:00+00:00</td>\n",
       "      <td>671.5</td>\n",
       "      <td>2024-04-26 17:00:00</td>\n",
       "      <td>647.0</td>\n",
       "      <td>-4.224928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16266</th>\n",
       "      <td>2024-05-04 18:00:00+00:00</td>\n",
       "      <td>690.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>2</td>\n",
       "      <td>634.285595</td>\n",
       "      <td>668.181818</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-05-04 18:00:00+00:00</td>\n",
       "      <td>690.0</td>\n",
       "      <td>2024-05-16 12:45:00</td>\n",
       "      <td>652.5</td>\n",
       "      <td>-6.000477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17200</th>\n",
       "      <td>2024-06-06 14:30:00+00:00</td>\n",
       "      <td>573.5</td>\n",
       "      <td>578.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>572.5</td>\n",
       "      <td>29</td>\n",
       "      <td>504.995124</td>\n",
       "      <td>559.463068</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-06 14:30:00+00:00</td>\n",
       "      <td>578.0</td>\n",
       "      <td>2024-06-20 13:15:00</td>\n",
       "      <td>537.0</td>\n",
       "      <td>-7.649198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18498</th>\n",
       "      <td>2024-07-23 15:15:00+00:00</td>\n",
       "      <td>509.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>6</td>\n",
       "      <td>479.067705</td>\n",
       "      <td>504.576705</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-23 15:15:00+00:00</td>\n",
       "      <td>509.0</td>\n",
       "      <td>2024-08-20 13:15:00</td>\n",
       "      <td>526.0</td>\n",
       "      <td>2.721697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20322</th>\n",
       "      <td>2024-09-18 09:30:00+00:00</td>\n",
       "      <td>486.5</td>\n",
       "      <td>486.5</td>\n",
       "      <td>486.5</td>\n",
       "      <td>486.5</td>\n",
       "      <td>1</td>\n",
       "      <td>453.170078</td>\n",
       "      <td>477.678977</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-09-18 09:30:00+00:00</td>\n",
       "      <td>486.5</td>\n",
       "      <td>2024-10-23 20:45:00</td>\n",
       "      <td>479.0</td>\n",
       "      <td>-2.130607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22105</th>\n",
       "      <td>2024-11-11 19:00:00+00:00</td>\n",
       "      <td>464.0</td>\n",
       "      <td>464.5</td>\n",
       "      <td>464.5</td>\n",
       "      <td>464.0</td>\n",
       "      <td>2</td>\n",
       "      <td>433.390891</td>\n",
       "      <td>453.039773</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-11-11 19:00:00+00:00</td>\n",
       "      <td>464.5</td>\n",
       "      <td>2024-11-19 20:15:00</td>\n",
       "      <td>440.5</td>\n",
       "      <td>-5.734143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23336</th>\n",
       "      <td>2024-12-20 17:00:00+00:00</td>\n",
       "      <td>375.5</td>\n",
       "      <td>376.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>375.5</td>\n",
       "      <td>13</td>\n",
       "      <td>323.927065</td>\n",
       "      <td>354.940341</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-20 17:00:00+00:00</td>\n",
       "      <td>376.0</td>\n",
       "      <td>2025-02-03 17:15:00</td>\n",
       "      <td>482.5</td>\n",
       "      <td>27.556824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25448</th>\n",
       "      <td>2025-02-19 18:00:00+00:00</td>\n",
       "      <td>507.0</td>\n",
       "      <td>506.5</td>\n",
       "      <td>509.0</td>\n",
       "      <td>504.5</td>\n",
       "      <td>114</td>\n",
       "      <td>477.451343</td>\n",
       "      <td>493.911932</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-19 18:00:00+00:00</td>\n",
       "      <td>506.5</td>\n",
       "      <td>2025-02-27 19:15:00</td>\n",
       "      <td>481.5</td>\n",
       "      <td>-5.504513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27391</th>\n",
       "      <td>2025-04-27 15:30:00+00:00</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.5</td>\n",
       "      <td>405.5</td>\n",
       "      <td>405.0</td>\n",
       "      <td>10</td>\n",
       "      <td>382.401748</td>\n",
       "      <td>400.943182</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-04-27 15:30:00+00:00</td>\n",
       "      <td>405.5</td>\n",
       "      <td>2025-05-05 10:45:00</td>\n",
       "      <td>380.0</td>\n",
       "      <td>-6.849120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time   open  close   high    low  volume  \\\n",
       "1823  2022-09-14 16:00:00+00:00  152.5  152.5  152.5  152.5       2   \n",
       "2715  2022-10-28 18:45:00+00:00  132.0  132.0  132.0  132.0       7   \n",
       "7386  2023-05-23 15:45:00+00:00  357.0  356.0  359.0  355.0     293   \n",
       "11184 2023-10-18 13:00:00+00:00  811.0  807.0  811.0  805.0     200   \n",
       "12809 2023-12-20 11:30:00+00:00  516.0  519.0  520.0  515.0     217   \n",
       "15254 2024-03-28 17:45:00+00:00  671.5  671.5  671.5  671.5       1   \n",
       "16266 2024-05-04 18:00:00+00:00  690.0  690.0  690.0  690.0       2   \n",
       "17200 2024-06-06 14:30:00+00:00  573.5  578.0  578.0  572.5      29   \n",
       "18498 2024-07-23 15:15:00+00:00  509.0  509.0  509.0  509.0       6   \n",
       "20322 2024-09-18 09:30:00+00:00  486.5  486.5  486.5  486.5       1   \n",
       "22105 2024-11-11 19:00:00+00:00  464.0  464.5  464.5  464.0       2   \n",
       "23336 2024-12-20 17:00:00+00:00  375.5  376.0  376.0  375.5      13   \n",
       "25448 2025-02-19 18:00:00+00:00  507.0  506.5  509.0  504.5     114   \n",
       "27391 2025-04-27 15:30:00+00:00  405.0  405.5  405.5  405.0      10   \n",
       "\n",
       "             pmax          ma  buy_signal  sell_signal  \\\n",
       "1823   146.815541  152.329545        True        False   \n",
       "2715   118.936831  127.633523        True        False   \n",
       "7386   335.477639  359.187500        True        False   \n",
       "11184  690.172206  735.613636        True        False   \n",
       "12809  425.218225  479.372159        True        False   \n",
       "15254  646.604037  671.965909        True        False   \n",
       "16266  634.285595  668.181818        True        False   \n",
       "17200  504.995124  559.463068        True        False   \n",
       "18498  479.067705  504.576705        True        False   \n",
       "20322  453.170078  477.678977        True        False   \n",
       "22105  433.390891  453.039773        True        False   \n",
       "23336  323.927065  354.940341        True        False   \n",
       "25448  477.451343  493.911932        True        False   \n",
       "27391  382.401748  400.943182        True        False   \n",
       "\n",
       "                     event_time  event_price     event_sell_time  \\\n",
       "1823  2022-09-14 16:00:00+00:00        152.5 2022-09-22 14:30:00   \n",
       "2715  2022-10-28 18:45:00+00:00        132.0 2023-05-04 10:15:00   \n",
       "7386  2023-05-23 15:45:00+00:00        356.0 2023-09-14 14:15:00   \n",
       "11184 2023-10-18 13:00:00+00:00        807.0 2023-11-06 13:00:00   \n",
       "12809 2023-12-20 11:30:00+00:00        519.0 2024-02-13 11:15:00   \n",
       "15254 2024-03-28 17:45:00+00:00        671.5 2024-04-26 17:00:00   \n",
       "16266 2024-05-04 18:00:00+00:00        690.0 2024-05-16 12:45:00   \n",
       "17200 2024-06-06 14:30:00+00:00        578.0 2024-06-20 13:15:00   \n",
       "18498 2024-07-23 15:15:00+00:00        509.0 2024-08-20 13:15:00   \n",
       "20322 2024-09-18 09:30:00+00:00        486.5 2024-10-23 20:45:00   \n",
       "22105 2024-11-11 19:00:00+00:00        464.5 2024-11-19 20:15:00   \n",
       "23336 2024-12-20 17:00:00+00:00        376.0 2025-02-03 17:15:00   \n",
       "25448 2025-02-19 18:00:00+00:00        506.5 2025-02-27 19:15:00   \n",
       "27391 2025-04-27 15:30:00+00:00        405.5 2025-05-05 10:45:00   \n",
       "\n",
       "       event_sell_price         pnl  target  \n",
       "1823              144.0   -6.138633       0  \n",
       "2715              337.0  153.775794       1  \n",
       "7386              759.0  111.926860       1  \n",
       "11184             735.0   -9.466767       0  \n",
       "12809             715.0   36.940815       1  \n",
       "15254             647.0   -4.224928       0  \n",
       "16266             652.5   -6.000477       0  \n",
       "17200             537.0   -7.649198       0  \n",
       "18498             526.0    2.721697       1  \n",
       "20322             479.0   -2.130607       0  \n",
       "22105             440.5   -5.734143       0  \n",
       "23336             482.5   27.556824       1  \n",
       "25448             481.5   -5.504513       0  \n",
       "27391             380.0   -6.849120       0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init[df_init['buy_signal']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40b16b46-9184-4914-98d2-6f5d30f2f1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193.11929558205432, 279.2236050923523)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_phase[df_phase['buy_signal']==True].pnl), np.sum(df_init[df_init['buy_signal']==True].pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7093a552-bab1-4ca2-ac94-5e2aebfa7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "open_trades = {}\n",
    "ticker = 'RAGR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f28bf63-4246-430c-aea1-e7459e8cc79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleksandrovva1\\AppData\\Local\\Temp\\ipykernel_5892\\3873933436.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  'buy_time': dt.utcnow(),\n"
     ]
    }
   ],
   "source": [
    "open_trades[ticker] = {\n",
    "                              'buy_price': 123,\n",
    "                              'buy_time': dt.utcnow(),\n",
    "                              'max_price': 123,\n",
    "                              'status': 'open',\n",
    "                              'reason': 'base'                  \n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76fbf5df-9ad5-4a48-b714-dd12f290ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RAGR': {'buy_price': 123,\n",
       "  'buy_time': datetime.datetime(2025, 5, 29, 7, 21, 35, 203849),\n",
       "  'max_price': 123,\n",
       "  'status': 'open',\n",
       "  'reason': 'base'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab172e25-89e6-48b1-b3a3-446a3866282e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type datetime is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen_trades.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(json\u001b[38;5;241m.\u001b[39mdumps(open_trades))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_encoder\u001b[38;5;241m.\u001b[39mencode(obj)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _iterencode(o, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type datetime is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('open_trades.txt', 'w') as f:\n",
    "    f.write(json.dumps(open_trades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce0cbd7a-ecbf-4a44-af20-11aa08079b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_open_trades(ticker):\n",
    "        \"\"\"Проверяет состояние открытой позиции по конкретному тикеру\"\"\"\n",
    "        # Проверяем, есть ли такая открытая позиция и она действительно открыта\n",
    "        if (ticker not in open_trades or open_trades[ticker]['status']!= 'open' or ticker not in close_price or not close_price[ticker]):\n",
    "            pass\n",
    "        \n",
    "        trade_info = open_trades[ticker]\n",
    "        current_price = close_price[ticker][-1]\n",
    "        \n",
    "        # Обновляем максимальную цену, если текущая выше\n",
    "        if 'max_price' in trade_info and current_price > trade_info['max_price']:\n",
    "            trade_info['max_price'] = current_price\n",
    "        \n",
    "        # Проверяем стоп-лосс (если он задан)\n",
    "        if 'stop_loss' in trade_info:\n",
    "            stop_loss_price = trade_info['buy_price'] * (1 - trade_info['stop_loss'])\n",
    "            \n",
    "            if current_price <= stop_loss_price:\n",
    "                # Триггерим сигнал на продажу\n",
    "                self.signals[ticker] = 'sell'\n",
    "                trade_info.update({\n",
    "                    'reason': 'TAKE_LOSS',\n",
    "                    'status': 'closed',\n",
    "                    'close_price': current_price,\n",
    "                    'close_time': dt.utcnow().isoformat()\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31791e42-b64a-4c23-9ee2-7d8b4c1de373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:/Users/aleksandrovva1/Downloads/open_trades (1).txt') as f:\n",
    "    open_trades = json.load(f)\n",
    "with open('C:/Users/aleksandrovva1/Downloads/close_price (1).txt') as f:\n",
    "    close_price = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ba7377-aae0-43a8-aa45-a9fc3f58cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buy_price': 15.582,\n",
       " 'buy_time': '2025-05-28T20:15:00+00:00',\n",
       " 'max_price': 18,\n",
       " 'status': 'open'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_trades['AFKS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6e2f253-3060-44a2-a8d9-e5da7445e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_open_trades('AFKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "125d104a-b1a6-4318-8ca6-a4e6d13f1bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.622,\n",
       " 15.574,\n",
       " 15.556000000000001,\n",
       " 15.544,\n",
       " 15.637,\n",
       " 15.631,\n",
       " 15.727,\n",
       " 15.713000000000001,\n",
       " 15.653,\n",
       " 18]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_price['AFKS'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf399e9-1f54-4258-bc52-bcf2caba39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_candle_stream(self, candle: Candle):\n",
    "        ticker = self.figi_to_ticker.get(candle.figi)\n",
    "        if not ticker:\n",
    "            return\n",
    "\n",
    "        ts = candle.time + timedelta(hours=3)\n",
    "        tc = ts + self.update_interval\n",
    "        open_price[ticker] = open_price[ticker][1:] + [float(candle.open.units + candle.open.nano * 1e-9)]\n",
    "        close_price[ticker] = close_price[ticker][1:] + [float(candle.close.units + candle.close.nano * 1e-9)]\n",
    "        high_price[ticker] = high_price[ticker][1:] + [float(candle.high.units + candle.high.nano * 1e-9)]\n",
    "        low_price[ticker] = low_price[ticker][1:] + [float(candle.low.units + candle.low.nano * 1e-9)]\n",
    "        volume[ticker] = volume[ticker][1:] + [candle.volume]\n",
    "        time_last_kline_start[ticker] = time_last_kline_start[ticker][1:] + [ts.isoformat()]\n",
    "        time_last_kline_end[ticker] = time_last_kline_end[ticker][1:] + [tc.isoformat()]\n",
    "\n",
    "        # Обработка сигналов\n",
    "        await self.calculate_indicators_and_signals(ticker)\n",
    "\n",
    "        print(f\"[{ticker}] Time Start: {ts:%Y-%m-%d %H:%M} \"\n",
    "              f\"O: {open_price[ticker][-1]:.2f} H: {high_price[ticker][-1]:.2f} \"\n",
    "              f\"L: {low_price[ticker][-1]:.2f} C: {close_price[ticker][-1]:.2f} \"\n",
    "              f\"Signal: {signals[ticker]} Pmax: {pmax[ticker][-1]:.2f} Ma: {ma[ticker][-1]:.2f} \"\n",
    "              f\"Time Close: {tc:%Y-%m-%d %H:%M}\")\n",
    "\n",
    "\n",
    "        if signals[ticker] == 'buy':\n",
    "\n",
    "            way = ticker_params[ticker]['way']\n",
    "            ticker_parametrs = ticker_params[ticker]['params']\n",
    "            stop_loss_y_n = ticker_params[ticker]['change']\n",
    "            stop_loss = ticker_params[ticker]['stop_loss_pst']\n",
    "\n",
    "            if way == 'Базовый':\n",
    "\n",
    "                if stop_loss_y_n == 'No':\n",
    "\n",
    "                    open_trades[ticker] = {\n",
    "                          'buy_price': close_price[ticker][-1],\n",
    "                          'buy_time': dt.utcnow().isoformat(),\n",
    "                          'max_price': close_price[ticker][-1],\n",
    "                          'status': 'open',\n",
    "                          'reason': 'BASE'                   \n",
    "                      }\n",
    "                else:\n",
    "                    open_trades[ticker] = {\n",
    "                          'buy_price': close_price[ticker][-1],\n",
    "                          'buy_time': dt.utcnow().isoformat(),\n",
    "                          'max_price': close_price[ticker][-1],\n",
    "                          'status': 'open',\n",
    "                          'reason': 'BASE',\n",
    "                          'stop_loss': stop_loss                  \n",
    "                      }\n",
    "                    \n",
    "\n",
    "                print(open_trades[ticker])\n",
    "\n",
    "                bot.send_message(\n",
    "                    self.stat_tg,\n",
    "                    f\"[TRADE OPENED] {ticker} по {close_price[ticker][-1]} в {dt.utcnow()}\"\n",
    "                )\n",
    "\n",
    "\n",
    "            elif way == 'RSI':\n",
    "                rsi_length = ticker_parametrs['rsi_length']\n",
    "                use_smoothing = ticker_parametrs['use_smoothing']\n",
    "                smoothing_length = ticker_parametrs['smoothing_length']\n",
    "                smoothing_type = ticker_parametrs['smoothing_type']\n",
    "                alma_sigma = ticker_parametrs['alma_sigma']\n",
    "                rsi_overbought = ticker_parametrs['rsi_overbought']\n",
    "                rsi_oversold = ticker_parametrs['rsi_oversold']\n",
    "                use_knn = ticker_parametrs['use_knn']\n",
    "                knn_neighbors = ticker_parametrs['knn_neighbors']\n",
    "                knn_lookback = ticker_parametrs['knn_lookback']\n",
    "                knn_weight = ticker_parametrs['knn_weight']\n",
    "                feature_count = ticker_parametrs['feature_count']\n",
    "                use_filter = ticker_parametrs['use_filter']\n",
    "                filter_method = ticker_parametrs['filter_method']\n",
    "                filter_strength = ticker_parametrs['filter_strength']\n",
    "                sma_length = ticker_parametrs['sma_length']\n",
    "                ema_length = ticker_parametrs['ema_length']\n",
    "                rsi_theasold = ticker_parametrs['rsi_helbuth']\n",
    "\n",
    "                ml_rsi = MachineLearningRSI(\n",
    "                    rsi_length=int(rsi_length),\n",
    "                    use_smoothing=use_smoothing,\n",
    "                    smoothing_length=int(smoothing_length),\n",
    "                    smoothing_type=smoothing_type,\n",
    "                    alma_sigma=int(alma_sigma),\n",
    "                    rsi_overbought=int(rsi_overbought),\n",
    "                    rsi_oversold=int(rsi_oversold),\n",
    "                    use_knn=use_knn,\n",
    "                    knn_neighbors=int(knn_neighbors),\n",
    "                    knn_lookback=int(knn_lookback),\n",
    "                    knn_weight=knn_weight,\n",
    "                    feature_count=int(feature_count),\n",
    "                    use_filter=use_filter,\n",
    "                    filter_method=filter_method,\n",
    "                    filter_strength=filter_strength,\n",
    "                    sma_length=int(sma_length),\n",
    "                    ema_length=int(ema_length)\n",
    "                )\n",
    "\n",
    "                rsi, sma, ma_sma = ml_rsi.fit(pd.Series(close_price[ticker]))\n",
    "\n",
    "                if rsi>=rsi_theasold:\n",
    "                  if stop_loss_y_n == 'No':\n",
    "\n",
    "                      open_trades[ticker] = {\n",
    "                            'buy_price': close_price[ticker][-1],\n",
    "                            'buy_time': dt.utcnow().isoformat(),\n",
    "                            'max_price': close_price[ticker][-1],\n",
    "                            'status': 'open',\n",
    "                            'reason': 'BASE'                 \n",
    "                        }\n",
    "                  else:\n",
    "                      open_trades[ticker] = {\n",
    "                            'buy_price': close_price[ticker][-1],\n",
    "                            'buy_time': dt.utcnow().isoformat(),\n",
    "                            'max_price': close_price[ticker][-1],\n",
    "                            'status': 'open',\n",
    "                            'reason': 'BASE',\n",
    "                            'stop_loss': stop_loss                  \n",
    "                        }\n",
    "                  print(open_trades[ticker])\n",
    "                  bot.send_message(\n",
    "                      self.stat_tg,\n",
    "                      f\"[TRADE OPENED] {ticker} по {close_price[ticker][-1]} в {dt.utcnow()}\"\n",
    "                  )\n",
    "                else:\n",
    "                  bot.send_message(\n",
    "                        self.stat_tg,\n",
    "                        f\"[TRADE NOT OPENED] {ticker} по {close_price[ticker][-1]} в {dt.utcnow()} не прошел проверку на трендовую линию\"\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "            elif way== 'RSI_SMA_EMA':\n",
    "                  rsi_length = ticker_parametrs['rsi_length']\n",
    "                  use_smoothing = ticker_parametrs['use_smoothing']\n",
    "                  smoothing_length = ticker_parametrs['smoothing_length']\n",
    "                  smoothing_type = ticker_parametrs['smoothing_type']\n",
    "                  alma_sigma = ticker_parametrs['alma_sigma']\n",
    "                  rsi_overbought = ticker_parametrs['rsi_overbought']\n",
    "                  rsi_oversold = ticker_parametrs['rsi_oversold']\n",
    "                  use_knn = ticker_parametrs['use_knn']\n",
    "                  knn_neighbors = ticker_parametrs['knn_neighbors']\n",
    "                  knn_lookback = ticker_parametrs['knn_lookback']\n",
    "                  knn_weight = ticker_parametrs['knn_weight']\n",
    "                  feature_count = ticker_parametrs['feature_count']\n",
    "                  use_filter = ticker_parametrs['use_filter']\n",
    "                  filter_method = ticker_parametrs['filter_method']\n",
    "                  filter_strength = ticker_parametrs['filter_strength']\n",
    "                  sma_length = ticker_parametrs['sma_length']\n",
    "                  ema_length = ticker_parametrs['ema_length']\n",
    "                  rsi_theasold = ticker_parametrs['rsi_helbuth']\n",
    "\n",
    "                  ml_rsi = MachineLearningRSI(\n",
    "                    rsi_length=int(rsi_length),\n",
    "                    use_smoothing=use_smoothing,\n",
    "                    smoothing_length=int(smoothing_length),\n",
    "                    smoothing_type=smoothing_type,\n",
    "                    alma_sigma=int(alma_sigma),\n",
    "                    rsi_overbought=int(rsi_overbought),\n",
    "                    rsi_oversold=int(rsi_oversold),\n",
    "                    use_knn=use_knn,\n",
    "                    knn_neighbors=int(knn_neighbors),\n",
    "                    knn_lookback=int(knn_lookback),\n",
    "                    knn_weight=knn_weight,\n",
    "                    feature_count=int(feature_count),\n",
    "                    use_filter=use_filter,\n",
    "                    filter_method=filter_method,\n",
    "                    filter_strength=filter_strength,\n",
    "                    sma_length=int(sma_length),\n",
    "                    ema_length=int(ema_length)\n",
    "                )\n",
    "\n",
    "                  rsi, sma, ma_sma = ml_rsi.fit(pd.Series(close_price[ticker]))\n",
    "\n",
    "                  if rsi>rsi_theasold and sma > close_price[ticker][-1] and ma_sma > close_price[ticker][-1]:\n",
    "\n",
    "                    if stop_loss_y_n == 'No':\n",
    "\n",
    "                        open_trades[ticker] = {\n",
    "                              'buy_price': close_price[ticker][-1],\n",
    "                              'buy_time': dt.utcnow().isoformat(),\n",
    "                              'max_price': close_price[ticker][-1],\n",
    "                              'status': 'open',\n",
    "                              'reason': 'BASE'                  \n",
    "                          }\n",
    "                    else:\n",
    "                        open_trades[ticker] = {\n",
    "                              'buy_price': close_price[ticker][-1],\n",
    "                              'buy_time': dt.utcnow().isoformat(),\n",
    "                              'max_price': close_price[ticker][-1],\n",
    "                              'status': 'open',\n",
    "                              'reason': 'BASE',\n",
    "                              'stop_loss': stop_loss                  \n",
    "                          }\n",
    "                    print(open_trades[ticker])\n",
    "\n",
    "                    bot.send_message(\n",
    "                        self.stat_tg,\n",
    "                        f\"[TRADE OPENED] {ticker} по {close_price[ticker][-1]} в {dt.utcnow()}\"\n",
    "                    )\n",
    "                  else:\n",
    "                    bot.send_message(\n",
    "                        self.stat_tg,\n",
    "                        f\"[TRADE NOT OPENED] {ticker} по {close_price[ticker][-1]} в {dt.utcnow()} не прошел проверку на Трендовая + недельные скользящие\"\n",
    "                    )\n",
    "\n",
    "        await self.check_open_trades(ticker)\n",
    "\n",
    "        if signals[ticker] == 'sell' and open_trades[ticker]['status']=='open':\n",
    "\n",
    "            reason = open_trades[ticker]['reason']\n",
    "\n",
    "            await self.close_trade(ticker, close_price[ticker][-1], open_trades[ticker]['max_price'], reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1da6764e-a4ae-4f64-b16d-921da83e5a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buy_price': 15.582,\n",
       " 'buy_time': '2025-05-28T20:15:00+00:00',\n",
       " 'max_price': 18,\n",
       " 'status': 'open'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_trades.get('AFKS', 'status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "638b6fac-a95d-4b1d-a503-475bf0b22797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleksandrovva1\\AppData\\Local\\Temp\\ipykernel_5892\\82119602.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now_utc = dt.utcnow().replace(tzinfo=pytz.utc) + timedelta(hours=3)\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import timedelta\n",
    "now_utc = dt.utcnow().replace(tzinfo=pytz.utc) + timedelta(hours=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad2e21b1-57e5-4759-a446-2058c6c73ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ddd = \"2025-05-29T16:15:00+00:00\"\n",
    "last_time = pd.to_datetime(ddd).astimezone(pytz.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d0d040f-533b-472e-bb62-b80dfa14c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time\n",
    "update_interval = timedelta(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bcad5a7d-d25d-45b8-8f7c-034e38cd49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-05-29 16:15:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e0e8a3b-643d-4a5d-b751-af24edddfbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((now_utc - last_time).total_seconds() // update_interval.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "145d2ce7-6f34-40dd-9546-b808762f4819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_interval.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3733abe-7527-458d-9579-8391b37d038e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975.849445"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(now_utc - last_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0daf8e92-cd56-48b4-bcbb-c679505d3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from optuna.trial import FrozenTrial\n",
    "import os\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (18, 10)\n",
    "plt.rcParams['axes.facecolor'] = 'black'\n",
    "sns.set_palette('Spectral')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def find_best_trial_by_weighted_three_score(\n",
    "    trials: List[FrozenTrial],\n",
    "    pnl_score = 0.45,\n",
    "    diff_score = 0.45,\n",
    "    weight_score = 0.10\n",
    ") -> Tuple[float, int, float, float, int, Dict]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме двух метрик:\n",
    "        - pnl (trial.values[0]), вес 0.65, диапазон 0..600\n",
    "        - diff (trial.values[1]), вес 0.35, диапазон 0..1\n",
    "\n",
    "    Возвращает:\n",
    "        - score: float — итоговый взвешенный скор\n",
    "        - trial_number: int — номер трейла\n",
    "        - pnl: float — значение pnl\n",
    "        - diff: float — значение diff\n",
    "        - params: dict — параметры трейла\n",
    "    \"\"\"\n",
    "    WEIGHT_PNL = pnl_score\n",
    "    WEIGHT_DIFF = diff_score\n",
    "    WEIGHT_SCORE = weight_score\n",
    "    MAX_PNL = np.max([i.values[0] for i in [trial for trial in trials if trial.values is not None]])*2.5  # для нормализации\n",
    "    MAX_SCORE = np.max([i.values[2] for i in [trial for trial in study.trials if trial.values is not None]])  # для нормализации\n",
    "    MAX_DIFF = 1   # для нормализации\n",
    "\n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    best_score_n = None\n",
    "    best_params = None\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит обе метрики\n",
    "        if not trial.values or len(trial.values) < 3:\n",
    "            continue\n",
    "\n",
    "        pnl = trial.values[0]\n",
    "        diff = trial.values[1]\n",
    "        score_n = trial.values[2]\n",
    "\n",
    "        # Нормализуем значения\n",
    "        norm_pnl = pnl / MAX_PNL if MAX_PNL else 0\n",
    "        norm_diff = diff / MAX_DIFF if MAX_DIFF else 0\n",
    "        norm_score = score_n / MAX_SCORE if WEIGHT_SCORE else 0\n",
    "\n",
    "        # Взвешенная сумма\n",
    "        score = WEIGHT_PNL * norm_pnl + WEIGHT_DIFF * norm_diff + WEIGHT_SCORE * norm_score\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_trial_number = trial.number\n",
    "            best_pnl = pnl\n",
    "            best_diff = diff\n",
    "            best_score_n = score_n\n",
    "            best_params = trial.params\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с двумя метриками (pnl и diff).\")\n",
    "\n",
    "    return best_score, best_trial_number, best_pnl, best_diff, best_score_n, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "84edeba4-0a5f-4210-8c86-b56f3c91aafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=140, state=1, values=[119.05172129805017, 0.6153846153846154, 26.0], datetime_start=datetime.datetime(2025, 6, 11, 19, 57, 47, 844628), datetime_complete=datetime.datetime(2025, 6, 11, 19, 57, 48, 643977), params={'regime_0_average_type': 'VAR', 'regime_0_ma_length': 130, 'regime_0_atr_period': 168, 'regime_0_atr_multiplier': 4.846128227413505, 'regime_1_average_type': 'VAR', 'regime_1_ma_length': 120, 'regime_1_atr_period': 54, 'regime_1_atr_multiplier': 7.067432018273977, 'regime_2_average_type': 'VAR', 'regime_2_ma_length': 59, 'regime_2_atr_period': 189, 'regime_2_atr_multiplier': 7.323105552668743, 'regime_3_average_type': 'VAR', 'regime_3_ma_length': 94, 'regime_3_atr_period': 122, 'regime_3_atr_multiplier': 5.683305530403509, 'regime_4_average_type': 'VAR', 'regime_4_ma_length': 114, 'regime_4_atr_period': 115, 'regime_4_atr_multiplier': 3.0864801729077955}, user_attrs={}, system_attrs={'NSGAIISampler:generation': 2}, intermediate_values={}, distributions={'regime_0_average_type': CategoricalDistribution(choices=('SMA', 'VAR', 'AMA')), 'regime_0_ma_length': IntDistribution(high=200, log=False, low=10, step=1), 'regime_0_atr_period': IntDistribution(high=200, log=False, low=10, step=1), 'regime_0_atr_multiplier': FloatDistribution(high=8.0, log=False, low=1.5, step=None), 'regime_1_average_type': CategoricalDistribution(choices=('SMA', 'VAR', 'AMA')), 'regime_1_ma_length': IntDistribution(high=200, log=False, low=10, step=1), 'regime_1_atr_period': IntDistribution(high=200, log=False, low=10, step=1), 'regime_1_atr_multiplier': FloatDistribution(high=8.0, log=False, low=1.5, step=None), 'regime_2_average_type': CategoricalDistribution(choices=('SMA', 'VAR', 'AMA')), 'regime_2_ma_length': IntDistribution(high=200, log=False, low=10, step=1), 'regime_2_atr_period': IntDistribution(high=200, log=False, low=10, step=1), 'regime_2_atr_multiplier': FloatDistribution(high=8.0, log=False, low=1.5, step=None), 'regime_3_average_type': CategoricalDistribution(choices=('SMA', 'VAR', 'AMA')), 'regime_3_ma_length': IntDistribution(high=200, log=False, low=10, step=1), 'regime_3_atr_period': IntDistribution(high=200, log=False, low=10, step=1), 'regime_3_atr_multiplier': FloatDistribution(high=8.0, log=False, low=1.5, step=None), 'regime_4_average_type': CategoricalDistribution(choices=('SMA', 'VAR', 'AMA')), 'regime_4_ma_length': IntDistribution(high=200, log=False, low=10, step=1), 'regime_4_atr_period': IntDistribution(high=200, log=False, low=10, step=1), 'regime_4_atr_multiplier': FloatDistribution(high=8.0, log=False, low=1.5, step=None)}, trial_id=141, value=None)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials[trial_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35d0f510-626e-483d-9721-3991f4340603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81839e8e6d0447fa9662bce92769abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = r'C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params_3/'\n",
    "\n",
    "tickers = [i.split('.')[0] for i in os.listdir(directory)]\n",
    "\n",
    "base_params = {}\n",
    "\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    db_path = f\"sqlite:///C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params_3/{ticker}.db\"\n",
    "    study_name=f'Поиск параметров для Pmax_{ticker}'\n",
    "    study = optuna.create_study(study_name=study_name,directions=['maximize', 'maximize', 'maximize'],storage=db_path,load_if_exists=True)\n",
    "    trial_n = find_best_trial_by_weighted_three_score(study.trials)[1]\n",
    "    params = study.trials[trial_n].params\n",
    "    values = study.trials[trial_n].values\n",
    "    base_params[ticker] = [trial_n, values[0], values[1], values[2], params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb09be1b-02f8-40b7-8df0-cc7aff75eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = pd.DataFrame(base_params).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "134e7dbd-75de-4b0b-954e-f4f17d685a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABRD</th>\n",
       "      <td>2971</td>\n",
       "      <td>83.197592</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFKS</th>\n",
       "      <td>3467</td>\n",
       "      <td>134.278352</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>27.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFLT</th>\n",
       "      <td>140</td>\n",
       "      <td>119.051721</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>26.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANE</th>\n",
       "      <td>753</td>\n",
       "      <td>160.507665</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>28.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANEP</th>\n",
       "      <td>2072</td>\n",
       "      <td>169.904539</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>37.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UWGN</th>\n",
       "      <td>1736</td>\n",
       "      <td>397.445092</td>\n",
       "      <td>0.45</td>\n",
       "      <td>40.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VKCO</th>\n",
       "      <td>2157</td>\n",
       "      <td>118.124234</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRSB</th>\n",
       "      <td>3144</td>\n",
       "      <td>500.897024</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>37.0</td>\n",
       "      <td>{'regime_0_average_type': 'AMA', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>3927</td>\n",
       "      <td>165.720057</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>46.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YDEX</th>\n",
       "      <td>3840</td>\n",
       "      <td>122.448277</td>\n",
       "      <td>0.35</td>\n",
       "      <td>60.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1         2     3  \\\n",
       "ABRD   2971   83.197592  0.371429  35.0   \n",
       "AFKS   3467  134.278352  0.444444  27.0   \n",
       "AFLT    140  119.051721  0.615385  26.0   \n",
       "BANE    753  160.507665  0.392857  28.0   \n",
       "BANEP  2072  169.904539  0.513514  37.0   \n",
       "...     ...         ...       ...   ...   \n",
       "UWGN   1736  397.445092      0.45  40.0   \n",
       "VKCO   2157  118.124234       0.4  50.0   \n",
       "VRSB   3144  500.897024   0.27027  37.0   \n",
       "X5     3927  165.720057  0.456522  46.0   \n",
       "YDEX   3840  122.448277      0.35  60.0   \n",
       "\n",
       "                                                       4  \n",
       "ABRD   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  \n",
       "AFKS   {'regime_0_average_type': 'SMA', 'regime_0_ma_...  \n",
       "AFLT   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  \n",
       "BANE   {'regime_0_average_type': 'SMA', 'regime_0_ma_...  \n",
       "BANEP  {'regime_0_average_type': 'SMA', 'regime_0_ma_...  \n",
       "...                                                  ...  \n",
       "UWGN   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  \n",
       "VKCO   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  \n",
       "VRSB   {'regime_0_average_type': 'AMA', 'regime_0_ma_...  \n",
       "X5     {'regime_0_average_type': 'VAR', 'regime_0_ma_...  \n",
       "YDEX   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  \n",
       "\n",
       "[89 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1794ebd-ff10-4c40-8228-e9cc51bca8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = pd.read_parquet('phase_modded.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8317ecfc-77c7-4a2d-a71a-ee29565a087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_df = pd.concat([phase_df, new_params], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced045a8-48dc-4b68-97ca-432af5a048cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAGR       1.289868\n",
       "MGNT     -28.312064\n",
       "MSTT      63.616327\n",
       "VRSB     -27.761474\n",
       "PRFN      23.270185\n",
       "            ...    \n",
       "LNZLP     18.302801\n",
       "CHMK      55.111222\n",
       "KZIZP    184.296836\n",
       "RKKE       2.802126\n",
       "FRHC      49.253242\n",
       "Length: 89, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_df[1] - phase_df['pnl']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2872d869-71db-4534-84e9-e4efd9c50294",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = phase_df[phase_df['way']=='Базовый']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fae3916c-2b26-4040-912a-0009eae41344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SELG     -19.557178\n",
       "RENI     -16.665457\n",
       "IRKT     -11.737137\n",
       "TRMK     -10.221657\n",
       "UNAC      -0.757941\n",
       "RKKE       2.802126\n",
       "YDEX       6.643588\n",
       "OZPH       7.892882\n",
       "FESH       7.971589\n",
       "BANEP     11.077265\n",
       "SPBE      11.464735\n",
       "AFLT      14.032364\n",
       "X5         15.31801\n",
       "VKCO      16.755359\n",
       "FLOT      18.344328\n",
       "LSRG      19.049476\n",
       "MDMG       21.34499\n",
       "UGLD      22.386816\n",
       "MAGN      23.865759\n",
       "GEMC      25.254152\n",
       "LENT      27.290692\n",
       "MRKU      31.169413\n",
       "OKEY       32.80389\n",
       "GTRK      38.300925\n",
       "BANE      38.592263\n",
       "CHMK      55.111222\n",
       "OBNE      58.865078\n",
       "CNRU      66.740752\n",
       "KLSB      67.174838\n",
       "MRKZ       97.37097\n",
       "SVAV     103.074307\n",
       "NKHP     117.644996\n",
       "NOMP     151.309891\n",
       "KZIZ      163.17319\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(base[1] - base['pnl']).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4bce6d5d-a3e8-49dc-aef4-8463257d0b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ea91d5dcd247c581558f6a48e93c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import mplfinance as mpf\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.signal import lfilter\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#plt.style.use('ggplot')\n",
    "#plt.rcParams['figure.figsize'] = (18, 10)\n",
    "#plt.rcParams['axes.facecolor'] = 'black'\n",
    "sns.set_palette('Spectral')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "from optuna.trial import FrozenTrial\n",
    "\n",
    "def find_best_trial_by_weighted_three_score(\n",
    "    trials: List[FrozenTrial],\n",
    "    pnl_score = 0.45,\n",
    "    diff_score = 0.45,\n",
    "    weight_score = 0.10\n",
    ") -> Tuple[float, int, float, float, int, Dict]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме двух метрик:\n",
    "        - pnl (trial.values[0]), вес 0.65, диапазон 0..600\n",
    "        - diff (trial.values[1]), вес 0.35, диапазон 0..1\n",
    "\n",
    "    Возвращает:\n",
    "        - score: float — итоговый взвешенный скор\n",
    "        - trial_number: int — номер трейла\n",
    "        - pnl: float — значение pnl\n",
    "        - diff: float — значение diff\n",
    "        - params: dict — параметры трейла\n",
    "    \"\"\"\n",
    "    WEIGHT_PNL = pnl_score\n",
    "    WEIGHT_DIFF = diff_score\n",
    "    WEIGHT_SCORE = weight_score\n",
    "    MAX_PNL = np.max([i.values[0] for i in [trial for trial in trials if trial.values is not None]])*2.5  # для нормализации\n",
    "    MAX_SCORE = np.max([i.values[2] for i in [trial for trial in study.trials if trial.values is not None]])  # для нормализации\n",
    "    MAX_DIFF = 1   # для нормализации\n",
    "\n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    best_score_n = None\n",
    "    best_params = None\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит обе метрики\n",
    "        if not trial.values or len(trial.values) < 3:\n",
    "            continue\n",
    "\n",
    "        pnl = trial.values[0]\n",
    "        diff = trial.values[1]\n",
    "        score_n = trial.values[2]\n",
    "\n",
    "        # Нормализуем значения\n",
    "        norm_pnl = pnl / MAX_PNL if MAX_PNL else 0\n",
    "        norm_diff = diff / MAX_DIFF if MAX_DIFF else 0\n",
    "        norm_score = score_n / MAX_SCORE if WEIGHT_SCORE else 0\n",
    "\n",
    "        # Взвешенная сумма\n",
    "        score = WEIGHT_PNL * norm_pnl + WEIGHT_DIFF * norm_diff + WEIGHT_SCORE * norm_score\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_trial_number = trial.number\n",
    "            best_pnl = pnl\n",
    "            best_diff = diff\n",
    "            best_score_n = score_n\n",
    "            best_params = trial.params\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с двумя метриками (pnl и diff).\")\n",
    "\n",
    "    return best_score, best_trial_number, best_pnl, best_diff, best_score_n, best_params\n",
    "\n",
    "def find_best_trial_by_weighted_score(\n",
    "    trials: List[FrozenTrial]\n",
    ") -> Tuple[float, int, float, float, Dict]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме двух метрик:\n",
    "        - pnl (trial.values[0]), вес 0.65, диапазон 0..600\n",
    "        - diff (trial.values[1]), вес 0.35, диапазон 0..1\n",
    "\n",
    "    Возвращает:\n",
    "        - score: float — итоговый взвешенный скор\n",
    "        - trial_number: int — номер трейла\n",
    "        - pnl: float — значение pnl\n",
    "        - diff: float — значение diff\n",
    "        - params: dict — параметры трейла\n",
    "    \"\"\"\n",
    "    WEIGHT_PNL = 0.60\n",
    "    WEIGHT_DIFF = 0.40\n",
    "    MAX_PNL = np.max([i.values for i in [trial for trial in trials if trial.values is not None]])*2.5  # для нормализации\n",
    "    MAX_DIFF = 1   # для нормализации\n",
    "\n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    best_params = None\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит обе метрики\n",
    "        if not trial.values or len(trial.values) < 2:\n",
    "            continue\n",
    "\n",
    "        pnl = trial.values[0]\n",
    "        diff = trial.values[1]\n",
    "\n",
    "        # Нормализуем значения\n",
    "        norm_pnl = pnl / MAX_PNL if MAX_PNL else 0\n",
    "        norm_diff = diff / MAX_DIFF if MAX_DIFF else 0\n",
    "\n",
    "        # Взвешенная сумма\n",
    "        score = WEIGHT_PNL * norm_pnl + WEIGHT_DIFF * norm_diff\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_trial_number = trial.number\n",
    "            best_pnl = pnl\n",
    "            best_diff = diff\n",
    "            best_params = trial.params\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с двумя метриками (pnl и diff).\")\n",
    "\n",
    "    return best_score, best_trial_number, best_pnl, best_diff, best_params\n",
    "\n",
    "def find_best_trial_by_weighted_score_extended(\n",
    "    trials: List[FrozenTrial]\n",
    ") -> Tuple[float, int, Dict, str, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме метрик для двух стратегий:\n",
    "        - Стратегия RSI: pnl_rsi и diff_rsi\n",
    "        - Стратегия RSI+SMA/EMA: pnl_full и diff_full\n",
    "    \n",
    "    Возвращает:\n",
    "        - best_score: float - наивысший взвешенный скор среди всех стратегий\n",
    "        - best_trial_number: int - номер лучшего трейла\n",
    "        - best_params: dict - параметры лучшего трейла\n",
    "        - best_strategy: str - название лучшей стратегии ('RSI' или 'RSI_SMA_EMA')\n",
    "        - best_pnl: float - лучшее значение PnL (из выбранной стратегии)\n",
    "        - best_diff: float - лучшее значение diff (из выбранной стратегии)\n",
    "        - pnl_rsi: float - значение PnL для стратегии RSI\n",
    "        - diff_rsi: float - значение diff для стратегии RSI\n",
    "        - pnl_full: float - значение PnL для стратегии RSI+SMA/EMA\n",
    "        - diff_full: float - значение diff для стратегии RSI+SMA/EMA\n",
    "    \"\"\"\n",
    "    # Веса для метрик\n",
    "    WEIGHT_PNL = 0.80\n",
    "    WEIGHT_DIFF = 0.20\n",
    "    \n",
    "    # Максимальные значения для нормализации (можно настроить)\n",
    "    MAX_PNL = np.max([i.values for i in [trial for trial in study.trials if trial.values is not None]])  # предполагаемый максимум PnL\n",
    "    MAX_DIFF = 1    # максимум для diff (уже нормализован)\n",
    "    \n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_params = None\n",
    "    best_strategy = None\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    \n",
    "    # Для хранения всех метрик (для отладки/анализа)\n",
    "    full_results = []\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит все 4 метрики\n",
    "        if not trial.values or len(trial.values) < 4 and trial.values:\n",
    "            continue\n",
    "            \n",
    "        pnl_rsi, pnl_full, diff_rsi, diff_full = trial.values\n",
    "        \n",
    "        # Нормализация значений (защита от деления на 0)\n",
    "        norm_pnl_rsi = pnl_rsi / MAX_PNL if MAX_PNL != 0 else 0\n",
    "        norm_pnl_full = pnl_full / MAX_PNL if MAX_PNL != 0 else 0\n",
    "        norm_diff_rsi = diff_rsi / MAX_DIFF if MAX_DIFF != 0 else 0\n",
    "        norm_diff_full = diff_full / MAX_DIFF if MAX_DIFF != 0 else 0\n",
    "        \n",
    "        # Вычисляем скоринг для обеих стратегий\n",
    "        score_rsi = WEIGHT_PNL * norm_pnl_rsi + WEIGHT_DIFF * norm_diff_rsi\n",
    "        score_full = WEIGHT_PNL * norm_pnl_full + WEIGHT_DIFF * norm_diff_full\n",
    "        \n",
    "        # Определяем какая стратегия лучше в этом трейле\n",
    "        if score_rsi > score_full:\n",
    "            current_score = score_rsi\n",
    "            current_strategy = 'С трендовой линией'\n",
    "            current_pnl = pnl_rsi\n",
    "            current_diff = diff_rsi\n",
    "        else:\n",
    "            current_score = score_full\n",
    "            current_strategy = 'Трендовая + недельные скользящие'\n",
    "            current_pnl = pnl_full\n",
    "            current_diff = diff_full\n",
    "        \n",
    "        # Сохраняем все метрики для анализа\n",
    "        full_results.append({\n",
    "            'trial_number': trial.number,\n",
    "            'score_rsi': score_rsi,\n",
    "            'score_full': score_full,\n",
    "            'strategy': current_strategy,\n",
    "            'score': current_score,\n",
    "            'params': trial.params\n",
    "        })\n",
    "        \n",
    "        # Обновляем лучший результат\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_trial_number = trial.number\n",
    "            best_params = trial.params\n",
    "            best_strategy = current_strategy\n",
    "            best_pnl = current_pnl\n",
    "            best_diff = current_diff\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с четырьмя метриками (pnl_rsi, pnl_full, diff_rsi, diff_full).\")\n",
    "\n",
    "    return (\n",
    "        best_score,\n",
    "        best_trial_number,\n",
    "        best_params,\n",
    "        best_strategy,\n",
    "        best_pnl,\n",
    "        best_diff,\n",
    "        # Возвращаем также все метрики для лучшего трейла\n",
    "        #next(t.values[0] for t in trials if t.number == best_trial_number),  # pnl_rsi\n",
    "        #next(t.values[2] for t in trials if t.number == best_trial_number),  # diff_rsi\n",
    "        #next(t.values[1] for t in trials if t.number == best_trial_number),  # pnl_full\n",
    "        #next(t.values[3] for t in trials if t.number == best_trial_number)   # diff_full\n",
    "    )\n",
    "\n",
    "def find_best_trial_by_weighted_score_extended1(\n",
    "    trials: List[FrozenTrial],\n",
    "    pnl_score: float = 0.45,\n",
    "    diff_score: float = 0.45,\n",
    "    weight_score: float = 0.10\n",
    ") -> Tuple[float, int, Dict, str, float, float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Ищет лучший трейл по взвешенной сумме метрик для двух стратегий:\n",
    "        - Стратегия RSI: pnl_rsi, diff_rsi, score_rsi\n",
    "        - Стратегия RSI+SMA/EMA: pnl_full, diff_full, score_full\n",
    "    \n",
    "    Параметры:\n",
    "        - pnl_score: вес для метрики PnL (по умолчанию 0.45)\n",
    "        - diff_score: вес для метрики diff (по умолчанию 0.45)\n",
    "        - weight_score: вес для дополнительной метрики score (по умолчанию 0.10)\n",
    "    \n",
    "    Возвращает:\n",
    "        - best_score: float - наивысший взвешенный скор среди всех стратегий\n",
    "        - best_trial_number: int - номер лучшего трейла\n",
    "        - best_params: dict - параметры лучшего трейла\n",
    "        - best_strategy: str - название лучшей стратегии ('RSI' или 'RSI_SMA_EMA')\n",
    "        - best_pnl: float - лучшее значение PnL (из выбранной стратегии)\n",
    "        - best_diff: float - лучшее значение diff (из выбранной стратегии)\n",
    "        - best_score_n: float - лучшее значение score (из выбранной стратегии)\n",
    "        - pnl_rsi: float - значение PnL для стратегии RSI\n",
    "        - diff_rsi: float - значение diff для стратегии RSI\n",
    "        - pnl_full: float - значение PnL для стратегии RSI+SMA/EMA\n",
    "        - diff_full: float - значение diff для стратегии RSI+SMA/EMA\n",
    "        - score_rsi: float - значение score для стратегии RSI\n",
    "        - score_full: float - значение score для стратегии RSI+SMA/EMA\n",
    "    \"\"\"\n",
    "    # Проверка корректности весов\n",
    "    total_weight = pnl_score + diff_score + weight_score\n",
    "    if not np.isclose(total_weight, 1.0):\n",
    "        raise ValueError(f\"Сумма весов должна быть равна 1.0 (получено {total_weight})\")\n",
    "    \n",
    "    # Максимальные значения для нормализации\n",
    "    MAX_PNL = np.max([max(trial.values[0], trial.values[1]) for trial in trials if trial.values is not None]) * 2.5\n",
    "    MAX_DIFF = 1.0    # максимум для diff (уже нормализован)\n",
    "    MAX_SCORE = np.max([max(trial.values[2], trial.values[3]) for trial in trials if trial.values is not None]) if weight_score > 0 else 1.0\n",
    "    \n",
    "    best_score = float('-inf')\n",
    "    best_trial_number = -1\n",
    "    best_params = None\n",
    "    best_strategy = None\n",
    "    best_pnl = None\n",
    "    best_diff = None\n",
    "    best_score_n = None\n",
    "    \n",
    "    # Для хранения всех метрик (для отладки/анализа)\n",
    "    full_results = []\n",
    "\n",
    "    for trial in trials:\n",
    "        # Проверяем что трейл валидный и содержит все 6 метрик\n",
    "        if not trial.values or len(trial.values) < 6:\n",
    "            continue\n",
    "            \n",
    "        pnl_rsi, pnl_full, score_rsi, score_full, diff_rsi, diff_full = trial.values\n",
    "        \n",
    "        # Нормализация значений (защита от деления на 0)\n",
    "        norm_pnl_rsi = pnl_rsi / MAX_PNL if MAX_PNL != 0 else 0\n",
    "        norm_pnl_full = pnl_full / MAX_PNL if MAX_PNL != 0 else 0\n",
    "        norm_diff_rsi = diff_rsi / MAX_DIFF if MAX_DIFF != 0 else 0\n",
    "        norm_diff_full = diff_full / MAX_DIFF if MAX_DIFF != 0 else 0\n",
    "        norm_score_rsi = score_rsi / MAX_SCORE if MAX_SCORE != 0 and weight_score > 0 else 0\n",
    "        norm_score_full = score_full / MAX_SCORE if MAX_SCORE != 0 and weight_score > 0 else 0\n",
    "        \n",
    "        # Вычисляем скоринг для обеих стратегий\n",
    "        score_rsi_weighted = (pnl_score * norm_pnl_rsi + \n",
    "                             diff_score * norm_diff_rsi + \n",
    "                             weight_score * norm_score_rsi)\n",
    "        \n",
    "        score_full_weighted = (pnl_score * norm_pnl_full + \n",
    "                              diff_score * norm_diff_full + \n",
    "                              weight_score * norm_score_full)\n",
    "        \n",
    "        # Определяем какая стратегия лучше в этом трейле\n",
    "        if score_rsi_weighted > score_full_weighted:\n",
    "            current_score = score_rsi_weighted\n",
    "            current_strategy = 'С трендовой линией'\n",
    "            current_pnl = pnl_rsi\n",
    "            current_diff = diff_rsi\n",
    "            current_score_n = score_rsi\n",
    "        else:\n",
    "            current_score = score_full_weighted\n",
    "            current_strategy = 'Трендовая + недельные скользящие'\n",
    "            current_pnl = pnl_full\n",
    "            current_diff = diff_full\n",
    "            current_score_n = score_full\n",
    "        \n",
    "        # Сохраняем все метрики для анализа\n",
    "        full_results.append({\n",
    "            'trial_number': trial.number,\n",
    "            'score_rsi': score_rsi_weighted,\n",
    "            'score_full': score_full_weighted,\n",
    "            'strategy': current_strategy,\n",
    "            'score': current_score,\n",
    "            'params': trial.params\n",
    "        })\n",
    "        \n",
    "        # Обновляем лучший результат\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_trial_number = trial.number\n",
    "            best_params = trial.params\n",
    "            best_strategy = current_strategy\n",
    "            best_pnl = current_pnl\n",
    "            best_diff = current_diff\n",
    "            best_score_n = current_score_n\n",
    "\n",
    "    if best_trial_number == -1:\n",
    "        raise ValueError(\"Нет подходящих трейлов с шестью метриками (pnl_rsi, pnl_full, score_rsi, score_full, diff_rsi, diff_full).\")\n",
    "\n",
    "    # Получаем все метрики для лучшего трейла\n",
    "    best_trial = next(t for t in trials if t.number == best_trial_number)\n",
    "    pnl_rsi, pnl_full, score_rsi, score_full, diff_rsi, diff_full = best_trial.values\n",
    "\n",
    "    return (\n",
    "        best_score,\n",
    "        best_trial_number,\n",
    "        best_params,\n",
    "        best_strategy,\n",
    "        best_pnl,\n",
    "        best_diff,\n",
    "        best_score_n,\n",
    "        pnl_rsi,\n",
    "        diff_rsi,\n",
    "        score_rsi,\n",
    "        pnl_full,\n",
    "        diff_full,\n",
    "        score_full\n",
    "    )\n",
    "\n",
    "def plot_price_with_indicators_mplfinance(df, ticker, save_path=None):\n",
    "    \"\"\"\n",
    "    Отрисовывает график движения цены с индикаторами и сигналами покупки/продажи, используя mplfinance.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame с данными о цене и индикаторах.\n",
    "        ticker (str): Тикер акции для заголовка графика.\n",
    "        save_path (str, optional): Путь для сохранения графика. Если None, то график покажется.\n",
    "    \"\"\"\n",
    "    # Копируем DataFrame, чтобы не менять оригинал\n",
    "    df = df.copy()\n",
    "\n",
    "    # Преобразуем столбец time в datetime и делаем индексом\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df = df.set_index(\"time\")\n",
    "\n",
    "    # Создаем список дополнительных панелей для индикаторов (без объема)\n",
    "    apds = []\n",
    "\n",
    "    #if way!='Базовая' or way!=None:\n",
    "    # ====== RSI: цветовая заливка по условию ======\n",
    "    if \"rsi\" in df.columns:\n",
    "        rsi_above_50 = df[\"rsi\"].where(df[\"rsi\"] >= 50)\n",
    "        rsi_below_50 = df[\"rsi\"].where(df[\"rsi\"] < 50)\n",
    "\n",
    "        apds.append(mpf.make_addplot(rsi_above_50, color=\"green\", panel=2, ylabel=\"RSI\",ylim=(30, 70)))\n",
    "        apds.append(mpf.make_addplot(rsi_below_50, color=\"red\", panel=2,ylim=(30, 70)))\n",
    "\n",
    "    # ====== Скользящие средние и другие индикаторы ======\n",
    "    if \"SMA_20w\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"SMA_20w\"], color=\"green\", panel=0))\n",
    "    if \"EMA_21w\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"EMA_21w\"], color=\"red\", panel=0))\n",
    "\n",
    "\n",
    "    if \"pmax\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"pmax\"], color=\"red\", ylabel=\"PMAX\", panel=0))\n",
    "    if \"ma\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"ma\"], color=\"blue\", ylabel=\"VAR\", panel=0))\n",
    "    if \"var\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"var\"], color=\"blue\", ylabel=\"VAR\", panel=0))\n",
    "    if \"ema\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"ema\"], color=\"purple\", ylabel=\"EMA\", panel=0))\n",
    "    if \"adaptive_ma\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"adaptive_ma\"], color=\"blue\", ylabel=\"VAR\", panel=0))\n",
    "    if \"adaptive_pmax\" in df.columns:\n",
    "        apds.append(mpf.make_addplot(df[\"adaptive_pmax\"], color=\"purple\", ylabel=\"EMA\", panel=0))\n",
    "\n",
    "    if \"regime\" in df.columns:\n",
    "        # Генерация цветовой карты по количеству уникальных режимов\n",
    "        unique_regimes = sorted(df['regime'].unique())\n",
    "        colors = plt.cm.get_cmap('tab10', len(unique_regimes))\n",
    "        \n",
    "        for i, reg in enumerate(unique_regimes):\n",
    "            # Создаем линию на уровне 5% от минимума\n",
    "            reg_line = (df[\"low\"] * 1.05).where(df[\"regime\"] == reg)\n",
    "            apds.append(mpf.make_addplot(\n",
    "                reg_line,\n",
    "                type='line',\n",
    "                color=colors(i),\n",
    "                panel=0\n",
    "            ))\n",
    "\n",
    "    # Подготовка сигналов для отрисовки\n",
    "    buy_signals = df[df[\"buy_signal\"]]\n",
    "    sell_signals = df[df[\"sell_signal\"]]\n",
    "\n",
    "    # Создаем Series для сигналов, выровненные по индексу основного DataFrame\n",
    "    buy_series = pd.Series(index=df.index, dtype='float64')\n",
    "    buy_series[buy_signals.index] = buy_signals['open']\n",
    "\n",
    "    sell_series = pd.Series(index=df.index, dtype='float64')\n",
    "    sell_series[sell_signals.index] = sell_signals['open']\n",
    "\n",
    "    # Добавляем сигналы покупки\n",
    "    if not buy_signals.empty:\n",
    "        apds.append(mpf.make_addplot(\n",
    "            buy_series,\n",
    "            type='scatter',\n",
    "            markersize=50,\n",
    "            marker='^',\n",
    "            color='green',\n",
    "            label='Buy Signal',\n",
    "            panel=0\n",
    "        ))\n",
    "\n",
    "    # Добавляем сигналы продажи\n",
    "    if not sell_signals.empty:\n",
    "        apds.append(mpf.make_addplot(\n",
    "            sell_series,\n",
    "            type='scatter',\n",
    "            markersize=50,\n",
    "            marker='v',\n",
    "            color='red',\n",
    "            label='Sell Signal',\n",
    "            panel=0\n",
    "        ))\n",
    "\n",
    "    # Подготовка vlines (единый словарь)\n",
    "    vlines_dict = {}\n",
    "    if not buy_signals.empty:\n",
    "        vlines_dict['vlines'] = buy_signals.index.to_list()\n",
    "        vlines_dict['linewidths'] = 0.5\n",
    "        vlines_dict['colors'] = ['green'] * len(buy_signals)\n",
    "        vlines_dict['alpha'] = 0.5\n",
    "\n",
    "    if not sell_signals.empty:\n",
    "        if 'vlines' in vlines_dict:\n",
    "            vlines_dict['vlines'].extend(sell_signals.index.to_list())\n",
    "            vlines_dict['colors'].extend(['red'] * len(sell_signals))\n",
    "        else:\n",
    "            vlines_dict['vlines'] = sell_signals.index.to_list()\n",
    "            vlines_dict['linewidths'] = 0.5\n",
    "            vlines_dict['colors'] = ['red'] * len(sell_signals)\n",
    "            vlines_dict['alpha'] = 0.5\n",
    "\n",
    "    # Отрисовка графика с mplfinance\n",
    "    plot_kwargs = dict(\n",
    "        type=\"candle\",\n",
    "        style=\"yahoo\",\n",
    "        title=f\"График цены {ticker} с индикаторами\",\n",
    "        ylabel=\"Цена\",\n",
    "        addplot=apds,\n",
    "        show_nontrading=False,\n",
    "        figsize=(18, 10),\n",
    "        warn_too_much_data=len(df) + 1,\n",
    "    )\n",
    "\n",
    "    if \"volume\" in df.columns:\n",
    "        plot_kwargs[\"volume\"] = True\n",
    "        plot_kwargs[\"panel_ratios\"] = (6, 3)\n",
    "    if vlines_dict:\n",
    "        plot_kwargs[\"vlines\"] = vlines_dict\n",
    "\n",
    "    if save_path:\n",
    "        plot_kwargs[\"savefig\"] = save_path\n",
    "\n",
    "    mpf.plot(df, **plot_kwargs)\n",
    "    \n",
    "def plot_3d_metrics(trials, x_label='среднее значение f1', y_label='среднее значение AUC ROC', z_label='стандартное отклонение f1', deffs=None, directions=['максимизировать', 'максимизировать', 'минимизировать']):\n",
    "    \"\"\"\n",
    "    Функция для построения 3D-графика на основе результатов Optuna.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    trials : list\n",
    "        Список объектов `optuna.trial.FrozenTrial` из study.trials.\n",
    "    x_label : str, optional\n",
    "        Название для оси X (по умолчанию 'среднее значение f1').\n",
    "    y_label : str, optional\n",
    "        Название для оси Y (по умолчанию 'среднее значение AUC ROC').\n",
    "    z_label : str, optional\n",
    "        Название для оси Z (по умолчанию 'стандартное отклонение f1').\n",
    "    deffs : list, optional\n",
    "        Пороговые значения для фильтрации trials (по умолчанию None).\n",
    "    directions : list, optional\n",
    "        Направления оптимизации для каждой метрики (по умолчанию ['максимизировать', 'максимизировать', 'минимизировать']).\n",
    "    \"\"\"\n",
    "    print(len(trials))\n",
    "\n",
    "    # Сопоставление направлений с операторами сравнения\n",
    "    direction_to_operator = {\n",
    "        'максимизировать': lambda a, b: a > b,\n",
    "        'минимизировать': lambda a, b: a < b\n",
    "    }\n",
    "\n",
    "    # Фильтрация trials\n",
    "    if deffs is None:\n",
    "        trials = [trial for trial in trials if trial.values is not None]\n",
    "    else:\n",
    "        trials = [\n",
    "            trial for trial in trials\n",
    "            if trial.values is not None\n",
    "            and direction_to_operator[directions[0]](trial.values[0], deffs[0])\n",
    "            and direction_to_operator[directions[1]](trial.values[1], deffs[1])\n",
    "            and direction_to_operator[directions[2]](trial.values[2], deffs[2])\n",
    "        ]\n",
    "\n",
    "    print(len(trials))\n",
    "\n",
    "    # Извлечение значений метрик\n",
    "    x_vals = [trial.values[0] for trial in trials]\n",
    "    y_vals = [trial.values[1] for trial in trials]\n",
    "    z_vals = [trial.values[2] for trial in trials]\n",
    "\n",
    "    # Форматирование параметров для hover text\n",
    "    def format_params(params):\n",
    "        return '<br>'.join([f\"{key}: {value}\" for key, value in params.items()])\n",
    "\n",
    "    # Создание текста для hover\n",
    "    hover_texts = [\n",
    "        f\"Number: {trial.number}<br>\"\n",
    "        f\"{x_label}: {trial.values[0]:.4f}<br>\"\n",
    "        f\"{y_label}: {trial.values[1]:.4f}<br>\"\n",
    "        f\"{z_label}: {trial.values[2]:.4f}<br>\"\n",
    "        f\"Params:<br>{format_params(trial.params)}\"\n",
    "        for trial in trials\n",
    "    ]\n",
    "\n",
    "    # Создание 3D-графика\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x_vals, y=y_vals, z=z_vals,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=x_vals,  # Цветовая шкала может быть привязана к одной из метрик\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=hover_texts,  # Добавляем hover text\n",
    "        hoverinfo='text'   # Указываем, что при наведении нужно показывать текст\n",
    "    )])\n",
    "\n",
    "    # Добавление меток к осям\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=x_label,\n",
    "            yaxis_title=y_label,\n",
    "            zaxis_title=z_label\n",
    "        ),\n",
    "        title=\"3 метрики через Optuna\"\n",
    "    )\n",
    "\n",
    "    # Отображение графика\n",
    "    fig.show()\n",
    "\n",
    "import joblib\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TinkoffHistoricalDataCollector:\n",
    "    def __init__(self):\n",
    "        self.sma_state = {}\n",
    "\n",
    "    def generateVar(self, high_array, low_array, moving_average_length=10):\n",
    "        valpha = 2 / (moving_average_length + 1)\n",
    "        hl2 = (high_array + low_array) / 2\n",
    "\n",
    "        before_val = hl2[0] if len(hl2) > 0 else 0\n",
    "\n",
    "        vud1 = []\n",
    "        vdd1 = []\n",
    "        for current_hl2 in hl2:\n",
    "            if current_hl2 > before_val:\n",
    "                vud1.append(current_hl2 - before_val)\n",
    "                vdd1.append(0)\n",
    "            elif current_hl2 < before_val:\n",
    "                vdd1.append(before_val - current_hl2)\n",
    "                vud1.append(0)\n",
    "            else:\n",
    "                vud1.append(0)\n",
    "                vdd1.append(0)\n",
    "            before_val = current_hl2\n",
    "\n",
    "        def calculate_window_sums(arr, window_size=9):\n",
    "          return [sum(arr[max(0, i - window_size + 1):i+1]) for i in range(len(arr))]\n",
    "\n",
    "        vUD = calculate_window_sums(vud1, 9)\n",
    "        vDD = calculate_window_sums(vdd1, 9)\n",
    "\n",
    "        vUD_ar = np.array(vUD)\n",
    "        vDD_ar = np.array(vDD)\n",
    "\n",
    "        epsilon = 1e-10\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            vCMO = np.divide(vUD_ar - vDD_ar, vUD_ar + vDD_ar + epsilon)\n",
    "\n",
    "        vCMO = np.nan_to_num(vCMO, nan=0.0)\n",
    "\n",
    "        var = []\n",
    "        var_before = 0.0\n",
    "        for i in range(len(hl2)):\n",
    "            if i < len(vCMO):\n",
    "                cmo = abs(vCMO[i])\n",
    "                var_current = (valpha * cmo * hl2[i]) + (1 - valpha * cmo) * var_before\n",
    "            else:\n",
    "                var_current = var_before\n",
    "            var.append(var_current)\n",
    "            var_before = var_current\n",
    "\n",
    "        return np.array(var)\n",
    "\n",
    "    def generateAma(self, high_array, low_array, close_array, atr_period=14, min_period=5, max_period=50):\n",
    "        \"\"\"\n",
    "        Генерация адаптивного скользящего среднего на основе волатильности.\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param min_period: Минимальный период скользящего среднего.\n",
    "        :param max_period: Максимальный период скользящего среднего.\n",
    "        :return: Массив значений адаптивного скользящего среднего.\n",
    "        \"\"\"\n",
    "        # Рассчитываем ATR\n",
    "        atr = self._calculate_atr(high_array, low_array, close_array, atr_period)\n",
    "\n",
    "        # Нормализуем ATR для использования в качестве коэффициента\n",
    "        normalized_atr = (atr - np.min(atr)) / (np.max(atr) - np.min(atr) + 1e-10)\n",
    "\n",
    "        # Рассчитываем динамический период\n",
    "        dynamic_period = min_period + (max_period - min_period) * normalized_atr\n",
    "\n",
    "        # Рассчитываем адаптивное скользящее среднее (гибрид SMA и EMA)\n",
    "        adaptive_ma = np.zeros_like(close_array)\n",
    "        for i in range(len(close_array)):\n",
    "            if i < int(dynamic_period[i]):\n",
    "                adaptive_ma[i] = np.mean(close_array[:i+1])  # SMA для начальных значений\n",
    "            else:\n",
    "                period = int(dynamic_period[i])\n",
    "                alpha = 2 / (period + 1)\n",
    "                adaptive_ma[i] = alpha * close_array[i] + (1 - alpha) * adaptive_ma[i-1]  # EMA\n",
    "\n",
    "        return adaptive_ma\n",
    "\n",
    "    def _calculate_atr(self, high_array, low_array, close_array, period=14):\n",
    "        \"\"\"\n",
    "        Рассчитывает Average True Range (ATR).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param period: Период для расчета ATR.\n",
    "        :return: Массив значений ATR.\n",
    "        \"\"\"\n",
    "        tr = np.zeros_like(high_array)\n",
    "        tr[0] = high_array[0] - low_array[0]\n",
    "\n",
    "        for i in range(1, len(high_array)):\n",
    "            hl = high_array[i] - low_array[i]\n",
    "            hc = abs(high_array[i] - close_array[i-1])\n",
    "            lc = abs(low_array[i] - close_array[i-1])\n",
    "            tr[i] = max(hl, hc, lc)\n",
    "\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period-1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i-1] * (period-1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateAtr1(self, high_array, low_array, close_array, period=14):\n",
    "\n",
    "        # Рассчитываем True Range (TR)\n",
    "        tr1 = high_array - low_array\n",
    "        tr2 = np.abs(high_array - np.roll(close_array, 1))\n",
    "        tr3 = np.abs(low_array - np.roll(close_array, 1))\n",
    "\n",
    "        tr = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "\n",
    "        # Рассчитываем ATR\n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period - 1] = np.mean(tr[:period])\n",
    "\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i - 1] * (period - 1) + tr[i]) / period\n",
    "\n",
    "        return atr\n",
    "\n",
    "    def generateAtr(self, high_array, low_array, close_array, period=14):\n",
    "        \"\"\"\n",
    "        Улучшенный расчет ATR с обработкой случаев, когда данных меньше периода\n",
    "        \"\"\"\n",
    "        # Рассчитываем True Range (TR)\n",
    "        tr1 = high_array - low_array\n",
    "        tr2 = np.abs(high_array - np.roll(close_array, 1))\n",
    "        tr3 = np.abs(low_array - np.roll(close_array, 1))\n",
    "        \n",
    "        # Первый элемент TR2 и TR3 будет NaN (т.к. close[-1] не существует)\n",
    "        tr2[0] = tr1[0]\n",
    "        tr3[0] = tr1[0]\n",
    "        \n",
    "        tr = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "        \n",
    "        # Рассчитываем ATR с проверкой длины массива\n",
    "        atr = np.zeros_like(tr)\n",
    "        \n",
    "        # Если данных меньше периода, используем доступные данные\n",
    "        available_period = min(period, len(tr))\n",
    "        \n",
    "        if available_period > 0:\n",
    "            atr[available_period - 1] = np.mean(tr[:available_period])\n",
    "            \n",
    "            for i in range(available_period, len(tr)):\n",
    "                atr[i] = (atr[i - 1] * (period - 1) + tr[i]) / period\n",
    "        \n",
    "        return atr\n",
    "\n",
    "    def generateSma(self, high_array, low_array, window=10):\n",
    "        \"\"\"\n",
    "        Генерация Simple Moving Average (SMA).\n",
    "\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param window: Период SMA.\n",
    "        :return: Массив значений SMA.\n",
    "        \"\"\"\n",
    "        hl2 = (high_array + low_array) * 0.5\n",
    "\n",
    "        if window <= 1:\n",
    "            return hl2\n",
    "\n",
    "        # Создаем массив для результатов с NaN\n",
    "        sma = np.full_like(hl2, np.nan)\n",
    "\n",
    "        # Рассчитываем кумулятивную сумму\n",
    "        cumsum = np.cumsum(hl2)\n",
    "\n",
    "        # Создаем сдвинутый кумулятивный массив\n",
    "        shifted_cumsum = np.zeros_like(cumsum)\n",
    "        shifted_cumsum[window:] = cumsum[:-window]\n",
    "\n",
    "        # Вычисляем SMA для валидных периодов\n",
    "        valid = slice(window - 1, None)\n",
    "        sma[valid] = (cumsum[valid] - shifted_cumsum[valid]) / window\n",
    "\n",
    "        return sma\n",
    "    def generateEma(self, high_array, low_array, moving_average_length=14):\n",
    "        \"\"\"Вычисление EMA.\"\"\"\n",
    "        if len(high_array)==0 or len(low_array)==0:\n",
    "            return []\n",
    "\n",
    "        hl2 = [(high + low) / 2 for high, low in zip(high_array, low_array)]\n",
    "        ema = np.full_like(hl2, np.nan)\n",
    "        alpha = 2 / (moving_average_length + 1)\n",
    "\n",
    "        if moving_average_length <= 1:\n",
    "            return hl2\n",
    "\n",
    "        start_idx = moving_average_length - 1\n",
    "        sma = np.mean(hl2[:moving_average_length])\n",
    "        ema[start_idx] = sma\n",
    "\n",
    "        for i in range(start_idx + 1, len(hl2)):\n",
    "            ema[i] = alpha * hl2[i] + (1 - alpha) * ema[i - 1]\n",
    "\n",
    "        del hl2, alpha, start_idx, sma\n",
    "        return ema\n",
    "\n",
    "    def generatePMax(self, var_array, close_array, high_array, low_array, atr_period, atr_multiplier):\n",
    "        \"\"\"\n",
    "        Генерация PMax (Profit Maximizer).\n",
    "\n",
    "        :param var_array: Массив значений скользящего среднего.\n",
    "        :param close_array: Массив значений close.\n",
    "        :param high_array: Массив значений high.\n",
    "        :param low_array: Массив значений low.\n",
    "        :param atr_period: Период для расчета ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :return: Массив значений PMax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            atr = self.generateAtr(high_array, low_array, close_array, period=atr_period)\n",
    "        except Exception as exp:\n",
    "            print('exception in atr:', str(exp), flush=True)\n",
    "            return []\n",
    "\n",
    "        previous_final_upperband = 0\n",
    "        previous_final_lowerband = 0\n",
    "        final_upperband = 0\n",
    "        final_lowerband = 0\n",
    "        previous_var = 0\n",
    "        previous_pmax = 0\n",
    "        pmax = []\n",
    "        pmaxc = 0\n",
    "\n",
    "        for i in range(0, len(close_array)):\n",
    "            if np.isnan(close_array[i]):\n",
    "                pass\n",
    "            else:\n",
    "                atrc = atr[i]\n",
    "                varc = var_array[i]\n",
    "\n",
    "                if math.isnan(atrc):\n",
    "                    atrc = 0\n",
    "\n",
    "                basic_upperband = varc + atr_multiplier * atrc\n",
    "                basic_lowerband = varc - atr_multiplier * atrc\n",
    "\n",
    "                if basic_upperband < previous_final_upperband or previous_var > previous_final_upperband:\n",
    "                    final_upperband = basic_upperband\n",
    "                else:\n",
    "                    final_upperband = previous_final_upperband\n",
    "\n",
    "                if basic_lowerband > previous_final_lowerband or previous_var < previous_final_lowerband:\n",
    "                    final_lowerband = basic_lowerband\n",
    "                else:\n",
    "                    final_lowerband = previous_final_lowerband\n",
    "\n",
    "                if previous_pmax == previous_final_upperband and varc <= final_upperband:\n",
    "                    pmaxc = final_upperband\n",
    "                else:\n",
    "                    if previous_pmax == previous_final_upperband and varc >= final_upperband:\n",
    "                        pmaxc = final_lowerband\n",
    "                    else:\n",
    "                        if previous_pmax == previous_final_lowerband and varc >= final_lowerband:\n",
    "                            pmaxc = final_lowerband\n",
    "                        elif previous_pmax == previous_final_lowerband and varc <= final_lowerband:\n",
    "                            pmaxc = final_upperband\n",
    "\n",
    "                pmax.append(pmaxc)\n",
    "\n",
    "                previous_var = varc\n",
    "\n",
    "                previous_final_upperband = final_upperband\n",
    "\n",
    "                previous_final_lowerband = final_lowerband\n",
    "\n",
    "                previous_pmax = pmaxc\n",
    "\n",
    "        return pmax\n",
    "    def generate_signals(self, df, moving_average_length=10, atr_period=10, atr_multiplier=3, average_type='SMA',\n",
    "        ama_params=None):\n",
    "        \"\"\"\n",
    "        Генерация сигналов на основе SMA или AMA.\n",
    "        \n",
    "        asciidoc\n",
    "        \n",
    "        Copy\n",
    "        :param df: DataFrame с данными.\n",
    "        :param moving_average_length: Период скользящего среднего.\n",
    "        :param atr_period: Период ATR.\n",
    "        :param atr_multiplier: Множитель ATR.\n",
    "        :param average_type: Тип скользящего среднего ('SMA' или 'AMA').\n",
    "        :param ama_params: Параметры для AMA (если используется).\n",
    "        :return: DataFrame с добавленными сигналами.\n",
    "        \"\"\"\n",
    "        high_array = df[\"high\"].values\n",
    "        low_array = df[\"low\"].values\n",
    "        close_array = df[\"close\"].values\n",
    "        df = df.copy()\n",
    "        \n",
    "        if average_type == 'SMA':\n",
    "            ma_arr = self.generateSma(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'VAR':\n",
    "            ma_arr = self.generateVar(high_array, low_array, moving_average_length)\n",
    "        elif average_type == 'AMA':\n",
    "            if ama_params is None:\n",
    "                raise ValueError(\"Для AMA необходимо указать параметры ama_params.\")\n",
    "            ma_arr = self.generateAma(high_array, low_array, close_array, **ama_params)\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемый тип скользящего среднего.\")\n",
    "        \n",
    "        pmax = self.generatePMax(ma_arr, close_array, high_array, low_array, atr_period, atr_multiplier)\n",
    "        df[\"pmax\"] = pmax\n",
    "        df[\"ma\"] = ma_arr\n",
    "        df[\"buy_signal\"] = (df[\"ma\"] > df[\"pmax\"]) & (df[\"ma\"].shift(1) < df[\"pmax\"].shift(1))\n",
    "        df[\"sell_signal\"] = (df[\"ma\"] < df[\"pmax\"]) & (df[\"ma\"].shift(1) > df[\"pmax\"].shift(1))\n",
    "        \n",
    "        return df\n",
    "    def generate_signals_vectorized(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        regime_series: pd.Series,\n",
    "        regime_params: dict\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Полностью векторизованная реализация с оптимизированными расчетами:\n",
    "        - Использует cumsum для скользящих средних\n",
    "        - Применяет бинарные маски для режимов\n",
    "        - Минимизирует промежуточные вычисления\n",
    "        \"\"\"\n",
    "        # Подготовка данных\n",
    "        df = df.copy()\n",
    "        high = df['high'].values\n",
    "        low = df['low'].values\n",
    "        close = df['close'].values\n",
    "        regimes = regime_series.astype(int).values\n",
    "        \n",
    "        # Инициализация выходных массивов\n",
    "        ma_array = np.empty(len(df))\n",
    "        pmax_array = np.empty(len(df))\n",
    "        atr_array = np.empty(len(df))\n",
    "        \n",
    "        # Предварительные расчеты для всех возможных параметров\n",
    "        unique_regimes = np.unique(regimes)\n",
    "        cache = {}\n",
    "        \n",
    "        for regime in unique_regimes:\n",
    "            params = regime_params.get(regime, regime_params[0])\n",
    "            L = params['moving_average_length']\n",
    "            atr_period = params['atr_period']\n",
    "            \n",
    "            # Кешируем все необходимые расчеты\n",
    "            hl2 = (high + low) / 2\n",
    "            cache[regime] = {\n",
    "                'ma': self._vectorized_ma(close, high, low, params),\n",
    "                'atr': self._vectorized_atr(high, low, close, atr_period)\n",
    "            }\n",
    "        \n",
    "        # Векторизованный расчет по всем точкам\n",
    "        regime_mask = {r: (regimes == r) for r in unique_regimes}\n",
    "        \n",
    "        for r in unique_regimes:\n",
    "            mask = regime_mask[r]\n",
    "            params = regime_params[r]\n",
    "            \n",
    "            ma_array[mask] = cache[r]['ma'][mask]\n",
    "            atr_array[mask] = cache[r]['atr'][mask]\n",
    "            \n",
    "            # Векторизованный расчет PMax\n",
    "            basic_upper = ma_array[mask] + params['atr_multiplier'] * atr_array[mask]\n",
    "            basic_lower = ma_array[mask] - params['atr_multiplier'] * atr_array[mask]\n",
    "            \n",
    "            # Оптимизированный state machine для PMax\n",
    "            pmax_array[mask] = self._vectorized_pmax(\n",
    "                ma_array[mask], \n",
    "                basic_upper, \n",
    "                basic_lower,\n",
    "                initial_state=pmax_array[mask][0] if mask[0] else None\n",
    "            )\n",
    "        \n",
    "        # Формирование сигналов\n",
    "        df['ma'] = ma_array\n",
    "        df['pmax'] = pmax_array\n",
    "        df['atr'] = atr_array\n",
    "        \n",
    "        cross_up = (df['ma'] > df['pmax']) & (df['ma'].shift(1) <= df['pmax'].shift(1))\n",
    "        cross_down = (df['ma'] < df['pmax']) & (df['ma'].shift(1) >= df['pmax'].shift(1))\n",
    "        \n",
    "        df['buy_signal'] = cross_up\n",
    "        df['sell_signal'] = cross_down\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _vectorized_ma(self, close, high, low, params):\n",
    "        \"\"\"Векторизованный расчет скользящих средних\"\"\"\n",
    "        if params['average_type'] == 'SMA':\n",
    "            window = params['moving_average_length']\n",
    "            hl2 = (high + low) / 2\n",
    "            cumsum = np.cumsum(hl2)\n",
    "            return (cumsum[window:] - cumsum[:-window]) / window\n",
    "        \n",
    "        elif params['average_type'] == 'EMA':\n",
    "            alpha = 2 / (params['moving_average_length'] + 1)\n",
    "            ema = np.zeros_like(close)\n",
    "            ema[0] = close[0]\n",
    "            for i in range(1, len(close)):\n",
    "                ema[i] = alpha * close[i] + (1 - alpha) * ema[i-1]\n",
    "            return ema\n",
    "        \n",
    "        # Аналогично для других типов MA\n",
    "    \n",
    "    def _vectorized_atr(self, high, low, close, period):\n",
    "        \"\"\"Векторизованный расчет ATR\"\"\"\n",
    "        tr = np.maximum(high - low, \n",
    "                       np.maximum(np.abs(high - np.roll(close, 1)),\n",
    "                                 np.abs(low - np.roll(close, 1))))\n",
    "        tr[0] = high[0] - low[0]\n",
    "        \n",
    "        atr = np.zeros_like(tr)\n",
    "        atr[period-1] = np.mean(tr[:period])\n",
    "        \n",
    "        # Векторизованное обновление ATR\n",
    "        for i in range(period, len(tr)):\n",
    "            atr[i] = (atr[i-1] * (period - 1) + tr[i]) / period\n",
    "        \n",
    "        return atr\n",
    "    \n",
    "    def _vectorized_pmax(self, ma, upper, lower, initial_state=None):\n",
    "        \"\"\"Векторизованная реализация PMax\"\"\"\n",
    "        pmax = np.empty_like(ma)\n",
    "        state = initial_state if initial_state is not None else ma[0]\n",
    "        \n",
    "        for i in range(len(ma)):\n",
    "            if ma[i] > upper[i]:\n",
    "                state = upper[i]\n",
    "            elif ma[i] < lower[i]:\n",
    "                state = lower[i]\n",
    "            pmax[i] = state\n",
    "        \n",
    "        return pmax\n",
    "\n",
    "def calculate_target(df, threshold=3.0):\n",
    "    # Проверка необходимых колонок\n",
    "    required_columns = ['event_price', 'event_sell_price']\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Отсутствуют необходимые колонки: {missing_cols}\")\n",
    "\n",
    "    # Копируем DataFrame чтобы не менять оригинал\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Рассчитываем процентное изменение\n",
    "    result_df['price_change_pct'] = (\n",
    "        (result_df['event_sell_price'] / result_df['event_price'] - 1) * 100\n",
    "    )\n",
    "\n",
    "    # Создаем целевой признак\n",
    "    result_df['target'] = (result_df['price_change_pct'] >= threshold).astype(int)\n",
    "\n",
    "    # Обработка случаев с отсутствующими данными\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df[['event_price', 'event_sell_price']].notnull().all(axis=1),\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Обработка случаев с нулевой ценой покупки (если такие есть)\n",
    "    result_df['target'] = result_df['target'].where(\n",
    "        result_df['event_price'] != 0,\n",
    "        other=0\n",
    "    )\n",
    "\n",
    "    # Удаляем временную колонку\n",
    "    result_df.drop('price_change_pct', axis=1, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "class FastRollingMode:\n",
    "    def __init__(self, window_size):\n",
    "        self.window = deque(maxlen=window_size)\n",
    "        self.counts = {}\n",
    "        \n",
    "    def update(self, new_val):\n",
    "        if len(self.window) == self.window.maxlen:\n",
    "            old_val = self.window.popleft()\n",
    "            self.counts[old_val] -= 1\n",
    "            if self.counts[old_val] == 0:\n",
    "                del self.counts[old_val]\n",
    "        \n",
    "        self.window.append(new_val)\n",
    "        self.counts[new_val] = self.counts.get(new_val, 0) + 1\n",
    "        return max(self.counts.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "def extract_features(df: pd.DataFrame, window: int = 126):\n",
    "    \"\"\"\n",
    "    Вычисляет устойчивые признаки для кластеризации рыночных режимов.\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_macd(df, macd_fast_periods=[12], macd_slow_periods=[26], macd_signal_periods=[9]):\n",
    "        \"\"\"\n",
    "        Быстрый расчет нормализованного MACD с использованием векторизованных операций\n",
    "        \"\"\"\n",
    "        close = df['close']\n",
    "\n",
    "        # Создаем множества для уникальных периодов\n",
    "        unique_fast = set(macd_fast_periods)\n",
    "        unique_slow = set(macd_slow_periods)\n",
    "\n",
    "\n",
    "        # Предварительно вычисляем все необходимые EMA и скользящие средние\n",
    "        ema_cache = {}\n",
    "        rolling_cache = {}\n",
    "\n",
    "        # Кешируем быстрые EMA\n",
    "        for fp in unique_fast:\n",
    "            ema_cache[f'ema_{fp}'] = close.ewm(span=fp, adjust=False).mean()\n",
    "\n",
    "        # Кешируем медленные EMA и скользящие средние\n",
    "        for sp in unique_slow:\n",
    "            ema_cache[f'ema_{sp}'] = close.ewm(span=sp, adjust=False).mean()\n",
    "            rolling_cache[f'rolling_{sp}'] = close.rolling(window=sp).mean()\n",
    "\n",
    "        # Основной цикл вычислений\n",
    "        for fp in macd_fast_periods:\n",
    "            ema_fast = ema_cache[f'ema_{fp}']\n",
    "            for sp in macd_slow_periods:\n",
    "                ema_slow = ema_cache[f'ema_{sp}']\n",
    "                rolling_mean = rolling_cache[f'rolling_{sp}']\n",
    "\n",
    "                # Вычисляем MACD и нормализацию\n",
    "                macd = ema_fast - ema_slow\n",
    "                macd_norm = macd / rolling_mean\n",
    "\n",
    "                # Сохраняем MACD только один раз для комбинации fp/sp\n",
    "\n",
    "                # Обрабатываем сигнальные периоды\n",
    "                for sig in macd_signal_periods:\n",
    "                    # Вычисляем сигнальную линию\n",
    "                    signal = macd.ewm(span=sig, adjust=False).mean()\n",
    "                    signal_norm = signal / rolling_mean\n",
    "\n",
    "        return pd.DataFrame([macd_norm, signal_norm, macd_norm - signal_norm]).T.fillna(0)\n",
    "\n",
    "    def calculate_atr(df, atr_window=14):\n",
    "        \"\"\"\n",
    "        Расчет ATR и его сдвигов.\n",
    "        \"\"\"\n",
    "        high = df['high']\n",
    "        low = df['low']\n",
    "        close = df['close']\n",
    "    \n",
    "        tr1 = high - low\n",
    "        tr2 = np.abs(high - close.shift(1))\n",
    "        tr3 = np.abs(low - close.shift(1))\n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        atr = tr.rolling(atr_window).mean()\n",
    "    \n",
    "        return pd.Series(atr).fillna(0)\n",
    "    \n",
    "    def calculate_rsi(df, rsi_period=14):\n",
    "        \"\"\"\n",
    "        Расчет RSI и его сдвиги.\n",
    "        \"\"\"\n",
    "        close = df['close']\n",
    "        delta = close.diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "        avg_gain = gain.rolling(rsi_period).mean()\n",
    "        avg_loss = loss.rolling(rsi_period).mean()\n",
    "        rs = avg_gain / (avg_loss + 1e-10)\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        return pd.Series(rsi).fillna(0)\n",
    "    \n",
    "    def calculate_bollinger_bands(df, bollinger_window=20):\n",
    "        \"\"\"\n",
    "        Расчет Bollinger Bands (ширины полос) и сдвигов.\n",
    "        \"\"\"\n",
    "        close = df['close']\n",
    "        ma = close.rolling(bollinger_window).mean()\n",
    "        std = close.rolling(bollinger_window).std()\n",
    "        bb_width = (2 * std) / ma\n",
    "    \n",
    "        return pd.Series(bb_width).fillna(0)\n",
    "    \n",
    "    def detect_market_regime(df: pd.DataFrame, window: int = 30, n_clusters: int = 3) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Классифицирует рыночную фазу на основе кластеризации признаков: волатильность, автокорреляция, наклон тренда.\n",
    "        Возвращает метку режима рынка для каждого окна.\n",
    "        \"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "    \n",
    "        features = []\n",
    "    \n",
    "        for i in range(len(df) - window + 1):\n",
    "            window_df = df.iloc[i:i+window]\n",
    "            close = window_df['close'].values\n",
    "    \n",
    "            # Волатильность (стандартное отклонение)\n",
    "            volatility = np.std(np.diff(close))\n",
    "    \n",
    "            # Наклон тренда (регрессия по времени)\n",
    "            x = np.arange(window)\n",
    "            y = close\n",
    "            slope = np.polyfit(x, y, deg=1)[0]\n",
    "    \n",
    "            # Автокорреляция лаг-1\n",
    "            autocorr = np.corrcoef(close[:-1], close[1:])[0, 1]\n",
    "    \n",
    "            features.append([volatility, slope, autocorr])\n",
    "    \n",
    "        features = np.array(features)\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "        labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "        # Расширим метки до длины df\n",
    "        regime_series = pd.Series(np.nan, index=df.index)\n",
    "        regime_series.iloc[window - 1:] = labels\n",
    "    \n",
    "        return regime_series.fillna(0).ffill().astype(int)\n",
    "    macd_trend = calculate_macd(df, macd_slow_periods=[window], macd_fast_periods=[window//3], \n",
    "                                 macd_signal_periods=[window//6])\n",
    "    atr = calculate_atr(df, atr_window=window)\n",
    "    rel_volatility = atr / df[\"close\"]\n",
    "    rsi_ind = calculate_rsi(df, rsi_period=window//2)\n",
    "    volume_ratio = df['volume'].rolling(window).apply(\n",
    "        lambda x: x[-1]/x.mean(), raw=True\n",
    "    ).fillna(1).values\n",
    "\n",
    "    features = np.column_stack([\n",
    "        macd_trend,\n",
    "        rel_volatility,\n",
    "        rsi_ind,\n",
    "        volume_ratio\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def fast_generate_var(high: np.ndarray,\n",
    "                      low:  np.ndarray,\n",
    "                      L:    int = 10,\n",
    "                      W:    int = 9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized generation of your VAR (CMO‐smoothed) series.\n",
    "    \"\"\"\n",
    "    α0 = 2.0 / (L + 1.0)\n",
    "    hl2 = (high + low) * 0.5\n",
    "\n",
    "    # 1) first diffs\n",
    "    diff = np.empty_like(hl2)\n",
    "    diff[0] = 0.0\n",
    "    diff[1:] = hl2[1:] - hl2[:-1]\n",
    "\n",
    "    # 2) up/down\n",
    "    up = np.where(diff > 0, diff, 0.0)\n",
    "    dn = np.where(diff < 0, -diff, 0.0)\n",
    "\n",
    "    # 3) W‐period sums via convolution\n",
    "    kernel = np.ones(W, dtype=np.float64)\n",
    "    sum_up = np.convolve(up, kernel, mode=\"full\")[: len(up)]\n",
    "    sum_dn = np.convolve(dn, kernel, mode=\"full\")[: len(dn)]\n",
    "\n",
    "    # 4) CMO\n",
    "    denom = sum_up + sum_dn + 1e-10\n",
    "    cmo   = np.abs((sum_up - sum_dn) / denom)\n",
    "\n",
    "    # 5) final EMA‐like smoothing\n",
    "    var = np.empty_like(hl2)\n",
    "    var[0] = 0.0\n",
    "    for i in range(1, len(hl2)):\n",
    "        α      = α0 * cmo[i]\n",
    "        var[i] = α * hl2[i] + (1 - α) * var[i - 1]\n",
    "\n",
    "    return var\n",
    "\n",
    "\n",
    "class AdaptiveTradingSystem:\n",
    "    def __init__(self, regime_params: Dict[int, dict]):\n",
    "        self.regime_params = regime_params\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    def generate_adaptive_signals(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        regime_series: pd.Series\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        df      = df.reset_index(drop=True)\n",
    "        regimes = regime_series.reset_index(drop=True).astype(int).values\n",
    "        n       = len(df)\n",
    "        high    = df['high'].values\n",
    "        low     = df['low'].values\n",
    "        close   = df['close'].values\n",
    "\n",
    "        # 0) создаём «коллектор» – единая точка доступа ко всем MA/ATR\n",
    "        collector = TinkoffHistoricalDataCollector()\n",
    "\n",
    "        # ────────────────────────────── 1. PRECOMPUTE  ────────────\n",
    "        ma_cache:  Dict[int, np.ndarray] = {}\n",
    "        atr_cache: Dict[int, np.ndarray] = {}\n",
    "\n",
    "        for regime, p in self.regime_params.items():\n",
    "            atype = p['average_type']\n",
    "            L     = p['moving_average_length']\n",
    "            P     = p['atr_period']\n",
    "\n",
    "            # ---- MA ------------------------------------------------\n",
    "            if atype == 'SMA':\n",
    "                # готовая реализация из collector\n",
    "                ma = collector.generateSma(high, low, window=L)\n",
    "\n",
    "            elif atype == 'VAR':\n",
    "                ma = collector.generateVar(high, low, moving_average_length=L)\n",
    "\n",
    "            elif atype == 'EMA':\n",
    "                ma = collector.generateEma(high, low, moving_average_length=L)\n",
    "\n",
    "            elif atype == 'AMA':\n",
    "                ama_pars = p.get('ama_params',                   # защита от None\n",
    "                                 {'atr_period': 14,\n",
    "                                  'min_period': 5,\n",
    "                                  'max_period': 50})\n",
    "                ma = collector.generateAma(\n",
    "                    high, low, close,\n",
    "                    atr_period=ama_pars['atr_period'],\n",
    "                    min_period=ama_pars['min_period'],\n",
    "                    max_period=ama_pars['max_period']\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown MA type {atype!r}\")\n",
    "\n",
    "            ma_cache[regime] = ma\n",
    "\n",
    "            # ---- ATR ----------------------------------------------\n",
    "            atr_cache[regime] = collector.generateAtr(\n",
    "                high, low, close, period=P\n",
    "            )\n",
    "\n",
    "        # ────────────────────────────── 2. МЭРДЖ ПО РЕЖИМАМ ───────\n",
    "        var_all = np.empty(n, dtype=np.float64)\n",
    "        atr_all = np.empty(n, dtype=np.float64)\n",
    "        mul_all = np.empty(n, dtype=np.float64)\n",
    "\n",
    "        for regime, p in self.regime_params.items():\n",
    "            mask          = (regimes == regime)\n",
    "            var_all[mask] = ma_cache[regime][mask]\n",
    "            atr_all[mask] = atr_cache[regime][mask]\n",
    "            mul_all[mask] = p['atr_multiplier']\n",
    "\n",
    "        # Заполняем возможные NaN в начале серии MA одной первой валидной точкой\n",
    "        if np.isnan(var_all[0]):\n",
    "            first_valid = var_all[~np.isnan(var_all)][0]\n",
    "            var_all[np.isnan(var_all)] = first_valid\n",
    "\n",
    "        # ────────────────────────────── 3. PMax STATE MACHINE ─────\n",
    "        pmax_all = np.empty(n, dtype=np.float64)\n",
    "\n",
    "        prev_var = var_all[0]\n",
    "        prev_atr = atr_all[0]\n",
    "        prev_mul = mul_all[0]\n",
    "\n",
    "        prev_fu = prev_var + prev_mul * prev_atr\n",
    "        prev_fl = prev_var - prev_mul * prev_atr\n",
    "        prev_p  = prev_fl                                # стартовое состояние\n",
    "        pmax_all[0] = prev_p\n",
    "\n",
    "        for i in range(1, n):\n",
    "            v   = var_all[i]\n",
    "            a   = atr_all[i]\n",
    "            m   = mul_all[i]\n",
    "\n",
    "            bu  = v + m * a\n",
    "            bl  = v - m * a\n",
    "\n",
    "            fu = bu if (bu < prev_fu or prev_var > prev_fu) else prev_fu\n",
    "            fl = bl if (bl > prev_fl or prev_var < prev_fl) else prev_fl\n",
    "\n",
    "            if prev_p == prev_fu:\n",
    "                p = fu if v <= fu else fl\n",
    "            else:  # prev_p == prev_fl\n",
    "                p = fl if v >= fl else fu\n",
    "\n",
    "            pmax_all[i] = p\n",
    "\n",
    "            prev_var, prev_fu, prev_fl, prev_p = v, fu, fl, p\n",
    "\n",
    "        # ────────────────────────────── 4. СИГНАЛЫ ────────────────\n",
    "        v_prev = np.concatenate(([var_all[0]], var_all[:-1]))\n",
    "        p_prev = np.concatenate(([pmax_all[0]], pmax_all[:-1]))\n",
    "\n",
    "        buy  = (v_prev < p_prev) & (var_all > pmax_all)\n",
    "        sell = (v_prev > p_prev) & (var_all < pmax_all)\n",
    "\n",
    "        # ────────────────────────────── 5. ВЫХОДНОЙ DataFrame ──────\n",
    "        out = df.copy()\n",
    "        out['adaptive_ma']   = var_all\n",
    "        out['adaptive_pmax'] = pmax_all\n",
    "        out['buy_signal']    = buy\n",
    "        out['sell_signal']   = sell\n",
    "        out['regime']        = regimes\n",
    "\n",
    "        return out\n",
    "\n",
    "def prepare_regime_params(optuna_params):\n",
    "    \"\"\"\n",
    "    Преобразует параметры из формата Optuna в формат для generate_signals_with_regime_v8\n",
    "    с поддержкой AMA во всех режимах.\n",
    "    \n",
    "    Args:\n",
    "        optuna_params (dict): Словарь с параметрами из Optuna\n",
    "        \n",
    "    Returns:\n",
    "        dict: Словарь с параметрами в нужном формате\n",
    "    \"\"\"\n",
    "    #base_params = {}\n",
    "    regime_params = {}\n",
    "    \n",
    "\n",
    "    #base_params['threshold_atr_factor'] = optuna_params['threshold_atr_factor']\n",
    "    #base_params['smoothing_alpha'] = optuna_params['smoothing_alpha']\n",
    "    #base_params['min_atr_period'] = optuna_params['min_atr_period']\n",
    "    \n",
    "    for regime in range(5):  # Режимы от 0 до 4\n",
    "        regime_key = f'regime_{regime}_'\n",
    "        average_type = optuna_params.get(f'{regime_key}average_type', 'SMA')\n",
    "        \n",
    "        # Базовые параметры для всех типов скользящих средних\n",
    "        regime_params[regime] = {\n",
    "            'average_type': average_type,\n",
    "            'moving_average_length': optuna_params.get(f'{regime_key}ma_length', 50),\n",
    "            'atr_period': optuna_params.get(f'{regime_key}atr_period', 14),\n",
    "            'atr_multiplier': optuna_params.get(f'{regime_key}atr_multiplier', 3.0)\n",
    "        }\n",
    "        \n",
    "        # Дополнительные параметры для AMA\n",
    "        if average_type == 'AMA':\n",
    "            regime_params[regime]['ama_params'] = {\n",
    "                'atr_period': int(optuna_params.get(f'{regime_key}ama_atr_period', 10)),\n",
    "                'min_period': int(optuna_params.get(f'{regime_key}ama_min_period', 5)),\n",
    "                'max_period': int(optuna_params.get(f'{regime_key}ama_max_period', 50))\n",
    "            }\n",
    "    \n",
    "    return regime_params\n",
    "    \n",
    "new_params['real'] = np.nan\n",
    "        \n",
    "#ticker = 'KZIZP'\n",
    "phase_df = pd.read_parquet('phase_modded.pq')\n",
    "\n",
    "for ticker in tqdm(phase_df.index):\n",
    "\n",
    "    path = r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\test_files_15_2'\n",
    "    file_name = [i for i in os.listdir(r'C:\\Users\\aleksandrovva1\\Desktop\\data science\\0-trade\\t\\test_files_15_2') if ticker == i.split('_')[0]][0]\n",
    "    db_path = f\"sqlite:///C:/Users/aleksandrovva1/Desktop/data science/0-trade/t/tickers_params_3/{ticker}.db\"\n",
    "    study_phase = optuna.create_study(study_name=f'Поиск параметров для Pmax_{ticker}', directions=['maximize', 'maximize', 'maximize'], storage=db_path, load_if_exists=True)\n",
    "    df_phase = pd.read_parquet(os.path.join(path, file_name))\n",
    "    window = int(phase_df['params'][ticker]['moving_average_length']*9.5)\n",
    "    features = extract_features(df_phase, window=window)\n",
    "    scaled = joblib.load(\"scaler_global.pkl\").transform(features)\n",
    "    labels = joblib.load(\"kmeans_global.pkl\").predict(scaled)\n",
    "    trial_n = find_best_trial_by_weighted_three_score(study_phase.trials)[1]\n",
    "\n",
    "    #trial_n = new_params[new_params.index==ticker][0].values[0]\n",
    "    \n",
    "    regime_series = pd.Series(labels, index=df_phase.index)\n",
    "    window_size = int(phase_df['params'][ticker]['atr_period']*5.5)\n",
    "    \n",
    "    smoother = FastRollingMode(window_size=window_size)\n",
    "    smoothed = [smoother.update(x) for x in labels]\n",
    "    smoothed_regime = pd.Series(smoothed, index=df_phase.index)\n",
    "    \n",
    "    regime_params = prepare_regime_params(study_phase.trials[trial_n].params)\n",
    "    \n",
    "    CV = AdaptiveTradingSystem(regime_params)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_phase = CV.generate_adaptive_signals(df_phase, regime_series=smoothed_regime)\n",
    "    \n",
    "    buy_signals = df_phase[df_phase['buy_signal']]\n",
    "    sell_signals = df_phase[df_phase['sell_signal']]\n",
    "    for _, buy in buy_signals.iterrows():\n",
    "        sell = sell_signals[sell_signals.time > buy.time].head(1)\n",
    "        if not sell.empty:\n",
    "            df_phase.loc[buy.name, \"event_time\"] = buy.time\n",
    "            df_phase.loc[buy.name, \"event_price\"] = buy.close\n",
    "            df_phase.loc[buy.name, \"event_sell_time\"] = sell.time.values[0]\n",
    "            df_phase.loc[buy.name, \"event_sell_price\"] = sell.close.values[0]\n",
    "    \n",
    "    df_phase['pnl'] = ((df_phase['event_sell_price'] * (1 - 0.003)) / (df_phase['event_price'] * (1 + 0.003)) - 1) * 100\n",
    "    df_phase = calculate_target(df_phase, threshold=1.9)\n",
    "    \n",
    "    real_sum = np.sum(df_phase[df_phase['buy_signal']==True].pnl)\n",
    "    new_params.at[ticker, 'real'] =real_sum\n",
    "    #print(ticker, study_phase.trials[trial_n].values[0],real_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e27fdef-aa97-470d-b4cd-02cae6d45017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>real</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOMP</th>\n",
       "      <td>588</td>\n",
       "      <td>602.47642</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>654.557396</td>\n",
       "      <td>52.080975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1         2    3  \\\n",
       "NOMP  588  602.47642  0.666667  9.0   \n",
       "\n",
       "                                                      4        real       diff  \n",
       "NOMP  {'regime_0_average_type': 'VAR', 'regime_0_ma_...  654.557396  52.080975  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params[new_params.index=='NOMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b241ff52-4f6c-440b-a6f9-b7e46b74e16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaIAAAMtCAYAAABtqwbJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9v0lEQVR4nO3de5DV9Xn48edQjrise8ELco8gF8XE1cSEpEI1KkmLtHRtZifRRB3IFZI26djUCUmrLZEh7VgziemkxcYkjm0B2WIDrUZqMpCkcRITSKRFjdeuVdzqusuKsITz+8Ph/ETQcJQnu+fL6zXjzJ7P+ZyzH2aePYNvv363VKlUKgEAAAAAAEmGDfYBAAAAAAAoNiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAECq4YN9gFdy6aWXxn//939XHzc2NsamTZtizpw50d/fP4gngyPHXFNE5pqiMdMUkbmmiMw1RWSuKSJzXSynnXZa3HrrrYe1t1SpVCrJ53lN3vzmN8dPfvKT6uOmpqbo7e2N5ubm6OvrG8STwZFjrikic03RmGmKyFxTROaaIjLXFJG5Lpazzz477r333sPa69YcAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASDV8sA8AAAAAAEXwWPu8wT5CXXj8kovjvovmDPYxjqhJnRsG+whDniuiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmG17L5l7/8ZaxevTo2bdoUPT09MWrUqDj//PPjkksuiWHDXmzalUolVq9eHRs3boydO3fGtGnTYtGiRTFx4sSUPwAAAAAAAENbTSF63bp18e1vfzuWLFkSEyZMiIceeii+8pWvxMiRI2PevHnVPevXr4/FixfH2LFjY+3atbFs2bK44YYboqGhIeUPAQAAAADA0FXTrTnuv//+OOecc+LNb35zjB49Ot7+9rfHmWeeGb/4xS8i4sWroTds2BDt7e0xa9asmDRpUixZsiR2794dmzdvTvkDAAAAAAAwtNV0RfRpp50W3/72t+OJJ56IcePGxSOPPBLbt2+PK664IiIiduzYET09PdHW1lZ9TblcjpkzZ8b27dtj7ty5B73nwMBADAwMVB+XSqVoaGiIxsbGaGpqqq7v//qla1DvzDVFZK4pGjNNEZlrishcU0TmGurH0fpz2tjYeNh7awrRCxYsiOeffz4+9alPxbBhw2Lfvn3x3ve+N2bPnh0RET09PRER0dLScsDrWlpaoru7+5Dv2dnZGWvWrKk+njx5cqxYsSI2bdp0yP1dXV21HBnqgrmmiMw1RWOmKSJzTRGZa4rIXNePxy+5eLCPwCDp7e0d7CMMeTWF6O9///uxadOm+MM//MOYOHFiPPLII3HzzTdXf2nhfqVS6YDXVSqVV3zP9vb2mD9//kGvnTNnTmzZsqW63tTUFF1dXTF+/Pjo6+ur5dgwZJlrishcUzRmmiIy1xSRuaaIzHX9ue+iOYN9BAZJc3PzYB9hULS1tb3iBcUvV1OIvuWWW2LBggVx7rnnRkTEpEmT4umnn45/+Zd/ifPPPz9aW1sj4sUro0eNGlV9XW9v70FXSe9XLpejXC4ftN7f33/ID9m+vj4fvhSOuaaIzDVFY6YpInNNEZlrishcw9B3tP6M9vf3H/bemn5Z4e7du2PYsANfMmzYsOoVz6NHj47W1tbYunVr9fm9e/fGtm3bYsaMGbV8KwAAAAAACqKmK6Lf8pa3xNq1a+PEE0+MCRMmxCOPPBLf+ta34p3vfGdEvHhbjXnz5kVnZ2eMHTs2xowZE52dnTFixIjqfaQBAAAAADi61BSiFy5cGP/8z/8cK1eujOeeey6OP/74mDt3brznPe+p7lmwYEHs2bMnVq5cGf39/TF16tRYunRpNDQ0HPHDAwAAAAAw9NUUohsaGuLKK6+MK6+88hX3lEql6OjoiI6Ojtd7NgAAAAAACqCme0QDAAAAAECthGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABINbyWzUuWLImnn376oPV3vetd8cEPfjAqlUqsXr06Nm7cGDt37oxp06bFokWLYuLEiUfswAAAAAAA1JeaQvTy5ctj37591cePPfZYLFu2LN7xjndERMS6deti/fr1sXjx4hg7dmysXbs2li1bFjfccEM0NDQc2ZMDAAAAAFAXaro1R3Nzc7S2tlb/uffee+Pkk0+OmTNnRqVSiQ0bNkR7e3vMmjUrJk2aFEuWLIndu3fH5s2bs84PAAAAAMAQV9MV0S+1d+/e2LRpU1x88cVRKpXiqaeeip6enmhra6vuKZfLMXPmzNi+fXvMnTv3kO8zMDAQAwMD1celUikaGhqisbExmpqaquv7v37pGtQ7c00RmWuKxkxTROaaIjLXFJG5hvpxtP6cNjY2Hvbe1xyi77nnnujv74/zzz8/IiJ6enoiIqKlpeWAfS0tLdHd3f2K79PZ2Rlr1qypPp48eXKsWLEiNm3adMj9XV1dr/XIMGSZa4rIXFM0ZpoiMtcUkbmmiMx1/Xj8kosH+wgMkt7e3sE+wpD3mkP03XffHWeddVYcf/zxB6yXSqUDHlcqlVd9n/b29pg/f/5Br58zZ05s2bKlut7U1BRdXV0xfvz46Ovre63HhiHFXFNE5pqiMdMUkbmmiMw1RWSu6899F80Z7CMwSJqbmwf7CIOira3tFS8ofrnXFKKffvrp2Lp1a1x11VXVtdbW1oh48croUaNGVdd7e3sPukr6pcrlcpTL5YPW+/v7D/kh29fX58OXwjHXFJG5pmjMNEVkrikic00RmWsY+o7Wn9H+/v7D3lvTLyvc7+67746WlpZ485vfXF0bPXp0tLa2xtatW6tre/fujW3btsWMGTNey7cBAAAAAKAAar4iet++ffGd73wnzjvvvPiN3/iN6nqpVIp58+ZFZ2dnjB07NsaMGROdnZ0xYsSImD179hE9NAAAAAAA9aPmEP2zn/0suru7453vfOdBzy1YsCD27NkTK1eujP7+/pg6dWosXbo0GhoajshhAQAAAACoPzWH6La2tli1atUhnyuVStHR0REdHR2v+2AAAAAAABTDa7pHNAAAAAAAHC4hGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBpe6wueeeaZuOWWW+KnP/1p7NmzJ8aOHRsf+9jHYsqUKRERUalUYvXq1bFx48bYuXNnTJs2LRYtWhQTJ0484ocHAAAAAGDoqylE79y5Mz73uc/FGWecEZ/5zGeiubk5nnrqqRg5cmR1z7p162L9+vWxePHiGDt2bKxduzaWLVsWN9xwQzQ0NBzxPwAAAAAAAENbTSF63bp1ccIJJ8TixYura6NHj65+XalUYsOGDdHe3h6zZs2KiIglS5bEhz70odi8eXPMnTv3oPccGBiIgYGB6uNSqRQNDQ3R2NgYTU1N1fX9X790DeqduaaIzDVFY6YpInNNEZlrishcQ/04Wn9OGxsbD3tvTSH6Rz/6UbS1tcX1118f27Zti+OPPz7e9a53xUUXXRQRETt27Iienp5oa2urvqZcLsfMmTNj+/bthwzRnZ2dsWbNmurjyZMnx4oVK2LTpk2HPENXV1ctR4a6YK4pInNN0ZhpishcU0TmmiIy1/Xj8UsuHuwjMEh6e3sH+whDXk0heseOHfHtb387Lr744mhvb48HH3wwvva1r0W5XI7zzjsvenp6IiKipaXlgNe1tLREd3f3Id+zvb095s+fX31cKpUiImLOnDmxZcuW6npTU1N0dXXF+PHjo6+vr5Zjw5Blrikic03RmGmKyFxTROaaIjLX9ee+i+YM9hEYJM3NzYN9hEHR1tb2ihcUv1xNIXrfvn1x6qmnxqWXXhoRL169/Pjjj8edd94Z5513XnXf/pi8X6VSecX3LJfLUS6XD1rv7+8/5IdsX1+fD18Kx1xTROaaojHTFJG5pojMNUVkrmHoO1p/Rvv7+w9777Ba3njUqFExYcKEA9YmTJhQvdq5tbU1IqJ6ZfR+vb29B10lDQAAAADA0aGmED1jxox44oknDlh74okn4qSTToqIF39xYWtra2zdurX6/N69e2Pbtm0xY8aMI3BcAAAAAADqTU0h+uKLL44HHngg1q5dG08++WRs3rw5Nm7cGO9+97sj4sVbcsybNy86OzvjnnvuicceeyxuvPHGGDFiRMyePTvlDwAAAAAAwNBW0z2ip06dGldddVXceuutcdttt8Xo0aPjiiuuiDlz/v+N2BcsWBB79uyJlStXRn9/f0ydOjWWLl0aDQ0NR/zwAAAAAAAMfTWF6IiIt7zlLfGWt7zlFZ8vlUrR0dERHR0dr+tgAAAAAAAUQ0235gAAAAAAgFoJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBqeC2bV61aFWvWrDlgraWlJf7+7/8+IiIqlUqsXr06Nm7cGDt37oxp06bFokWLYuLEiUfuxAAAAAAA1JWaQnRExMSJE+Nzn/tc9fGwYf//oup169bF+vXrY/HixTF27NhYu3ZtLFu2LG644YZoaGg4MicGAAAAAKCu1HxrjmHDhkVra2v1n+bm5oh48WroDRs2RHt7e8yaNSsmTZoUS5Ysid27d8fmzZuP+MEBAAAAAKgPNV8R/eSTT8ZHPvKRGD58eEybNi3e9773xcknnxw7duyInp6eaGtrq+4tl8sxc+bM2L59e8ydO/eQ7zcwMBADAwPVx6VSKRoaGqKxsTGampqq6/u/fuka1DtzTRGZa4rGTFNE5poiMtcUkbmG+nG0/pw2NjYe9t6aQvS0adNiyZIlMW7cuOjp6Ym1a9fGZz/72bj++uujp6cnIl68Z/RLtbS0RHd39yu+Z2dn5wH3nZ48eXKsWLEiNm3adMj9XV1dtRwZ6oK5pojMNUVjpikic00RmWuKyFzXj8cvuXiwj8Ag6e3tHewjDHk1heizzz67+vWkSZNi+vTp8YlPfCK++93vxrRp0yLixSuaX6pSqbzqe7a3t8f8+fOrj/e/fs6cObFly5bqelNTU3R1dcX48eOjr6+vlmPDkGWuKSJzTdGYaYrIXFNE5poiMtf1576L5gz2ERgk+29ffLRpa2t7xQuKX67mW3O81LHHHhuTJk2K//3f/423vvWtERHR09MTo0aNqu7p7e096CrplyqXy1Eulw9a7+/vP+SHbF9fnw9fCsdcU0TmmqIx0xSRuaaIzDVFZK5h6Dtaf0b7+/sPe2/Nv6zwpQYGBqKrqytGjRoVo0ePjtbW1ti6dWv1+b1798a2bdtixowZr+fbAAAAAABQx2q6Ivob3/hGnHPOOXHiiSfGc889F7fddlvs2rUrzjvvvCiVSjFv3rzo7OyMsWPHxpgxY6KzszNGjBgRs2fPzjo/AAAAAABDXE0h+plnnokvfvGL0dvbG83NzTFt2rT4/Oc/HyeddFJERCxYsCD27NkTK1eujP7+/pg6dWosXbo0GhoaUg4PAAAAAMDQV1OI/uQnP/mqz5dKpejo6IiOjo7XcyYAAAAAAArkdd0jGgAAAAAAfhUhGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFINfz0v7uzsjH/8x3+MefPmxZVXXhkREZVKJVavXh0bN26MnTt3xrRp02LRokUxceLEI3FeAAAAAADqzGu+IvrBBx+Mu+66K97whjccsL5u3bpYv359LFy4MJYvXx6tra2xbNmy2LVr1+s+LAAAAAAA9ec1hegXXnghvvSlL8VHPvKRaGxsrK5XKpXYsGFDtLe3x6xZs2LSpEmxZMmS2L17d2zevPmIHRoAAAAAgPrxmm7NsXLlyjj77LPjzDPPjLVr11bXd+zYET09PdHW1lZdK5fLMXPmzNi+fXvMnTv3oPcaGBiIgYGB6uNSqRQNDQ3R2NgYTU1N1fX9X790DeqduaaIzDVFY6YpInNNEZlrishcQ/04Wn9OX3qR8q9Sc4j+3ve+Fw8//HAsX778oOd6enoiIqKlpeWA9ZaWluju7j7k+3V2dsaaNWuqjydPnhwrVqyITZs2HXJ/V1dXrUeGIc9cU0TmmqIx0xSRuaaIzDVFZK7rx+OXXDzYR2CQ9Pb2DvYRhryaQnR3d3fcfPPNsXTp0jjmmGNecV+pVDrgcaVSecW97e3tMX/+/INeO2fOnNiyZUt1vampKbq6umL8+PHR19dXy7FhyDLXFJG5pmjMNEVkrikic00Rmev6c99Fcwb7CAyS5ubmwT7CoGhra3vFC4pfrqYQ/dBDD8Vzzz0XV199dXVt37598V//9V/x7//+73HDDTdExItXRo8aNaq6p7e396CrpPcrl8tRLpcPWu/v7z/kh2xfX58PXwrHXFNE5pqiMdMUkbmmiMw1RWSuYeg7Wn9G+/v7D3tvTSH6TW96U/z1X//1AWt/+7d/G+PGjYsFCxbEySefHK2trbF169aYPHlyRETs3bs3tm3bFpdddlkt3woAAAAAgIKoKUQ3NDTEpEmTDlgbMWJENDU1VdfnzZsXnZ2dMXbs2BgzZkx0dnbGiBEjYvbs2Ufu1AAAAAAA1I2af1nhr7JgwYLYs2dPrFy5Mvr7+2Pq1KmxdOnSaGhoONLfCgAAAACAOvC6Q/Q111xzwONSqRQdHR3R0dHxet8aAAAAAIACGDbYBwAAAAAAoNiEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkGp4LZvvvPPOuPPOO+Ppp5+OiIgJEybEe97znjj77LMjIqJSqcTq1atj48aNsXPnzpg2bVosWrQoJk6ceORPDgAAAABAXajpiujjjz8+Lr300li+fHksX7483vjGN8YXvvCFePzxxyMiYt26dbF+/fpYuHBhLF++PFpbW2PZsmWxa9eulMMDAAAAADD01XRF9DnnnHPA4/e9731x5513xgMPPBATJkyIDRs2RHt7e8yaNSsiIpYsWRIf+tCHYvPmzTF37txDvufAwEAMDAxUH5dKpWhoaIjGxsZoamqqru//+qVrUO/MNUVkrikaM00RmWuKyFxTROYa6sfR+nPa2Nh42HtrCtEvtW/fvvjBD34Qu3fvjunTp8eOHTuip6cn2traqnvK5XLMnDkztm/f/oohurOzM9asWVN9PHny5FixYkVs2rTpkPu7urpe65FhyDLXFJG5pmjMNEVkrikic00Rmev68fglFw/2ERgkvb29g32EIa/mEP3YY4/F0qVLY2BgII499ti46qqrYsKECbF9+/aIiGhpaTlgf0tLS3R3d7/i+7W3t8f8+fOrj0ulUkREzJkzJ7Zs2VJdb2pqiq6urhg/fnz09fXVemwYksw1RWSuKRozTRGZa4rIXFNE5rr+3HfRnME+AoOkubl5sI8wKNra2l7xguKXqzlEjxs3Lv7qr/4q+vv744c//GHceOONce2111af3x+S96tUKq/6fuVyOcrl8kHr/f39h/yQ7evr8+FL4ZhrishcUzRmmiIy1xSRuaaIzDUMfUfrz2h/f/9h7605RA8fPjzGjBkTERGnnnpq/OIXv4gNGzbEggULIiKip6cnRo0aVd3f29t70FXSAAAAAAAcPYa93jeoVCoxMDAQo0ePjtbW1ti6dWv1ub1798a2bdtixowZr/fbAAAAAABQp2q6IvrWW2+Ns88+O0444YR44YUX4nvf+17cd999sXTp0iiVSjFv3rzo7OyMsWPHxpgxY6KzszNGjBgRs2fPzjo/AAAAAABDXE0h+rnnnosvf/nL8eyzz8bIkSPjDW94QyxdujTOPPPMiIhYsGBB7NmzJ1auXBn9/f0xderUWLp0aTQ0NKQcHgAAAACAoa+mEP2xj33sVZ8vlUrR0dERHR0dr+tQAAAAAAAUx+u+RzQAAAAAALwaIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSDa9lc2dnZ9xzzz3R1dUVxxxzTEyfPj3e//73x7hx46p7KpVKrF69OjZu3Bg7d+6MadOmxaJFi2LixIlH/PAAAAAAAAx9NV0RvW3btnj3u98dn//85+Ozn/1s7Nu3L5YtWxYvvPBCdc+6deti/fr1sXDhwli+fHm0trbGsmXLYteuXUf88AAAAAAADH01heilS5fG+eefHxMnToxTTjklFi9eHN3d3fHQQw9FxItXQ2/YsCHa29tj1qxZMWnSpFiyZEns3r07Nm/enPIHAAAAAABgaKvp1hwv9/zzz0dExHHHHRcRETt27Iienp5oa2ur7imXyzFz5szYvn17zJ0796D3GBgYiIGBgerjUqkUDQ0N0djYGE1NTdX1/V+/dA3qnbmmiMw1RWOmKSJzTRGZa4rIXEP9OFp/ThsbGw9772sO0ZVKJb7+9a/HaaedFpMmTYqIiJ6enoiIaGlpOWBvS0tLdHd3H/J9Ojs7Y82aNdXHkydPjhUrVsSmTZsOub+rq+u1HhmGLHNNEZlrisZMU0TmmiIy1xSRua4fj19y8WAfgUHS29s72EcY8l5ziL7pppvisccei7/4i7846LlSqXTA40ql8orv097eHvPnzz/otXPmzIktW7ZU15uamqKrqyvGjx8ffX19r/XYMKSYa4rIXFM0ZpoiMtcUkbmmiMx1/bnvojmDfQQGSXNz82AfYVC0tbW94gXFL/eaQvQ//MM/xI9//OO49tpr44QTTqiut7a2RsSLV0aPGjWqut7b23vQVdL7lcvlKJfLB6339/cf8kO2r6/Phy+FY64pInNN0ZhpishcU0TmmiIy1zD0Ha0/o/39/Ye9t6ZfVlipVOKmm26KH/7wh/Fnf/ZnMXr06AOeHz16dLS2tsbWrVura3v37o1t27bFjBkzavlWAAAAAAAURE1XRN90002xefPm+PSnPx0NDQ3Ve0KPHDkyjjnmmCiVSjFv3rzo7OyMsWPHxpgxY6KzszNGjBgRs2fPzjg/AAAAAABDXE0h+s4774yIiGuuueaA9cWLF8f5558fERELFiyIPXv2xMqVK6O/vz+mTp0aS5cujYaGhiNyYAAAAAAA6ktNIXrVqlW/ck+pVIqOjo7o6Oh4zYcCAAAAAKA4arpHNAAAAAAA1EqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFTDa33Btm3b4vbbb4+HH344nn322bjqqqvibW97W/X5SqUSq1evjo0bN8bOnTtj2rRpsWjRopg4ceIRPTgAAAAAAPWh5iuid+/eHaecckosXLjwkM+vW7cu1q9fHwsXLozly5dHa2trLFu2LHbt2vW6DwsAAAAAQP2pOUSfffbZ8d73vjdmzZp10HOVSiU2bNgQ7e3tMWvWrJg0aVIsWbIkdu/eHZs3bz4iBwYAAAAAoL7UfGuOV7Njx47o6emJtra26lq5XI6ZM2fG9u3bY+7cuQe9ZmBgIAYGBqqPS6VSNDQ0RGNjYzQ1NVXX93/90jWod+aaIjLXFI2ZpojMNUVkrikicw3142j9OW1sbDzsvUc0RPf09EREREtLywHrLS0t0d3dfcjXdHZ2xpo1a6qPJ0+eHCtWrIhNmzYdcn9XV9eROSwMIeaaIjLXFI2ZpojMNUVkrikic10/Hr/k4sE+AoOkt7d3sI8w5B3REL1fqVQ64HGlUnnFve3t7TF//vyDXjtnzpzYsmVLdb2pqSm6urpi/Pjx0dfXd4RPDIPDXFNE5pqiMdMUkbmmiMw1RWSu6899F80Z7CMwSJqbmwf7CIOira3tFS8ofrkjGqJbW1sj4sUro0eNGlVd7+3tPegq6f3K5XKUy+WD1vv7+w/5IdvX1+fDl8Ix1xSRuaZozDRFZK4pInNNEZlrGPqO1p/R/v7+w95b8y8rfDWjR4+O1tbW2Lp1a3Vt7969sW3btpgxY8aR/FYAAAAAANSJmq+IfuGFF+LJJ5+sPt6xY0c88sgjcdxxx8WJJ54Y8+bNi87Ozhg7dmyMGTMmOjs7Y8SIETF79uwjenAAAAAAAOpDzSH6F7/4RVx77bXVx9/4xjciIuK8886LJUuWxIIFC2LPnj2xcuXK6O/vj6lTp8bSpUujoaHhyJ0aAAAAAIC6UXOIPuOMM2LVqlWv+HypVIqOjo7o6Oh4XQcDAAAAAKAYjug9ogEAAAAA4OWEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQCohGgAAAACAVEI0AAAAAACphGgAAAAAAFIJ0QAAAAAApBKiAQAAAABIJUQDAAAAAJBKiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUQjQAAAAAAKmEaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQSogGAAAAACCVEA0AAAAAQKrhg30AAACAonusfd5gH+Go8PglF8d9F80Z7GMcYFLnhsE+AgAMCa6IBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKQSogEAAAAASCVEAwAAAACQavhgH4CDPdY+b7CPwK/R45dcHPddNCciIiZ1bhjk0wAAAEeSf7/j9XrpvzMC1DNXRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRpv6zwjjvuiNtvvz16enpiwoQJceWVV8bpp5+e9e0AAAAAABiiUq6I/v73vx8333xzXHLJJbFixYo4/fTT47rrrovu7u6MbwcAAAAAwBCWckX0t771rbjgggviwgsvjIiIK6+8MrZs2RJ33nlnXHrppQfsHRgYiIGBgerjUqkUDQ0NcfbZZ0djY2N1feTIkRER8Y53vCOef/75jGMPGeUppw72ERgks2fPHuwjwOt2NH1ec3Qw0xSRuf7183d8ACi2o7XpTJ8+/bD3liqVSuVIfvO9e/fG+9///vjjP/7jeNvb3lZd/9rXvhaPPPJIXHvttQfsX7VqVaxZs6b6+Nxzz40/+qM/OpJHAgAAAABgEB3xW3P09vbGvn37oqWl5YD1lpaW6OnpOWh/e3t73HzzzdV/PvShDx1whfR+u3btij/90z+NXbt2Hekjw6Ax1xSRuaZozDRFZK4pInNNEZlrishcH73SfllhqVQ6rLVyuRzlcvlXvl+lUomHH344jvAF3DCozDVFZK4pGjNNEZlrishcU0TmmiIy10evI35FdHNzcwwbNuygq5+fe+65g66SBgAAAACg+I54iB4+fHhMmTIltm7desD61q1bY8aMGUf62wEAAAAAMMSl3Jpj/vz58aUvfSmmTJkS06dPj7vuuiu6u7tj7ty5r/k9y+VyvOc97zms23hAvTDXFJG5pmjMNEVkrikic00RmWuKyFwfvUqVpBuy3HHHHXH77bfHs88+GxMnTowrrrgiZs6cmfGtAAAAAAAYwtJCNAAAAAAARCTcIxoAAAAAAF5KiAYAAAAAIJUQDQAAAABAKiEaAAAAAIBUwwf7AL/KfffdF9dee+0hn7vuuuti6tSpERHR3d0dK1eujPvuuy+OOeaYOPfcc+Pyyy+P4cOH/B+Ro9i9994ba9asiUcffTSOPfbYOP300+Oqq66qPm+uqSdLliyJp59++oC1BQsWxGWXXVZ9bKapVwMDA/GZz3wmHn300fjCF74Qp5xySvU5c029WbFiRTzyyCPR29sbjY2N8aY3vSkuu+yyOP7446t7zDX1ZMeOHXHbbbfFz3/+8+jp6Ynjjz8+5syZE5dccskBM2uuqTdr166Ne++9Nx555JEYPnx43HzzzQftMdfUmzvuuCNuv/326OnpiQkTJsSVV14Zp59++mAfi1+TIf/JNGPGjPi7v/u7A9b+6Z/+KX72s5/FqaeeGhER+/bti+XLl0dzc3P8xV/8RfT19cWNN94YERELFy78tZ8ZDsd//ud/xle/+tV43/veF2984xsjIuKxxx6rPm+uqUcdHR1x0UUXVR8fe+yx1a/NNPXslltuieOPPz4effTRA9bNNfXojDPOiPb29hg1alQ888wz8c1vfjOuv/76WLZsWUSYa+rPE088EZVKJT784Q/HmDFj4vHHH4+vfvWr8cILL8Tll18eEeaa+rR37954+9vfHtOnT4//+I//OOh5c029+f73vx8333xzfPCDH4wZM2bEXXfdFdddd138zd/8TZx44omDfTx+DYb8rTmGDx8era2t1X+OO+64+PGPfxzvfOc7o1QqRUTEli1b4n/+53/iE5/4REyePDnOPPPMuPzyy2Pjxo3x/PPPD/KfAA72y1/+Mm6++eb4wAc+EO9617ti3LhxMW7cuHj7299e3WOuqUcNDQ0HfGa/NESbaerVT37yk9i6dWt84AMfOOg5c009mj9/fkyfPj1OOumkmDFjRvz+7/9+PPDAA7F3796IMNfUn7POOisWL14cbW1tcfLJJ8c555wTv/u7vxv33HNPdY+5ph51dHTE/PnzY9KkSYd83lxTb771rW/FBRdcEBdeeGH1augTTzwx7rzzzsE+Gr8mQz5Ev9yPfvSj6O3tjfPPP7+6dv/998ekSZMO+N8J29raYmBgIB566KFBOCW8uocffjieeeaZKJVK8elPfzo+/OEPx3XXXRePP/54dY+5ph6tW7cuFi5cGH/yJ38Sa9eurUaNCDNNferp6YmvfvWr8fGPfzyOOeaYg54319S7nTt3xqZNm2L69OnV/43bXFMEzz//fBx33HHVx+aaIjLX1JO9e/fGQw89FG1tbQesn3nmmbF9+/ZBOhW/bkP+1hwvd/fdd8dZZ511wCX7PT090dLScsC+4447LoYPHx49PT2/5hPCr/bUU09FRMTq1avj8ssvj9GjR8e//uu/xjXXXBNf/OIX47jjjjPX1J3f+Z3fiSlTpkRjY2M8+OCDceutt8aOHTviox/9aET4rKb+VCqV+MpXvhJz586NU089NXbs2HHQHnNNvbrlllvijjvuiN27d8e0adPi6quvrj5nrql3Tz75ZPzbv/1b9bYcEeaaYjLX1JPe3t7Yt2/fQTPb0tJiXo8igxaiV61aFWvWrHnVPcuXL6/eBzoi4v/+7//ipz/9aXzqU586aO/+23S8VKVSOeQ6ZDncua5UKhERcckll1Rvx7F48eL46Ec/Gj/4wQ9i7ty5EWGuGXy1fFbPnz+/uvaGN7whGhsb4/rrr4/LLrssmpqaIsJMMzQc7lxv3749du3aFe3t7a+611wzFNT6d+vf+73fiwsuuCC6u7tj9erV8eUvfzmuvvrq6tyaa4aC1/LvjM8880xcd9118Y53vCMuvPDCA/aaa4aC1zLXr8ZcU28ONZvm9egxaCH6t3/7t+Pcc8991T0nnXTSAY/vvvvuaGpqinPOOeeA9dbW1njwwQcPWNu5c2f88pe/POi/tECmw53rXbt2RUTEhAkTquvlcjlOPvnk6O7ujghzzdDwWj6r95s+fXpEvHhVUlNTk5lmyDjcub7tttvi/vvvj0svvfSA566++uqYPXt2fPzjHzfXDBm1fl43NzdHc3NzjBs3LsaPHx8f+9jH4oEHHojp06eba4aMWuf6mWeeiWuvvTamT58eH/7whw/YZ64ZKl7P369fzlxTT5qbm2PYsGEHXf383HPPmdejyKCF6P1/+T1clUolvvOd78Rv/dZvVe9ft9/06dNj7dq18eyzz8aoUaMiImLr1q1RLpdjypQpR/Tc8GoOd66nTJkS5XI5nnjiiTjttNMi4sX7JT399NPVv3SYa4aCWj+rX+rhhx+OiKjOr5lmqDjcuV64cGG8973vrT5+9tln4/Of/3x88pOfjGnTpkWEuWboeD2f1/v/T62BgYGIMNcMHbXM9f4IPXny5Fi8eHEMG3bgr0My1wwVr+fz+uXMNfVk+PDhMWXKlNi6dWu87W1vq65v3bo13vrWtw7iyfh1qpt7RP/85z+PHTt2xAUXXHDQc21tbTFhwoT48pe/HO9///tj586d8c1vfjMuvPDCGDly5CCcFl7dyJEjY+7cubFq1ao44YQT4qSTTorbb789IqJ6qw5zTT25//774/777483vvGNMXLkyHjwwQfj61//epxzzjnVe/qbaerNS38fRUTEscceGxERY8aMiRNOOCEizDX158EHH4wHH3wwTjvttGhsbIynnnoqVq1aFSeffHL1/2Qx19SbZ555Jq655po48cQT4/LLL4/e3t7qc62trRFhrqlP3d3dsXPnzuju7o59+/bFI488EhEv/l3k2GOPNdfUnfnz58eXvvSlmDJlSkyfPj3uuuuu6O7urt6elOIrVfZfAjHEffGLX4zu7u74y7/8y0M+393dHStXroyf//znccwxx8Ts2bPjAx/4QJTL5V/zSeHw7N27N2699dbYtGlT7NmzJ6ZOnRpXXnllTJw4sbrHXFMvHnroobjpppuiq6srBgYG4qSTTorf/M3fjAULFsSIESOq+8w09WzHjh3x8Y9/PL7whS/EKaecUl0319STxx57LL72ta/Fo48+Grt3747W1tY466yz4g/+4A/i+OOPr+4z19ST73znO/GVr3zlkM+tWrWq+rW5pt7ceOON8d3vfveg9T//8z+PM844IyLMNfXnjjvuiNtvvz2effbZmDhxYlxxxRUxc+bMwT4WvyZ1E6IBAAAAAKhPw371FgAAAAAAeO2EaAAAAAAAUgnRAAAAAACkEqIBAAAAAEglRAMAAAAAkEqIBgAAAAAglRANAAAAAEAqIRoAAAAAgFRCNAAAAAAAqYRoAAAAAABSCdEAAAAAAKT6f+r48TOcvtYOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_params['real']-new_params[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81c66605-9bd6-4009-9fc2-de24ff101837",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params['diff'] = new_params[1] - new_params['real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "79066a65-3973-456d-a40b-4e0ad40501a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>real</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSRG</th>\n",
       "      <td>2467</td>\n",
       "      <td>113.897901</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>31.0</td>\n",
       "      <td>{'regime_0_average_type': 'AMA', 'regime_0_ma_...</td>\n",
       "      <td>116.831686</td>\n",
       "      <td>-2.933786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSNGP</th>\n",
       "      <td>746</td>\n",
       "      <td>82.208377</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>17.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "      <td>84.695726</td>\n",
       "      <td>-2.487349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YDEX</th>\n",
       "      <td>3840</td>\n",
       "      <td>122.448277</td>\n",
       "      <td>0.35</td>\n",
       "      <td>60.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>122.641037</td>\n",
       "      <td>-0.19276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGKBP</th>\n",
       "      <td>2580</td>\n",
       "      <td>160.82616</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "      <td>155.240511</td>\n",
       "      <td>5.585649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHMK</th>\n",
       "      <td>1521</td>\n",
       "      <td>213.316304</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>200.188313</td>\n",
       "      <td>13.127991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1         2     3  \\\n",
       "LSRG   2467  113.897901  0.387097  31.0   \n",
       "LSNGP   746   82.208377  0.411765  17.0   \n",
       "YDEX   3840  122.448277      0.35  60.0   \n",
       "TGKBP  2580   160.82616       0.4  25.0   \n",
       "CHMK   1521  213.316304      0.75   8.0   \n",
       "\n",
       "                                                       4        real  \\\n",
       "LSRG   {'regime_0_average_type': 'AMA', 'regime_0_ma_...  116.831686   \n",
       "LSNGP  {'regime_0_average_type': 'SMA', 'regime_0_ma_...   84.695726   \n",
       "YDEX   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  122.641037   \n",
       "TGKBP  {'regime_0_average_type': 'SMA', 'regime_0_ma_...  155.240511   \n",
       "CHMK   {'regime_0_average_type': 'VAR', 'regime_0_ma_...  200.188313   \n",
       "\n",
       "            diff  \n",
       "LSRG   -2.933786  \n",
       "LSNGP  -2.487349  \n",
       "YDEX    -0.19276  \n",
       "TGKBP   5.585649  \n",
       "CHMK   13.127991  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params[new_params['diff']!=0].sort_values('diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40bf2124-ab0c-4e26-87fc-1a6a3469837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4174434087882823"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(new_params[2]*new_params[3])/np.sum(new_params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f84bdbf3-8215-48a5-a370-cbad493f3047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOMP', 'KZIZP', 'UWGN', 'UNAC', 'MGTSP', 'CNRU', 'TGKB', 'MSTT',\n",
       "       'GTRK', 'MTLR', 'X5', 'RBCM', 'MRKP', 'UPRO', 'FLOT', 'TTLK', 'CNTLP',\n",
       "       'LNZLP', 'NVTK', 'IRKT', 'RAGR', 'MGNT', 'UGLD', 'MRKU', 'PMSB', 'ETLN',\n",
       "       'FRHC', 'AFLT', 'BANE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params[new_params['diff']!=0].sort_values('diff').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "beace393-8c52-4215-9827-50a407b5f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params.to_parquet('regime_params_2.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "353a74cc-b85c-48c8-a3b6-8a63c49dd14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>real</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABRD</th>\n",
       "      <td>2971</td>\n",
       "      <td>83.197592</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFKS</th>\n",
       "      <td>3467</td>\n",
       "      <td>134.278352</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>27.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFLT</th>\n",
       "      <td>140</td>\n",
       "      <td>119.051721</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>26.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANE</th>\n",
       "      <td>753</td>\n",
       "      <td>160.507665</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>28.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANEP</th>\n",
       "      <td>2072</td>\n",
       "      <td>169.904539</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>37.0</td>\n",
       "      <td>{'regime_0_average_type': 'SMA', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UWGN</th>\n",
       "      <td>1736</td>\n",
       "      <td>397.445092</td>\n",
       "      <td>0.45</td>\n",
       "      <td>40.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VKCO</th>\n",
       "      <td>2157</td>\n",
       "      <td>118.124234</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRSB</th>\n",
       "      <td>3144</td>\n",
       "      <td>500.897024</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>37.0</td>\n",
       "      <td>{'regime_0_average_type': 'AMA', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>3927</td>\n",
       "      <td>165.720057</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>46.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YDEX</th>\n",
       "      <td>3840</td>\n",
       "      <td>122.448277</td>\n",
       "      <td>0.35</td>\n",
       "      <td>60.0</td>\n",
       "      <td>{'regime_0_average_type': 'VAR', 'regime_0_ma_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1         2     3  \\\n",
       "ABRD   2971   83.197592  0.371429  35.0   \n",
       "AFKS   3467  134.278352  0.444444  27.0   \n",
       "AFLT    140  119.051721  0.615385  26.0   \n",
       "BANE    753  160.507665  0.392857  28.0   \n",
       "BANEP  2072  169.904539  0.513514  37.0   \n",
       "...     ...         ...       ...   ...   \n",
       "UWGN   1736  397.445092      0.45  40.0   \n",
       "VKCO   2157  118.124234       0.4  50.0   \n",
       "VRSB   3144  500.897024   0.27027  37.0   \n",
       "X5     3927  165.720057  0.456522  46.0   \n",
       "YDEX   3840  122.448277      0.35  60.0   \n",
       "\n",
       "                                                       4  real     diff  \n",
       "ABRD   {'regime_0_average_type': 'VAR', 'regime_0_ma_...   NaN      0.0  \n",
       "AFKS   {'regime_0_average_type': 'SMA', 'regime_0_ma_...   NaN      0.0  \n",
       "AFLT   {'regime_0_average_type': 'VAR', 'regime_0_ma_...   NaN      0.0  \n",
       "BANE   {'regime_0_average_type': 'SMA', 'regime_0_ma_...   NaN      0.0  \n",
       "BANEP  {'regime_0_average_type': 'SMA', 'regime_0_ma_...   NaN      0.0  \n",
       "...                                                  ...   ...      ...  \n",
       "UWGN   {'regime_0_average_type': 'VAR', 'regime_0_ma_...   NaN      0.0  \n",
       "VKCO   {'regime_0_average_type': 'VAR', 'regime_0_ma_...   NaN      0.0  \n",
       "VRSB   {'regime_0_average_type': 'AMA', 'regime_0_ma_...   NaN      0.0  \n",
       "X5     {'regime_0_average_type': 'VAR', 'regime_0_ma_...   NaN      0.0  \n",
       "YDEX   {'regime_0_average_type': 'VAR', 'regime_0_ma_...   NaN  0.19276  \n",
       "\n",
       "[89 rows x 7 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f14ecb00-c0e5-4819-8d93-752010c87870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4597027806342647"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31f98f-1e73-41f1-a8fb-6a9ec00ea29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
